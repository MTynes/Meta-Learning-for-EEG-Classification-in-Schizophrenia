{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of LeNet_with_raw_EEG_data_2020_02_02 - input transformed, low acc.ipynb","provenance":[{"file_id":"1ZTLszdvf67kp9fpYI7k4RPIde4bHyLwD","timestamp":1580646207164},{"file_id":"1PPExaff_m8WcOW8jDGmM4OWZ92Iqab9r","timestamp":1580639120778},{"file_id":"1e9IEENxc5UEz5rRNCrGRIn7oMLnb4Shu","timestamp":1580306273314}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"X_ZRvtEVHxY2","outputId":"7c918bfe-ede7-4f10-ffb0-73efd3768643","executionInfo":{"status":"ok","timestamp":1580639746693,"user_tz":-60,"elapsed":8966,"user":{"displayName":"Maritza Tynes","photoUrl":"","userId":"02324384993274756811"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["import os\n","raw_data_dir = ''\n","\n","if  'COLAB_GPU' in os.environ:\n","    print('Using Google Colab. Setting up environment')\n","    raw_data_dir = '/content/drive/My Drive/Colab Notebooks/' \n","    !pip install mne\n","    !pip install pyedflib\n","\n","    print('\\n \\n To load files from Google Drive, account validation is required.')\n","    #mount to drive -- files should be located in the Colab notebooks directory\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\", force_remount=True)\n","else:\n","    if 'HOMEPATH' in os.environ:\n","        print('Using homepath ' + os.environ['HOMEPATH'])\n","    raw_data_dir = '../../Data/Raw/'\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using Google Colab. Setting up environment\n","Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.19.2)\n","Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.17.5)\n","Requirement already satisfied: pyedflib in /usr/local/lib/python3.6/dist-packages (0.1.15)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from pyedflib) (1.17.5)\n","\n"," \n"," To load files from Google Drive, account validation is required.\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2ibl3Xz6AXWV","outputId":"f8ac5b3f-d9cb-4af9-f386-b7a4c7e5e39b","executionInfo":{"status":"ok","timestamp":1580639748442,"user_tz":-60,"elapsed":10660,"user":{"displayName":"Maritza Tynes","photoUrl":"","userId":"02324384993274756811"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import SpatialDropout2D\n","from tensorflow.keras.regularizers import l1_l2\n","from tensorflow.keras.layers import Input, Flatten\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras import backend as K\n","\n","import pandas as pd\n","import pyedflib\n","\n","\n","import tensorflow as tf\n","use_gpu = tf.test.is_gpu_available(\n","    cuda_only=False,\n","    min_cuda_compute_capability=None\n",")\n","\n","\n","import numpy as np\n","\n","# mne imports\n","import mne\n","from mne import io\n","\n","# Model-specific imports\n","from tensorflow.keras import utils as np_utils\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Convolution2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","\n","\n","# tools for plotting confusion matrices\n","from matplotlib import pyplot as plt\n","\n","import random \n","import math\n","\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-P1L5LqkAXXa","colab":{}},"source":["from tensorflow.keras import layers\n","#https://www.tensorflow.org/guide/keras/rnn\n","\n","def LSTM(samples, time_steps, nb_features, chans, nb_classes):\n","\n","    model=tf.keras.Sequential()\n","    \n","    print('chans: ', chans)\n","    print('nb_features: ', nb_features)\n","    model.add(layers.LSTM(128,\n","                          input_shape=(chans, time_steps)\n","            #input_shape=(chans* nb_features, time_steps),\n","            ))\n","    \n","\n","    model.add(Dense(16,kernel_initializer='he_uniform',activation='relu'))\n","    \n","\n","    model.add(Dense(nb_classes,activation='softmax'))\n","    \n","    return model\n","\n","\n","\n","    #LSTM(samles, time_steps=20, input_size=30, chans)\n","\n","\n","    \n","    \n","from tensorflow.keras import layers\n","#https://www.tensorflow.org/guide/keras/rnn\n","\n","def GRU_RNN(samples, time_steps, nb_features, chans, nb_classes):\n","    model=tf.keras.Sequential()\n","    \n","    #model.add(layers.LSTM(128,\n","    #         input_shape=(chans, time_steps),\n","    #         ))\n","    \n","    # The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n","    model.add(layers.GRU(512, \n","                         input_shape=(chans, time_steps),\n","                         return_sequences=True))\n","\n","    model.add(layers.SimpleRNN(128))\n","    #model.add(layers.SimpleRNN(128))\n","    \n","\n","    model.add(Dense(32,kernel_initializer='he_uniform',activation='relu'))\n","    \n","\n","    model.add(Dense(nb_classes,activation='softmax'))\n","    \n","    return model  \n","\n","\n","\n","\n","\"\"\"def LeNet(nb_classes, Chans = 64, Samples = 128, Kernels=1,\n","          dropoutRate = 0.5, kernLength = 64, F1 = 8, \n","          D = 2, F2 = 16, norm_rate = 0.25):\"\"\"\n","\n","def LeNet(samples, time_steps, nb_features, chans, nb_classes):\n","\n","    model = Sequential()\n","\n","    # first set of CONV => RELU => POOL\n","    model.add(Convolution2D(6, 3, 3, # border_mode=\"same\",\n","        #input_shape=( time_steps, chans, 50), name='conv2D_1'))\n","        input_shape=( chans, time_steps, 5), name='conv2D_1'))\n","    model.add(Activation(\"relu\"))\n","    model.add(layers.AveragePooling2D())\n","    #model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='maxpool_1'))\n","\n","    # second set of CONV => RELU => POOL\n","    model.add(Convolution2D(16, 3, 3, name='conv2D_2')) #, border_mode=\"same\"))\n","    model.add(Activation(\"relu\"))\n","    #model.add(layers.AveragePooling2D())\n","    #model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='maxpool_2'))\n","\n","    # set of FC => RELU layers\n","    model.add(Flatten())\n","    model.add(Dense(500))\n","    model.add(Activation(\"relu\"))\n","\n","    # softmax classifier\n","    model.add(Dense(nb_classes))\n","    model.add(Activation(\"softmax\"))\n","    \n","\n","\n","    return model  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XwxuGEB7AXYS","colab":{}},"source":["\n","ignore_list = ['s07']  #list of patient files that should be skipped\n","#seconds of data to include in one slice\n","time_window = 125\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jlcbxNN3AXZL","colab":{}},"source":["mne.set_log_level(\"WARNING\")\n","\n","\n","# get the minimum length of the files\n","def get_minimum_duration(group_directory_name, patient_group_file_prefix):\n","    file_durations = []\n","    for i in range (1, 15): # reading 14 files\n","        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n","        file_name = raw_data_dir +'{}/{}.edf'.format(group_directory_name, patient_id)\n","        f = pyedflib.EdfReader(file_name)\n","        file_durations.append(f.file_duration)\n","        f.close()\n","    return(min(file_durations))\n","\n","# modified based on https://stackoverflow.com/a/48704557/2466781\n","def chunk(seq, size):\n","    sl = len(seq) - (len(seq)%size) #exclude values that will be out of range\n","    r = [pd.DataFrame(seq[pos:pos + size]) for pos in range(0, sl, size)]\n","    return r\n","\n","# modified version of process_patient_group in older notebooks\n","# Uses the raw EDF files and converts to dataframe, dropping the first 150 and last 30 seconds of the shortest  file\n","# All other files are trimmed similarly to produce the same size\n","# Adapted from page 1 of https://buildmedia.readthedocs.org/media/pdf/pyedflib/latest/pyedflib.pdf\n","def process_patient_group(group_directory_name, patient_group_file_prefix, \n","                          minimum_original_duration,\n","                          time_window = 20,\n","                          plot_channels = False,\n","                         channels = ['F8', 'F7', 'F4', 'F3', 'Fz']):\n","    meta_df = pd.DataFrame()\n","    meta = []\n","    patient_id_list = []\n","\n","    for i in range (1, 15): # reading 14 files\n","        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n","        patient_id_list.append(patient_id)\n","        \n","        file_name = raw_data_dir + '{}/{}.edf'.format(group_directory_name, patient_id)\n","        data = mne.io.read_raw_edf(file_name)\n","        df = data.to_data_frame()\n","        df2 = df[channels]\n","        ## based on visual inspection, drop the first 120 seconds\n","        df2 = df2[120: (minimum_original_duration-120)]\n","        f = pyedflib.EdfReader(file_name)\n","        f.close()\n","        if patient_id not in ignore_list:\n","            meta_df = meta_df.append(df2)\n","            \n","    batches = chunk(meta_df, time_window)\n","\n","    for batch in batches:\n","        #display(np.asarray(batch.values).shape)\n","        meta.append([np.asarray(batch.values)])\n","           \n","                    \n","    return meta\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MHAeuZnVAXZc","outputId":"63a7066d-7040-4319-e79b-b23ebff73739","executionInfo":{"status":"ok","timestamp":1580643155804,"user_tz":-60,"elapsed":3151,"user":{"displayName":"Maritza Tynes","photoUrl":"","userId":"02324384993274756811"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# Retrieve patient data, using a time window determined by the shortest recording\n","# patient s07 is removed\n","\n","minimum_duration = min(get_minimum_duration(\"Healthy Controls\", \"h\"), get_minimum_duration('SZ Patients', 's'))\n","print('Minimum duration: ', minimum_duration)\n","\n","all_channels = ['Fp2', 'F8', 'T4', 'T6', 'O2', 'Fp1', 'F7', 'T3', 'T5', 'O1', 'F4',\n","                'C4', 'P4', 'F3', 'C3', 'P3', 'Fz', 'Cz', 'Pz']\n","\n","target_channels = ['T4', 'T6', 'O2', 'T3', 'T5', 'O1',\n","                   'C4', 'P4', 'C3', 'P3', 'Cz', 'Pz']\n","\n","print(\"Healthy Controls\")\n","hc_data = process_patient_group('Healthy Controls', 'h', minimum_duration, \n","                                #channels=target_channels, \n","                                channels=all_channels, \n","                                time_window=time_window)\n","display(np.asarray(hc_data).shape)\n","\n","\n","\n","print('Sz Patients')\n","sz_data = np.asarray(process_patient_group('SZ Patients', 's', minimum_duration, \n","                                           channels=all_channels, \n","                                           #channels=target_channels, \n","                                           time_window=time_window))\n","display(np.asarray(sz_data).shape)\n","\n","\n","##### combine groups and create Y (labels)\n","\n","X =  np.concatenate((hc_data, sz_data), axis=0)\n","display('Input size: ', X.shape)\n","y = ([0] * len(hc_data)) +( [1] * len(sz_data))\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Minimum duration:  740\n","Healthy Controls\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["(56, 1, 125, 19)"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Sz Patients\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["(52, 1, 125, 19)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["'Input size: '"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["(108, 1, 125, 19)"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bOd_LccVvXcc","outputId":"a672ee5b-4db0-4127-903d-08417c15ed71","executionInfo":{"status":"ok","timestamp":1580643057291,"user_tz":-60,"elapsed":1316,"user":{"displayName":"Maritza Tynes","photoUrl":"","userId":"02324384993274756811"}},"colab":{"base_uri":"https://localhost:8080/","height":299}},"source":["#X[1].plot()\n","from IPython.display import display\n","\n","import pylab as pylab\n","\n","print('Input (X) shape: ' + str(X.shape))\n","print('Preview of data. First slice of unfiltered data')\n","for el in X[1][0]:\n","  #print(el)\n","  #pylab.scatter(x=range(len(el)), y=el)\n","  pylab.plot(el)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Input (X) shape: (108, 1, 125, 19)\n","Preview of data. First slice of unfiltered data\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/T8SU+3WNKfDygAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M2C7VyiTAXbC","colab":{}},"source":["# create the /tmp directory if it doesn't already exist\n","import os\n","if not os.path.exists('tmp'):\n","    os.makedirs('tmp')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"90B3pZ2ZAXbN","colab":{}},"source":["# get a list of randomly selected sets of numbers based on a range\n","# the proportion of values selected for each set is determined by the ratio_array\n","def get_mixed_indexes_for_ml_train_test(length, ratios_array):\n","    input_indexes = range(0, length)\n","    output_indexes = []\n","    for ratio in ratios_array:\n","        selection = random.choices(input_indexes, k=math.floor(ratio * length))\n","        input_indexes = [i for i in input_indexes if i not in selection]\n","        output_indexes.append(selection)\n","    return output_indexes\n","    \n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_luI4i6LAXbn","outputId":"266c518d-453a-40f3-d322-eaa292985591","executionInfo":{"status":"ok","timestamp":1580645983552,"user_tz":-60,"elapsed":835,"user":{"displayName":"Maritza Tynes","photoUrl":"","userId":"02324384993274756811"}},"colab":{"base_uri":"https://localhost:8080/","height":561}},"source":["\n","kern_len = 5\n","kernels, chans, samples = 1, 19, time_window/kern_len\n","full_size = len(X)\n","train_idxs, validate_idxs, test_idxs = get_mixed_indexes_for_ml_train_test(len(X), [.70, 0.15, 0.15])\n","\n","\n","\n","X_train      = X[train_idxs][0:,]\n","Y_train      = np.asarray(y)[train_idxs]\n","X_validate   = X[validate_idxs][0:,]\n","Y_validate   = np.asarray(y)[validate_idxs]\n","X_test       = X[test_idxs][0:,]\n","Y_test       = np.asarray(y)[test_idxs]\n","\n","############################# EEGNet portion ##################################\n","\n","# convert labels to one-hot encodings.\n","Y_train      = np_utils.to_categorical(Y_train, num_classes=2)\n","Y_validate   = np_utils.to_categorical(Y_validate, num_classes=2)\n","Y_test       = np_utils.to_categorical(Y_test, num_classes=2)\n","\n","\n","tw_mod = math.floor(time_window/kern_len)\n","X_train      = X_train.reshape(X_train.shape[0],  chans, tw_mod,   kern_len)\n","X_validate   = X_validate.reshape( X_validate.shape[0], chans, tw_mod, kern_len)\n","X_test       = X_test.reshape( X_test.shape[0], chans, tw_mod, kern_len)\n","\n","\n"," \n","print('X_train shape:', X_train.shape)\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')\n","\n","\n","\n","#LSTM(samles, time_steps=20, input_size=30, chans)\n","#model = LSTM(samples=samples, time_steps=time_window, chans=chans, nb_features=1, nb_classes=2, )\n","\n","print('tw_mod: ', tw_mod)\n","model = LeNet(samples=samples, time_steps=time_window/kern_len, chans=chans, nb_features=1, nb_classes=2 )\n","model.summary()\n","\n","#import tensorflow \n","import tensorflow.keras.optimizers\n","opt_adam = tensorflow.keras.optimizers.Adam(lr=0.000001, \n","                                beta_1=0.99,\n","                                beta_2=0.999,\n","                                epsilon=1e-07)\n","sgd = tensorflow.keras.optimizers.SGD(lr=0.01)\n","\n","\n","\n","def rmse (y_true, y_pred):\n","\n","    return K.sqrt(K.mean(K.square(y_pred -y_true)))\n","\n","def rmse_np (y_true, y_pred):\n","    y_true = y_true.astype(int)\n","    y_pred=y_pred.astype(int)\n","    print(y_pred.dtype)\n","    return K.sqrt(K.mean(K.square(y_pred -y_true)))\n","\n","# compile the model and set the optimizers\n","model.compile(loss='categorical_crossentropy', optimizer=opt_adam, \n","              metrics=[#'mse', 'mae', \n","                  'accuracy', rmse\n","                 ])\n","\n","\n","# count number of parameters in the model\n","numParams    = model.count_params()    \n","\n","# set a valid path for your system to record model checkpoints\n","checkpointer = ModelCheckpoint(filepath='/tmp/LSTM_checkpoint.h5', verbose=1,\n","                               save_best_only=True)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X_train shape: (75, 19, 25, 5)\n","75 train samples\n","16 test samples\n","tw_mod:  25\n","Model: \"sequential_56\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2D_1 (Conv2D)            (None, 6, 8, 6)           276       \n","_________________________________________________________________\n","activation_124 (Activation)  (None, 6, 8, 6)           0         \n","_________________________________________________________________\n","average_pooling2d_40 (Averag (None, 3, 4, 6)           0         \n","_________________________________________________________________\n","conv2D_2 (Conv2D)            (None, 1, 1, 16)          880       \n","_________________________________________________________________\n","activation_125 (Activation)  (None, 1, 1, 16)          0         \n","_________________________________________________________________\n","flatten_23 (Flatten)         (None, 16)                0         \n","_________________________________________________________________\n","dense_46 (Dense)             (None, 500)               8500      \n","_________________________________________________________________\n","activation_126 (Activation)  (None, 500)               0         \n","_________________________________________________________________\n","dense_47 (Dense)             (None, 2)                 1002      \n","_________________________________________________________________\n","activation_127 (Activation)  (None, 2)                 0         \n","=================================================================\n","Total params: 10,658\n","Trainable params: 10,658\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3tvCkHx4AXb4","outputId":"ddfbf14b-6ece-4370-81c2-3d7b39a10156","executionInfo":{"status":"ok","timestamp":1580646045449,"user_tz":-60,"elapsed":61984,"user":{"displayName":"Maritza Tynes","photoUrl":"","userId":"02324384993274756811"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","import tensorflow.keras.backend as K\n","#import tensorflow.keras.callbacks.LearningRateScheduler\n","#import tensorflow.keras.callbacks.LearningRateScheduler\n","def scheduler(epoch):\n","  if epoch == 700:\n","    K.set_value(model.optimizer.lr, 0.0000001)\n","  if epoch == 1000:\n","    K.set_value(model.optimizer.lr, 0.00000009)\n","  if epoch == 1200:\n","    K.set_value(model.optimizer.lr, 0.000000007)\n"," \n","  return K.get_value(model.optimizer.lr)\n","\n","\n","change_lr = tensorflow.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","\n","fitted_model = model.fit(X_train, Y_train, batch_size = 8, epochs = 800, \n","                        verbose = 2, validation_data=(X_validate, Y_validate),\n","                        callbacks=[checkpointer, change_lr])\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 75 samples, validate on 16 samples\n","Epoch 1/800\n","\n","Epoch 00001: val_loss improved from inf to 0.80804, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 1s - loss: 0.7215 - acc: 0.5333 - rmse: 0.5124 - val_loss: 0.8080 - val_acc: 0.5000 - val_rmse: 0.5345\n","Epoch 2/800\n","\n","Epoch 00002: val_loss improved from 0.80804 to 0.80766, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7212 - acc: 0.5333 - rmse: 0.5131 - val_loss: 0.8077 - val_acc: 0.5000 - val_rmse: 0.5339\n","Epoch 3/800\n","\n","Epoch 00003: val_loss improved from 0.80766 to 0.80730, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7207 - acc: 0.5333 - rmse: 0.5119 - val_loss: 0.8073 - val_acc: 0.5000 - val_rmse: 0.5351\n","Epoch 4/800\n","\n","Epoch 00004: val_loss improved from 0.80730 to 0.80695, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7203 - acc: 0.5333 - rmse: 0.5149 - val_loss: 0.8070 - val_acc: 0.5000 - val_rmse: 0.5355\n","Epoch 5/800\n","\n","Epoch 00005: val_loss improved from 0.80695 to 0.80659, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7200 - acc: 0.5333 - rmse: 0.5130 - val_loss: 0.8066 - val_acc: 0.5000 - val_rmse: 0.5351\n","Epoch 6/800\n","\n","Epoch 00006: val_loss improved from 0.80659 to 0.80623, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7196 - acc: 0.5200 - rmse: 0.5140 - val_loss: 0.8062 - val_acc: 0.5000 - val_rmse: 0.5345\n","Epoch 7/800\n","\n","Epoch 00007: val_loss improved from 0.80623 to 0.80585, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7192 - acc: 0.5200 - rmse: 0.5144 - val_loss: 0.8059 - val_acc: 0.5000 - val_rmse: 0.5324\n","Epoch 8/800\n","\n","Epoch 00008: val_loss improved from 0.80585 to 0.80548, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7188 - acc: 0.5200 - rmse: 0.5123 - val_loss: 0.8055 - val_acc: 0.5000 - val_rmse: 0.5328\n","Epoch 9/800\n","\n","Epoch 00009: val_loss improved from 0.80548 to 0.80512, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7184 - acc: 0.5200 - rmse: 0.5089 - val_loss: 0.8051 - val_acc: 0.5000 - val_rmse: 0.5351\n","Epoch 10/800\n","\n","Epoch 00010: val_loss improved from 0.80512 to 0.80476, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7180 - acc: 0.5200 - rmse: 0.5094 - val_loss: 0.8048 - val_acc: 0.5000 - val_rmse: 0.5349\n","Epoch 11/800\n","\n","Epoch 00011: val_loss improved from 0.80476 to 0.80442, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7176 - acc: 0.5200 - rmse: 0.5076 - val_loss: 0.8044 - val_acc: 0.5000 - val_rmse: 0.5352\n","Epoch 12/800\n","\n","Epoch 00012: val_loss improved from 0.80442 to 0.80408, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7172 - acc: 0.5333 - rmse: 0.5103 - val_loss: 0.8041 - val_acc: 0.5000 - val_rmse: 0.5353\n","Epoch 13/800\n","\n","Epoch 00013: val_loss improved from 0.80408 to 0.80374, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7168 - acc: 0.5200 - rmse: 0.5104 - val_loss: 0.8037 - val_acc: 0.5000 - val_rmse: 0.5345\n","Epoch 14/800\n","\n","Epoch 00014: val_loss improved from 0.80374 to 0.80340, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7165 - acc: 0.5200 - rmse: 0.5093 - val_loss: 0.8034 - val_acc: 0.5000 - val_rmse: 0.5327\n","Epoch 15/800\n","\n","Epoch 00015: val_loss improved from 0.80340 to 0.80307, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7161 - acc: 0.5200 - rmse: 0.5100 - val_loss: 0.8031 - val_acc: 0.5000 - val_rmse: 0.5349\n","Epoch 16/800\n","\n","Epoch 00016: val_loss improved from 0.80307 to 0.80274, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7157 - acc: 0.5200 - rmse: 0.5111 - val_loss: 0.8027 - val_acc: 0.5000 - val_rmse: 0.5340\n","Epoch 17/800\n","\n","Epoch 00017: val_loss improved from 0.80274 to 0.80241, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7153 - acc: 0.5200 - rmse: 0.5136 - val_loss: 0.8024 - val_acc: 0.5000 - val_rmse: 0.5339\n","Epoch 18/800\n","\n","Epoch 00018: val_loss improved from 0.80241 to 0.80208, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7149 - acc: 0.5200 - rmse: 0.5083 - val_loss: 0.8021 - val_acc: 0.5000 - val_rmse: 0.5352\n","Epoch 19/800\n","\n","Epoch 00019: val_loss improved from 0.80208 to 0.80175, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7146 - acc: 0.5200 - rmse: 0.5081 - val_loss: 0.8018 - val_acc: 0.5000 - val_rmse: 0.5349\n","Epoch 20/800\n","\n","Epoch 00020: val_loss improved from 0.80175 to 0.80143, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7142 - acc: 0.5200 - rmse: 0.5114 - val_loss: 0.8014 - val_acc: 0.5000 - val_rmse: 0.5349\n","Epoch 21/800\n","\n","Epoch 00021: val_loss improved from 0.80143 to 0.80111, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7139 - acc: 0.5200 - rmse: 0.5087 - val_loss: 0.8011 - val_acc: 0.5000 - val_rmse: 0.5335\n","Epoch 22/800\n","\n","Epoch 00022: val_loss improved from 0.80111 to 0.80080, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7135 - acc: 0.5200 - rmse: 0.5064 - val_loss: 0.8008 - val_acc: 0.5000 - val_rmse: 0.5338\n","Epoch 23/800\n","\n","Epoch 00023: val_loss improved from 0.80080 to 0.80048, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7131 - acc: 0.5200 - rmse: 0.5083 - val_loss: 0.8005 - val_acc: 0.5000 - val_rmse: 0.5325\n","Epoch 24/800\n","\n","Epoch 00024: val_loss improved from 0.80048 to 0.80017, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7128 - acc: 0.5200 - rmse: 0.5034 - val_loss: 0.8002 - val_acc: 0.5000 - val_rmse: 0.5334\n","Epoch 25/800\n","\n","Epoch 00025: val_loss improved from 0.80017 to 0.79986, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7124 - acc: 0.5200 - rmse: 0.5111 - val_loss: 0.7999 - val_acc: 0.5000 - val_rmse: 0.5347\n","Epoch 26/800\n","\n","Epoch 00026: val_loss improved from 0.79986 to 0.79955, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7121 - acc: 0.5200 - rmse: 0.5031 - val_loss: 0.7996 - val_acc: 0.5000 - val_rmse: 0.5329\n","Epoch 27/800\n","\n","Epoch 00027: val_loss improved from 0.79955 to 0.79925, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7117 - acc: 0.5200 - rmse: 0.5083 - val_loss: 0.7993 - val_acc: 0.5000 - val_rmse: 0.5341\n","Epoch 28/800\n","\n","Epoch 00028: val_loss improved from 0.79925 to 0.79895, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7114 - acc: 0.5200 - rmse: 0.5081 - val_loss: 0.7990 - val_acc: 0.5625 - val_rmse: 0.5338\n","Epoch 29/800\n","\n","Epoch 00029: val_loss improved from 0.79895 to 0.79865, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7110 - acc: 0.5200 - rmse: 0.5102 - val_loss: 0.7986 - val_acc: 0.5625 - val_rmse: 0.5335\n","Epoch 30/800\n","\n","Epoch 00030: val_loss improved from 0.79865 to 0.79834, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7108 - acc: 0.5200 - rmse: 0.5087 - val_loss: 0.7983 - val_acc: 0.5625 - val_rmse: 0.5322\n","Epoch 31/800\n","\n","Epoch 00031: val_loss improved from 0.79834 to 0.79804, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7103 - acc: 0.5200 - rmse: 0.5085 - val_loss: 0.7980 - val_acc: 0.5625 - val_rmse: 0.5328\n","Epoch 32/800\n","\n","Epoch 00032: val_loss improved from 0.79804 to 0.79773, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7101 - acc: 0.5200 - rmse: 0.5066 - val_loss: 0.7977 - val_acc: 0.5625 - val_rmse: 0.5345\n","Epoch 33/800\n","\n","Epoch 00033: val_loss improved from 0.79773 to 0.79743, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7097 - acc: 0.5200 - rmse: 0.5079 - val_loss: 0.7974 - val_acc: 0.5625 - val_rmse: 0.5342\n","Epoch 34/800\n","\n","Epoch 00034: val_loss improved from 0.79743 to 0.79713, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7093 - acc: 0.5200 - rmse: 0.5090 - val_loss: 0.7971 - val_acc: 0.5625 - val_rmse: 0.5348\n","Epoch 35/800\n","\n","Epoch 00035: val_loss improved from 0.79713 to 0.79684, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7090 - acc: 0.5200 - rmse: 0.5074 - val_loss: 0.7968 - val_acc: 0.5625 - val_rmse: 0.5348\n","Epoch 36/800\n","\n","Epoch 00036: val_loss improved from 0.79684 to 0.79654, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7086 - acc: 0.5200 - rmse: 0.5067 - val_loss: 0.7965 - val_acc: 0.5625 - val_rmse: 0.5336\n","Epoch 37/800\n","\n","Epoch 00037: val_loss improved from 0.79654 to 0.79625, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7083 - acc: 0.5200 - rmse: 0.5079 - val_loss: 0.7963 - val_acc: 0.5625 - val_rmse: 0.5324\n","Epoch 38/800\n","\n","Epoch 00038: val_loss improved from 0.79625 to 0.79596, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7080 - acc: 0.5200 - rmse: 0.5033 - val_loss: 0.7960 - val_acc: 0.5625 - val_rmse: 0.5339\n","Epoch 39/800\n","\n","Epoch 00039: val_loss improved from 0.79596 to 0.79568, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7076 - acc: 0.5200 - rmse: 0.5087 - val_loss: 0.7957 - val_acc: 0.5625 - val_rmse: 0.5346\n","Epoch 40/800\n","\n","Epoch 00040: val_loss improved from 0.79568 to 0.79539, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7073 - acc: 0.5067 - rmse: 0.5098 - val_loss: 0.7954 - val_acc: 0.5625 - val_rmse: 0.5340\n","Epoch 41/800\n","\n","Epoch 00041: val_loss improved from 0.79539 to 0.79511, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7070 - acc: 0.5067 - rmse: 0.5058 - val_loss: 0.7951 - val_acc: 0.5625 - val_rmse: 0.5345\n","Epoch 42/800\n","\n","Epoch 00042: val_loss improved from 0.79511 to 0.79483, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7066 - acc: 0.5067 - rmse: 0.5112 - val_loss: 0.7948 - val_acc: 0.5625 - val_rmse: 0.5337\n","Epoch 43/800\n","\n","Epoch 00043: val_loss improved from 0.79483 to 0.79455, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7063 - acc: 0.5067 - rmse: 0.5097 - val_loss: 0.7946 - val_acc: 0.5625 - val_rmse: 0.5338\n","Epoch 44/800\n","\n","Epoch 00044: val_loss improved from 0.79455 to 0.79427, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7059 - acc: 0.5067 - rmse: 0.5077 - val_loss: 0.7943 - val_acc: 0.5625 - val_rmse: 0.5341\n","Epoch 45/800\n","\n","Epoch 00045: val_loss improved from 0.79427 to 0.79398, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7056 - acc: 0.5067 - rmse: 0.5060 - val_loss: 0.7940 - val_acc: 0.5625 - val_rmse: 0.5341\n","Epoch 46/800\n","\n","Epoch 00046: val_loss improved from 0.79398 to 0.79370, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7053 - acc: 0.5200 - rmse: 0.5072 - val_loss: 0.7937 - val_acc: 0.5625 - val_rmse: 0.5315\n","Epoch 47/800\n","\n","Epoch 00047: val_loss improved from 0.79370 to 0.79343, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7049 - acc: 0.5333 - rmse: 0.5013 - val_loss: 0.7934 - val_acc: 0.5625 - val_rmse: 0.5327\n","Epoch 48/800\n","\n","Epoch 00048: val_loss improved from 0.79343 to 0.79316, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7046 - acc: 0.5333 - rmse: 0.5039 - val_loss: 0.7932 - val_acc: 0.5625 - val_rmse: 0.5339\n","Epoch 49/800\n","\n","Epoch 00049: val_loss improved from 0.79316 to 0.79288, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7043 - acc: 0.5333 - rmse: 0.5020 - val_loss: 0.7929 - val_acc: 0.5625 - val_rmse: 0.5323\n","Epoch 50/800\n","\n","Epoch 00050: val_loss improved from 0.79288 to 0.79261, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7040 - acc: 0.5333 - rmse: 0.5027 - val_loss: 0.7926 - val_acc: 0.5625 - val_rmse: 0.5339\n","Epoch 51/800\n","\n","Epoch 00051: val_loss improved from 0.79261 to 0.79235, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7036 - acc: 0.5333 - rmse: 0.5057 - val_loss: 0.7924 - val_acc: 0.5625 - val_rmse: 0.5334\n","Epoch 52/800\n","\n","Epoch 00052: val_loss improved from 0.79235 to 0.79209, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7033 - acc: 0.5467 - rmse: 0.5009 - val_loss: 0.7921 - val_acc: 0.5625 - val_rmse: 0.5334\n","Epoch 53/800\n","\n","Epoch 00053: val_loss improved from 0.79209 to 0.79183, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7030 - acc: 0.5467 - rmse: 0.5065 - val_loss: 0.7918 - val_acc: 0.5625 - val_rmse: 0.5341\n","Epoch 54/800\n","\n","Epoch 00054: val_loss improved from 0.79183 to 0.79156, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7027 - acc: 0.5467 - rmse: 0.5037 - val_loss: 0.7916 - val_acc: 0.5625 - val_rmse: 0.5331\n","Epoch 55/800\n","\n","Epoch 00055: val_loss improved from 0.79156 to 0.79131, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7023 - acc: 0.5467 - rmse: 0.5071 - val_loss: 0.7913 - val_acc: 0.5625 - val_rmse: 0.5321\n","Epoch 56/800\n","\n","Epoch 00056: val_loss improved from 0.79131 to 0.79105, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7021 - acc: 0.5467 - rmse: 0.5065 - val_loss: 0.7910 - val_acc: 0.5625 - val_rmse: 0.5336\n","Epoch 57/800\n","\n","Epoch 00057: val_loss improved from 0.79105 to 0.79079, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7017 - acc: 0.5467 - rmse: 0.5060 - val_loss: 0.7908 - val_acc: 0.5625 - val_rmse: 0.5339\n","Epoch 58/800\n","\n","Epoch 00058: val_loss improved from 0.79079 to 0.79053, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7014 - acc: 0.5600 - rmse: 0.5055 - val_loss: 0.7905 - val_acc: 0.5625 - val_rmse: 0.5330\n","Epoch 59/800\n","\n","Epoch 00059: val_loss improved from 0.79053 to 0.79027, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7011 - acc: 0.5600 - rmse: 0.5069 - val_loss: 0.7903 - val_acc: 0.5625 - val_rmse: 0.5332\n","Epoch 60/800\n","\n","Epoch 00060: val_loss improved from 0.79027 to 0.79000, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7008 - acc: 0.5600 - rmse: 0.5040 - val_loss: 0.7900 - val_acc: 0.5625 - val_rmse: 0.5334\n","Epoch 61/800\n","\n","Epoch 00061: val_loss improved from 0.79000 to 0.78975, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7005 - acc: 0.5600 - rmse: 0.5010 - val_loss: 0.7897 - val_acc: 0.5625 - val_rmse: 0.5321\n","Epoch 62/800\n","\n","Epoch 00062: val_loss improved from 0.78975 to 0.78949, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.7002 - acc: 0.5600 - rmse: 0.4994 - val_loss: 0.7895 - val_acc: 0.5625 - val_rmse: 0.5326\n","Epoch 63/800\n","\n","Epoch 00063: val_loss improved from 0.78949 to 0.78924, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6999 - acc: 0.5600 - rmse: 0.5006 - val_loss: 0.7892 - val_acc: 0.5625 - val_rmse: 0.5332\n","Epoch 64/800\n","\n","Epoch 00064: val_loss improved from 0.78924 to 0.78899, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6996 - acc: 0.5600 - rmse: 0.5053 - val_loss: 0.7890 - val_acc: 0.5625 - val_rmse: 0.5315\n","Epoch 65/800\n","\n","Epoch 00065: val_loss improved from 0.78899 to 0.78875, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6993 - acc: 0.5600 - rmse: 0.5005 - val_loss: 0.7887 - val_acc: 0.5625 - val_rmse: 0.5331\n","Epoch 66/800\n","\n","Epoch 00066: val_loss improved from 0.78875 to 0.78850, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6990 - acc: 0.5600 - rmse: 0.5009 - val_loss: 0.7885 - val_acc: 0.5625 - val_rmse: 0.5340\n","Epoch 67/800\n","\n","Epoch 00067: val_loss improved from 0.78850 to 0.78826, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6987 - acc: 0.5600 - rmse: 0.4977 - val_loss: 0.7883 - val_acc: 0.5625 - val_rmse: 0.5317\n","Epoch 68/800\n","\n","Epoch 00068: val_loss improved from 0.78826 to 0.78802, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6984 - acc: 0.5467 - rmse: 0.5008 - val_loss: 0.7880 - val_acc: 0.5625 - val_rmse: 0.5340\n","Epoch 69/800\n","\n","Epoch 00069: val_loss improved from 0.78802 to 0.78779, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6981 - acc: 0.5467 - rmse: 0.5027 - val_loss: 0.7878 - val_acc: 0.5625 - val_rmse: 0.5340\n","Epoch 70/800\n","\n","Epoch 00070: val_loss improved from 0.78779 to 0.78755, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6979 - acc: 0.5467 - rmse: 0.5012 - val_loss: 0.7876 - val_acc: 0.5625 - val_rmse: 0.5339\n","Epoch 71/800\n","\n","Epoch 00071: val_loss improved from 0.78755 to 0.78732, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6976 - acc: 0.5467 - rmse: 0.4973 - val_loss: 0.7873 - val_acc: 0.5625 - val_rmse: 0.5339\n","Epoch 72/800\n","\n","Epoch 00072: val_loss improved from 0.78732 to 0.78709, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6974 - acc: 0.5467 - rmse: 0.5053 - val_loss: 0.7871 - val_acc: 0.5625 - val_rmse: 0.5327\n","Epoch 73/800\n","\n","Epoch 00073: val_loss improved from 0.78709 to 0.78687, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6971 - acc: 0.5467 - rmse: 0.5009 - val_loss: 0.7869 - val_acc: 0.5625 - val_rmse: 0.5338\n","Epoch 74/800\n","\n","Epoch 00074: val_loss improved from 0.78687 to 0.78665, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6968 - acc: 0.5467 - rmse: 0.4982 - val_loss: 0.7867 - val_acc: 0.5625 - val_rmse: 0.5337\n","Epoch 75/800\n","\n","Epoch 00075: val_loss improved from 0.78665 to 0.78643, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6965 - acc: 0.5467 - rmse: 0.5074 - val_loss: 0.7864 - val_acc: 0.5625 - val_rmse: 0.5333\n","Epoch 76/800\n","\n","Epoch 00076: val_loss improved from 0.78643 to 0.78621, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6963 - acc: 0.5467 - rmse: 0.5044 - val_loss: 0.7862 - val_acc: 0.5625 - val_rmse: 0.5322\n","Epoch 77/800\n","\n","Epoch 00077: val_loss improved from 0.78621 to 0.78598, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6960 - acc: 0.5467 - rmse: 0.5038 - val_loss: 0.7860 - val_acc: 0.5625 - val_rmse: 0.5339\n","Epoch 78/800\n","\n","Epoch 00078: val_loss improved from 0.78598 to 0.78576, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6957 - acc: 0.5467 - rmse: 0.4991 - val_loss: 0.7858 - val_acc: 0.5625 - val_rmse: 0.5339\n","Epoch 79/800\n","\n","Epoch 00079: val_loss improved from 0.78576 to 0.78554, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6956 - acc: 0.5467 - rmse: 0.5002 - val_loss: 0.7855 - val_acc: 0.5625 - val_rmse: 0.5320\n","Epoch 80/800\n","\n","Epoch 00080: val_loss improved from 0.78554 to 0.78532, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6953 - acc: 0.5467 - rmse: 0.5026 - val_loss: 0.7853 - val_acc: 0.5625 - val_rmse: 0.5321\n","Epoch 81/800\n","\n","Epoch 00081: val_loss improved from 0.78532 to 0.78510, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6949 - acc: 0.5467 - rmse: 0.5018 - val_loss: 0.7851 - val_acc: 0.5625 - val_rmse: 0.5325\n","Epoch 82/800\n","\n","Epoch 00082: val_loss improved from 0.78510 to 0.78488, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6948 - acc: 0.5467 - rmse: 0.5018 - val_loss: 0.7849 - val_acc: 0.5625 - val_rmse: 0.5313\n","Epoch 83/800\n","\n","Epoch 00083: val_loss improved from 0.78488 to 0.78467, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6945 - acc: 0.5467 - rmse: 0.5022 - val_loss: 0.7847 - val_acc: 0.5625 - val_rmse: 0.5326\n","Epoch 84/800\n","\n","Epoch 00084: val_loss improved from 0.78467 to 0.78445, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6942 - acc: 0.5467 - rmse: 0.5027 - val_loss: 0.7845 - val_acc: 0.6250 - val_rmse: 0.5339\n","Epoch 85/800\n","\n","Epoch 00085: val_loss improved from 0.78445 to 0.78424, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6940 - acc: 0.5467 - rmse: 0.5028 - val_loss: 0.7842 - val_acc: 0.6250 - val_rmse: 0.5330\n","Epoch 86/800\n","\n","Epoch 00086: val_loss improved from 0.78424 to 0.78402, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6937 - acc: 0.5467 - rmse: 0.5005 - val_loss: 0.7840 - val_acc: 0.6250 - val_rmse: 0.5311\n","Epoch 87/800\n","\n","Epoch 00087: val_loss improved from 0.78402 to 0.78381, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6934 - acc: 0.5467 - rmse: 0.4966 - val_loss: 0.7838 - val_acc: 0.6250 - val_rmse: 0.5337\n","Epoch 88/800\n","\n","Epoch 00088: val_loss improved from 0.78381 to 0.78359, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6932 - acc: 0.5467 - rmse: 0.5003 - val_loss: 0.7836 - val_acc: 0.6250 - val_rmse: 0.5335\n","Epoch 89/800\n","\n","Epoch 00089: val_loss improved from 0.78359 to 0.78339, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6929 - acc: 0.5600 - rmse: 0.4978 - val_loss: 0.7834 - val_acc: 0.6250 - val_rmse: 0.5332\n","Epoch 90/800\n","\n","Epoch 00090: val_loss improved from 0.78339 to 0.78318, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6926 - acc: 0.5733 - rmse: 0.4997 - val_loss: 0.7832 - val_acc: 0.6250 - val_rmse: 0.5325\n","Epoch 91/800\n","\n","Epoch 00091: val_loss improved from 0.78318 to 0.78297, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6924 - acc: 0.5733 - rmse: 0.4989 - val_loss: 0.7830 - val_acc: 0.6250 - val_rmse: 0.5325\n","Epoch 92/800\n","\n","Epoch 00092: val_loss improved from 0.78297 to 0.78277, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6922 - acc: 0.5733 - rmse: 0.4974 - val_loss: 0.7828 - val_acc: 0.6250 - val_rmse: 0.5326\n","Epoch 93/800\n","\n","Epoch 00093: val_loss improved from 0.78277 to 0.78256, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6919 - acc: 0.5733 - rmse: 0.5003 - val_loss: 0.7826 - val_acc: 0.6250 - val_rmse: 0.5335\n","Epoch 94/800\n","\n","Epoch 00094: val_loss improved from 0.78256 to 0.78236, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6917 - acc: 0.5733 - rmse: 0.4990 - val_loss: 0.7824 - val_acc: 0.6250 - val_rmse: 0.5329\n","Epoch 95/800\n","\n","Epoch 00095: val_loss improved from 0.78236 to 0.78216, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6914 - acc: 0.5733 - rmse: 0.4993 - val_loss: 0.7822 - val_acc: 0.6250 - val_rmse: 0.5324\n","Epoch 96/800\n","\n","Epoch 00096: val_loss improved from 0.78216 to 0.78196, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6911 - acc: 0.5733 - rmse: 0.4980 - val_loss: 0.7820 - val_acc: 0.6250 - val_rmse: 0.5331\n","Epoch 97/800\n","\n","Epoch 00097: val_loss improved from 0.78196 to 0.78177, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6909 - acc: 0.5733 - rmse: 0.4946 - val_loss: 0.7818 - val_acc: 0.6250 - val_rmse: 0.5326\n","Epoch 98/800\n","\n","Epoch 00098: val_loss improved from 0.78177 to 0.78158, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6907 - acc: 0.5733 - rmse: 0.4983 - val_loss: 0.7816 - val_acc: 0.6250 - val_rmse: 0.5315\n","Epoch 99/800\n","\n","Epoch 00099: val_loss improved from 0.78158 to 0.78139, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6904 - acc: 0.5733 - rmse: 0.4981 - val_loss: 0.7814 - val_acc: 0.6250 - val_rmse: 0.5328\n","Epoch 100/800\n","\n","Epoch 00100: val_loss improved from 0.78139 to 0.78120, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6902 - acc: 0.5733 - rmse: 0.4979 - val_loss: 0.7812 - val_acc: 0.6250 - val_rmse: 0.5328\n","Epoch 101/800\n","\n","Epoch 00101: val_loss improved from 0.78120 to 0.78101, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6899 - acc: 0.6000 - rmse: 0.4976 - val_loss: 0.7810 - val_acc: 0.6250 - val_rmse: 0.5333\n","Epoch 102/800\n","\n","Epoch 00102: val_loss improved from 0.78101 to 0.78082, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6897 - acc: 0.6133 - rmse: 0.4984 - val_loss: 0.7808 - val_acc: 0.6250 - val_rmse: 0.5335\n","Epoch 103/800\n","\n","Epoch 00103: val_loss improved from 0.78082 to 0.78063, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6895 - acc: 0.6133 - rmse: 0.4969 - val_loss: 0.7806 - val_acc: 0.6250 - val_rmse: 0.5327\n","Epoch 104/800\n","\n","Epoch 00104: val_loss improved from 0.78063 to 0.78044, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6892 - acc: 0.6000 - rmse: 0.4975 - val_loss: 0.7804 - val_acc: 0.6250 - val_rmse: 0.5335\n","Epoch 105/800\n","\n","Epoch 00105: val_loss improved from 0.78044 to 0.78025, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6890 - acc: 0.6000 - rmse: 0.4951 - val_loss: 0.7803 - val_acc: 0.6250 - val_rmse: 0.5311\n","Epoch 106/800\n","\n","Epoch 00106: val_loss improved from 0.78025 to 0.78007, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6888 - acc: 0.6000 - rmse: 0.4974 - val_loss: 0.7801 - val_acc: 0.6250 - val_rmse: 0.5330\n","Epoch 107/800\n","\n","Epoch 00107: val_loss improved from 0.78007 to 0.77989, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6885 - acc: 0.6000 - rmse: 0.4989 - val_loss: 0.7799 - val_acc: 0.6250 - val_rmse: 0.5321\n","Epoch 108/800\n","\n","Epoch 00108: val_loss improved from 0.77989 to 0.77971, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6883 - acc: 0.6000 - rmse: 0.4979 - val_loss: 0.7797 - val_acc: 0.6250 - val_rmse: 0.5319\n","Epoch 109/800\n","\n","Epoch 00109: val_loss improved from 0.77971 to 0.77953, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6880 - acc: 0.6000 - rmse: 0.4971 - val_loss: 0.7795 - val_acc: 0.6250 - val_rmse: 0.5318\n","Epoch 110/800\n","\n","Epoch 00110: val_loss improved from 0.77953 to 0.77936, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6878 - acc: 0.6000 - rmse: 0.4991 - val_loss: 0.7794 - val_acc: 0.6250 - val_rmse: 0.5323\n","Epoch 111/800\n","\n","Epoch 00111: val_loss improved from 0.77936 to 0.77918, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6876 - acc: 0.6000 - rmse: 0.4982 - val_loss: 0.7792 - val_acc: 0.6250 - val_rmse: 0.5331\n","Epoch 112/800\n","\n","Epoch 00112: val_loss improved from 0.77918 to 0.77899, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6873 - acc: 0.6000 - rmse: 0.4956 - val_loss: 0.7790 - val_acc: 0.6250 - val_rmse: 0.5326\n","Epoch 113/800\n","\n","Epoch 00113: val_loss improved from 0.77899 to 0.77881, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6871 - acc: 0.6000 - rmse: 0.4977 - val_loss: 0.7788 - val_acc: 0.6250 - val_rmse: 0.5333\n","Epoch 114/800\n","\n","Epoch 00114: val_loss improved from 0.77881 to 0.77863, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6868 - acc: 0.6000 - rmse: 0.4977 - val_loss: 0.7786 - val_acc: 0.6250 - val_rmse: 0.5311\n","Epoch 115/800\n","\n","Epoch 00115: val_loss improved from 0.77863 to 0.77845, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6866 - acc: 0.6000 - rmse: 0.4982 - val_loss: 0.7784 - val_acc: 0.6250 - val_rmse: 0.5331\n","Epoch 116/800\n","\n","Epoch 00116: val_loss improved from 0.77845 to 0.77827, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6864 - acc: 0.6000 - rmse: 0.4943 - val_loss: 0.7783 - val_acc: 0.5000 - val_rmse: 0.5329\n","Epoch 117/800\n","\n","Epoch 00117: val_loss improved from 0.77827 to 0.77809, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6861 - acc: 0.6000 - rmse: 0.4970 - val_loss: 0.7781 - val_acc: 0.5000 - val_rmse: 0.5331\n","Epoch 118/800\n","\n","Epoch 00118: val_loss improved from 0.77809 to 0.77791, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6859 - acc: 0.6000 - rmse: 0.4938 - val_loss: 0.7779 - val_acc: 0.5000 - val_rmse: 0.5333\n","Epoch 119/800\n","\n","Epoch 00119: val_loss improved from 0.77791 to 0.77774, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6856 - acc: 0.6000 - rmse: 0.4973 - val_loss: 0.7777 - val_acc: 0.5625 - val_rmse: 0.5318\n","Epoch 120/800\n","\n","Epoch 00120: val_loss improved from 0.77774 to 0.77757, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6855 - acc: 0.6000 - rmse: 0.4985 - val_loss: 0.7776 - val_acc: 0.5625 - val_rmse: 0.5331\n","Epoch 121/800\n","\n","Epoch 00121: val_loss improved from 0.77757 to 0.77740, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6852 - acc: 0.6000 - rmse: 0.4954 - val_loss: 0.7774 - val_acc: 0.5625 - val_rmse: 0.5332\n","Epoch 122/800\n","\n","Epoch 00122: val_loss improved from 0.77740 to 0.77724, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6850 - acc: 0.6000 - rmse: 0.4977 - val_loss: 0.7772 - val_acc: 0.5625 - val_rmse: 0.5326\n","Epoch 123/800\n","\n","Epoch 00123: val_loss improved from 0.77724 to 0.77707, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6848 - acc: 0.6000 - rmse: 0.4990 - val_loss: 0.7771 - val_acc: 0.5625 - val_rmse: 0.5329\n","Epoch 124/800\n","\n","Epoch 00124: val_loss improved from 0.77707 to 0.77690, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6845 - acc: 0.6000 - rmse: 0.4973 - val_loss: 0.7769 - val_acc: 0.5625 - val_rmse: 0.5313\n","Epoch 125/800\n","\n","Epoch 00125: val_loss improved from 0.77690 to 0.77673, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6844 - acc: 0.6000 - rmse: 0.4969 - val_loss: 0.7767 - val_acc: 0.5625 - val_rmse: 0.5326\n","Epoch 126/800\n","\n","Epoch 00126: val_loss improved from 0.77673 to 0.77657, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6841 - acc: 0.6000 - rmse: 0.4956 - val_loss: 0.7766 - val_acc: 0.5625 - val_rmse: 0.5305\n","Epoch 127/800\n","\n","Epoch 00127: val_loss improved from 0.77657 to 0.77641, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6839 - acc: 0.6000 - rmse: 0.4973 - val_loss: 0.7764 - val_acc: 0.5625 - val_rmse: 0.5324\n","Epoch 128/800\n","\n","Epoch 00128: val_loss improved from 0.77641 to 0.77625, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6837 - acc: 0.6000 - rmse: 0.4946 - val_loss: 0.7762 - val_acc: 0.5625 - val_rmse: 0.5302\n","Epoch 129/800\n","\n","Epoch 00129: val_loss improved from 0.77625 to 0.77609, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6835 - acc: 0.6000 - rmse: 0.4942 - val_loss: 0.7761 - val_acc: 0.5625 - val_rmse: 0.5327\n","Epoch 130/800\n","\n","Epoch 00130: val_loss improved from 0.77609 to 0.77594, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6833 - acc: 0.5733 - rmse: 0.4957 - val_loss: 0.7759 - val_acc: 0.5625 - val_rmse: 0.5325\n","Epoch 131/800\n","\n","Epoch 00131: val_loss improved from 0.77594 to 0.77579, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6831 - acc: 0.5733 - rmse: 0.4938 - val_loss: 0.7758 - val_acc: 0.5625 - val_rmse: 0.5328\n","Epoch 132/800\n","\n","Epoch 00132: val_loss improved from 0.77579 to 0.77563, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6829 - acc: 0.5733 - rmse: 0.4918 - val_loss: 0.7756 - val_acc: 0.5625 - val_rmse: 0.5325\n","Epoch 133/800\n","\n","Epoch 00133: val_loss improved from 0.77563 to 0.77549, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6827 - acc: 0.5733 - rmse: 0.4898 - val_loss: 0.7755 - val_acc: 0.5625 - val_rmse: 0.5310\n","Epoch 134/800\n","\n","Epoch 00134: val_loss improved from 0.77549 to 0.77534, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6825 - acc: 0.5733 - rmse: 0.4886 - val_loss: 0.7753 - val_acc: 0.5625 - val_rmse: 0.5318\n","Epoch 135/800\n","\n","Epoch 00135: val_loss improved from 0.77534 to 0.77521, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6823 - acc: 0.5733 - rmse: 0.4937 - val_loss: 0.7752 - val_acc: 0.5625 - val_rmse: 0.5315\n","Epoch 136/800\n","\n","Epoch 00136: val_loss improved from 0.77521 to 0.77507, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6821 - acc: 0.5733 - rmse: 0.4962 - val_loss: 0.7751 - val_acc: 0.5625 - val_rmse: 0.5329\n","Epoch 137/800\n","\n","Epoch 00137: val_loss improved from 0.77507 to 0.77493, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6818 - acc: 0.5733 - rmse: 0.4951 - val_loss: 0.7749 - val_acc: 0.5625 - val_rmse: 0.5325\n","Epoch 138/800\n","\n","Epoch 00138: val_loss improved from 0.77493 to 0.77479, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6817 - acc: 0.6000 - rmse: 0.4931 - val_loss: 0.7748 - val_acc: 0.5625 - val_rmse: 0.5318\n","Epoch 139/800\n","\n","Epoch 00139: val_loss improved from 0.77479 to 0.77465, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6815 - acc: 0.6133 - rmse: 0.4918 - val_loss: 0.7746 - val_acc: 0.5625 - val_rmse: 0.5317\n","Epoch 140/800\n","\n","Epoch 00140: val_loss improved from 0.77465 to 0.77451, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6813 - acc: 0.6133 - rmse: 0.4946 - val_loss: 0.7745 - val_acc: 0.5625 - val_rmse: 0.5326\n","Epoch 141/800\n","\n","Epoch 00141: val_loss improved from 0.77451 to 0.77438, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6811 - acc: 0.6267 - rmse: 0.4929 - val_loss: 0.7744 - val_acc: 0.5625 - val_rmse: 0.5328\n","Epoch 142/800\n","\n","Epoch 00142: val_loss improved from 0.77438 to 0.77425, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6808 - acc: 0.6267 - rmse: 0.4931 - val_loss: 0.7743 - val_acc: 0.5625 - val_rmse: 0.5329\n","Epoch 143/800\n","\n","Epoch 00143: val_loss improved from 0.77425 to 0.77412, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6807 - acc: 0.6267 - rmse: 0.4944 - val_loss: 0.7741 - val_acc: 0.5625 - val_rmse: 0.5317\n","Epoch 144/800\n","\n","Epoch 00144: val_loss improved from 0.77412 to 0.77399, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6805 - acc: 0.6267 - rmse: 0.4948 - val_loss: 0.7740 - val_acc: 0.5625 - val_rmse: 0.5310\n","Epoch 145/800\n","\n","Epoch 00145: val_loss improved from 0.77399 to 0.77386, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6803 - acc: 0.6267 - rmse: 0.4919 - val_loss: 0.7739 - val_acc: 0.5625 - val_rmse: 0.5298\n","Epoch 146/800\n","\n","Epoch 00146: val_loss improved from 0.77386 to 0.77373, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6801 - acc: 0.6267 - rmse: 0.4938 - val_loss: 0.7737 - val_acc: 0.5625 - val_rmse: 0.5321\n","Epoch 147/800\n","\n","Epoch 00147: val_loss improved from 0.77373 to 0.77360, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6799 - acc: 0.6267 - rmse: 0.4926 - val_loss: 0.7736 - val_acc: 0.5625 - val_rmse: 0.5318\n","Epoch 148/800\n","\n","Epoch 00148: val_loss improved from 0.77360 to 0.77347, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6797 - acc: 0.6400 - rmse: 0.4935 - val_loss: 0.7735 - val_acc: 0.5625 - val_rmse: 0.5310\n","Epoch 149/800\n","\n","Epoch 00149: val_loss improved from 0.77347 to 0.77334, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6795 - acc: 0.6400 - rmse: 0.4915 - val_loss: 0.7733 - val_acc: 0.5625 - val_rmse: 0.5302\n","Epoch 150/800\n","\n","Epoch 00150: val_loss improved from 0.77334 to 0.77321, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6793 - acc: 0.6400 - rmse: 0.4937 - val_loss: 0.7732 - val_acc: 0.5625 - val_rmse: 0.5319\n","Epoch 151/800\n","\n","Epoch 00151: val_loss improved from 0.77321 to 0.77308, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6791 - acc: 0.6267 - rmse: 0.4972 - val_loss: 0.7731 - val_acc: 0.5625 - val_rmse: 0.5327\n","Epoch 152/800\n","\n","Epoch 00152: val_loss improved from 0.77308 to 0.77295, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6789 - acc: 0.6133 - rmse: 0.4930 - val_loss: 0.7730 - val_acc: 0.5625 - val_rmse: 0.5327\n","Epoch 153/800\n","\n","Epoch 00153: val_loss improved from 0.77295 to 0.77282, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6787 - acc: 0.6133 - rmse: 0.4938 - val_loss: 0.7728 - val_acc: 0.5625 - val_rmse: 0.5326\n","Epoch 154/800\n","\n","Epoch 00154: val_loss improved from 0.77282 to 0.77270, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6785 - acc: 0.6133 - rmse: 0.4947 - val_loss: 0.7727 - val_acc: 0.5000 - val_rmse: 0.5324\n","Epoch 155/800\n","\n","Epoch 00155: val_loss improved from 0.77270 to 0.77257, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6783 - acc: 0.6133 - rmse: 0.4908 - val_loss: 0.7726 - val_acc: 0.5000 - val_rmse: 0.5322\n","Epoch 156/800\n","\n","Epoch 00156: val_loss improved from 0.77257 to 0.77244, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6782 - acc: 0.6133 - rmse: 0.4907 - val_loss: 0.7724 - val_acc: 0.5000 - val_rmse: 0.5313\n","Epoch 157/800\n","\n","Epoch 00157: val_loss improved from 0.77244 to 0.77232, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6779 - acc: 0.6133 - rmse: 0.4928 - val_loss: 0.7723 - val_acc: 0.5000 - val_rmse: 0.5317\n","Epoch 158/800\n","\n","Epoch 00158: val_loss improved from 0.77232 to 0.77220, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6778 - acc: 0.6133 - rmse: 0.4945 - val_loss: 0.7722 - val_acc: 0.5000 - val_rmse: 0.5325\n","Epoch 159/800\n","\n","Epoch 00159: val_loss improved from 0.77220 to 0.77207, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6776 - acc: 0.6133 - rmse: 0.4921 - val_loss: 0.7721 - val_acc: 0.5000 - val_rmse: 0.5312\n","Epoch 160/800\n","\n","Epoch 00160: val_loss improved from 0.77207 to 0.77195, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6774 - acc: 0.6133 - rmse: 0.4923 - val_loss: 0.7719 - val_acc: 0.5000 - val_rmse: 0.5314\n","Epoch 161/800\n","\n","Epoch 00161: val_loss improved from 0.77195 to 0.77183, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6772 - acc: 0.6133 - rmse: 0.4917 - val_loss: 0.7718 - val_acc: 0.5000 - val_rmse: 0.5326\n","Epoch 162/800\n","\n","Epoch 00162: val_loss improved from 0.77183 to 0.77170, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6770 - acc: 0.6133 - rmse: 0.4906 - val_loss: 0.7717 - val_acc: 0.5000 - val_rmse: 0.5319\n","Epoch 163/800\n","\n","Epoch 00163: val_loss improved from 0.77170 to 0.77158, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6768 - acc: 0.6133 - rmse: 0.4884 - val_loss: 0.7716 - val_acc: 0.5000 - val_rmse: 0.5324\n","Epoch 164/800\n","\n","Epoch 00164: val_loss improved from 0.77158 to 0.77147, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6767 - acc: 0.6133 - rmse: 0.4912 - val_loss: 0.7715 - val_acc: 0.5000 - val_rmse: 0.5325\n","Epoch 165/800\n","\n","Epoch 00165: val_loss improved from 0.77147 to 0.77135, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6765 - acc: 0.6133 - rmse: 0.4937 - val_loss: 0.7713 - val_acc: 0.5000 - val_rmse: 0.5324\n","Epoch 166/800\n","\n","Epoch 00166: val_loss improved from 0.77135 to 0.77122, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6763 - acc: 0.6133 - rmse: 0.4905 - val_loss: 0.7712 - val_acc: 0.5000 - val_rmse: 0.5315\n","Epoch 167/800\n","\n","Epoch 00167: val_loss improved from 0.77122 to 0.77110, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6761 - acc: 0.6133 - rmse: 0.4903 - val_loss: 0.7711 - val_acc: 0.5000 - val_rmse: 0.5321\n","Epoch 168/800\n","\n","Epoch 00168: val_loss improved from 0.77110 to 0.77098, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6760 - acc: 0.6133 - rmse: 0.4911 - val_loss: 0.7710 - val_acc: 0.5000 - val_rmse: 0.5317\n","Epoch 169/800\n","\n","Epoch 00169: val_loss improved from 0.77098 to 0.77087, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6758 - acc: 0.6133 - rmse: 0.4901 - val_loss: 0.7709 - val_acc: 0.4375 - val_rmse: 0.5322\n","Epoch 170/800\n","\n","Epoch 00170: val_loss improved from 0.77087 to 0.77075, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6756 - acc: 0.6133 - rmse: 0.4909 - val_loss: 0.7708 - val_acc: 0.4375 - val_rmse: 0.5313\n","Epoch 171/800\n","\n","Epoch 00171: val_loss improved from 0.77075 to 0.77064, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6754 - acc: 0.6133 - rmse: 0.4957 - val_loss: 0.7706 - val_acc: 0.4375 - val_rmse: 0.5317\n","Epoch 172/800\n","\n","Epoch 00172: val_loss improved from 0.77064 to 0.77053, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6753 - acc: 0.6133 - rmse: 0.4915 - val_loss: 0.7705 - val_acc: 0.4375 - val_rmse: 0.5319\n","Epoch 173/800\n","\n","Epoch 00173: val_loss improved from 0.77053 to 0.77042, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6751 - acc: 0.6133 - rmse: 0.4917 - val_loss: 0.7704 - val_acc: 0.4375 - val_rmse: 0.5307\n","Epoch 174/800\n","\n","Epoch 00174: val_loss improved from 0.77042 to 0.77030, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6749 - acc: 0.6133 - rmse: 0.4909 - val_loss: 0.7703 - val_acc: 0.4375 - val_rmse: 0.5301\n","Epoch 175/800\n","\n","Epoch 00175: val_loss improved from 0.77030 to 0.77018, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6747 - acc: 0.6133 - rmse: 0.4901 - val_loss: 0.7702 - val_acc: 0.4375 - val_rmse: 0.5309\n","Epoch 176/800\n","\n","Epoch 00176: val_loss improved from 0.77018 to 0.77007, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6745 - acc: 0.6133 - rmse: 0.4900 - val_loss: 0.7701 - val_acc: 0.4375 - val_rmse: 0.5319\n","Epoch 177/800\n","\n","Epoch 00177: val_loss improved from 0.77007 to 0.76996, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6744 - acc: 0.6133 - rmse: 0.4892 - val_loss: 0.7700 - val_acc: 0.4375 - val_rmse: 0.5319\n","Epoch 178/800\n","\n","Epoch 00178: val_loss improved from 0.76996 to 0.76985, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6742 - acc: 0.6133 - rmse: 0.4909 - val_loss: 0.7699 - val_acc: 0.4375 - val_rmse: 0.5322\n","Epoch 179/800\n","\n","Epoch 00179: val_loss improved from 0.76985 to 0.76975, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6740 - acc: 0.6133 - rmse: 0.4914 - val_loss: 0.7698 - val_acc: 0.4375 - val_rmse: 0.5321\n","Epoch 180/800\n","\n","Epoch 00180: val_loss improved from 0.76975 to 0.76964, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6739 - acc: 0.6133 - rmse: 0.4914 - val_loss: 0.7696 - val_acc: 0.4375 - val_rmse: 0.5314\n","Epoch 181/800\n","\n","Epoch 00181: val_loss improved from 0.76964 to 0.76953, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6737 - acc: 0.6133 - rmse: 0.4915 - val_loss: 0.7695 - val_acc: 0.4375 - val_rmse: 0.5322\n","Epoch 182/800\n","\n","Epoch 00182: val_loss improved from 0.76953 to 0.76942, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6735 - acc: 0.6133 - rmse: 0.4904 - val_loss: 0.7694 - val_acc: 0.4375 - val_rmse: 0.5312\n","Epoch 183/800\n","\n","Epoch 00183: val_loss improved from 0.76942 to 0.76931, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6733 - acc: 0.6133 - rmse: 0.4895 - val_loss: 0.7693 - val_acc: 0.4375 - val_rmse: 0.5320\n","Epoch 184/800\n","\n","Epoch 00184: val_loss improved from 0.76931 to 0.76921, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6732 - acc: 0.6133 - rmse: 0.4906 - val_loss: 0.7692 - val_acc: 0.4375 - val_rmse: 0.5315\n","Epoch 185/800\n","\n","Epoch 00185: val_loss improved from 0.76921 to 0.76911, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6730 - acc: 0.6133 - rmse: 0.4905 - val_loss: 0.7691 - val_acc: 0.4375 - val_rmse: 0.5309\n","Epoch 186/800\n","\n","Epoch 00186: val_loss improved from 0.76911 to 0.76900, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6728 - acc: 0.6133 - rmse: 0.4908 - val_loss: 0.7690 - val_acc: 0.4375 - val_rmse: 0.5322\n","Epoch 187/800\n","\n","Epoch 00187: val_loss improved from 0.76900 to 0.76890, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6727 - acc: 0.6133 - rmse: 0.4899 - val_loss: 0.7689 - val_acc: 0.5000 - val_rmse: 0.5319\n","Epoch 188/800\n","\n","Epoch 00188: val_loss improved from 0.76890 to 0.76880, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6725 - acc: 0.6133 - rmse: 0.4841 - val_loss: 0.7688 - val_acc: 0.5000 - val_rmse: 0.5318\n","Epoch 189/800\n","\n","Epoch 00189: val_loss improved from 0.76880 to 0.76871, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6723 - acc: 0.6133 - rmse: 0.4892 - val_loss: 0.7687 - val_acc: 0.5000 - val_rmse: 0.5321\n","Epoch 190/800\n","\n","Epoch 00190: val_loss improved from 0.76871 to 0.76862, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6721 - acc: 0.6133 - rmse: 0.4866 - val_loss: 0.7686 - val_acc: 0.5000 - val_rmse: 0.5321\n","Epoch 191/800\n","\n","Epoch 00191: val_loss improved from 0.76862 to 0.76853, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6720 - acc: 0.6133 - rmse: 0.4884 - val_loss: 0.7685 - val_acc: 0.5000 - val_rmse: 0.5321\n","Epoch 192/800\n","\n","Epoch 00192: val_loss improved from 0.76853 to 0.76844, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6718 - acc: 0.6133 - rmse: 0.4880 - val_loss: 0.7684 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 193/800\n","\n","Epoch 00193: val_loss improved from 0.76844 to 0.76836, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6716 - acc: 0.6133 - rmse: 0.4859 - val_loss: 0.7684 - val_acc: 0.5000 - val_rmse: 0.5314\n","Epoch 194/800\n","\n","Epoch 00194: val_loss improved from 0.76836 to 0.76828, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6715 - acc: 0.6133 - rmse: 0.4901 - val_loss: 0.7683 - val_acc: 0.5000 - val_rmse: 0.5313\n","Epoch 195/800\n","\n","Epoch 00195: val_loss improved from 0.76828 to 0.76820, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6713 - acc: 0.6133 - rmse: 0.4889 - val_loss: 0.7682 - val_acc: 0.5000 - val_rmse: 0.5316\n","Epoch 196/800\n","\n","Epoch 00196: val_loss improved from 0.76820 to 0.76811, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6712 - acc: 0.6133 - rmse: 0.4846 - val_loss: 0.7681 - val_acc: 0.5000 - val_rmse: 0.5318\n","Epoch 197/800\n","\n","Epoch 00197: val_loss improved from 0.76811 to 0.76803, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6710 - acc: 0.6133 - rmse: 0.4860 - val_loss: 0.7680 - val_acc: 0.5000 - val_rmse: 0.5318\n","Epoch 198/800\n","\n","Epoch 00198: val_loss improved from 0.76803 to 0.76794, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6708 - acc: 0.6133 - rmse: 0.4884 - val_loss: 0.7679 - val_acc: 0.5000 - val_rmse: 0.5320\n","Epoch 199/800\n","\n","Epoch 00199: val_loss improved from 0.76794 to 0.76786, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6707 - acc: 0.6133 - rmse: 0.4851 - val_loss: 0.7679 - val_acc: 0.5000 - val_rmse: 0.5297\n","Epoch 200/800\n","\n","Epoch 00200: val_loss improved from 0.76786 to 0.76778, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6705 - acc: 0.6133 - rmse: 0.4878 - val_loss: 0.7678 - val_acc: 0.5000 - val_rmse: 0.5300\n","Epoch 201/800\n","\n","Epoch 00201: val_loss improved from 0.76778 to 0.76769, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6704 - acc: 0.6133 - rmse: 0.4859 - val_loss: 0.7677 - val_acc: 0.5000 - val_rmse: 0.5314\n","Epoch 202/800\n","\n","Epoch 00202: val_loss improved from 0.76769 to 0.76761, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6702 - acc: 0.6133 - rmse: 0.4866 - val_loss: 0.7676 - val_acc: 0.5000 - val_rmse: 0.5315\n","Epoch 203/800\n","\n","Epoch 00203: val_loss improved from 0.76761 to 0.76753, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6700 - acc: 0.6000 - rmse: 0.4865 - val_loss: 0.7675 - val_acc: 0.5000 - val_rmse: 0.5303\n","Epoch 204/800\n","\n","Epoch 00204: val_loss improved from 0.76753 to 0.76745, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6699 - acc: 0.5867 - rmse: 0.4885 - val_loss: 0.7675 - val_acc: 0.5000 - val_rmse: 0.5313\n","Epoch 205/800\n","\n","Epoch 00205: val_loss improved from 0.76745 to 0.76738, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6697 - acc: 0.5867 - rmse: 0.4864 - val_loss: 0.7674 - val_acc: 0.5000 - val_rmse: 0.5310\n","Epoch 206/800\n","\n","Epoch 00206: val_loss improved from 0.76738 to 0.76730, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6696 - acc: 0.5867 - rmse: 0.4887 - val_loss: 0.7673 - val_acc: 0.5000 - val_rmse: 0.5319\n","Epoch 207/800\n","\n","Epoch 00207: val_loss improved from 0.76730 to 0.76722, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6694 - acc: 0.5867 - rmse: 0.4897 - val_loss: 0.7672 - val_acc: 0.5000 - val_rmse: 0.5316\n","Epoch 208/800\n","\n","Epoch 00208: val_loss improved from 0.76722 to 0.76713, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6692 - acc: 0.5867 - rmse: 0.4859 - val_loss: 0.7671 - val_acc: 0.5000 - val_rmse: 0.5319\n","Epoch 209/800\n","\n","Epoch 00209: val_loss improved from 0.76713 to 0.76705, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6691 - acc: 0.5867 - rmse: 0.4913 - val_loss: 0.7671 - val_acc: 0.5000 - val_rmse: 0.5294\n","Epoch 210/800\n","\n","Epoch 00210: val_loss improved from 0.76705 to 0.76698, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6689 - acc: 0.5867 - rmse: 0.4879 - val_loss: 0.7670 - val_acc: 0.5000 - val_rmse: 0.5318\n","Epoch 211/800\n","\n","Epoch 00211: val_loss improved from 0.76698 to 0.76689, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6687 - acc: 0.5867 - rmse: 0.4863 - val_loss: 0.7669 - val_acc: 0.5000 - val_rmse: 0.5316\n","Epoch 212/800\n","\n","Epoch 00212: val_loss improved from 0.76689 to 0.76681, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6686 - acc: 0.5867 - rmse: 0.4862 - val_loss: 0.7668 - val_acc: 0.5000 - val_rmse: 0.5318\n","Epoch 213/800\n","\n","Epoch 00213: val_loss improved from 0.76681 to 0.76673, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6685 - acc: 0.5867 - rmse: 0.4876 - val_loss: 0.7667 - val_acc: 0.5000 - val_rmse: 0.5306\n","Epoch 214/800\n","\n","Epoch 00214: val_loss improved from 0.76673 to 0.76665, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6683 - acc: 0.5867 - rmse: 0.4870 - val_loss: 0.7667 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 215/800\n","\n","Epoch 00215: val_loss improved from 0.76665 to 0.76657, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6681 - acc: 0.5867 - rmse: 0.4842 - val_loss: 0.7666 - val_acc: 0.5000 - val_rmse: 0.5297\n","Epoch 216/800\n","\n","Epoch 00216: val_loss improved from 0.76657 to 0.76650, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6679 - acc: 0.5867 - rmse: 0.4882 - val_loss: 0.7665 - val_acc: 0.5000 - val_rmse: 0.5317\n","Epoch 217/800\n","\n","Epoch 00217: val_loss improved from 0.76650 to 0.76642, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6678 - acc: 0.5867 - rmse: 0.4869 - val_loss: 0.7664 - val_acc: 0.5000 - val_rmse: 0.5313\n","Epoch 218/800\n","\n","Epoch 00218: val_loss improved from 0.76642 to 0.76635, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6676 - acc: 0.5867 - rmse: 0.4863 - val_loss: 0.7664 - val_acc: 0.5000 - val_rmse: 0.5312\n","Epoch 219/800\n","\n","Epoch 00219: val_loss improved from 0.76635 to 0.76628, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6675 - acc: 0.5867 - rmse: 0.4862 - val_loss: 0.7663 - val_acc: 0.5000 - val_rmse: 0.5304\n","Epoch 220/800\n","\n","Epoch 00220: val_loss improved from 0.76628 to 0.76621, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6673 - acc: 0.5867 - rmse: 0.4830 - val_loss: 0.7662 - val_acc: 0.5000 - val_rmse: 0.5310\n","Epoch 221/800\n","\n","Epoch 00221: val_loss improved from 0.76621 to 0.76614, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6672 - acc: 0.5867 - rmse: 0.4868 - val_loss: 0.7661 - val_acc: 0.5000 - val_rmse: 0.5297\n","Epoch 222/800\n","\n","Epoch 00222: val_loss improved from 0.76614 to 0.76607, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6670 - acc: 0.5867 - rmse: 0.4881 - val_loss: 0.7661 - val_acc: 0.5000 - val_rmse: 0.5315\n","Epoch 223/800\n","\n","Epoch 00223: val_loss improved from 0.76607 to 0.76600, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6669 - acc: 0.5600 - rmse: 0.4875 - val_loss: 0.7660 - val_acc: 0.5000 - val_rmse: 0.5313\n","Epoch 224/800\n","\n","Epoch 00224: val_loss improved from 0.76600 to 0.76594, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6667 - acc: 0.5600 - rmse: 0.4871 - val_loss: 0.7659 - val_acc: 0.5000 - val_rmse: 0.5316\n","Epoch 225/800\n","\n","Epoch 00225: val_loss improved from 0.76594 to 0.76587, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6665 - acc: 0.5600 - rmse: 0.4871 - val_loss: 0.7659 - val_acc: 0.5000 - val_rmse: 0.5312\n","Epoch 226/800\n","\n","Epoch 00226: val_loss improved from 0.76587 to 0.76580, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6664 - acc: 0.5600 - rmse: 0.4875 - val_loss: 0.7658 - val_acc: 0.5000 - val_rmse: 0.5276\n","Epoch 227/800\n","\n","Epoch 00227: val_loss improved from 0.76580 to 0.76573, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6663 - acc: 0.5600 - rmse: 0.4845 - val_loss: 0.7657 - val_acc: 0.5000 - val_rmse: 0.5312\n","Epoch 228/800\n","\n","Epoch 00228: val_loss improved from 0.76573 to 0.76565, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6661 - acc: 0.5600 - rmse: 0.4828 - val_loss: 0.7657 - val_acc: 0.5000 - val_rmse: 0.5316\n","Epoch 229/800\n","\n","Epoch 00229: val_loss improved from 0.76565 to 0.76558, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6660 - acc: 0.5600 - rmse: 0.4876 - val_loss: 0.7656 - val_acc: 0.5000 - val_rmse: 0.5299\n","Epoch 230/800\n","\n","Epoch 00230: val_loss improved from 0.76558 to 0.76551, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6658 - acc: 0.5733 - rmse: 0.4843 - val_loss: 0.7655 - val_acc: 0.5000 - val_rmse: 0.5311\n","Epoch 231/800\n","\n","Epoch 00231: val_loss improved from 0.76551 to 0.76544, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6656 - acc: 0.5733 - rmse: 0.4860 - val_loss: 0.7654 - val_acc: 0.5000 - val_rmse: 0.5316\n","Epoch 232/800\n","\n","Epoch 00232: val_loss improved from 0.76544 to 0.76537, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6655 - acc: 0.5733 - rmse: 0.4873 - val_loss: 0.7654 - val_acc: 0.5000 - val_rmse: 0.5314\n","Epoch 233/800\n","\n","Epoch 00233: val_loss improved from 0.76537 to 0.76530, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6653 - acc: 0.5733 - rmse: 0.4872 - val_loss: 0.7653 - val_acc: 0.5000 - val_rmse: 0.5316\n","Epoch 234/800\n","\n","Epoch 00234: val_loss improved from 0.76530 to 0.76523, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6652 - acc: 0.5733 - rmse: 0.4874 - val_loss: 0.7652 - val_acc: 0.5000 - val_rmse: 0.5315\n","Epoch 235/800\n","\n","Epoch 00235: val_loss improved from 0.76523 to 0.76515, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6650 - acc: 0.5200 - rmse: 0.4856 - val_loss: 0.7652 - val_acc: 0.5000 - val_rmse: 0.5303\n","Epoch 236/800\n","\n","Epoch 00236: val_loss improved from 0.76515 to 0.76508, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6649 - acc: 0.5200 - rmse: 0.4841 - val_loss: 0.7651 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 237/800\n","\n","Epoch 00237: val_loss improved from 0.76508 to 0.76502, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6647 - acc: 0.5200 - rmse: 0.4885 - val_loss: 0.7650 - val_acc: 0.5000 - val_rmse: 0.5310\n","Epoch 238/800\n","\n","Epoch 00238: val_loss improved from 0.76502 to 0.76495, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6646 - acc: 0.5200 - rmse: 0.4793 - val_loss: 0.7649 - val_acc: 0.5000 - val_rmse: 0.5310\n","Epoch 239/800\n","\n","Epoch 00239: val_loss improved from 0.76495 to 0.76488, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6645 - acc: 0.5200 - rmse: 0.4826 - val_loss: 0.7649 - val_acc: 0.5000 - val_rmse: 0.5292\n","Epoch 240/800\n","\n","Epoch 00240: val_loss improved from 0.76488 to 0.76482, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6643 - acc: 0.5200 - rmse: 0.4852 - val_loss: 0.7648 - val_acc: 0.5000 - val_rmse: 0.5313\n","Epoch 241/800\n","\n","Epoch 00241: val_loss improved from 0.76482 to 0.76475, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6642 - acc: 0.5200 - rmse: 0.4853 - val_loss: 0.7648 - val_acc: 0.5000 - val_rmse: 0.5315\n","Epoch 242/800\n","\n","Epoch 00242: val_loss improved from 0.76475 to 0.76470, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6640 - acc: 0.5200 - rmse: 0.4861 - val_loss: 0.7647 - val_acc: 0.5000 - val_rmse: 0.5315\n","Epoch 243/800\n","\n","Epoch 00243: val_loss improved from 0.76470 to 0.76463, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6639 - acc: 0.5200 - rmse: 0.4864 - val_loss: 0.7646 - val_acc: 0.5000 - val_rmse: 0.5297\n","Epoch 244/800\n","\n","Epoch 00244: val_loss improved from 0.76463 to 0.76457, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6637 - acc: 0.5200 - rmse: 0.4871 - val_loss: 0.7646 - val_acc: 0.5000 - val_rmse: 0.5304\n","Epoch 245/800\n","\n","Epoch 00245: val_loss improved from 0.76457 to 0.76450, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6636 - acc: 0.5200 - rmse: 0.4878 - val_loss: 0.7645 - val_acc: 0.5000 - val_rmse: 0.5314\n","Epoch 246/800\n","\n","Epoch 00246: val_loss improved from 0.76450 to 0.76444, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6635 - acc: 0.5200 - rmse: 0.4867 - val_loss: 0.7644 - val_acc: 0.5000 - val_rmse: 0.5283\n","Epoch 247/800\n","\n","Epoch 00247: val_loss improved from 0.76444 to 0.76437, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6633 - acc: 0.5200 - rmse: 0.4850 - val_loss: 0.7644 - val_acc: 0.5000 - val_rmse: 0.5302\n","Epoch 248/800\n","\n","Epoch 00248: val_loss improved from 0.76437 to 0.76430, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6632 - acc: 0.5200 - rmse: 0.4868 - val_loss: 0.7643 - val_acc: 0.5000 - val_rmse: 0.5278\n","Epoch 249/800\n","\n","Epoch 00249: val_loss improved from 0.76430 to 0.76423, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6631 - acc: 0.5200 - rmse: 0.4877 - val_loss: 0.7642 - val_acc: 0.5000 - val_rmse: 0.5295\n","Epoch 250/800\n","\n","Epoch 00250: val_loss improved from 0.76423 to 0.76415, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6629 - acc: 0.5200 - rmse: 0.4864 - val_loss: 0.7642 - val_acc: 0.5000 - val_rmse: 0.5314\n","Epoch 251/800\n","\n","Epoch 00251: val_loss improved from 0.76415 to 0.76408, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6627 - acc: 0.5200 - rmse: 0.4858 - val_loss: 0.7641 - val_acc: 0.5000 - val_rmse: 0.5314\n","Epoch 252/800\n","\n","Epoch 00252: val_loss improved from 0.76408 to 0.76401, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6626 - acc: 0.5200 - rmse: 0.4862 - val_loss: 0.7640 - val_acc: 0.5000 - val_rmse: 0.5312\n","Epoch 253/800\n","\n","Epoch 00253: val_loss improved from 0.76401 to 0.76394, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6625 - acc: 0.5200 - rmse: 0.4810 - val_loss: 0.7639 - val_acc: 0.5000 - val_rmse: 0.5310\n","Epoch 254/800\n","\n","Epoch 00254: val_loss improved from 0.76394 to 0.76387, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6623 - acc: 0.5200 - rmse: 0.4855 - val_loss: 0.7639 - val_acc: 0.5000 - val_rmse: 0.5313\n","Epoch 255/800\n","\n","Epoch 00255: val_loss improved from 0.76387 to 0.76380, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6622 - acc: 0.5200 - rmse: 0.4881 - val_loss: 0.7638 - val_acc: 0.5000 - val_rmse: 0.5312\n","Epoch 256/800\n","\n","Epoch 00256: val_loss improved from 0.76380 to 0.76374, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6621 - acc: 0.5200 - rmse: 0.4834 - val_loss: 0.7637 - val_acc: 0.5000 - val_rmse: 0.5313\n","Epoch 257/800\n","\n","Epoch 00257: val_loss improved from 0.76374 to 0.76368, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6619 - acc: 0.5200 - rmse: 0.4869 - val_loss: 0.7637 - val_acc: 0.5000 - val_rmse: 0.5296\n","Epoch 258/800\n","\n","Epoch 00258: val_loss improved from 0.76368 to 0.76362, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6618 - acc: 0.5200 - rmse: 0.4867 - val_loss: 0.7636 - val_acc: 0.5000 - val_rmse: 0.5312\n","Epoch 259/800\n","\n","Epoch 00259: val_loss improved from 0.76362 to 0.76356, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6616 - acc: 0.5200 - rmse: 0.4845 - val_loss: 0.7636 - val_acc: 0.5000 - val_rmse: 0.5308\n","Epoch 260/800\n","\n","Epoch 00260: val_loss improved from 0.76356 to 0.76349, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6615 - acc: 0.5200 - rmse: 0.4829 - val_loss: 0.7635 - val_acc: 0.5000 - val_rmse: 0.5286\n","Epoch 261/800\n","\n","Epoch 00261: val_loss improved from 0.76349 to 0.76343, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6614 - acc: 0.5200 - rmse: 0.4829 - val_loss: 0.7634 - val_acc: 0.5000 - val_rmse: 0.5290\n","Epoch 262/800\n","\n","Epoch 00262: val_loss improved from 0.76343 to 0.76337, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6612 - acc: 0.5200 - rmse: 0.4872 - val_loss: 0.7634 - val_acc: 0.5000 - val_rmse: 0.5311\n","Epoch 263/800\n","\n","Epoch 00263: val_loss improved from 0.76337 to 0.76332, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6611 - acc: 0.5200 - rmse: 0.4810 - val_loss: 0.7633 - val_acc: 0.5000 - val_rmse: 0.5284\n","Epoch 264/800\n","\n","Epoch 00264: val_loss improved from 0.76332 to 0.76325, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6609 - acc: 0.5200 - rmse: 0.4842 - val_loss: 0.7633 - val_acc: 0.5000 - val_rmse: 0.5297\n","Epoch 265/800\n","\n","Epoch 00265: val_loss improved from 0.76325 to 0.76319, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6608 - acc: 0.5200 - rmse: 0.4831 - val_loss: 0.7632 - val_acc: 0.5000 - val_rmse: 0.5284\n","Epoch 266/800\n","\n","Epoch 00266: val_loss improved from 0.76319 to 0.76313, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6606 - acc: 0.5200 - rmse: 0.4816 - val_loss: 0.7631 - val_acc: 0.5000 - val_rmse: 0.5312\n","Epoch 267/800\n","\n","Epoch 00267: val_loss improved from 0.76313 to 0.76307, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6605 - acc: 0.5200 - rmse: 0.4867 - val_loss: 0.7631 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 268/800\n","\n","Epoch 00268: val_loss improved from 0.76307 to 0.76301, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6604 - acc: 0.5200 - rmse: 0.4834 - val_loss: 0.7630 - val_acc: 0.5000 - val_rmse: 0.5305\n","Epoch 269/800\n","\n","Epoch 00269: val_loss improved from 0.76301 to 0.76295, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6602 - acc: 0.5200 - rmse: 0.4854 - val_loss: 0.7629 - val_acc: 0.5000 - val_rmse: 0.5293\n","Epoch 270/800\n","\n","Epoch 00270: val_loss improved from 0.76295 to 0.76289, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6601 - acc: 0.5200 - rmse: 0.4832 - val_loss: 0.7629 - val_acc: 0.5000 - val_rmse: 0.5310\n","Epoch 271/800\n","\n","Epoch 00271: val_loss improved from 0.76289 to 0.76284, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6599 - acc: 0.5200 - rmse: 0.4813 - val_loss: 0.7628 - val_acc: 0.5000 - val_rmse: 0.5312\n","Epoch 272/800\n","\n","Epoch 00272: val_loss improved from 0.76284 to 0.76278, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6598 - acc: 0.5200 - rmse: 0.4817 - val_loss: 0.7628 - val_acc: 0.5000 - val_rmse: 0.5297\n","Epoch 273/800\n","\n","Epoch 00273: val_loss improved from 0.76278 to 0.76272, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6597 - acc: 0.5067 - rmse: 0.4813 - val_loss: 0.7627 - val_acc: 0.5000 - val_rmse: 0.5309\n","Epoch 274/800\n","\n","Epoch 00274: val_loss improved from 0.76272 to 0.76267, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6595 - acc: 0.5200 - rmse: 0.4863 - val_loss: 0.7627 - val_acc: 0.5000 - val_rmse: 0.5297\n","Epoch 275/800\n","\n","Epoch 00275: val_loss improved from 0.76267 to 0.76262, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6594 - acc: 0.5200 - rmse: 0.4821 - val_loss: 0.7626 - val_acc: 0.5000 - val_rmse: 0.5311\n","Epoch 276/800\n","\n","Epoch 00276: val_loss improved from 0.76262 to 0.76257, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6593 - acc: 0.5200 - rmse: 0.4839 - val_loss: 0.7626 - val_acc: 0.5000 - val_rmse: 0.5309\n","Epoch 277/800\n","\n","Epoch 00277: val_loss improved from 0.76257 to 0.76251, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6591 - acc: 0.5200 - rmse: 0.4842 - val_loss: 0.7625 - val_acc: 0.5000 - val_rmse: 0.5304\n","Epoch 278/800\n","\n","Epoch 00278: val_loss improved from 0.76251 to 0.76245, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6590 - acc: 0.5200 - rmse: 0.4837 - val_loss: 0.7625 - val_acc: 0.5000 - val_rmse: 0.5296\n","Epoch 279/800\n","\n","Epoch 00279: val_loss improved from 0.76245 to 0.76240, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6588 - acc: 0.5200 - rmse: 0.4843 - val_loss: 0.7624 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 280/800\n","\n","Epoch 00280: val_loss improved from 0.76240 to 0.76235, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6587 - acc: 0.5200 - rmse: 0.4839 - val_loss: 0.7623 - val_acc: 0.5000 - val_rmse: 0.5293\n","Epoch 281/800\n","\n","Epoch 00281: val_loss improved from 0.76235 to 0.76229, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6586 - acc: 0.5467 - rmse: 0.4817 - val_loss: 0.7623 - val_acc: 0.5000 - val_rmse: 0.5311\n","Epoch 282/800\n","\n","Epoch 00282: val_loss improved from 0.76229 to 0.76225, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6585 - acc: 0.5467 - rmse: 0.4833 - val_loss: 0.7622 - val_acc: 0.5000 - val_rmse: 0.5302\n","Epoch 283/800\n","\n","Epoch 00283: val_loss improved from 0.76225 to 0.76220, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6583 - acc: 0.5467 - rmse: 0.4803 - val_loss: 0.7622 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 284/800\n","\n","Epoch 00284: val_loss improved from 0.76220 to 0.76215, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6582 - acc: 0.5467 - rmse: 0.4836 - val_loss: 0.7622 - val_acc: 0.5000 - val_rmse: 0.5305\n","Epoch 285/800\n","\n","Epoch 00285: val_loss improved from 0.76215 to 0.76211, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6580 - acc: 0.5733 - rmse: 0.4821 - val_loss: 0.7621 - val_acc: 0.5000 - val_rmse: 0.5292\n","Epoch 286/800\n","\n","Epoch 00286: val_loss improved from 0.76211 to 0.76206, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6579 - acc: 0.5733 - rmse: 0.4812 - val_loss: 0.7621 - val_acc: 0.5000 - val_rmse: 0.5303\n","Epoch 287/800\n","\n","Epoch 00287: val_loss improved from 0.76206 to 0.76202, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6578 - acc: 0.5733 - rmse: 0.4862 - val_loss: 0.7620 - val_acc: 0.5000 - val_rmse: 0.5302\n","Epoch 288/800\n","\n","Epoch 00288: val_loss improved from 0.76202 to 0.76197, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6576 - acc: 0.5733 - rmse: 0.4816 - val_loss: 0.7620 - val_acc: 0.5000 - val_rmse: 0.5308\n","Epoch 289/800\n","\n","Epoch 00289: val_loss improved from 0.76197 to 0.76192, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6575 - acc: 0.5733 - rmse: 0.4801 - val_loss: 0.7619 - val_acc: 0.5000 - val_rmse: 0.5290\n","Epoch 290/800\n","\n","Epoch 00290: val_loss improved from 0.76192 to 0.76188, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6574 - acc: 0.5733 - rmse: 0.4808 - val_loss: 0.7619 - val_acc: 0.5000 - val_rmse: 0.5294\n","Epoch 291/800\n","\n","Epoch 00291: val_loss improved from 0.76188 to 0.76183, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6572 - acc: 0.5733 - rmse: 0.4800 - val_loss: 0.7618 - val_acc: 0.5000 - val_rmse: 0.5303\n","Epoch 292/800\n","\n","Epoch 00292: val_loss improved from 0.76183 to 0.76178, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6571 - acc: 0.5733 - rmse: 0.4831 - val_loss: 0.7618 - val_acc: 0.5000 - val_rmse: 0.5292\n","Epoch 293/800\n","\n","Epoch 00293: val_loss improved from 0.76178 to 0.76174, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6570 - acc: 0.5733 - rmse: 0.4795 - val_loss: 0.7617 - val_acc: 0.5000 - val_rmse: 0.5295\n","Epoch 294/800\n","\n","Epoch 00294: val_loss improved from 0.76174 to 0.76170, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6568 - acc: 0.5467 - rmse: 0.4835 - val_loss: 0.7617 - val_acc: 0.5000 - val_rmse: 0.5309\n","Epoch 295/800\n","\n","Epoch 00295: val_loss improved from 0.76170 to 0.76165, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6567 - acc: 0.5467 - rmse: 0.4842 - val_loss: 0.7617 - val_acc: 0.5000 - val_rmse: 0.5309\n","Epoch 296/800\n","\n","Epoch 00296: val_loss improved from 0.76165 to 0.76161, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6565 - acc: 0.5467 - rmse: 0.4815 - val_loss: 0.7616 - val_acc: 0.5000 - val_rmse: 0.5309\n","Epoch 297/800\n","\n","Epoch 00297: val_loss improved from 0.76161 to 0.76157, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6564 - acc: 0.5467 - rmse: 0.4743 - val_loss: 0.7616 - val_acc: 0.5000 - val_rmse: 0.5308\n","Epoch 298/800\n","\n","Epoch 00298: val_loss improved from 0.76157 to 0.76153, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6563 - acc: 0.5467 - rmse: 0.4827 - val_loss: 0.7615 - val_acc: 0.5000 - val_rmse: 0.5285\n","Epoch 299/800\n","\n","Epoch 00299: val_loss improved from 0.76153 to 0.76149, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6562 - acc: 0.5467 - rmse: 0.4768 - val_loss: 0.7615 - val_acc: 0.5000 - val_rmse: 0.5295\n","Epoch 300/800\n","\n","Epoch 00300: val_loss improved from 0.76149 to 0.76145, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6560 - acc: 0.5467 - rmse: 0.4809 - val_loss: 0.7615 - val_acc: 0.5000 - val_rmse: 0.5285\n","Epoch 301/800\n","\n","Epoch 00301: val_loss improved from 0.76145 to 0.76142, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6559 - acc: 0.5467 - rmse: 0.4792 - val_loss: 0.7614 - val_acc: 0.5000 - val_rmse: 0.5309\n","Epoch 302/800\n","\n","Epoch 00302: val_loss improved from 0.76142 to 0.76138, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6558 - acc: 0.5467 - rmse: 0.4804 - val_loss: 0.7614 - val_acc: 0.5000 - val_rmse: 0.5304\n","Epoch 303/800\n","\n","Epoch 00303: val_loss improved from 0.76138 to 0.76135, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6556 - acc: 0.5467 - rmse: 0.4790 - val_loss: 0.7613 - val_acc: 0.5000 - val_rmse: 0.5283\n","Epoch 304/800\n","\n","Epoch 00304: val_loss improved from 0.76135 to 0.76131, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6555 - acc: 0.5467 - rmse: 0.4778 - val_loss: 0.7613 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 305/800\n","\n","Epoch 00305: val_loss improved from 0.76131 to 0.76127, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6554 - acc: 0.5467 - rmse: 0.4839 - val_loss: 0.7613 - val_acc: 0.5000 - val_rmse: 0.5296\n","Epoch 306/800\n","\n","Epoch 00306: val_loss improved from 0.76127 to 0.76123, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6552 - acc: 0.5467 - rmse: 0.4813 - val_loss: 0.7612 - val_acc: 0.5000 - val_rmse: 0.5294\n","Epoch 307/800\n","\n","Epoch 00307: val_loss improved from 0.76123 to 0.76119, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6551 - acc: 0.5467 - rmse: 0.4803 - val_loss: 0.7612 - val_acc: 0.5000 - val_rmse: 0.5299\n","Epoch 308/800\n","\n","Epoch 00308: val_loss improved from 0.76119 to 0.76115, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6550 - acc: 0.5600 - rmse: 0.4794 - val_loss: 0.7611 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 309/800\n","\n","Epoch 00309: val_loss improved from 0.76115 to 0.76111, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6549 - acc: 0.5600 - rmse: 0.4805 - val_loss: 0.7611 - val_acc: 0.5000 - val_rmse: 0.5295\n","Epoch 310/800\n","\n","Epoch 00310: val_loss improved from 0.76111 to 0.76108, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6547 - acc: 0.5600 - rmse: 0.4781 - val_loss: 0.7611 - val_acc: 0.5000 - val_rmse: 0.5270\n","Epoch 311/800\n","\n","Epoch 00311: val_loss improved from 0.76108 to 0.76104, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6546 - acc: 0.5600 - rmse: 0.4797 - val_loss: 0.7610 - val_acc: 0.5000 - val_rmse: 0.5301\n","Epoch 312/800\n","\n","Epoch 00312: val_loss improved from 0.76104 to 0.76100, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6545 - acc: 0.5600 - rmse: 0.4827 - val_loss: 0.7610 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 313/800\n","\n","Epoch 00313: val_loss improved from 0.76100 to 0.76097, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6543 - acc: 0.5600 - rmse: 0.4795 - val_loss: 0.7610 - val_acc: 0.5000 - val_rmse: 0.5308\n","Epoch 314/800\n","\n","Epoch 00314: val_loss improved from 0.76097 to 0.76093, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6542 - acc: 0.5600 - rmse: 0.4812 - val_loss: 0.7609 - val_acc: 0.5000 - val_rmse: 0.5302\n","Epoch 315/800\n","\n","Epoch 00315: val_loss improved from 0.76093 to 0.76089, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6541 - acc: 0.5600 - rmse: 0.4797 - val_loss: 0.7609 - val_acc: 0.5000 - val_rmse: 0.5308\n","Epoch 316/800\n","\n","Epoch 00316: val_loss improved from 0.76089 to 0.76086, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6539 - acc: 0.5600 - rmse: 0.4789 - val_loss: 0.7609 - val_acc: 0.5000 - val_rmse: 0.5291\n","Epoch 317/800\n","\n","Epoch 00317: val_loss improved from 0.76086 to 0.76082, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6538 - acc: 0.5600 - rmse: 0.4767 - val_loss: 0.7608 - val_acc: 0.5000 - val_rmse: 0.5308\n","Epoch 318/800\n","\n","Epoch 00318: val_loss improved from 0.76082 to 0.76078, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6537 - acc: 0.5600 - rmse: 0.4795 - val_loss: 0.7608 - val_acc: 0.5000 - val_rmse: 0.5308\n","Epoch 319/800\n","\n","Epoch 00319: val_loss improved from 0.76078 to 0.76075, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6536 - acc: 0.5600 - rmse: 0.4791 - val_loss: 0.7608 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 320/800\n","\n","Epoch 00320: val_loss improved from 0.76075 to 0.76072, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6534 - acc: 0.5600 - rmse: 0.4783 - val_loss: 0.7607 - val_acc: 0.5000 - val_rmse: 0.5289\n","Epoch 321/800\n","\n","Epoch 00321: val_loss improved from 0.76072 to 0.76069, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6533 - acc: 0.5600 - rmse: 0.4813 - val_loss: 0.7607 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 322/800\n","\n","Epoch 00322: val_loss improved from 0.76069 to 0.76065, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6531 - acc: 0.5600 - rmse: 0.4820 - val_loss: 0.7607 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 323/800\n","\n","Epoch 00323: val_loss improved from 0.76065 to 0.76062, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6530 - acc: 0.5600 - rmse: 0.4803 - val_loss: 0.7606 - val_acc: 0.5000 - val_rmse: 0.5294\n","Epoch 324/800\n","\n","Epoch 00324: val_loss improved from 0.76062 to 0.76059, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6529 - acc: 0.5600 - rmse: 0.4775 - val_loss: 0.7606 - val_acc: 0.5000 - val_rmse: 0.5295\n","Epoch 325/800\n","\n","Epoch 00325: val_loss improved from 0.76059 to 0.76056, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6528 - acc: 0.5600 - rmse: 0.4809 - val_loss: 0.7606 - val_acc: 0.5000 - val_rmse: 0.5273\n","Epoch 326/800\n","\n","Epoch 00326: val_loss improved from 0.76056 to 0.76053, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6526 - acc: 0.5600 - rmse: 0.4827 - val_loss: 0.7605 - val_acc: 0.5000 - val_rmse: 0.5303\n","Epoch 327/800\n","\n","Epoch 00327: val_loss improved from 0.76053 to 0.76050, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6525 - acc: 0.5600 - rmse: 0.4781 - val_loss: 0.7605 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 328/800\n","\n","Epoch 00328: val_loss improved from 0.76050 to 0.76046, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6524 - acc: 0.5600 - rmse: 0.4772 - val_loss: 0.7605 - val_acc: 0.5000 - val_rmse: 0.5296\n","Epoch 329/800\n","\n","Epoch 00329: val_loss improved from 0.76046 to 0.76043, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6522 - acc: 0.5600 - rmse: 0.4805 - val_loss: 0.7604 - val_acc: 0.5000 - val_rmse: 0.5283\n","Epoch 330/800\n","\n","Epoch 00330: val_loss improved from 0.76043 to 0.76040, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6521 - acc: 0.5600 - rmse: 0.4803 - val_loss: 0.7604 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 331/800\n","\n","Epoch 00331: val_loss improved from 0.76040 to 0.76037, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6520 - acc: 0.5600 - rmse: 0.4788 - val_loss: 0.7604 - val_acc: 0.5000 - val_rmse: 0.5307\n","Epoch 332/800\n","\n","Epoch 00332: val_loss improved from 0.76037 to 0.76034, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6519 - acc: 0.5600 - rmse: 0.4825 - val_loss: 0.7603 - val_acc: 0.5000 - val_rmse: 0.5303\n","Epoch 333/800\n","\n","Epoch 00333: val_loss improved from 0.76034 to 0.76031, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6517 - acc: 0.5600 - rmse: 0.4754 - val_loss: 0.7603 - val_acc: 0.5000 - val_rmse: 0.5305\n","Epoch 334/800\n","\n","Epoch 00334: val_loss improved from 0.76031 to 0.76028, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6516 - acc: 0.5600 - rmse: 0.4780 - val_loss: 0.7603 - val_acc: 0.5000 - val_rmse: 0.5305\n","Epoch 335/800\n","\n","Epoch 00335: val_loss improved from 0.76028 to 0.76025, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6515 - acc: 0.5600 - rmse: 0.4763 - val_loss: 0.7603 - val_acc: 0.5000 - val_rmse: 0.5306\n","Epoch 336/800\n","\n","Epoch 00336: val_loss improved from 0.76025 to 0.76022, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6513 - acc: 0.5600 - rmse: 0.4814 - val_loss: 0.7602 - val_acc: 0.5000 - val_rmse: 0.5306\n","Epoch 337/800\n","\n","Epoch 00337: val_loss improved from 0.76022 to 0.76019, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6512 - acc: 0.5600 - rmse: 0.4751 - val_loss: 0.7602 - val_acc: 0.5000 - val_rmse: 0.5300\n","Epoch 338/800\n","\n","Epoch 00338: val_loss improved from 0.76019 to 0.76016, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6511 - acc: 0.5600 - rmse: 0.4758 - val_loss: 0.7602 - val_acc: 0.5000 - val_rmse: 0.5296\n","Epoch 339/800\n","\n","Epoch 00339: val_loss improved from 0.76016 to 0.76013, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6510 - acc: 0.5600 - rmse: 0.4788 - val_loss: 0.7601 - val_acc: 0.5000 - val_rmse: 0.5306\n","Epoch 340/800\n","\n","Epoch 00340: val_loss improved from 0.76013 to 0.76010, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6508 - acc: 0.5867 - rmse: 0.4779 - val_loss: 0.7601 - val_acc: 0.5000 - val_rmse: 0.5283\n","Epoch 341/800\n","\n","Epoch 00341: val_loss improved from 0.76010 to 0.76007, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6507 - acc: 0.5867 - rmse: 0.4826 - val_loss: 0.7601 - val_acc: 0.5000 - val_rmse: 0.5261\n","Epoch 342/800\n","\n","Epoch 00342: val_loss improved from 0.76007 to 0.76004, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6506 - acc: 0.5867 - rmse: 0.4789 - val_loss: 0.7600 - val_acc: 0.5000 - val_rmse: 0.5306\n","Epoch 343/800\n","\n","Epoch 00343: val_loss improved from 0.76004 to 0.76001, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6504 - acc: 0.5867 - rmse: 0.4802 - val_loss: 0.7600 - val_acc: 0.5000 - val_rmse: 0.5278\n","Epoch 344/800\n","\n","Epoch 00344: val_loss improved from 0.76001 to 0.75998, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6503 - acc: 0.5867 - rmse: 0.4798 - val_loss: 0.7600 - val_acc: 0.5000 - val_rmse: 0.5294\n","Epoch 345/800\n","\n","Epoch 00345: val_loss improved from 0.75998 to 0.75995, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6502 - acc: 0.5867 - rmse: 0.4780 - val_loss: 0.7600 - val_acc: 0.5000 - val_rmse: 0.5301\n","Epoch 346/800\n","\n","Epoch 00346: val_loss improved from 0.75995 to 0.75992, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6501 - acc: 0.5867 - rmse: 0.4791 - val_loss: 0.7599 - val_acc: 0.5000 - val_rmse: 0.5279\n","Epoch 347/800\n","\n","Epoch 00347: val_loss improved from 0.75992 to 0.75989, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6499 - acc: 0.5867 - rmse: 0.4801 - val_loss: 0.7599 - val_acc: 0.5000 - val_rmse: 0.5302\n","Epoch 348/800\n","\n","Epoch 00348: val_loss improved from 0.75989 to 0.75985, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6498 - acc: 0.5867 - rmse: 0.4794 - val_loss: 0.7599 - val_acc: 0.5000 - val_rmse: 0.5281\n","Epoch 349/800\n","\n","Epoch 00349: val_loss improved from 0.75985 to 0.75983, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6497 - acc: 0.5867 - rmse: 0.4794 - val_loss: 0.7598 - val_acc: 0.5000 - val_rmse: 0.5290\n","Epoch 350/800\n","\n","Epoch 00350: val_loss improved from 0.75983 to 0.75980, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6496 - acc: 0.6000 - rmse: 0.4817 - val_loss: 0.7598 - val_acc: 0.5000 - val_rmse: 0.5295\n","Epoch 351/800\n","\n","Epoch 00351: val_loss improved from 0.75980 to 0.75977, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6494 - acc: 0.6000 - rmse: 0.4808 - val_loss: 0.7598 - val_acc: 0.5000 - val_rmse: 0.5293\n","Epoch 352/800\n","\n","Epoch 00352: val_loss improved from 0.75977 to 0.75974, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6493 - acc: 0.6000 - rmse: 0.4803 - val_loss: 0.7597 - val_acc: 0.5000 - val_rmse: 0.5304\n","Epoch 353/800\n","\n","Epoch 00353: val_loss improved from 0.75974 to 0.75971, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6492 - acc: 0.6000 - rmse: 0.4786 - val_loss: 0.7597 - val_acc: 0.5000 - val_rmse: 0.5305\n","Epoch 354/800\n","\n","Epoch 00354: val_loss improved from 0.75971 to 0.75968, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6491 - acc: 0.6000 - rmse: 0.4780 - val_loss: 0.7597 - val_acc: 0.4375 - val_rmse: 0.5305\n","Epoch 355/800\n","\n","Epoch 00355: val_loss improved from 0.75968 to 0.75965, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6490 - acc: 0.6000 - rmse: 0.4767 - val_loss: 0.7597 - val_acc: 0.4375 - val_rmse: 0.5295\n","Epoch 356/800\n","\n","Epoch 00356: val_loss improved from 0.75965 to 0.75963, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6488 - acc: 0.6000 - rmse: 0.4796 - val_loss: 0.7596 - val_acc: 0.4375 - val_rmse: 0.5303\n","Epoch 357/800\n","\n","Epoch 00357: val_loss improved from 0.75963 to 0.75960, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6487 - acc: 0.6000 - rmse: 0.4754 - val_loss: 0.7596 - val_acc: 0.4375 - val_rmse: 0.5297\n","Epoch 358/800\n","\n","Epoch 00358: val_loss improved from 0.75960 to 0.75957, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6486 - acc: 0.6000 - rmse: 0.4787 - val_loss: 0.7596 - val_acc: 0.4375 - val_rmse: 0.5281\n","Epoch 359/800\n","\n","Epoch 00359: val_loss improved from 0.75957 to 0.75954, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6485 - acc: 0.6000 - rmse: 0.4789 - val_loss: 0.7595 - val_acc: 0.4375 - val_rmse: 0.5303\n","Epoch 360/800\n","\n","Epoch 00360: val_loss improved from 0.75954 to 0.75951, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6483 - acc: 0.6000 - rmse: 0.4794 - val_loss: 0.7595 - val_acc: 0.4375 - val_rmse: 0.5302\n","Epoch 361/800\n","\n","Epoch 00361: val_loss improved from 0.75951 to 0.75948, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6482 - acc: 0.6000 - rmse: 0.4786 - val_loss: 0.7595 - val_acc: 0.4375 - val_rmse: 0.5304\n","Epoch 362/800\n","\n","Epoch 00362: val_loss improved from 0.75948 to 0.75945, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6481 - acc: 0.6000 - rmse: 0.4763 - val_loss: 0.7594 - val_acc: 0.4375 - val_rmse: 0.5303\n","Epoch 363/800\n","\n","Epoch 00363: val_loss improved from 0.75945 to 0.75942, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6480 - acc: 0.6000 - rmse: 0.4755 - val_loss: 0.7594 - val_acc: 0.4375 - val_rmse: 0.5304\n","Epoch 364/800\n","\n","Epoch 00364: val_loss improved from 0.75942 to 0.75939, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6479 - acc: 0.6000 - rmse: 0.4785 - val_loss: 0.7594 - val_acc: 0.4375 - val_rmse: 0.5265\n","Epoch 365/800\n","\n","Epoch 00365: val_loss improved from 0.75939 to 0.75936, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6478 - acc: 0.6000 - rmse: 0.4770 - val_loss: 0.7594 - val_acc: 0.4375 - val_rmse: 0.5302\n","Epoch 366/800\n","\n","Epoch 00366: val_loss improved from 0.75936 to 0.75933, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6477 - acc: 0.6000 - rmse: 0.4820 - val_loss: 0.7593 - val_acc: 0.4375 - val_rmse: 0.5286\n","Epoch 367/800\n","\n","Epoch 00367: val_loss improved from 0.75933 to 0.75930, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6475 - acc: 0.6000 - rmse: 0.4780 - val_loss: 0.7593 - val_acc: 0.4375 - val_rmse: 0.5284\n","Epoch 368/800\n","\n","Epoch 00368: val_loss improved from 0.75930 to 0.75927, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6474 - acc: 0.6000 - rmse: 0.4722 - val_loss: 0.7593 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 369/800\n","\n","Epoch 00369: val_loss improved from 0.75927 to 0.75924, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6473 - acc: 0.6000 - rmse: 0.4769 - val_loss: 0.7592 - val_acc: 0.4375 - val_rmse: 0.5291\n","Epoch 370/800\n","\n","Epoch 00370: val_loss improved from 0.75924 to 0.75922, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6472 - acc: 0.6000 - rmse: 0.4767 - val_loss: 0.7592 - val_acc: 0.4375 - val_rmse: 0.5303\n","Epoch 371/800\n","\n","Epoch 00371: val_loss improved from 0.75922 to 0.75921, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6470 - acc: 0.6000 - rmse: 0.4759 - val_loss: 0.7592 - val_acc: 0.4375 - val_rmse: 0.5302\n","Epoch 372/800\n","\n","Epoch 00372: val_loss improved from 0.75921 to 0.75919, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6469 - acc: 0.6000 - rmse: 0.4743 - val_loss: 0.7592 - val_acc: 0.4375 - val_rmse: 0.5299\n","Epoch 373/800\n","\n","Epoch 00373: val_loss improved from 0.75919 to 0.75917, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6468 - acc: 0.6000 - rmse: 0.4783 - val_loss: 0.7592 - val_acc: 0.4375 - val_rmse: 0.5298\n","Epoch 374/800\n","\n","Epoch 00374: val_loss improved from 0.75917 to 0.75915, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6467 - acc: 0.6000 - rmse: 0.4756 - val_loss: 0.7591 - val_acc: 0.4375 - val_rmse: 0.5303\n","Epoch 375/800\n","\n","Epoch 00375: val_loss improved from 0.75915 to 0.75913, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6466 - acc: 0.6000 - rmse: 0.4765 - val_loss: 0.7591 - val_acc: 0.4375 - val_rmse: 0.5301\n","Epoch 376/800\n","\n","Epoch 00376: val_loss improved from 0.75913 to 0.75912, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6465 - acc: 0.6000 - rmse: 0.4768 - val_loss: 0.7591 - val_acc: 0.4375 - val_rmse: 0.5302\n","Epoch 377/800\n","\n","Epoch 00377: val_loss improved from 0.75912 to 0.75911, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6463 - acc: 0.6000 - rmse: 0.4785 - val_loss: 0.7591 - val_acc: 0.4375 - val_rmse: 0.5301\n","Epoch 378/800\n","\n","Epoch 00378: val_loss improved from 0.75911 to 0.75909, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6462 - acc: 0.6000 - rmse: 0.4749 - val_loss: 0.7591 - val_acc: 0.4375 - val_rmse: 0.5302\n","Epoch 379/800\n","\n","Epoch 00379: val_loss improved from 0.75909 to 0.75908, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6461 - acc: 0.6000 - rmse: 0.4743 - val_loss: 0.7591 - val_acc: 0.4375 - val_rmse: 0.5298\n","Epoch 380/800\n","\n","Epoch 00380: val_loss improved from 0.75908 to 0.75906, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6460 - acc: 0.6000 - rmse: 0.4768 - val_loss: 0.7591 - val_acc: 0.4375 - val_rmse: 0.5300\n","Epoch 381/800\n","\n","Epoch 00381: val_loss improved from 0.75906 to 0.75904, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6459 - acc: 0.6000 - rmse: 0.4766 - val_loss: 0.7590 - val_acc: 0.4375 - val_rmse: 0.5269\n","Epoch 382/800\n","\n","Epoch 00382: val_loss improved from 0.75904 to 0.75903, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6457 - acc: 0.6000 - rmse: 0.4775 - val_loss: 0.7590 - val_acc: 0.4375 - val_rmse: 0.5268\n","Epoch 383/800\n","\n","Epoch 00383: val_loss improved from 0.75903 to 0.75901, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6456 - acc: 0.6000 - rmse: 0.4781 - val_loss: 0.7590 - val_acc: 0.4375 - val_rmse: 0.5303\n","Epoch 384/800\n","\n","Epoch 00384: val_loss improved from 0.75901 to 0.75898, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6455 - acc: 0.6000 - rmse: 0.4703 - val_loss: 0.7590 - val_acc: 0.4375 - val_rmse: 0.5303\n","Epoch 385/800\n","\n","Epoch 00385: val_loss improved from 0.75898 to 0.75897, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6454 - acc: 0.6000 - rmse: 0.4802 - val_loss: 0.7590 - val_acc: 0.4375 - val_rmse: 0.5302\n","Epoch 386/800\n","\n","Epoch 00386: val_loss improved from 0.75897 to 0.75894, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6452 - acc: 0.6000 - rmse: 0.4722 - val_loss: 0.7589 - val_acc: 0.4375 - val_rmse: 0.5297\n","Epoch 387/800\n","\n","Epoch 00387: val_loss improved from 0.75894 to 0.75892, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6451 - acc: 0.6000 - rmse: 0.4719 - val_loss: 0.7589 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 388/800\n","\n","Epoch 00388: val_loss improved from 0.75892 to 0.75890, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6450 - acc: 0.6000 - rmse: 0.4799 - val_loss: 0.7589 - val_acc: 0.4375 - val_rmse: 0.5301\n","Epoch 389/800\n","\n","Epoch 00389: val_loss improved from 0.75890 to 0.75888, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6449 - acc: 0.6000 - rmse: 0.4770 - val_loss: 0.7589 - val_acc: 0.4375 - val_rmse: 0.5300\n","Epoch 390/800\n","\n","Epoch 00390: val_loss improved from 0.75888 to 0.75885, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6448 - acc: 0.6000 - rmse: 0.4781 - val_loss: 0.7589 - val_acc: 0.4375 - val_rmse: 0.5295\n","Epoch 391/800\n","\n","Epoch 00391: val_loss improved from 0.75885 to 0.75884, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6447 - acc: 0.6000 - rmse: 0.4726 - val_loss: 0.7588 - val_acc: 0.4375 - val_rmse: 0.5271\n","Epoch 392/800\n","\n","Epoch 00392: val_loss improved from 0.75884 to 0.75882, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6446 - acc: 0.6000 - rmse: 0.4732 - val_loss: 0.7588 - val_acc: 0.4375 - val_rmse: 0.5302\n","Epoch 393/800\n","\n","Epoch 00393: val_loss improved from 0.75882 to 0.75880, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6444 - acc: 0.6000 - rmse: 0.4723 - val_loss: 0.7588 - val_acc: 0.4375 - val_rmse: 0.5297\n","Epoch 394/800\n","\n","Epoch 00394: val_loss improved from 0.75880 to 0.75878, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6443 - acc: 0.6133 - rmse: 0.4773 - val_loss: 0.7588 - val_acc: 0.4375 - val_rmse: 0.5301\n","Epoch 395/800\n","\n","Epoch 00395: val_loss improved from 0.75878 to 0.75876, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6442 - acc: 0.6133 - rmse: 0.4760 - val_loss: 0.7588 - val_acc: 0.4375 - val_rmse: 0.5301\n","Epoch 396/800\n","\n","Epoch 00396: val_loss improved from 0.75876 to 0.75875, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6441 - acc: 0.6133 - rmse: 0.4784 - val_loss: 0.7587 - val_acc: 0.4375 - val_rmse: 0.5293\n","Epoch 397/800\n","\n","Epoch 00397: val_loss improved from 0.75875 to 0.75873, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6440 - acc: 0.6133 - rmse: 0.4787 - val_loss: 0.7587 - val_acc: 0.4375 - val_rmse: 0.5298\n","Epoch 398/800\n","\n","Epoch 00398: val_loss improved from 0.75873 to 0.75871, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6439 - acc: 0.6000 - rmse: 0.4727 - val_loss: 0.7587 - val_acc: 0.4375 - val_rmse: 0.5300\n","Epoch 399/800\n","\n","Epoch 00399: val_loss improved from 0.75871 to 0.75868, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6437 - acc: 0.6000 - rmse: 0.4759 - val_loss: 0.7587 - val_acc: 0.4375 - val_rmse: 0.5301\n","Epoch 400/800\n","\n","Epoch 00400: val_loss improved from 0.75868 to 0.75866, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6436 - acc: 0.6000 - rmse: 0.4769 - val_loss: 0.7587 - val_acc: 0.4375 - val_rmse: 0.5302\n","Epoch 401/800\n","\n","Epoch 00401: val_loss improved from 0.75866 to 0.75863, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6435 - acc: 0.6000 - rmse: 0.4753 - val_loss: 0.7586 - val_acc: 0.4375 - val_rmse: 0.5293\n","Epoch 402/800\n","\n","Epoch 00402: val_loss improved from 0.75863 to 0.75860, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6434 - acc: 0.6000 - rmse: 0.4733 - val_loss: 0.7586 - val_acc: 0.4375 - val_rmse: 0.5300\n","Epoch 403/800\n","\n","Epoch 00403: val_loss improved from 0.75860 to 0.75858, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6433 - acc: 0.6133 - rmse: 0.4760 - val_loss: 0.7586 - val_acc: 0.4375 - val_rmse: 0.5280\n","Epoch 404/800\n","\n","Epoch 00404: val_loss improved from 0.75858 to 0.75856, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6432 - acc: 0.6133 - rmse: 0.4763 - val_loss: 0.7586 - val_acc: 0.4375 - val_rmse: 0.5301\n","Epoch 405/800\n","\n","Epoch 00405: val_loss improved from 0.75856 to 0.75854, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6430 - acc: 0.6267 - rmse: 0.4721 - val_loss: 0.7585 - val_acc: 0.4375 - val_rmse: 0.5301\n","Epoch 406/800\n","\n","Epoch 00406: val_loss improved from 0.75854 to 0.75852, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6429 - acc: 0.6267 - rmse: 0.4739 - val_loss: 0.7585 - val_acc: 0.4375 - val_rmse: 0.5249\n","Epoch 407/800\n","\n","Epoch 00407: val_loss improved from 0.75852 to 0.75850, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6428 - acc: 0.6267 - rmse: 0.4774 - val_loss: 0.7585 - val_acc: 0.4375 - val_rmse: 0.5263\n","Epoch 408/800\n","\n","Epoch 00408: val_loss improved from 0.75850 to 0.75848, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6427 - acc: 0.6267 - rmse: 0.4759 - val_loss: 0.7585 - val_acc: 0.4375 - val_rmse: 0.5296\n","Epoch 409/800\n","\n","Epoch 00409: val_loss improved from 0.75848 to 0.75846, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6426 - acc: 0.6267 - rmse: 0.4728 - val_loss: 0.7585 - val_acc: 0.4375 - val_rmse: 0.5298\n","Epoch 410/800\n","\n","Epoch 00410: val_loss improved from 0.75846 to 0.75844, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6425 - acc: 0.6267 - rmse: 0.4777 - val_loss: 0.7584 - val_acc: 0.4375 - val_rmse: 0.5282\n","Epoch 411/800\n","\n","Epoch 00411: val_loss improved from 0.75844 to 0.75842, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6423 - acc: 0.6267 - rmse: 0.4708 - val_loss: 0.7584 - val_acc: 0.4375 - val_rmse: 0.5299\n","Epoch 412/800\n","\n","Epoch 00412: val_loss improved from 0.75842 to 0.75840, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6422 - acc: 0.6267 - rmse: 0.4755 - val_loss: 0.7584 - val_acc: 0.4375 - val_rmse: 0.5298\n","Epoch 413/800\n","\n","Epoch 00413: val_loss improved from 0.75840 to 0.75838, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6421 - acc: 0.6267 - rmse: 0.4744 - val_loss: 0.7584 - val_acc: 0.4375 - val_rmse: 0.5296\n","Epoch 414/800\n","\n","Epoch 00414: val_loss improved from 0.75838 to 0.75836, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6420 - acc: 0.6267 - rmse: 0.4729 - val_loss: 0.7584 - val_acc: 0.4375 - val_rmse: 0.5297\n","Epoch 415/800\n","\n","Epoch 00415: val_loss improved from 0.75836 to 0.75835, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6419 - acc: 0.6267 - rmse: 0.4736 - val_loss: 0.7583 - val_acc: 0.4375 - val_rmse: 0.5300\n","Epoch 416/800\n","\n","Epoch 00416: val_loss improved from 0.75835 to 0.75833, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6418 - acc: 0.6267 - rmse: 0.4718 - val_loss: 0.7583 - val_acc: 0.4375 - val_rmse: 0.5299\n","Epoch 417/800\n","\n","Epoch 00417: val_loss improved from 0.75833 to 0.75831, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6417 - acc: 0.6267 - rmse: 0.4732 - val_loss: 0.7583 - val_acc: 0.4375 - val_rmse: 0.5285\n","Epoch 418/800\n","\n","Epoch 00418: val_loss improved from 0.75831 to 0.75830, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6415 - acc: 0.6267 - rmse: 0.4754 - val_loss: 0.7583 - val_acc: 0.4375 - val_rmse: 0.5264\n","Epoch 419/800\n","\n","Epoch 00419: val_loss improved from 0.75830 to 0.75829, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6414 - acc: 0.6267 - rmse: 0.4733 - val_loss: 0.7583 - val_acc: 0.4375 - val_rmse: 0.5300\n","Epoch 420/800\n","\n","Epoch 00420: val_loss improved from 0.75829 to 0.75828, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6413 - acc: 0.6267 - rmse: 0.4757 - val_loss: 0.7583 - val_acc: 0.4375 - val_rmse: 0.5298\n","Epoch 421/800\n","\n","Epoch 00421: val_loss improved from 0.75828 to 0.75825, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6412 - acc: 0.6267 - rmse: 0.4722 - val_loss: 0.7583 - val_acc: 0.4375 - val_rmse: 0.5300\n","Epoch 422/800\n","\n","Epoch 00422: val_loss improved from 0.75825 to 0.75824, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6411 - acc: 0.6267 - rmse: 0.4707 - val_loss: 0.7582 - val_acc: 0.4375 - val_rmse: 0.5299\n","Epoch 423/800\n","\n","Epoch 00423: val_loss improved from 0.75824 to 0.75823, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6410 - acc: 0.6267 - rmse: 0.4744 - val_loss: 0.7582 - val_acc: 0.4375 - val_rmse: 0.5300\n","Epoch 424/800\n","\n","Epoch 00424: val_loss improved from 0.75823 to 0.75821, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6408 - acc: 0.6267 - rmse: 0.4752 - val_loss: 0.7582 - val_acc: 0.4375 - val_rmse: 0.5299\n","Epoch 425/800\n","\n","Epoch 00425: val_loss improved from 0.75821 to 0.75820, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6408 - acc: 0.6267 - rmse: 0.4739 - val_loss: 0.7582 - val_acc: 0.4375 - val_rmse: 0.5297\n","Epoch 426/800\n","\n","Epoch 00426: val_loss improved from 0.75820 to 0.75818, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6406 - acc: 0.6267 - rmse: 0.4746 - val_loss: 0.7582 - val_acc: 0.4375 - val_rmse: 0.5293\n","Epoch 427/800\n","\n","Epoch 00427: val_loss improved from 0.75818 to 0.75817, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6405 - acc: 0.6267 - rmse: 0.4732 - val_loss: 0.7582 - val_acc: 0.4375 - val_rmse: 0.5299\n","Epoch 428/800\n","\n","Epoch 00428: val_loss improved from 0.75817 to 0.75815, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6404 - acc: 0.6267 - rmse: 0.4735 - val_loss: 0.7582 - val_acc: 0.4375 - val_rmse: 0.5280\n","Epoch 429/800\n","\n","Epoch 00429: val_loss improved from 0.75815 to 0.75815, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6403 - acc: 0.6267 - rmse: 0.4755 - val_loss: 0.7581 - val_acc: 0.4375 - val_rmse: 0.5299\n","Epoch 430/800\n","\n","Epoch 00430: val_loss improved from 0.75815 to 0.75812, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6402 - acc: 0.6267 - rmse: 0.4754 - val_loss: 0.7581 - val_acc: 0.4375 - val_rmse: 0.5299\n","Epoch 431/800\n","\n","Epoch 00431: val_loss improved from 0.75812 to 0.75810, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6401 - acc: 0.6267 - rmse: 0.4714 - val_loss: 0.7581 - val_acc: 0.4375 - val_rmse: 0.5299\n","Epoch 432/800\n","\n","Epoch 00432: val_loss improved from 0.75810 to 0.75809, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6400 - acc: 0.6267 - rmse: 0.4758 - val_loss: 0.7581 - val_acc: 0.4375 - val_rmse: 0.5298\n","Epoch 433/800\n","\n","Epoch 00433: val_loss improved from 0.75809 to 0.75806, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6398 - acc: 0.6267 - rmse: 0.4753 - val_loss: 0.7581 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 434/800\n","\n","Epoch 00434: val_loss improved from 0.75806 to 0.75804, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6397 - acc: 0.6267 - rmse: 0.4777 - val_loss: 0.7580 - val_acc: 0.4375 - val_rmse: 0.5272\n","Epoch 435/800\n","\n","Epoch 00435: val_loss improved from 0.75804 to 0.75801, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6396 - acc: 0.6267 - rmse: 0.4652 - val_loss: 0.7580 - val_acc: 0.4375 - val_rmse: 0.5298\n","Epoch 436/800\n","\n","Epoch 00436: val_loss improved from 0.75801 to 0.75799, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6395 - acc: 0.6267 - rmse: 0.4726 - val_loss: 0.7580 - val_acc: 0.4375 - val_rmse: 0.5298\n","Epoch 437/800\n","\n","Epoch 00437: val_loss improved from 0.75799 to 0.75796, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6394 - acc: 0.6267 - rmse: 0.4687 - val_loss: 0.7580 - val_acc: 0.4375 - val_rmse: 0.5286\n","Epoch 438/800\n","\n","Epoch 00438: val_loss improved from 0.75796 to 0.75794, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6393 - acc: 0.6267 - rmse: 0.4687 - val_loss: 0.7579 - val_acc: 0.4375 - val_rmse: 0.5286\n","Epoch 439/800\n","\n","Epoch 00439: val_loss improved from 0.75794 to 0.75793, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6392 - acc: 0.6267 - rmse: 0.4678 - val_loss: 0.7579 - val_acc: 0.4375 - val_rmse: 0.5297\n","Epoch 440/800\n","\n","Epoch 00440: val_loss improved from 0.75793 to 0.75791, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6391 - acc: 0.6267 - rmse: 0.4702 - val_loss: 0.7579 - val_acc: 0.4375 - val_rmse: 0.5296\n","Epoch 441/800\n","\n","Epoch 00441: val_loss improved from 0.75791 to 0.75789, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6389 - acc: 0.6267 - rmse: 0.4680 - val_loss: 0.7579 - val_acc: 0.4375 - val_rmse: 0.5287\n","Epoch 442/800\n","\n","Epoch 00442: val_loss improved from 0.75789 to 0.75787, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6388 - acc: 0.6267 - rmse: 0.4706 - val_loss: 0.7579 - val_acc: 0.4375 - val_rmse: 0.5297\n","Epoch 443/800\n","\n","Epoch 00443: val_loss improved from 0.75787 to 0.75786, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6387 - acc: 0.6267 - rmse: 0.4752 - val_loss: 0.7579 - val_acc: 0.4375 - val_rmse: 0.5285\n","Epoch 444/800\n","\n","Epoch 00444: val_loss improved from 0.75786 to 0.75785, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6386 - acc: 0.6267 - rmse: 0.4739 - val_loss: 0.7579 - val_acc: 0.4375 - val_rmse: 0.5268\n","Epoch 445/800\n","\n","Epoch 00445: val_loss improved from 0.75785 to 0.75784, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6385 - acc: 0.6267 - rmse: 0.4703 - val_loss: 0.7578 - val_acc: 0.4375 - val_rmse: 0.5283\n","Epoch 446/800\n","\n","Epoch 00446: val_loss improved from 0.75784 to 0.75782, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6384 - acc: 0.6267 - rmse: 0.4738 - val_loss: 0.7578 - val_acc: 0.4375 - val_rmse: 0.5282\n","Epoch 447/800\n","\n","Epoch 00447: val_loss improved from 0.75782 to 0.75781, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6383 - acc: 0.6267 - rmse: 0.4715 - val_loss: 0.7578 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 448/800\n","\n","Epoch 00448: val_loss improved from 0.75781 to 0.75779, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6381 - acc: 0.6267 - rmse: 0.4729 - val_loss: 0.7578 - val_acc: 0.4375 - val_rmse: 0.5296\n","Epoch 449/800\n","\n","Epoch 00449: val_loss improved from 0.75779 to 0.75778, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6380 - acc: 0.6267 - rmse: 0.4732 - val_loss: 0.7578 - val_acc: 0.4375 - val_rmse: 0.5286\n","Epoch 450/800\n","\n","Epoch 00450: val_loss improved from 0.75778 to 0.75777, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6379 - acc: 0.6267 - rmse: 0.4739 - val_loss: 0.7578 - val_acc: 0.4375 - val_rmse: 0.5296\n","Epoch 451/800\n","\n","Epoch 00451: val_loss improved from 0.75777 to 0.75776, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6378 - acc: 0.6267 - rmse: 0.4713 - val_loss: 0.7578 - val_acc: 0.4375 - val_rmse: 0.5280\n","Epoch 452/800\n","\n","Epoch 00452: val_loss improved from 0.75776 to 0.75775, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6377 - acc: 0.6267 - rmse: 0.4741 - val_loss: 0.7577 - val_acc: 0.4375 - val_rmse: 0.5273\n","Epoch 453/800\n","\n","Epoch 00453: val_loss improved from 0.75775 to 0.75773, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6376 - acc: 0.6267 - rmse: 0.4747 - val_loss: 0.7577 - val_acc: 0.4375 - val_rmse: 0.5280\n","Epoch 454/800\n","\n","Epoch 00454: val_loss improved from 0.75773 to 0.75771, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6375 - acc: 0.6267 - rmse: 0.4734 - val_loss: 0.7577 - val_acc: 0.4375 - val_rmse: 0.5261\n","Epoch 455/800\n","\n","Epoch 00455: val_loss improved from 0.75771 to 0.75768, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6374 - acc: 0.6267 - rmse: 0.4740 - val_loss: 0.7577 - val_acc: 0.4375 - val_rmse: 0.5287\n","Epoch 456/800\n","\n","Epoch 00456: val_loss improved from 0.75768 to 0.75765, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6372 - acc: 0.6267 - rmse: 0.4676 - val_loss: 0.7577 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 457/800\n","\n","Epoch 00457: val_loss improved from 0.75765 to 0.75762, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6371 - acc: 0.6267 - rmse: 0.4745 - val_loss: 0.7576 - val_acc: 0.4375 - val_rmse: 0.5277\n","Epoch 458/800\n","\n","Epoch 00458: val_loss improved from 0.75762 to 0.75759, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6370 - acc: 0.6267 - rmse: 0.4662 - val_loss: 0.7576 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 459/800\n","\n","Epoch 00459: val_loss improved from 0.75759 to 0.75757, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6369 - acc: 0.6267 - rmse: 0.4730 - val_loss: 0.7576 - val_acc: 0.4375 - val_rmse: 0.5297\n","Epoch 460/800\n","\n","Epoch 00460: val_loss improved from 0.75757 to 0.75754, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6368 - acc: 0.6267 - rmse: 0.4711 - val_loss: 0.7575 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 461/800\n","\n","Epoch 00461: val_loss improved from 0.75754 to 0.75752, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6367 - acc: 0.6267 - rmse: 0.4709 - val_loss: 0.7575 - val_acc: 0.4375 - val_rmse: 0.5272\n","Epoch 462/800\n","\n","Epoch 00462: val_loss improved from 0.75752 to 0.75750, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6366 - acc: 0.6267 - rmse: 0.4682 - val_loss: 0.7575 - val_acc: 0.4375 - val_rmse: 0.5295\n","Epoch 463/800\n","\n","Epoch 00463: val_loss improved from 0.75750 to 0.75747, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6365 - acc: 0.6267 - rmse: 0.4714 - val_loss: 0.7575 - val_acc: 0.4375 - val_rmse: 0.5283\n","Epoch 464/800\n","\n","Epoch 00464: val_loss improved from 0.75747 to 0.75745, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6364 - acc: 0.6267 - rmse: 0.4706 - val_loss: 0.7574 - val_acc: 0.4375 - val_rmse: 0.5284\n","Epoch 465/800\n","\n","Epoch 00465: val_loss improved from 0.75745 to 0.75742, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6362 - acc: 0.6267 - rmse: 0.4704 - val_loss: 0.7574 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 466/800\n","\n","Epoch 00466: val_loss improved from 0.75742 to 0.75741, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6361 - acc: 0.6267 - rmse: 0.4714 - val_loss: 0.7574 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 467/800\n","\n","Epoch 00467: val_loss improved from 0.75741 to 0.75739, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6360 - acc: 0.6267 - rmse: 0.4711 - val_loss: 0.7574 - val_acc: 0.4375 - val_rmse: 0.5285\n","Epoch 468/800\n","\n","Epoch 00468: val_loss improved from 0.75739 to 0.75738, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6359 - acc: 0.6267 - rmse: 0.4719 - val_loss: 0.7574 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 469/800\n","\n","Epoch 00469: val_loss improved from 0.75738 to 0.75736, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6358 - acc: 0.6267 - rmse: 0.4700 - val_loss: 0.7574 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 470/800\n","\n","Epoch 00470: val_loss improved from 0.75736 to 0.75734, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6357 - acc: 0.6267 - rmse: 0.4745 - val_loss: 0.7573 - val_acc: 0.4375 - val_rmse: 0.5295\n","Epoch 471/800\n","\n","Epoch 00471: val_loss improved from 0.75734 to 0.75732, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6356 - acc: 0.6267 - rmse: 0.4711 - val_loss: 0.7573 - val_acc: 0.4375 - val_rmse: 0.5270\n","Epoch 472/800\n","\n","Epoch 00472: val_loss improved from 0.75732 to 0.75730, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6355 - acc: 0.6267 - rmse: 0.4722 - val_loss: 0.7573 - val_acc: 0.4375 - val_rmse: 0.5295\n","Epoch 473/800\n","\n","Epoch 00473: val_loss improved from 0.75730 to 0.75728, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6354 - acc: 0.6267 - rmse: 0.4663 - val_loss: 0.7573 - val_acc: 0.4375 - val_rmse: 0.5270\n","Epoch 474/800\n","\n","Epoch 00474: val_loss improved from 0.75728 to 0.75726, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6353 - acc: 0.6267 - rmse: 0.4721 - val_loss: 0.7573 - val_acc: 0.4375 - val_rmse: 0.5281\n","Epoch 475/800\n","\n","Epoch 00475: val_loss improved from 0.75726 to 0.75725, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6352 - acc: 0.6267 - rmse: 0.4712 - val_loss: 0.7572 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 476/800\n","\n","Epoch 00476: val_loss improved from 0.75725 to 0.75724, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6351 - acc: 0.6267 - rmse: 0.4726 - val_loss: 0.7572 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 477/800\n","\n","Epoch 00477: val_loss improved from 0.75724 to 0.75722, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6349 - acc: 0.6267 - rmse: 0.4730 - val_loss: 0.7572 - val_acc: 0.4375 - val_rmse: 0.5272\n","Epoch 478/800\n","\n","Epoch 00478: val_loss improved from 0.75722 to 0.75721, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6348 - acc: 0.6267 - rmse: 0.4710 - val_loss: 0.7572 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 479/800\n","\n","Epoch 00479: val_loss improved from 0.75721 to 0.75720, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6347 - acc: 0.6267 - rmse: 0.4696 - val_loss: 0.7572 - val_acc: 0.4375 - val_rmse: 0.5277\n","Epoch 480/800\n","\n","Epoch 00480: val_loss improved from 0.75720 to 0.75719, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6346 - acc: 0.6267 - rmse: 0.4684 - val_loss: 0.7572 - val_acc: 0.4375 - val_rmse: 0.5286\n","Epoch 481/800\n","\n","Epoch 00481: val_loss improved from 0.75719 to 0.75718, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6345 - acc: 0.6267 - rmse: 0.4702 - val_loss: 0.7572 - val_acc: 0.4375 - val_rmse: 0.5264\n","Epoch 482/800\n","\n","Epoch 00482: val_loss improved from 0.75718 to 0.75717, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6344 - acc: 0.6267 - rmse: 0.4707 - val_loss: 0.7572 - val_acc: 0.4375 - val_rmse: 0.5272\n","Epoch 483/800\n","\n","Epoch 00483: val_loss improved from 0.75717 to 0.75715, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6343 - acc: 0.6267 - rmse: 0.4697 - val_loss: 0.7572 - val_acc: 0.4375 - val_rmse: 0.5291\n","Epoch 484/800\n","\n","Epoch 00484: val_loss improved from 0.75715 to 0.75715, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6342 - acc: 0.6133 - rmse: 0.4711 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5275\n","Epoch 485/800\n","\n","Epoch 00485: val_loss improved from 0.75715 to 0.75714, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6341 - acc: 0.6133 - rmse: 0.4670 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5285\n","Epoch 486/800\n","\n","Epoch 00486: val_loss improved from 0.75714 to 0.75713, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6340 - acc: 0.6133 - rmse: 0.4687 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 487/800\n","\n","Epoch 00487: val_loss improved from 0.75713 to 0.75712, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6339 - acc: 0.6133 - rmse: 0.4704 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5268\n","Epoch 488/800\n","\n","Epoch 00488: val_loss improved from 0.75712 to 0.75711, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6338 - acc: 0.6133 - rmse: 0.4699 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5253\n","Epoch 489/800\n","\n","Epoch 00489: val_loss improved from 0.75711 to 0.75711, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6337 - acc: 0.6133 - rmse: 0.4688 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 490/800\n","\n","Epoch 00490: val_loss improved from 0.75711 to 0.75711, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6335 - acc: 0.6133 - rmse: 0.4698 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 491/800\n","\n","Epoch 00491: val_loss did not improve from 0.75711\n","75/75 - 0s - loss: 0.6334 - acc: 0.6133 - rmse: 0.4699 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 492/800\n","\n","Epoch 00492: val_loss did not improve from 0.75711\n","75/75 - 0s - loss: 0.6333 - acc: 0.6133 - rmse: 0.4679 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5274\n","Epoch 493/800\n","\n","Epoch 00493: val_loss did not improve from 0.75711\n","75/75 - 0s - loss: 0.6332 - acc: 0.6133 - rmse: 0.4701 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 494/800\n","\n","Epoch 00494: val_loss improved from 0.75711 to 0.75710, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6331 - acc: 0.6133 - rmse: 0.4685 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 495/800\n","\n","Epoch 00495: val_loss improved from 0.75710 to 0.75710, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6330 - acc: 0.6133 - rmse: 0.4688 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 496/800\n","\n","Epoch 00496: val_loss improved from 0.75710 to 0.75709, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6329 - acc: 0.6133 - rmse: 0.4731 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5283\n","Epoch 497/800\n","\n","Epoch 00497: val_loss improved from 0.75709 to 0.75709, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6328 - acc: 0.6133 - rmse: 0.4717 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5288\n","Epoch 498/800\n","\n","Epoch 00498: val_loss improved from 0.75709 to 0.75708, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6327 - acc: 0.6133 - rmse: 0.4703 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 499/800\n","\n","Epoch 00499: val_loss improved from 0.75708 to 0.75708, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6326 - acc: 0.6133 - rmse: 0.4694 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5293\n","Epoch 500/800\n","\n","Epoch 00500: val_loss improved from 0.75708 to 0.75707, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6325 - acc: 0.6133 - rmse: 0.4654 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5293\n","Epoch 501/800\n","\n","Epoch 00501: val_loss improved from 0.75707 to 0.75707, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6324 - acc: 0.6133 - rmse: 0.4662 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5288\n","Epoch 502/800\n","\n","Epoch 00502: val_loss improved from 0.75707 to 0.75707, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6323 - acc: 0.6133 - rmse: 0.4699 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5282\n","Epoch 503/800\n","\n","Epoch 00503: val_loss did not improve from 0.75707\n","75/75 - 0s - loss: 0.6322 - acc: 0.6133 - rmse: 0.4716 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5216\n","Epoch 504/800\n","\n","Epoch 00504: val_loss did not improve from 0.75707\n","75/75 - 0s - loss: 0.6321 - acc: 0.6133 - rmse: 0.4685 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 505/800\n","\n","Epoch 00505: val_loss improved from 0.75707 to 0.75706, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6320 - acc: 0.6133 - rmse: 0.4713 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5277\n","Epoch 506/800\n","\n","Epoch 00506: val_loss improved from 0.75706 to 0.75705, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6319 - acc: 0.6133 - rmse: 0.4700 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 507/800\n","\n","Epoch 00507: val_loss improved from 0.75705 to 0.75705, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6318 - acc: 0.6133 - rmse: 0.4672 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5267\n","Epoch 508/800\n","\n","Epoch 00508: val_loss improved from 0.75705 to 0.75705, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6317 - acc: 0.6133 - rmse: 0.4625 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5293\n","Epoch 509/800\n","\n","Epoch 00509: val_loss improved from 0.75705 to 0.75705, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6316 - acc: 0.6133 - rmse: 0.4635 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5282\n","Epoch 510/800\n","\n","Epoch 00510: val_loss did not improve from 0.75705\n","75/75 - 0s - loss: 0.6315 - acc: 0.6133 - rmse: 0.4703 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5293\n","Epoch 511/800\n","\n","Epoch 00511: val_loss improved from 0.75705 to 0.75704, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6314 - acc: 0.6133 - rmse: 0.4673 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5276\n","Epoch 512/800\n","\n","Epoch 00512: val_loss did not improve from 0.75704\n","75/75 - 0s - loss: 0.6313 - acc: 0.6133 - rmse: 0.4693 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 513/800\n","\n","Epoch 00513: val_loss did not improve from 0.75704\n","75/75 - 0s - loss: 0.6312 - acc: 0.6133 - rmse: 0.4716 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5291\n","Epoch 514/800\n","\n","Epoch 00514: val_loss did not improve from 0.75704\n","75/75 - 0s - loss: 0.6310 - acc: 0.6133 - rmse: 0.4725 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5287\n","Epoch 515/800\n","\n","Epoch 00515: val_loss did not improve from 0.75704\n","75/75 - 0s - loss: 0.6309 - acc: 0.6133 - rmse: 0.4723 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 516/800\n","\n","Epoch 00516: val_loss did not improve from 0.75704\n","75/75 - 0s - loss: 0.6308 - acc: 0.6133 - rmse: 0.4703 - val_loss: 0.7571 - val_acc: 0.4375 - val_rmse: 0.5282\n","Epoch 517/800\n","\n","Epoch 00517: val_loss did not improve from 0.75704\n","75/75 - 0s - loss: 0.6307 - acc: 0.6133 - rmse: 0.4689 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5294\n","Epoch 518/800\n","\n","Epoch 00518: val_loss improved from 0.75704 to 0.75704, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6306 - acc: 0.6133 - rmse: 0.4718 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 519/800\n","\n","Epoch 00519: val_loss improved from 0.75704 to 0.75703, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6305 - acc: 0.6133 - rmse: 0.4678 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5293\n","Epoch 520/800\n","\n","Epoch 00520: val_loss improved from 0.75703 to 0.75702, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6304 - acc: 0.6133 - rmse: 0.4650 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5277\n","Epoch 521/800\n","\n","Epoch 00521: val_loss improved from 0.75702 to 0.75701, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6303 - acc: 0.6133 - rmse: 0.4714 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 522/800\n","\n","Epoch 00522: val_loss improved from 0.75701 to 0.75701, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6302 - acc: 0.6133 - rmse: 0.4723 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 523/800\n","\n","Epoch 00523: val_loss improved from 0.75701 to 0.75700, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6301 - acc: 0.6133 - rmse: 0.4689 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 524/800\n","\n","Epoch 00524: val_loss improved from 0.75700 to 0.75699, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6300 - acc: 0.6133 - rmse: 0.4673 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5282\n","Epoch 525/800\n","\n","Epoch 00525: val_loss improved from 0.75699 to 0.75697, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6299 - acc: 0.6133 - rmse: 0.4655 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5293\n","Epoch 526/800\n","\n","Epoch 00526: val_loss improved from 0.75697 to 0.75696, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6298 - acc: 0.6133 - rmse: 0.4723 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 527/800\n","\n","Epoch 00527: val_loss improved from 0.75696 to 0.75695, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6297 - acc: 0.6133 - rmse: 0.4671 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 528/800\n","\n","Epoch 00528: val_loss improved from 0.75695 to 0.75695, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6296 - acc: 0.6133 - rmse: 0.4687 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5241\n","Epoch 529/800\n","\n","Epoch 00529: val_loss improved from 0.75695 to 0.75693, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6295 - acc: 0.6133 - rmse: 0.4644 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5286\n","Epoch 530/800\n","\n","Epoch 00530: val_loss improved from 0.75693 to 0.75693, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6294 - acc: 0.6133 - rmse: 0.4684 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5282\n","Epoch 531/800\n","\n","Epoch 00531: val_loss improved from 0.75693 to 0.75692, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6293 - acc: 0.6133 - rmse: 0.4653 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5285\n","Epoch 532/800\n","\n","Epoch 00532: val_loss improved from 0.75692 to 0.75691, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6292 - acc: 0.6133 - rmse: 0.4665 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 533/800\n","\n","Epoch 00533: val_loss improved from 0.75691 to 0.75691, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6291 - acc: 0.6133 - rmse: 0.4631 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 534/800\n","\n","Epoch 00534: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6290 - acc: 0.6133 - rmse: 0.4600 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 535/800\n","\n","Epoch 00535: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6289 - acc: 0.6133 - rmse: 0.4703 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 536/800\n","\n","Epoch 00536: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6288 - acc: 0.6133 - rmse: 0.4668 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 537/800\n","\n","Epoch 00537: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6287 - acc: 0.6133 - rmse: 0.4669 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5278\n","Epoch 538/800\n","\n","Epoch 00538: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6286 - acc: 0.6133 - rmse: 0.4672 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 539/800\n","\n","Epoch 00539: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6285 - acc: 0.6133 - rmse: 0.4637 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 540/800\n","\n","Epoch 00540: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6284 - acc: 0.6133 - rmse: 0.4709 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5266\n","Epoch 541/800\n","\n","Epoch 00541: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6283 - acc: 0.6133 - rmse: 0.4691 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5277\n","Epoch 542/800\n","\n","Epoch 00542: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6282 - acc: 0.6133 - rmse: 0.4646 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5291\n","Epoch 543/800\n","\n","Epoch 00543: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6281 - acc: 0.6133 - rmse: 0.4614 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 544/800\n","\n","Epoch 00544: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6280 - acc: 0.6133 - rmse: 0.4627 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5267\n","Epoch 545/800\n","\n","Epoch 00545: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6279 - acc: 0.6133 - rmse: 0.4710 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5291\n","Epoch 546/800\n","\n","Epoch 00546: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6278 - acc: 0.6133 - rmse: 0.4674 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5291\n","Epoch 547/800\n","\n","Epoch 00547: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6277 - acc: 0.6133 - rmse: 0.4683 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5287\n","Epoch 548/800\n","\n","Epoch 00548: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6276 - acc: 0.6133 - rmse: 0.4664 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 549/800\n","\n","Epoch 00549: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6275 - acc: 0.6133 - rmse: 0.4687 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 550/800\n","\n","Epoch 00550: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6274 - acc: 0.6133 - rmse: 0.4676 - val_loss: 0.7570 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 551/800\n","\n","Epoch 00551: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6273 - acc: 0.6133 - rmse: 0.4688 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5239\n","Epoch 552/800\n","\n","Epoch 00552: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6272 - acc: 0.6133 - rmse: 0.4651 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5284\n","Epoch 553/800\n","\n","Epoch 00553: val_loss did not improve from 0.75691\n","75/75 - 0s - loss: 0.6271 - acc: 0.6133 - rmse: 0.4600 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5288\n","Epoch 554/800\n","\n","Epoch 00554: val_loss improved from 0.75691 to 0.75690, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6270 - acc: 0.6133 - rmse: 0.4685 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5277\n","Epoch 555/800\n","\n","Epoch 00555: val_loss improved from 0.75690 to 0.75689, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6269 - acc: 0.6133 - rmse: 0.4687 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 556/800\n","\n","Epoch 00556: val_loss improved from 0.75689 to 0.75687, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6268 - acc: 0.6133 - rmse: 0.4698 - val_loss: 0.7569 - val_acc: 0.4375 - val_rmse: 0.5292\n","Epoch 557/800\n","\n","Epoch 00557: val_loss improved from 0.75687 to 0.75685, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6267 - acc: 0.6133 - rmse: 0.4630 - val_loss: 0.7568 - val_acc: 0.4375 - val_rmse: 0.5256\n","Epoch 558/800\n","\n","Epoch 00558: val_loss improved from 0.75685 to 0.75683, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6266 - acc: 0.6133 - rmse: 0.4650 - val_loss: 0.7568 - val_acc: 0.4375 - val_rmse: 0.5288\n","Epoch 559/800\n","\n","Epoch 00559: val_loss improved from 0.75683 to 0.75681, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6265 - acc: 0.6133 - rmse: 0.4659 - val_loss: 0.7568 - val_acc: 0.4375 - val_rmse: 0.5268\n","Epoch 560/800\n","\n","Epoch 00560: val_loss improved from 0.75681 to 0.75681, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6264 - acc: 0.6133 - rmse: 0.4680 - val_loss: 0.7568 - val_acc: 0.4375 - val_rmse: 0.5284\n","Epoch 561/800\n","\n","Epoch 00561: val_loss improved from 0.75681 to 0.75680, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6263 - acc: 0.6133 - rmse: 0.4670 - val_loss: 0.7568 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 562/800\n","\n","Epoch 00562: val_loss improved from 0.75680 to 0.75679, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6262 - acc: 0.6133 - rmse: 0.4672 - val_loss: 0.7568 - val_acc: 0.4375 - val_rmse: 0.5284\n","Epoch 563/800\n","\n","Epoch 00563: val_loss improved from 0.75679 to 0.75678, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6261 - acc: 0.6133 - rmse: 0.4694 - val_loss: 0.7568 - val_acc: 0.4375 - val_rmse: 0.5287\n","Epoch 564/800\n","\n","Epoch 00564: val_loss improved from 0.75678 to 0.75676, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6260 - acc: 0.6133 - rmse: 0.4661 - val_loss: 0.7568 - val_acc: 0.4375 - val_rmse: 0.5283\n","Epoch 565/800\n","\n","Epoch 00565: val_loss improved from 0.75676 to 0.75675, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6259 - acc: 0.6133 - rmse: 0.4677 - val_loss: 0.7568 - val_acc: 0.4375 - val_rmse: 0.5291\n","Epoch 566/800\n","\n","Epoch 00566: val_loss improved from 0.75675 to 0.75674, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6258 - acc: 0.6267 - rmse: 0.4686 - val_loss: 0.7567 - val_acc: 0.4375 - val_rmse: 0.5275\n","Epoch 567/800\n","\n","Epoch 00567: val_loss improved from 0.75674 to 0.75672, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6257 - acc: 0.6267 - rmse: 0.4693 - val_loss: 0.7567 - val_acc: 0.4375 - val_rmse: 0.5290\n","Epoch 568/800\n","\n","Epoch 00568: val_loss improved from 0.75672 to 0.75670, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6256 - acc: 0.6267 - rmse: 0.4609 - val_loss: 0.7567 - val_acc: 0.4375 - val_rmse: 0.5280\n","Epoch 569/800\n","\n","Epoch 00569: val_loss improved from 0.75670 to 0.75669, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6255 - acc: 0.6267 - rmse: 0.4665 - val_loss: 0.7567 - val_acc: 0.4375 - val_rmse: 0.5284\n","Epoch 570/800\n","\n","Epoch 00570: val_loss improved from 0.75669 to 0.75668, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6254 - acc: 0.6267 - rmse: 0.4691 - val_loss: 0.7567 - val_acc: 0.4375 - val_rmse: 0.5288\n","Epoch 571/800\n","\n","Epoch 00571: val_loss improved from 0.75668 to 0.75666, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6253 - acc: 0.6267 - rmse: 0.4670 - val_loss: 0.7567 - val_acc: 0.4375 - val_rmse: 0.5269\n","Epoch 572/800\n","\n","Epoch 00572: val_loss improved from 0.75666 to 0.75664, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6252 - acc: 0.6267 - rmse: 0.4686 - val_loss: 0.7566 - val_acc: 0.4375 - val_rmse: 0.5280\n","Epoch 573/800\n","\n","Epoch 00573: val_loss improved from 0.75664 to 0.75663, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6251 - acc: 0.6267 - rmse: 0.4673 - val_loss: 0.7566 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 574/800\n","\n","Epoch 00574: val_loss improved from 0.75663 to 0.75661, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6250 - acc: 0.6267 - rmse: 0.4687 - val_loss: 0.7566 - val_acc: 0.4375 - val_rmse: 0.5283\n","Epoch 575/800\n","\n","Epoch 00575: val_loss improved from 0.75661 to 0.75659, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6249 - acc: 0.6267 - rmse: 0.4618 - val_loss: 0.7566 - val_acc: 0.4375 - val_rmse: 0.5287\n","Epoch 576/800\n","\n","Epoch 00576: val_loss improved from 0.75659 to 0.75657, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6248 - acc: 0.6267 - rmse: 0.4669 - val_loss: 0.7566 - val_acc: 0.4375 - val_rmse: 0.5288\n","Epoch 577/800\n","\n","Epoch 00577: val_loss improved from 0.75657 to 0.75655, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6247 - acc: 0.6267 - rmse: 0.4578 - val_loss: 0.7566 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 578/800\n","\n","Epoch 00578: val_loss improved from 0.75655 to 0.75654, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6246 - acc: 0.6267 - rmse: 0.4591 - val_loss: 0.7565 - val_acc: 0.4375 - val_rmse: 0.5275\n","Epoch 579/800\n","\n","Epoch 00579: val_loss improved from 0.75654 to 0.75652, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6245 - acc: 0.6267 - rmse: 0.4679 - val_loss: 0.7565 - val_acc: 0.4375 - val_rmse: 0.5288\n","Epoch 580/800\n","\n","Epoch 00580: val_loss improved from 0.75652 to 0.75651, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6244 - acc: 0.6267 - rmse: 0.4622 - val_loss: 0.7565 - val_acc: 0.4375 - val_rmse: 0.5284\n","Epoch 581/800\n","\n","Epoch 00581: val_loss improved from 0.75651 to 0.75650, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6243 - acc: 0.6267 - rmse: 0.4590 - val_loss: 0.7565 - val_acc: 0.4375 - val_rmse: 0.5277\n","Epoch 582/800\n","\n","Epoch 00582: val_loss improved from 0.75650 to 0.75650, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6242 - acc: 0.6267 - rmse: 0.4636 - val_loss: 0.7565 - val_acc: 0.4375 - val_rmse: 0.5288\n","Epoch 583/800\n","\n","Epoch 00583: val_loss improved from 0.75650 to 0.75649, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6241 - acc: 0.6267 - rmse: 0.4644 - val_loss: 0.7565 - val_acc: 0.4375 - val_rmse: 0.5289\n","Epoch 584/800\n","\n","Epoch 00584: val_loss improved from 0.75649 to 0.75648, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6240 - acc: 0.6267 - rmse: 0.4646 - val_loss: 0.7565 - val_acc: 0.4375 - val_rmse: 0.5258\n","Epoch 585/800\n","\n","Epoch 00585: val_loss improved from 0.75648 to 0.75647, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6239 - acc: 0.6267 - rmse: 0.4649 - val_loss: 0.7565 - val_acc: 0.4375 - val_rmse: 0.5269\n","Epoch 586/800\n","\n","Epoch 00586: val_loss improved from 0.75647 to 0.75646, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6238 - acc: 0.6267 - rmse: 0.4640 - val_loss: 0.7565 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 587/800\n","\n","Epoch 00587: val_loss improved from 0.75646 to 0.75645, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6237 - acc: 0.6267 - rmse: 0.4663 - val_loss: 0.7565 - val_acc: 0.3750 - val_rmse: 0.5289\n","Epoch 588/800\n","\n","Epoch 00588: val_loss improved from 0.75645 to 0.75645, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6236 - acc: 0.6267 - rmse: 0.4648 - val_loss: 0.7564 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 589/800\n","\n","Epoch 00589: val_loss improved from 0.75645 to 0.75644, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6235 - acc: 0.6267 - rmse: 0.4640 - val_loss: 0.7564 - val_acc: 0.3750 - val_rmse: 0.5245\n","Epoch 590/800\n","\n","Epoch 00590: val_loss improved from 0.75644 to 0.75642, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6234 - acc: 0.6267 - rmse: 0.4651 - val_loss: 0.7564 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 591/800\n","\n","Epoch 00591: val_loss improved from 0.75642 to 0.75642, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6233 - acc: 0.6267 - rmse: 0.4679 - val_loss: 0.7564 - val_acc: 0.3750 - val_rmse: 0.5278\n","Epoch 592/800\n","\n","Epoch 00592: val_loss improved from 0.75642 to 0.75640, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6232 - acc: 0.6267 - rmse: 0.4647 - val_loss: 0.7564 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 593/800\n","\n","Epoch 00593: val_loss improved from 0.75640 to 0.75638, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6231 - acc: 0.6267 - rmse: 0.4676 - val_loss: 0.7564 - val_acc: 0.3750 - val_rmse: 0.5288\n","Epoch 594/800\n","\n","Epoch 00594: val_loss improved from 0.75638 to 0.75637, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6230 - acc: 0.6267 - rmse: 0.4598 - val_loss: 0.7564 - val_acc: 0.3750 - val_rmse: 0.5287\n","Epoch 595/800\n","\n","Epoch 00595: val_loss improved from 0.75637 to 0.75636, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6229 - acc: 0.6267 - rmse: 0.4672 - val_loss: 0.7564 - val_acc: 0.3750 - val_rmse: 0.5281\n","Epoch 596/800\n","\n","Epoch 00596: val_loss improved from 0.75636 to 0.75634, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6228 - acc: 0.6267 - rmse: 0.4672 - val_loss: 0.7563 - val_acc: 0.3750 - val_rmse: 0.5284\n","Epoch 597/800\n","\n","Epoch 00597: val_loss improved from 0.75634 to 0.75631, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6227 - acc: 0.6267 - rmse: 0.4667 - val_loss: 0.7563 - val_acc: 0.3750 - val_rmse: 0.5265\n","Epoch 598/800\n","\n","Epoch 00598: val_loss improved from 0.75631 to 0.75629, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6226 - acc: 0.6267 - rmse: 0.4612 - val_loss: 0.7563 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 599/800\n","\n","Epoch 00599: val_loss improved from 0.75629 to 0.75628, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6225 - acc: 0.6267 - rmse: 0.4669 - val_loss: 0.7563 - val_acc: 0.3750 - val_rmse: 0.5273\n","Epoch 600/800\n","\n","Epoch 00600: val_loss improved from 0.75628 to 0.75626, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6224 - acc: 0.6267 - rmse: 0.4635 - val_loss: 0.7563 - val_acc: 0.3750 - val_rmse: 0.5278\n","Epoch 601/800\n","\n","Epoch 00601: val_loss improved from 0.75626 to 0.75625, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6223 - acc: 0.6267 - rmse: 0.4708 - val_loss: 0.7562 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 602/800\n","\n","Epoch 00602: val_loss improved from 0.75625 to 0.75623, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6222 - acc: 0.6267 - rmse: 0.4630 - val_loss: 0.7562 - val_acc: 0.3750 - val_rmse: 0.5287\n","Epoch 603/800\n","\n","Epoch 00603: val_loss improved from 0.75623 to 0.75623, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6221 - acc: 0.6267 - rmse: 0.4676 - val_loss: 0.7562 - val_acc: 0.3750 - val_rmse: 0.5277\n","Epoch 604/800\n","\n","Epoch 00604: val_loss improved from 0.75623 to 0.75622, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6220 - acc: 0.6267 - rmse: 0.4661 - val_loss: 0.7562 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 605/800\n","\n","Epoch 00605: val_loss improved from 0.75622 to 0.75621, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6219 - acc: 0.6267 - rmse: 0.4626 - val_loss: 0.7562 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 606/800\n","\n","Epoch 00606: val_loss improved from 0.75621 to 0.75619, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6218 - acc: 0.6267 - rmse: 0.4628 - val_loss: 0.7562 - val_acc: 0.3750 - val_rmse: 0.5286\n","Epoch 607/800\n","\n","Epoch 00607: val_loss improved from 0.75619 to 0.75618, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6217 - acc: 0.6267 - rmse: 0.4648 - val_loss: 0.7562 - val_acc: 0.3750 - val_rmse: 0.5284\n","Epoch 608/800\n","\n","Epoch 00608: val_loss improved from 0.75618 to 0.75616, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6216 - acc: 0.6267 - rmse: 0.4655 - val_loss: 0.7562 - val_acc: 0.3750 - val_rmse: 0.5286\n","Epoch 609/800\n","\n","Epoch 00609: val_loss improved from 0.75616 to 0.75615, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6215 - acc: 0.6267 - rmse: 0.4652 - val_loss: 0.7561 - val_acc: 0.3750 - val_rmse: 0.5283\n","Epoch 610/800\n","\n","Epoch 00610: val_loss improved from 0.75615 to 0.75614, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6214 - acc: 0.6267 - rmse: 0.4646 - val_loss: 0.7561 - val_acc: 0.3125 - val_rmse: 0.5280\n","Epoch 611/800\n","\n","Epoch 00611: val_loss improved from 0.75614 to 0.75613, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6212 - acc: 0.6267 - rmse: 0.4659 - val_loss: 0.7561 - val_acc: 0.3125 - val_rmse: 0.5264\n","Epoch 612/800\n","\n","Epoch 00612: val_loss improved from 0.75613 to 0.75612, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6212 - acc: 0.6267 - rmse: 0.4622 - val_loss: 0.7561 - val_acc: 0.3125 - val_rmse: 0.5286\n","Epoch 613/800\n","\n","Epoch 00613: val_loss did not improve from 0.75612\n","75/75 - 0s - loss: 0.6211 - acc: 0.6267 - rmse: 0.4665 - val_loss: 0.7561 - val_acc: 0.3125 - val_rmse: 0.5269\n","Epoch 614/800\n","\n","Epoch 00614: val_loss improved from 0.75612 to 0.75612, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6210 - acc: 0.6267 - rmse: 0.4659 - val_loss: 0.7561 - val_acc: 0.3125 - val_rmse: 0.5251\n","Epoch 615/800\n","\n","Epoch 00615: val_loss improved from 0.75612 to 0.75611, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6209 - acc: 0.6267 - rmse: 0.4639 - val_loss: 0.7561 - val_acc: 0.3125 - val_rmse: 0.5286\n","Epoch 616/800\n","\n","Epoch 00616: val_loss improved from 0.75611 to 0.75610, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6207 - acc: 0.6267 - rmse: 0.4661 - val_loss: 0.7561 - val_acc: 0.3750 - val_rmse: 0.5286\n","Epoch 617/800\n","\n","Epoch 00617: val_loss improved from 0.75610 to 0.75609, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6207 - acc: 0.6267 - rmse: 0.4633 - val_loss: 0.7561 - val_acc: 0.3750 - val_rmse: 0.5281\n","Epoch 618/800\n","\n","Epoch 00618: val_loss improved from 0.75609 to 0.75609, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6205 - acc: 0.6267 - rmse: 0.4622 - val_loss: 0.7561 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 619/800\n","\n","Epoch 00619: val_loss improved from 0.75609 to 0.75608, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6205 - acc: 0.6267 - rmse: 0.4650 - val_loss: 0.7561 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 620/800\n","\n","Epoch 00620: val_loss improved from 0.75608 to 0.75608, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6204 - acc: 0.6267 - rmse: 0.4683 - val_loss: 0.7561 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 621/800\n","\n","Epoch 00621: val_loss improved from 0.75608 to 0.75606, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6202 - acc: 0.6267 - rmse: 0.4615 - val_loss: 0.7561 - val_acc: 0.3750 - val_rmse: 0.5280\n","Epoch 622/800\n","\n","Epoch 00622: val_loss improved from 0.75606 to 0.75605, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6201 - acc: 0.6267 - rmse: 0.4609 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5283\n","Epoch 623/800\n","\n","Epoch 00623: val_loss improved from 0.75605 to 0.75604, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6201 - acc: 0.6267 - rmse: 0.4662 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 624/800\n","\n","Epoch 00624: val_loss improved from 0.75604 to 0.75603, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6199 - acc: 0.6267 - rmse: 0.4621 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5259\n","Epoch 625/800\n","\n","Epoch 00625: val_loss improved from 0.75603 to 0.75603, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6198 - acc: 0.6267 - rmse: 0.4632 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5277\n","Epoch 626/800\n","\n","Epoch 00626: val_loss improved from 0.75603 to 0.75602, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6198 - acc: 0.6267 - rmse: 0.4609 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 627/800\n","\n","Epoch 00627: val_loss improved from 0.75602 to 0.75602, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6197 - acc: 0.6267 - rmse: 0.4602 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 628/800\n","\n","Epoch 00628: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6195 - acc: 0.6267 - rmse: 0.4617 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5286\n","Epoch 629/800\n","\n","Epoch 00629: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6195 - acc: 0.6267 - rmse: 0.4671 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 630/800\n","\n","Epoch 00630: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6193 - acc: 0.6267 - rmse: 0.4628 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 631/800\n","\n","Epoch 00631: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6193 - acc: 0.6267 - rmse: 0.4637 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5270\n","Epoch 632/800\n","\n","Epoch 00632: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6192 - acc: 0.6267 - rmse: 0.4685 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5286\n","Epoch 633/800\n","\n","Epoch 00633: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6191 - acc: 0.6267 - rmse: 0.4683 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5283\n","Epoch 634/800\n","\n","Epoch 00634: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6190 - acc: 0.6267 - rmse: 0.4636 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5265\n","Epoch 635/800\n","\n","Epoch 00635: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6189 - acc: 0.6267 - rmse: 0.4559 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5239\n","Epoch 636/800\n","\n","Epoch 00636: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6188 - acc: 0.6267 - rmse: 0.4647 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5271\n","Epoch 637/800\n","\n","Epoch 00637: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6187 - acc: 0.6267 - rmse: 0.4616 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5268\n","Epoch 638/800\n","\n","Epoch 00638: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6186 - acc: 0.6267 - rmse: 0.4654 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 639/800\n","\n","Epoch 00639: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6185 - acc: 0.6267 - rmse: 0.4644 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 640/800\n","\n","Epoch 00640: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6184 - acc: 0.6267 - rmse: 0.4661 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 641/800\n","\n","Epoch 00641: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6183 - acc: 0.6267 - rmse: 0.4658 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5284\n","Epoch 642/800\n","\n","Epoch 00642: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6182 - acc: 0.6267 - rmse: 0.4592 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 643/800\n","\n","Epoch 00643: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6181 - acc: 0.6267 - rmse: 0.4644 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5267\n","Epoch 644/800\n","\n","Epoch 00644: val_loss did not improve from 0.75602\n","75/75 - 0s - loss: 0.6180 - acc: 0.6267 - rmse: 0.4654 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 645/800\n","\n","Epoch 00645: val_loss improved from 0.75602 to 0.75602, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6179 - acc: 0.6267 - rmse: 0.4646 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5284\n","Epoch 646/800\n","\n","Epoch 00646: val_loss improved from 0.75602 to 0.75602, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6178 - acc: 0.6267 - rmse: 0.4664 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5280\n","Epoch 647/800\n","\n","Epoch 00647: val_loss improved from 0.75602 to 0.75601, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6177 - acc: 0.6267 - rmse: 0.4657 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 648/800\n","\n","Epoch 00648: val_loss improved from 0.75601 to 0.75600, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6176 - acc: 0.6267 - rmse: 0.4656 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5285\n","Epoch 649/800\n","\n","Epoch 00649: val_loss improved from 0.75600 to 0.75598, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6175 - acc: 0.6267 - rmse: 0.4620 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5271\n","Epoch 650/800\n","\n","Epoch 00650: val_loss improved from 0.75598 to 0.75595, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6174 - acc: 0.6267 - rmse: 0.4654 - val_loss: 0.7560 - val_acc: 0.3750 - val_rmse: 0.5284\n","Epoch 651/800\n","\n","Epoch 00651: val_loss improved from 0.75595 to 0.75593, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6173 - acc: 0.6267 - rmse: 0.4654 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5275\n","Epoch 652/800\n","\n","Epoch 00652: val_loss improved from 0.75593 to 0.75590, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6172 - acc: 0.6267 - rmse: 0.4466 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5269\n","Epoch 653/800\n","\n","Epoch 00653: val_loss improved from 0.75590 to 0.75588, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6171 - acc: 0.6267 - rmse: 0.4616 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5278\n","Epoch 654/800\n","\n","Epoch 00654: val_loss improved from 0.75588 to 0.75588, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6170 - acc: 0.6267 - rmse: 0.4628 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5254\n","Epoch 655/800\n","\n","Epoch 00655: val_loss improved from 0.75588 to 0.75587, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6169 - acc: 0.6267 - rmse: 0.4629 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5284\n","Epoch 656/800\n","\n","Epoch 00656: val_loss improved from 0.75587 to 0.75586, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6168 - acc: 0.6267 - rmse: 0.4647 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5284\n","Epoch 657/800\n","\n","Epoch 00657: val_loss improved from 0.75586 to 0.75585, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6167 - acc: 0.6267 - rmse: 0.4670 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5272\n","Epoch 658/800\n","\n","Epoch 00658: val_loss improved from 0.75585 to 0.75584, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6166 - acc: 0.6267 - rmse: 0.4604 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5266\n","Epoch 659/800\n","\n","Epoch 00659: val_loss improved from 0.75584 to 0.75583, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6166 - acc: 0.6267 - rmse: 0.4609 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5284\n","Epoch 660/800\n","\n","Epoch 00660: val_loss improved from 0.75583 to 0.75582, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6165 - acc: 0.6267 - rmse: 0.4585 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5267\n","Epoch 661/800\n","\n","Epoch 00661: val_loss did not improve from 0.75582\n","75/75 - 0s - loss: 0.6164 - acc: 0.6267 - rmse: 0.4658 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 662/800\n","\n","Epoch 00662: val_loss improved from 0.75582 to 0.75580, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6163 - acc: 0.6267 - rmse: 0.4655 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 663/800\n","\n","Epoch 00663: val_loss improved from 0.75580 to 0.75579, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6162 - acc: 0.6267 - rmse: 0.4634 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5284\n","Epoch 664/800\n","\n","Epoch 00664: val_loss improved from 0.75579 to 0.75578, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6161 - acc: 0.6267 - rmse: 0.4610 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 665/800\n","\n","Epoch 00665: val_loss improved from 0.75578 to 0.75576, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6160 - acc: 0.6267 - rmse: 0.4609 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 666/800\n","\n","Epoch 00666: val_loss improved from 0.75576 to 0.75575, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6159 - acc: 0.6267 - rmse: 0.4595 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5251\n","Epoch 667/800\n","\n","Epoch 00667: val_loss improved from 0.75575 to 0.75574, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6158 - acc: 0.6267 - rmse: 0.4673 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5268\n","Epoch 668/800\n","\n","Epoch 00668: val_loss improved from 0.75574 to 0.75573, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6157 - acc: 0.6267 - rmse: 0.4619 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5277\n","Epoch 669/800\n","\n","Epoch 00669: val_loss improved from 0.75573 to 0.75572, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6156 - acc: 0.6267 - rmse: 0.4588 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 670/800\n","\n","Epoch 00670: val_loss improved from 0.75572 to 0.75572, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6155 - acc: 0.6400 - rmse: 0.4621 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5267\n","Epoch 671/800\n","\n","Epoch 00671: val_loss improved from 0.75572 to 0.75572, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6154 - acc: 0.6533 - rmse: 0.4649 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5242\n","Epoch 672/800\n","\n","Epoch 00672: val_loss improved from 0.75572 to 0.75571, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6153 - acc: 0.6533 - rmse: 0.4584 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5265\n","Epoch 673/800\n","\n","Epoch 00673: val_loss improved from 0.75571 to 0.75571, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6152 - acc: 0.6533 - rmse: 0.4636 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5283\n","Epoch 674/800\n","\n","Epoch 00674: val_loss improved from 0.75571 to 0.75570, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6151 - acc: 0.6533 - rmse: 0.4622 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5283\n","Epoch 675/800\n","\n","Epoch 00675: val_loss improved from 0.75570 to 0.75569, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6150 - acc: 0.6533 - rmse: 0.4563 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5269\n","Epoch 676/800\n","\n","Epoch 00676: val_loss improved from 0.75569 to 0.75568, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6149 - acc: 0.6533 - rmse: 0.4623 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 677/800\n","\n","Epoch 00677: val_loss improved from 0.75568 to 0.75567, saving model to /tmp/LSTM_checkpoint.h5\n","75/75 - 0s - loss: 0.6148 - acc: 0.6533 - rmse: 0.4605 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5283\n","Epoch 678/800\n","\n","Epoch 00678: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6147 - acc: 0.6533 - rmse: 0.4639 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5280\n","Epoch 679/800\n","\n","Epoch 00679: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6146 - acc: 0.6533 - rmse: 0.4625 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5271\n","Epoch 680/800\n","\n","Epoch 00680: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6145 - acc: 0.6533 - rmse: 0.4625 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5281\n","Epoch 681/800\n","\n","Epoch 00681: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6144 - acc: 0.6533 - rmse: 0.4609 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5275\n","Epoch 682/800\n","\n","Epoch 00682: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6144 - acc: 0.6533 - rmse: 0.4599 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 683/800\n","\n","Epoch 00683: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6143 - acc: 0.6533 - rmse: 0.4592 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5255\n","Epoch 684/800\n","\n","Epoch 00684: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6142 - acc: 0.6533 - rmse: 0.4560 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5265\n","Epoch 685/800\n","\n","Epoch 00685: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6141 - acc: 0.6533 - rmse: 0.4631 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 686/800\n","\n","Epoch 00686: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6140 - acc: 0.6533 - rmse: 0.4653 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 687/800\n","\n","Epoch 00687: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6139 - acc: 0.6533 - rmse: 0.4569 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 688/800\n","\n","Epoch 00688: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6138 - acc: 0.6533 - rmse: 0.4648 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 689/800\n","\n","Epoch 00689: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6137 - acc: 0.6533 - rmse: 0.4629 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 690/800\n","\n","Epoch 00690: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6136 - acc: 0.6533 - rmse: 0.4632 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 691/800\n","\n","Epoch 00691: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6135 - acc: 0.6533 - rmse: 0.4571 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5259\n","Epoch 692/800\n","\n","Epoch 00692: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6134 - acc: 0.6533 - rmse: 0.4556 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5280\n","Epoch 693/800\n","\n","Epoch 00693: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6133 - acc: 0.6533 - rmse: 0.4592 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 694/800\n","\n","Epoch 00694: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6132 - acc: 0.6533 - rmse: 0.4596 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 695/800\n","\n","Epoch 00695: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6131 - acc: 0.6533 - rmse: 0.4629 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5278\n","Epoch 696/800\n","\n","Epoch 00696: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6130 - acc: 0.6533 - rmse: 0.4607 - val_loss: 0.7557 - val_acc: 0.3750 - val_rmse: 0.5270\n","Epoch 697/800\n","\n","Epoch 00697: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6129 - acc: 0.6533 - rmse: 0.4603 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5281\n","Epoch 698/800\n","\n","Epoch 00698: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6128 - acc: 0.6533 - rmse: 0.4547 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 699/800\n","\n","Epoch 00699: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6127 - acc: 0.6533 - rmse: 0.4621 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5280\n","Epoch 700/800\n","\n","Epoch 00700: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6126 - acc: 0.6667 - rmse: 0.4603 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5244\n","Epoch 701/800\n","\n","Epoch 00701: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6126 - acc: 0.6667 - rmse: 0.4485 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5262\n","Epoch 702/800\n","\n","Epoch 00702: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6126 - acc: 0.6667 - rmse: 0.4592 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 703/800\n","\n","Epoch 00703: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6126 - acc: 0.6667 - rmse: 0.4642 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 704/800\n","\n","Epoch 00704: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4603 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 705/800\n","\n","Epoch 00705: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4618 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5264\n","Epoch 706/800\n","\n","Epoch 00706: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4593 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5265\n","Epoch 707/800\n","\n","Epoch 00707: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4576 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5264\n","Epoch 708/800\n","\n","Epoch 00708: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4556 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5281\n","Epoch 709/800\n","\n","Epoch 00709: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4528 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5247\n","Epoch 710/800\n","\n","Epoch 00710: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4635 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5275\n","Epoch 711/800\n","\n","Epoch 00711: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4613 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 712/800\n","\n","Epoch 00712: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4621 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5251\n","Epoch 713/800\n","\n","Epoch 00713: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6125 - acc: 0.6667 - rmse: 0.4577 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5265\n","Epoch 714/800\n","\n","Epoch 00714: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4600 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5260\n","Epoch 715/800\n","\n","Epoch 00715: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4552 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 716/800\n","\n","Epoch 00716: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4608 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 717/800\n","\n","Epoch 00717: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4596 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 718/800\n","\n","Epoch 00718: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4571 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5243\n","Epoch 719/800\n","\n","Epoch 00719: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4627 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5271\n","Epoch 720/800\n","\n","Epoch 00720: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4598 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 721/800\n","\n","Epoch 00721: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4506 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 722/800\n","\n","Epoch 00722: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4625 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5271\n","Epoch 723/800\n","\n","Epoch 00723: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6124 - acc: 0.6667 - rmse: 0.4598 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5272\n","Epoch 724/800\n","\n","Epoch 00724: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4606 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 725/800\n","\n","Epoch 00725: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4590 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 726/800\n","\n","Epoch 00726: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4535 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5269\n","Epoch 727/800\n","\n","Epoch 00727: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4618 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5256\n","Epoch 728/800\n","\n","Epoch 00728: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4607 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5271\n","Epoch 729/800\n","\n","Epoch 00729: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4620 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 730/800\n","\n","Epoch 00730: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4612 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 731/800\n","\n","Epoch 00731: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4607 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5269\n","Epoch 732/800\n","\n","Epoch 00732: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4591 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 733/800\n","\n","Epoch 00733: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6123 - acc: 0.6667 - rmse: 0.4608 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 734/800\n","\n","Epoch 00734: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4519 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5273\n","Epoch 735/800\n","\n","Epoch 00735: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4633 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5271\n","Epoch 736/800\n","\n","Epoch 00736: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4551 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5272\n","Epoch 737/800\n","\n","Epoch 00737: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4613 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5258\n","Epoch 738/800\n","\n","Epoch 00738: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4572 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 739/800\n","\n","Epoch 00739: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4600 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5277\n","Epoch 740/800\n","\n","Epoch 00740: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4624 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5275\n","Epoch 741/800\n","\n","Epoch 00741: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4578 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5254\n","Epoch 742/800\n","\n","Epoch 00742: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4583 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5259\n","Epoch 743/800\n","\n","Epoch 00743: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4622 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 744/800\n","\n","Epoch 00744: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6122 - acc: 0.6667 - rmse: 0.4587 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5244\n","Epoch 745/800\n","\n","Epoch 00745: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4584 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5277\n","Epoch 746/800\n","\n","Epoch 00746: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4633 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 747/800\n","\n","Epoch 00747: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4585 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 748/800\n","\n","Epoch 00748: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4545 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5275\n","Epoch 749/800\n","\n","Epoch 00749: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4566 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 750/800\n","\n","Epoch 00750: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4606 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5264\n","Epoch 751/800\n","\n","Epoch 00751: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4626 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 752/800\n","\n","Epoch 00752: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4534 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5273\n","Epoch 753/800\n","\n","Epoch 00753: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4536 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 754/800\n","\n","Epoch 00754: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6121 - acc: 0.6667 - rmse: 0.4584 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5277\n","Epoch 755/800\n","\n","Epoch 00755: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4597 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 756/800\n","\n","Epoch 00756: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4571 - val_loss: 0.7558 - val_acc: 0.3750 - val_rmse: 0.5275\n","Epoch 757/800\n","\n","Epoch 00757: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4493 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 758/800\n","\n","Epoch 00758: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4493 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5239\n","Epoch 759/800\n","\n","Epoch 00759: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4571 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5281\n","Epoch 760/800\n","\n","Epoch 00760: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4590 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 761/800\n","\n","Epoch 00761: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4544 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 762/800\n","\n","Epoch 00762: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4553 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5247\n","Epoch 763/800\n","\n","Epoch 00763: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4585 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5233\n","Epoch 764/800\n","\n","Epoch 00764: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6120 - acc: 0.6667 - rmse: 0.4615 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 765/800\n","\n","Epoch 00765: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4605 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 766/800\n","\n","Epoch 00766: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4582 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 767/800\n","\n","Epoch 00767: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4572 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 768/800\n","\n","Epoch 00768: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4523 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5272\n","Epoch 769/800\n","\n","Epoch 00769: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4600 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 770/800\n","\n","Epoch 00770: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4610 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5251\n","Epoch 771/800\n","\n","Epoch 00771: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4574 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5280\n","Epoch 772/800\n","\n","Epoch 00772: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4604 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 773/800\n","\n","Epoch 00773: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4597 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5249\n","Epoch 774/800\n","\n","Epoch 00774: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6119 - acc: 0.6667 - rmse: 0.4617 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5252\n","Epoch 775/800\n","\n","Epoch 00775: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4570 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5280\n","Epoch 776/800\n","\n","Epoch 00776: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4593 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 777/800\n","\n","Epoch 00777: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4589 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5259\n","Epoch 778/800\n","\n","Epoch 00778: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4575 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5260\n","Epoch 779/800\n","\n","Epoch 00779: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4619 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5274\n","Epoch 780/800\n","\n","Epoch 00780: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4581 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5272\n","Epoch 781/800\n","\n","Epoch 00781: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4612 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 782/800\n","\n","Epoch 00782: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4630 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5281\n","Epoch 783/800\n","\n","Epoch 00783: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4641 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 784/800\n","\n","Epoch 00784: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4633 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5259\n","Epoch 785/800\n","\n","Epoch 00785: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6118 - acc: 0.6667 - rmse: 0.4598 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5264\n","Epoch 786/800\n","\n","Epoch 00786: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4615 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5281\n","Epoch 787/800\n","\n","Epoch 00787: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4574 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5274\n","Epoch 788/800\n","\n","Epoch 00788: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4542 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5269\n","Epoch 789/800\n","\n","Epoch 00789: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4621 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 790/800\n","\n","Epoch 00790: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4559 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 791/800\n","\n","Epoch 00791: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4594 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 792/800\n","\n","Epoch 00792: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4562 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5276\n","Epoch 793/800\n","\n","Epoch 00793: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4611 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5279\n","Epoch 794/800\n","\n","Epoch 00794: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4583 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5265\n","Epoch 795/800\n","\n","Epoch 00795: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6117 - acc: 0.6667 - rmse: 0.4646 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 796/800\n","\n","Epoch 00796: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6116 - acc: 0.6667 - rmse: 0.4540 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5277\n","Epoch 797/800\n","\n","Epoch 00797: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6116 - acc: 0.6667 - rmse: 0.4616 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 798/800\n","\n","Epoch 00798: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6116 - acc: 0.6667 - rmse: 0.4553 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5269\n","Epoch 799/800\n","\n","Epoch 00799: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6116 - acc: 0.6667 - rmse: 0.4559 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5282\n","Epoch 800/800\n","\n","Epoch 00800: val_loss did not improve from 0.75567\n","75/75 - 0s - loss: 0.6116 - acc: 0.6667 - rmse: 0.4612 - val_loss: 0.7559 - val_acc: 0.3750 - val_rmse: 0.5279\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DHEoNhy6f0dH","colab_type":"code","outputId":"37d8a8f7-02ba-421a-8201-8074edb26ff0","executionInfo":{"status":"ok","timestamp":1580646186797,"user_tz":-60,"elapsed":1461,"user":{"displayName":"Maritza Tynes","photoUrl":"","userId":"02324384993274756811"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# load optimal weights\n","model.load_weights('/tmp/LSTM_checkpoint.h5')\n","\n","\n","\n","probs       = model.predict(X_test)\n","preds       = probs.argmax(axis = -1)  \n","acc         = np.mean(preds == Y_test.argmax(axis=-1))\n","print(\"Classification accuracy: %f \" % (acc))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Classification accuracy: 0.625000 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JJ6N4S6CAXcW","colab":{}},"source":["# list all data in history\n","#print(fitted_model.history.keys())\n","\n","print('Diagrammed History of Model Metrics')\n","\n","# summarize history for accuracy\n","plt.plot(fitted_model.history['acc'])\n","plt.plot(fitted_model.history['val_acc'])\n","plt.title('Model Accuracy over Epochs')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6BGAOKIaAXcr","colab":{}},"source":["# summarize history for rmse\n","plt.plot(fitted_model.history['rmse'])\n","plt.plot(fitted_model.history['val_rmse'])\n","plt.title('Model RMSE over Epochs')\n","plt.ylabel('RMSE')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8bWhpV5toeGO","colab":{}},"source":["# summarize loss history\n","plt.plot(fitted_model.history['loss'])\n","plt.plot(fitted_model.history['val_loss'])\n","plt.title('Model Loss over Epochs')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oCjtEji1AXdK","colab":{}},"source":["!pip freeze"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KNEh8pXvAXdo","colab":{}},"source":["from platform import python_version\n","\n","print(python_version())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c7RNlm6OAXeG","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}