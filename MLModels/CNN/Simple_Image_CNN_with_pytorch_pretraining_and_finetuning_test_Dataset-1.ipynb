{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Simple Image CNN with pytorch pretraining and finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IulYndEgkpMu"
      },
      "source": [
        "#############################\n",
        "## For this version, training is done with two classes of mini-imagenet,\n",
        "## further training / fine tuning is done with the second EEG dataset (MSU)\n",
        "## The 1st dataset, EEG of Sz is split into a validation and test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMxAxj4Lyjkq",
        "outputId": "40d5f2dd-dc86-4c38-b97c-6d89ac2e6f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.9->scikit-plot) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ds2tvhWyEs9",
        "outputId": "89fe2092-fe28-4fd1-974c-9a550e4fa92b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# To improve the speed of setting up, retrieve only the files for the two groups used in training\n",
        "# Swap with the line below to get the entire dataset as a zip file\n",
        "# gdown.download('https://drive.google.com/uc?id=1-QTtycxsVNeym17zrMBSZCAAtEZEs05p', '/content/miniimagenet.zip', quiet=False)\n",
        "gdown.download('https://drive.google.com/uc?id=1CZeMPRt4OZGJL_xQNfgi5evJW1PpA77l', '/content/miniimagenet.zip', quiet=False) # selected groups only\n",
        "images_directory = '/content/miniimagenet/images/'\n",
        "if not os.path.exists(images_directory):\n",
        "  os.makedirs(images_directory) \n",
        "!unzip -qq /content/miniimagenet.zip -d {images_directory}\n",
        "\n",
        "\n",
        "# get the CSV with the list of all file names\n",
        "mini_imagenet_file_list_csv = '/content/all_imagenet_file_names.csv'\n",
        "gdown.download('https://drive.google.com/uc?id=1-1JiyyEC6JlnEi0H0x-JKIGEKjdI_Nea', mini_imagenet_file_list_csv, quiet=False)\n",
        "file_list = pd.read_csv(mini_imagenet_file_list_csv)\n",
        "\n",
        "mini_imagenet_file_list = os.listdir(images_directory) #to exclude the directories created next\n",
        "selected_groups = ['n01532829', 'n01558993']\n",
        "for group_name in selected_groups:\n",
        "  group_file = '/content/miniimagenet/images/' +  group_name\n",
        "  if not os.path.isdir(group_file):\n",
        "    os.makedirs(group_file)\n",
        "samples_miniimagenet = file_list[file_list['label'].isin(selected_groups)].groupby('label').first()\n",
        "\n",
        "# Other options for group pairs\n",
        "# n01532829, n01558993\n",
        "# n02108551, n02108915\n",
        "\n",
        "for file in mini_imagenet_file_list:\n",
        "  group = file[:9]\n",
        "  file_dst = '/content/miniimagenet/images/{}/{}'.format(group, file)\n",
        "  shutil.copyfile(images_directory + file, file_dst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CZeMPRt4OZGJL_xQNfgi5evJW1PpA77l\n",
            "To: /content/miniimagenet.zip\n",
            "59.8MB [00:01, 46.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-1JiyyEC6JlnEi0H0x-JKIGEKjdI_Nea\n",
            "To: /content/all_imagenet_file_names.csv\n",
            "2.27MB [00:00, 129MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P6yjksbyGJ8",
        "outputId": "9cfb5082-5400-4df1-cd66-7c32eae9334a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Get the EEG spectrograms zip file and unzip it\n",
        "eeg_image_directory = '/content/eeg_sz_spectrograms'\n",
        "gdown.download('https://drive.google.com/uc?id=1WZ1yIFE2bng0McnY_4UBJHqTttsXTTNX', '{}.zip'.format(eeg_image_directory), quiet=False) \n",
        "!unzip -qq {eeg_image_directory}.zip -d {eeg_image_directory}\n",
        "\n",
        "# rename \n",
        "dl_link = '/content/eeg_sz_spectrograms/gen_data_20s_70pct_overlap_-_high_nfft_all_channels_sml/'\n",
        "!mv \"{dl_link}/hc\" {eeg_image_directory}\n",
        "!mv \"{dl_link}/sz\" {eeg_image_directory}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WZ1yIFE2bng0McnY_4UBJHqTttsXTTNX\n",
            "To: /content/eeg_sz_spectrograms.zip\n",
            "44.2MB [00:00, 55.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSn6_62Kurxn"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5mT1trFuxKP",
        "outputId": "c2c97fa7-8a29-47f4-d019-bed41f5888ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Get the spectrograms zip file for the fine tuning step\n",
        "# For this version of the program, we attempt to use spectrograms from a different EEG dataset to fine-tune the program. The first EEG dataset will still be used for testing\n",
        "\n",
        "fine_tuning_image_directory = '/content/fine_tuning_eeg_spectrograms'\n",
        "gdown.download('https://drive.google.com/uc?id=1vSKS0I_ZoIaBVJAATqEGp_s8UcynWwPL', '{}.zip'.format(fine_tuning_image_directory), quiet=False) \n",
        "!unzip -qq {fine_tuning_image_directory}.zip -d {fine_tuning_image_directory}\n",
        "\n",
        "# rename \n",
        "ft_dl_link = '{}/content/drive/My Drive/ML Projects/data/MSU.ru__gen_data_5s_70pct_overlap_-_fractional_noverlap_all_channels_sml/'.format(fine_tuning_image_directory)\n",
        "!mv \"{ft_dl_link}/hc\" {fine_tuning_image_directory}\n",
        "!mv \"{ft_dl_link}/sz\" {fine_tuning_image_directory}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vSKS0I_ZoIaBVJAATqEGp_s8UcynWwPL\n",
            "To: /content/fine_tuning_eeg_spectrograms.zip\n",
            "117MB [00:00, 152MB/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iMjz3c7cFL_"
      },
      "source": [
        "#sorted([s.split('_')[0] for s in os.listdir(fine_tuning_image_directory + '/' + 'sz') ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv07AtSyvLv3",
        "outputId": "f512c441-a5bf-4061-f7c9-9efb10210508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# Use EEG of Sz for validation and testing\n",
        "# Extract files from an eeg_sz spectrogram directory where files are saved by subject\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "rand_seed = 1\n",
        "# List of raw patient file IDs that should be skipped based on categorization as outliers\n",
        "ignore_list = ['h09', 'h10', 's10', 's11', 's12']\n",
        "hc_subject_ids = ['hc' + str(i) for i in range(14) if \"h{:02}\".format(i) not in ignore_list] \n",
        "sz_subject_ids = ['sz' + str(i) for i in range(14) if \"s{:02}\".format(i) not in ignore_list] \n",
        "all_subject_ids = np.concatenate([hc_subject_ids, sz_subject_ids], axis=0)\n",
        "validate_hc, test_hc = train_test_split(hc_subject_ids, test_size=0.5, random_state=rand_seed)\n",
        "validate_sz, test_sz = train_test_split(sz_subject_ids, test_size=0.5, random_state=rand_seed)\n",
        "\n",
        "validation_ids = np.concatenate([validate_hc, validate_sz])  # unused\n",
        "test_ids = np.concatenate([test_hc, test_sz]) \n",
        "\n",
        "\n",
        "print('\\nSubjects assigned to groups using sklearn.model_selection.train_test_split')\n",
        "print('Test group: ', \", \".join(test_ids), \"\\n\")\n",
        "print('Validation group: ', \", \".join(validation_ids), \"\\n\")\n",
        "\n",
        "  \n",
        "\n",
        "from shutil import copyfile\n",
        "import pandas as pd\n",
        "import os \n",
        "\n",
        "\n",
        "test_images_output_directory = 'all_test_images'\n",
        "validation_images_output_directory = 'all_validation_images'\n",
        "\n",
        "if not os.path.exists(test_images_output_directory):\n",
        "    os.mkdir(test_images_output_directory)\n",
        "if not os.path.exists(validation_images_output_directory):\n",
        "    os.mkdir(validation_images_output_directory)\n",
        "\n",
        "\n",
        "\n",
        "# Note: CSV is only used for MAML and Prototypical networks\n",
        "def gen_csv_and_copy_sz_files(image_dir, img_output_dir, participant_ids, output_name, split_with_csv=False):\n",
        "    subdir_data = []\n",
        "    for group in ['hc', 'sz']: #['Healthy_Control', 'Sz_Patient']:\n",
        "        for pid in os.listdir(image_dir + '/' + group): # by participant IDs\n",
        "            if pid in participant_ids:\n",
        "              for file in os.listdir(image_dir + '/' + group + '/' + pid):\n",
        "                file_data = {'filename': file, 'label': group}\n",
        "                subdir_data.append(file_data)\n",
        "                destination = img_output_dir + '/' + file if split_with_csv else  '{}/{}/{}'.format(img_output_dir, group, file)\n",
        "                if not os.path.exists('{}/{}'.format(img_output_dir, group)):\n",
        "                  os.makedirs('{}/{}'.format(img_output_dir, group))\n",
        "                copyfile(image_dir + '/' + group + '/' + pid + '/' + file,  destination )\n",
        "    if split_with_csv:\n",
        "      pd.DataFrame(subdir_data).to_csv(img_output_dir + '/' + output_name)\n",
        "    return pd.DataFrame(subdir_data)\n",
        "\n",
        "\n",
        "df = gen_csv_and_copy_sz_files(image_dir=eeg_image_directory, \n",
        "                                img_output_dir=test_images_output_directory,\n",
        "                                participant_ids=test_ids,\n",
        "                               split_with_csv=False,\n",
        "                                output_name= 'test.csv')\n",
        "df = gen_csv_and_copy_sz_files(image_dir=eeg_image_directory, \n",
        "                                img_output_dir=validation_images_output_directory,\n",
        "                                participant_ids=validation_ids, \n",
        "                               split_with_csv=False,\n",
        "                                output_name= 'val.csv')\n",
        "print(df.head())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Subjects assigned to groups using sklearn.model_selection.train_test_split\n",
            "Test group:  hc2, hc3, hc4, hc12, hc1, hc6, sz2, sz3, sz4, sz9, sz1, sz6 \n",
            "\n",
            "Validation group:  hc0, hc7, hc13, hc11, hc8, hc5, sz0, sz7, sz13, sz8, sz5 \n",
            "\n",
            "     filename label\n",
            "0  hc0_22.png    hc\n",
            "1  hc0_18.png    hc\n",
            "2  hc0_20.png    hc\n",
            "3  hc0_26.png    hc\n",
            "4  hc0_11.png    hc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kc-elftvmlL",
        "outputId": "5be06d50-f146-47ae-c220-b914cde0bd94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "###########################\n",
        "### Process second training set (fine tuning set)\n",
        "\n",
        "# Use EEG of Sz for testing\n",
        "# Extract files from an eeg_sz spectrogram directory where files are saved by subject\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# List of raw patient file IDs that should be skipped based on categorization as outliers\n",
        "ft_ignore_list = []\n",
        "ft_hc_subject_ids = ['hc' + str(i) for i in range(38) if \"h{:02}\".format(i) not in ft_ignore_list] \n",
        "ft_sz_subject_ids = ['sz' + str(i) for i in range(38) if \"s{:02}\".format(i) not in ft_ignore_list] \n",
        "ft_all_subject_ids = np.concatenate([ft_hc_subject_ids, ft_sz_subject_ids], axis=0)\n",
        "\n",
        "ft_images_output_directory = '/content/all_fine_tuning_images'\n",
        "\n",
        "if not os.path.exists(ft_images_output_directory):\n",
        "    os.mkdir(ft_images_output_directory)\n",
        "\n",
        "print('\\nAll subjects assigned to training group for fine tuning')\n",
        "print(ft_all_subject_ids)\n",
        "\n",
        "ids = { 'test': test_ids}\n",
        "  \n",
        "\n",
        "\n",
        "ft_df = gen_csv_and_copy_sz_files(image_dir=fine_tuning_image_directory, \n",
        "                                img_output_dir=ft_images_output_directory,\n",
        "                                participant_ids=ft_all_subject_ids, \n",
        "                                split_with_csv = False,\n",
        "                                output_name= 'train.csv')\n",
        "print(ft_df.head())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "All subjects assigned to training group for fine tuning\n",
            "['hc0' 'hc1' 'hc2' 'hc3' 'hc4' 'hc5' 'hc6' 'hc7' 'hc8' 'hc9' 'hc10' 'hc11'\n",
            " 'hc12' 'hc13' 'hc14' 'hc15' 'hc16' 'hc17' 'hc18' 'hc19' 'hc20' 'hc21'\n",
            " 'hc22' 'hc23' 'hc24' 'hc25' 'hc26' 'hc27' 'hc28' 'hc29' 'hc30' 'hc31'\n",
            " 'hc32' 'hc33' 'hc34' 'hc35' 'hc36' 'hc37' 'sz0' 'sz1' 'sz2' 'sz3' 'sz4'\n",
            " 'sz5' 'sz6' 'sz7' 'sz8' 'sz9' 'sz10' 'sz11' 'sz12' 'sz13' 'sz14' 'sz15'\n",
            " 'sz16' 'sz17' 'sz18' 'sz19' 'sz20' 'sz21' 'sz22' 'sz23' 'sz24' 'sz25'\n",
            " 'sz26' 'sz27' 'sz28' 'sz29' 'sz30' 'sz31' 'sz32' 'sz33' 'sz34' 'sz35'\n",
            " 'sz36' 'sz37']\n",
            "      filename label\n",
            "0  hc34_14.png    hc\n",
            "1  hc34_32.png    hc\n",
            "2  hc34_18.png    hc\n",
            "3   hc34_9.png    hc\n",
            "4  hc34_12.png    hc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeMr_7-5vLVF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGdjsKKZFFsg",
        "outputId": "ea3b6ce7-f0a6-4fc2-ed48-770f6425ecd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "%cd /content\n",
        "\n",
        "#!git clone https://github.com/zhangrong1722/CheXNet-Pytorch.git binaryCNN\n",
        "\n",
        "gdown.download('https://drive.google.com/uc?id=1c1ADbwdNBxmN9jjzhcaCIIN5fD3BDCAc', 'main.py', quiet=False) \n",
        "\n",
        "train_directory ='/content/miniimagenet/images'\n",
        "test_directory ='/content/all_test_images'\n",
        "validation_directory = '/content/all_validation_images'\n",
        "fine_tuning_directory ='/content/all_fine_tuning_images'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1c1ADbwdNBxmN9jjzhcaCIIN5fD3BDCAc\n",
            "To: /content/main.py\n",
            "100%|██████████| 16.5k/16.5k [00:00<00:00, 4.14MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S50C3upOTx5P",
        "outputId": "c52c0fc9-4cbb-4be6-d1ab-46e1a65e6a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python main.py  --train_dir {train_directory} --fine_tuning_dir {fine_tuning_directory} --validation_dir {validation_directory} --test_dir {test_directory} --epochs 200 --fine_tuning_epochs 200\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 40/200\n",
            "----------\n",
            "Train Epoch: 40 [0/2812 (0%)]\tLoss: 1.989161\n",
            "Train Epoch: 40 [120/2812 (4%)]\tLoss: 8.255663\n",
            "Train Epoch: 40 [240/2812 (9%)]\tLoss: 9.911366\n",
            "Train Epoch: 40 [360/2812 (13%)]\tLoss: 18.733313\n",
            "Train Epoch: 40 [480/2812 (17%)]\tLoss: 15.227809\n",
            "Train Epoch: 40 [600/2812 (21%)]\tLoss: 12.342905\n",
            "Train Epoch: 40 [720/2812 (26%)]\tLoss: 8.308498\n",
            "Train Epoch: 40 [840/2812 (30%)]\tLoss: 7.095350\n",
            "Train Epoch: 40 [960/2812 (34%)]\tLoss: 17.809505\n",
            "Train Epoch: 40 [1080/2812 (38%)]\tLoss: 8.439089\n",
            "Train Epoch: 40 [1200/2812 (43%)]\tLoss: 19.333134\n",
            "Train Epoch: 40 [1320/2812 (47%)]\tLoss: 10.785610\n",
            "Train Epoch: 40 [1440/2812 (51%)]\tLoss: 6.795227\n",
            "Train Epoch: 40 [1560/2812 (55%)]\tLoss: 5.121434\n",
            "Train Epoch: 40 [1680/2812 (60%)]\tLoss: 6.888049\n",
            "Train Epoch: 40 [1800/2812 (64%)]\tLoss: 7.999932\n",
            "Train Epoch: 40 [1920/2812 (68%)]\tLoss: 8.568033\n",
            "Train Epoch: 40 [2040/2812 (72%)]\tLoss: 4.996950\n",
            "Train Epoch: 40 [2160/2812 (77%)]\tLoss: 5.110906\n",
            "Train Epoch: 40 [2280/2812 (81%)]\tLoss: 6.987885\n",
            "Train Epoch: 40 [2400/2812 (85%)]\tLoss: 22.767420\n",
            "Train Epoch: 40 [2520/2812 (89%)]\tLoss: 5.126193\n",
            "Train Epoch: 40 [2640/2812 (94%)]\tLoss: 19.996696\n",
            "Train Epoch: 40 [2760/2812 (98%)]\tLoss: 6.426189\n",
            "Training Loss: 11.0864 Acc: 49.9644\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6054, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 41/200\n",
            "----------\n",
            "Train Epoch: 41 [0/2812 (0%)]\tLoss: 18.029196\n",
            "Train Epoch: 41 [120/2812 (4%)]\tLoss: 3.657373\n",
            "Train Epoch: 41 [240/2812 (9%)]\tLoss: 10.581456\n",
            "Train Epoch: 41 [360/2812 (13%)]\tLoss: 6.371409\n",
            "Train Epoch: 41 [480/2812 (17%)]\tLoss: 8.727724\n",
            "Train Epoch: 41 [600/2812 (21%)]\tLoss: 5.987494\n",
            "Train Epoch: 41 [720/2812 (26%)]\tLoss: 7.678635\n",
            "Train Epoch: 41 [840/2812 (30%)]\tLoss: 11.099241\n",
            "Train Epoch: 41 [960/2812 (34%)]\tLoss: 12.093092\n",
            "Train Epoch: 41 [1080/2812 (38%)]\tLoss: 10.020479\n",
            "Train Epoch: 41 [1200/2812 (43%)]\tLoss: 3.388993\n",
            "Train Epoch: 41 [1320/2812 (47%)]\tLoss: 18.072428\n",
            "Train Epoch: 41 [1440/2812 (51%)]\tLoss: 11.650307\n",
            "Train Epoch: 41 [1560/2812 (55%)]\tLoss: 12.286328\n",
            "Train Epoch: 41 [1680/2812 (60%)]\tLoss: 5.426114\n",
            "Train Epoch: 41 [1800/2812 (64%)]\tLoss: 18.204927\n",
            "Train Epoch: 41 [1920/2812 (68%)]\tLoss: 23.569483\n",
            "Train Epoch: 41 [2040/2812 (72%)]\tLoss: 8.264906\n",
            "Train Epoch: 41 [2160/2812 (77%)]\tLoss: 9.011867\n",
            "Train Epoch: 41 [2280/2812 (81%)]\tLoss: 9.454823\n",
            "Train Epoch: 41 [2400/2812 (85%)]\tLoss: 11.330609\n",
            "Train Epoch: 41 [2520/2812 (89%)]\tLoss: 8.771432\n",
            "Train Epoch: 41 [2640/2812 (94%)]\tLoss: 5.893945\n",
            "Train Epoch: 41 [2760/2812 (98%)]\tLoss: 6.123231\n",
            "Training Loss: 11.3384 Acc: 50.2489\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5143, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 42/200\n",
            "----------\n",
            "Train Epoch: 42 [0/2812 (0%)]\tLoss: 14.105665\n",
            "Train Epoch: 42 [120/2812 (4%)]\tLoss: 1.833893\n",
            "Train Epoch: 42 [240/2812 (9%)]\tLoss: 16.514137\n",
            "Train Epoch: 42 [360/2812 (13%)]\tLoss: 7.029033\n",
            "Train Epoch: 42 [480/2812 (17%)]\tLoss: 4.191245\n",
            "Train Epoch: 42 [600/2812 (21%)]\tLoss: 10.032508\n",
            "Train Epoch: 42 [720/2812 (26%)]\tLoss: 15.776352\n",
            "Train Epoch: 42 [840/2812 (30%)]\tLoss: 22.727922\n",
            "Train Epoch: 42 [960/2812 (34%)]\tLoss: 8.732831\n",
            "Train Epoch: 42 [1080/2812 (38%)]\tLoss: 8.715326\n",
            "Train Epoch: 42 [1200/2812 (43%)]\tLoss: 21.054495\n",
            "Train Epoch: 42 [1320/2812 (47%)]\tLoss: 14.065434\n",
            "Train Epoch: 42 [1440/2812 (51%)]\tLoss: 25.627396\n",
            "Train Epoch: 42 [1560/2812 (55%)]\tLoss: 7.109245\n",
            "Train Epoch: 42 [1680/2812 (60%)]\tLoss: 3.849588\n",
            "Train Epoch: 42 [1800/2812 (64%)]\tLoss: 27.778849\n",
            "Train Epoch: 42 [1920/2812 (68%)]\tLoss: 17.235708\n",
            "Train Epoch: 42 [2040/2812 (72%)]\tLoss: 13.055966\n",
            "Train Epoch: 42 [2160/2812 (77%)]\tLoss: 10.501783\n",
            "Train Epoch: 42 [2280/2812 (81%)]\tLoss: 10.276499\n",
            "Train Epoch: 42 [2400/2812 (85%)]\tLoss: 8.143866\n",
            "Train Epoch: 42 [2520/2812 (89%)]\tLoss: 9.347364\n",
            "Train Epoch: 42 [2640/2812 (94%)]\tLoss: 10.695442\n",
            "Train Epoch: 42 [2760/2812 (98%)]\tLoss: 17.750864\n",
            "Training Loss: 10.9797 Acc: 50.0711\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5441, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 43/200\n",
            "----------\n",
            "Train Epoch: 43 [0/2812 (0%)]\tLoss: 15.194296\n",
            "Train Epoch: 43 [120/2812 (4%)]\tLoss: 11.108173\n",
            "Train Epoch: 43 [240/2812 (9%)]\tLoss: 19.120592\n",
            "Train Epoch: 43 [360/2812 (13%)]\tLoss: 10.672640\n",
            "Train Epoch: 43 [480/2812 (17%)]\tLoss: 15.669917\n",
            "Train Epoch: 43 [600/2812 (21%)]\tLoss: 14.177423\n",
            "Train Epoch: 43 [720/2812 (26%)]\tLoss: 7.398845\n",
            "Train Epoch: 43 [840/2812 (30%)]\tLoss: 14.270060\n",
            "Train Epoch: 43 [960/2812 (34%)]\tLoss: 5.156268\n",
            "Train Epoch: 43 [1080/2812 (38%)]\tLoss: 4.409331\n",
            "Train Epoch: 43 [1200/2812 (43%)]\tLoss: 7.117027\n",
            "Train Epoch: 43 [1320/2812 (47%)]\tLoss: 7.256011\n",
            "Train Epoch: 43 [1440/2812 (51%)]\tLoss: 17.852386\n",
            "Train Epoch: 43 [1560/2812 (55%)]\tLoss: 2.700359\n",
            "Train Epoch: 43 [1680/2812 (60%)]\tLoss: 9.608938\n",
            "Train Epoch: 43 [1800/2812 (64%)]\tLoss: 13.261952\n",
            "Train Epoch: 43 [1920/2812 (68%)]\tLoss: 12.625503\n",
            "Train Epoch: 43 [2040/2812 (72%)]\tLoss: 23.169708\n",
            "Train Epoch: 43 [2160/2812 (77%)]\tLoss: 4.308009\n",
            "Train Epoch: 43 [2280/2812 (81%)]\tLoss: 6.601155\n",
            "Train Epoch: 43 [2400/2812 (85%)]\tLoss: 11.067511\n",
            "Train Epoch: 43 [2520/2812 (89%)]\tLoss: 6.631925\n",
            "Train Epoch: 43 [2640/2812 (94%)]\tLoss: 30.046616\n",
            "Train Epoch: 43 [2760/2812 (98%)]\tLoss: 9.311816\n",
            "Training Loss: 11.4935 Acc: 50.5334\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6122, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 44/200\n",
            "----------\n",
            "Train Epoch: 44 [0/2812 (0%)]\tLoss: 5.379167\n",
            "Train Epoch: 44 [120/2812 (4%)]\tLoss: 23.292740\n",
            "Train Epoch: 44 [240/2812 (9%)]\tLoss: 4.964021\n",
            "Train Epoch: 44 [360/2812 (13%)]\tLoss: 9.739050\n",
            "Train Epoch: 44 [480/2812 (17%)]\tLoss: 18.199427\n",
            "Train Epoch: 44 [600/2812 (21%)]\tLoss: 10.633635\n",
            "Train Epoch: 44 [720/2812 (26%)]\tLoss: 10.849021\n",
            "Train Epoch: 44 [840/2812 (30%)]\tLoss: 10.993498\n",
            "Train Epoch: 44 [960/2812 (34%)]\tLoss: 11.925850\n",
            "Train Epoch: 44 [1080/2812 (38%)]\tLoss: 19.340172\n",
            "Train Epoch: 44 [1200/2812 (43%)]\tLoss: 4.801402\n",
            "Train Epoch: 44 [1320/2812 (47%)]\tLoss: 6.700952\n",
            "Train Epoch: 44 [1440/2812 (51%)]\tLoss: 19.374767\n",
            "Train Epoch: 44 [1560/2812 (55%)]\tLoss: 8.484857\n",
            "Train Epoch: 44 [1680/2812 (60%)]\tLoss: 7.126729\n",
            "Train Epoch: 44 [1800/2812 (64%)]\tLoss: 18.992344\n",
            "Train Epoch: 44 [1920/2812 (68%)]\tLoss: 6.605734\n",
            "Train Epoch: 44 [2040/2812 (72%)]\tLoss: 7.996385\n",
            "Train Epoch: 44 [2160/2812 (77%)]\tLoss: 12.467936\n",
            "Train Epoch: 44 [2280/2812 (81%)]\tLoss: 29.761784\n",
            "Train Epoch: 44 [2400/2812 (85%)]\tLoss: 12.866564\n",
            "Train Epoch: 44 [2520/2812 (89%)]\tLoss: 14.949593\n",
            "Train Epoch: 44 [2640/2812 (94%)]\tLoss: 20.958176\n",
            "Train Epoch: 44 [2760/2812 (98%)]\tLoss: 24.704145\n",
            "Training Loss: 11.0516 Acc: 50.2134\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5854, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 45/200\n",
            "----------\n",
            "Train Epoch: 45 [0/2812 (0%)]\tLoss: 9.274772\n",
            "Train Epoch: 45 [120/2812 (4%)]\tLoss: 4.362567\n",
            "Train Epoch: 45 [240/2812 (9%)]\tLoss: 20.632710\n",
            "Train Epoch: 45 [360/2812 (13%)]\tLoss: 11.950065\n",
            "Train Epoch: 45 [480/2812 (17%)]\tLoss: 10.805492\n",
            "Train Epoch: 45 [600/2812 (21%)]\tLoss: 6.608644\n",
            "Train Epoch: 45 [720/2812 (26%)]\tLoss: 7.434117\n",
            "Train Epoch: 45 [840/2812 (30%)]\tLoss: 18.610039\n",
            "Train Epoch: 45 [960/2812 (34%)]\tLoss: 11.926914\n",
            "Train Epoch: 45 [1080/2812 (38%)]\tLoss: 2.722323\n",
            "Train Epoch: 45 [1200/2812 (43%)]\tLoss: 9.313101\n",
            "Train Epoch: 45 [1320/2812 (47%)]\tLoss: 18.230337\n",
            "Train Epoch: 45 [1440/2812 (51%)]\tLoss: 21.434954\n",
            "Train Epoch: 45 [1560/2812 (55%)]\tLoss: 7.116889\n",
            "Train Epoch: 45 [1680/2812 (60%)]\tLoss: 14.068042\n",
            "Train Epoch: 45 [1800/2812 (64%)]\tLoss: 12.829801\n",
            "Train Epoch: 45 [1920/2812 (68%)]\tLoss: 6.877969\n",
            "Train Epoch: 45 [2040/2812 (72%)]\tLoss: 18.217852\n",
            "Train Epoch: 45 [2160/2812 (77%)]\tLoss: 10.930670\n",
            "Train Epoch: 45 [2280/2812 (81%)]\tLoss: 12.790052\n",
            "Train Epoch: 45 [2400/2812 (85%)]\tLoss: 5.373663\n",
            "Train Epoch: 45 [2520/2812 (89%)]\tLoss: 12.646219\n",
            "Train Epoch: 45 [2640/2812 (94%)]\tLoss: 6.057746\n",
            "Train Epoch: 45 [2760/2812 (98%)]\tLoss: 15.828458\n",
            "Training Loss: 11.4121 Acc: 50.1067\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5922, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 46/200\n",
            "----------\n",
            "Train Epoch: 46 [0/2812 (0%)]\tLoss: 18.116920\n",
            "Train Epoch: 46 [120/2812 (4%)]\tLoss: 15.520993\n",
            "Train Epoch: 46 [240/2812 (9%)]\tLoss: 4.206210\n",
            "Train Epoch: 46 [360/2812 (13%)]\tLoss: 4.485303\n",
            "Train Epoch: 46 [480/2812 (17%)]\tLoss: 19.341780\n",
            "Train Epoch: 46 [600/2812 (21%)]\tLoss: 11.253691\n",
            "Train Epoch: 46 [720/2812 (26%)]\tLoss: 15.360846\n",
            "Train Epoch: 46 [840/2812 (30%)]\tLoss: 15.566281\n",
            "Train Epoch: 46 [960/2812 (34%)]\tLoss: 14.378382\n",
            "Train Epoch: 46 [1080/2812 (38%)]\tLoss: 13.242937\n",
            "Train Epoch: 46 [1200/2812 (43%)]\tLoss: 15.477942\n",
            "Train Epoch: 46 [1320/2812 (47%)]\tLoss: 5.920522\n",
            "Train Epoch: 46 [1440/2812 (51%)]\tLoss: 24.557341\n",
            "Train Epoch: 46 [1560/2812 (55%)]\tLoss: 11.858763\n",
            "Train Epoch: 46 [1680/2812 (60%)]\tLoss: 9.540993\n",
            "Train Epoch: 46 [1800/2812 (64%)]\tLoss: 11.802303\n",
            "Train Epoch: 46 [1920/2812 (68%)]\tLoss: 7.486335\n",
            "Train Epoch: 46 [2040/2812 (72%)]\tLoss: 14.517323\n",
            "Train Epoch: 46 [2160/2812 (77%)]\tLoss: 7.083308\n",
            "Train Epoch: 46 [2280/2812 (81%)]\tLoss: 11.598269\n",
            "Train Epoch: 46 [2400/2812 (85%)]\tLoss: 10.267716\n",
            "Train Epoch: 46 [2520/2812 (89%)]\tLoss: 17.417263\n",
            "Train Epoch: 46 [2640/2812 (94%)]\tLoss: 8.266984\n",
            "Train Epoch: 46 [2760/2812 (98%)]\tLoss: 8.855531\n",
            "Training Loss: 11.0856 Acc: 49.8933\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5653, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 47/200\n",
            "----------\n",
            "Train Epoch: 47 [0/2812 (0%)]\tLoss: 8.690607\n",
            "Train Epoch: 47 [120/2812 (4%)]\tLoss: 8.117968\n",
            "Train Epoch: 47 [240/2812 (9%)]\tLoss: 6.882558\n",
            "Train Epoch: 47 [360/2812 (13%)]\tLoss: 14.070435\n",
            "Train Epoch: 47 [480/2812 (17%)]\tLoss: 15.192606\n",
            "Train Epoch: 47 [600/2812 (21%)]\tLoss: 9.025084\n",
            "Train Epoch: 47 [720/2812 (26%)]\tLoss: 13.699374\n",
            "Train Epoch: 47 [840/2812 (30%)]\tLoss: 3.667427\n",
            "Train Epoch: 47 [960/2812 (34%)]\tLoss: 9.303247\n",
            "Train Epoch: 47 [1080/2812 (38%)]\tLoss: 15.228488\n",
            "Train Epoch: 47 [1200/2812 (43%)]\tLoss: 2.444936\n",
            "Train Epoch: 47 [1320/2812 (47%)]\tLoss: 8.348850\n",
            "Train Epoch: 47 [1440/2812 (51%)]\tLoss: 10.700327\n",
            "Train Epoch: 47 [1560/2812 (55%)]\tLoss: 0.179404\n",
            "Train Epoch: 47 [1680/2812 (60%)]\tLoss: 19.026123\n",
            "Train Epoch: 47 [1800/2812 (64%)]\tLoss: 15.882925\n",
            "Train Epoch: 47 [1920/2812 (68%)]\tLoss: 12.596237\n",
            "Train Epoch: 47 [2040/2812 (72%)]\tLoss: 12.071596\n",
            "Train Epoch: 47 [2160/2812 (77%)]\tLoss: 3.338517\n",
            "Train Epoch: 47 [2280/2812 (81%)]\tLoss: 5.272820\n",
            "Train Epoch: 47 [2400/2812 (85%)]\tLoss: 16.967554\n",
            "Train Epoch: 47 [2520/2812 (89%)]\tLoss: 20.437431\n",
            "Train Epoch: 47 [2640/2812 (94%)]\tLoss: 4.949927\n",
            "Train Epoch: 47 [2760/2812 (98%)]\tLoss: 4.025174\n",
            "Training Loss: 10.9676 Acc: 51.1735\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5963, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 48/200\n",
            "----------\n",
            "Train Epoch: 48 [0/2812 (0%)]\tLoss: 22.765156\n",
            "Train Epoch: 48 [120/2812 (4%)]\tLoss: 8.709490\n",
            "Train Epoch: 48 [240/2812 (9%)]\tLoss: 11.052438\n",
            "Train Epoch: 48 [360/2812 (13%)]\tLoss: 8.542123\n",
            "Train Epoch: 48 [480/2812 (17%)]\tLoss: 15.332438\n",
            "Train Epoch: 48 [600/2812 (21%)]\tLoss: 19.413616\n",
            "Train Epoch: 48 [720/2812 (26%)]\tLoss: 27.297466\n",
            "Train Epoch: 48 [840/2812 (30%)]\tLoss: 10.488066\n",
            "Train Epoch: 48 [960/2812 (34%)]\tLoss: 3.166828\n",
            "Train Epoch: 48 [1080/2812 (38%)]\tLoss: 12.425001\n",
            "Train Epoch: 48 [1200/2812 (43%)]\tLoss: 10.242861\n",
            "Train Epoch: 48 [1320/2812 (47%)]\tLoss: 9.907869\n",
            "Train Epoch: 48 [1440/2812 (51%)]\tLoss: 12.714525\n",
            "Train Epoch: 48 [1560/2812 (55%)]\tLoss: 7.242687\n",
            "Train Epoch: 48 [1680/2812 (60%)]\tLoss: 7.012819\n",
            "Train Epoch: 48 [1800/2812 (64%)]\tLoss: 18.797842\n",
            "Train Epoch: 48 [1920/2812 (68%)]\tLoss: 14.379079\n",
            "Train Epoch: 48 [2040/2812 (72%)]\tLoss: 11.748795\n",
            "Train Epoch: 48 [2160/2812 (77%)]\tLoss: 11.534575\n",
            "Train Epoch: 48 [2280/2812 (81%)]\tLoss: 11.880138\n",
            "Train Epoch: 48 [2400/2812 (85%)]\tLoss: 7.482211\n",
            "Train Epoch: 48 [2520/2812 (89%)]\tLoss: 5.286925\n",
            "Train Epoch: 48 [2640/2812 (94%)]\tLoss: 25.469501\n",
            "Train Epoch: 48 [2760/2812 (98%)]\tLoss: 3.008786\n",
            "Training Loss: 11.3811 Acc: 50.2489\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5858, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 49/200\n",
            "----------\n",
            "Train Epoch: 49 [0/2812 (0%)]\tLoss: 5.581719\n",
            "Train Epoch: 49 [120/2812 (4%)]\tLoss: 6.051156\n",
            "Train Epoch: 49 [240/2812 (9%)]\tLoss: 7.456641\n",
            "Train Epoch: 49 [360/2812 (13%)]\tLoss: 12.032285\n",
            "Train Epoch: 49 [480/2812 (17%)]\tLoss: 11.785089\n",
            "Train Epoch: 49 [600/2812 (21%)]\tLoss: 15.154188\n",
            "Train Epoch: 49 [720/2812 (26%)]\tLoss: 3.957703\n",
            "Train Epoch: 49 [840/2812 (30%)]\tLoss: 2.315087\n",
            "Train Epoch: 49 [960/2812 (34%)]\tLoss: 17.420452\n",
            "Train Epoch: 49 [1080/2812 (38%)]\tLoss: 11.247046\n",
            "Train Epoch: 49 [1200/2812 (43%)]\tLoss: 8.648262\n",
            "Train Epoch: 49 [1320/2812 (47%)]\tLoss: 4.484232\n",
            "Train Epoch: 49 [1440/2812 (51%)]\tLoss: 4.487100\n",
            "Train Epoch: 49 [1560/2812 (55%)]\tLoss: 4.476336\n",
            "Train Epoch: 49 [1680/2812 (60%)]\tLoss: 7.525079\n",
            "Train Epoch: 49 [1800/2812 (64%)]\tLoss: 13.884639\n",
            "Train Epoch: 49 [1920/2812 (68%)]\tLoss: 15.788124\n",
            "Train Epoch: 49 [2040/2812 (72%)]\tLoss: 20.685865\n",
            "Train Epoch: 49 [2160/2812 (77%)]\tLoss: 11.700634\n",
            "Train Epoch: 49 [2280/2812 (81%)]\tLoss: 17.398479\n",
            "Train Epoch: 49 [2400/2812 (85%)]\tLoss: 14.965197\n",
            "Train Epoch: 49 [2520/2812 (89%)]\tLoss: 5.731791\n",
            "Train Epoch: 49 [2640/2812 (94%)]\tLoss: 9.922536\n",
            "Train Epoch: 49 [2760/2812 (98%)]\tLoss: 13.732546\n",
            "Training Loss: 11.0841 Acc: 50.1778\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5551, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 50/200\n",
            "----------\n",
            "Train Epoch: 50 [0/2812 (0%)]\tLoss: 12.331487\n",
            "Train Epoch: 50 [120/2812 (4%)]\tLoss: 6.817998\n",
            "Train Epoch: 50 [240/2812 (9%)]\tLoss: 8.547671\n",
            "Train Epoch: 50 [360/2812 (13%)]\tLoss: 23.036366\n",
            "Train Epoch: 50 [480/2812 (17%)]\tLoss: 10.235539\n",
            "Train Epoch: 50 [600/2812 (21%)]\tLoss: 1.612738\n",
            "Train Epoch: 50 [720/2812 (26%)]\tLoss: 7.121530\n",
            "Train Epoch: 50 [840/2812 (30%)]\tLoss: 17.025166\n",
            "Train Epoch: 50 [960/2812 (34%)]\tLoss: 1.729446\n",
            "Train Epoch: 50 [1080/2812 (38%)]\tLoss: 9.685228\n",
            "Train Epoch: 50 [1200/2812 (43%)]\tLoss: 27.948267\n",
            "Train Epoch: 50 [1320/2812 (47%)]\tLoss: 15.862198\n",
            "Train Epoch: 50 [1440/2812 (51%)]\tLoss: 9.142240\n",
            "Train Epoch: 50 [1560/2812 (55%)]\tLoss: 8.926781\n",
            "Train Epoch: 50 [1680/2812 (60%)]\tLoss: 12.064386\n",
            "Train Epoch: 50 [1800/2812 (64%)]\tLoss: 15.641073\n",
            "Train Epoch: 50 [1920/2812 (68%)]\tLoss: 14.701515\n",
            "Train Epoch: 50 [2040/2812 (72%)]\tLoss: 15.151627\n",
            "Train Epoch: 50 [2160/2812 (77%)]\tLoss: 15.709720\n",
            "Train Epoch: 50 [2280/2812 (81%)]\tLoss: 7.285116\n",
            "Train Epoch: 50 [2400/2812 (85%)]\tLoss: 11.647532\n",
            "Train Epoch: 50 [2520/2812 (89%)]\tLoss: 8.113137\n",
            "Train Epoch: 50 [2640/2812 (94%)]\tLoss: 2.844411\n",
            "Train Epoch: 50 [2760/2812 (98%)]\tLoss: 15.456553\n",
            "Training Loss: 11.5058 Acc: 50.7112\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6670, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 51/200\n",
            "----------\n",
            "Train Epoch: 51 [0/2812 (0%)]\tLoss: 15.801288\n",
            "Train Epoch: 51 [120/2812 (4%)]\tLoss: 9.253901\n",
            "Train Epoch: 51 [240/2812 (9%)]\tLoss: 5.480338\n",
            "Train Epoch: 51 [360/2812 (13%)]\tLoss: 7.933021\n",
            "Train Epoch: 51 [480/2812 (17%)]\tLoss: 14.975235\n",
            "Train Epoch: 51 [600/2812 (21%)]\tLoss: 8.314256\n",
            "Train Epoch: 51 [720/2812 (26%)]\tLoss: 7.642270\n",
            "Train Epoch: 51 [840/2812 (30%)]\tLoss: 25.372318\n",
            "Train Epoch: 51 [960/2812 (34%)]\tLoss: 8.158457\n",
            "Train Epoch: 51 [1080/2812 (38%)]\tLoss: 14.435036\n",
            "Train Epoch: 51 [1200/2812 (43%)]\tLoss: 19.494211\n",
            "Train Epoch: 51 [1320/2812 (47%)]\tLoss: 10.433357\n",
            "Train Epoch: 51 [1440/2812 (51%)]\tLoss: 4.896758\n",
            "Train Epoch: 51 [1560/2812 (55%)]\tLoss: 11.863994\n",
            "Train Epoch: 51 [1680/2812 (60%)]\tLoss: 13.444227\n",
            "Train Epoch: 51 [1800/2812 (64%)]\tLoss: 7.924829\n",
            "Train Epoch: 51 [1920/2812 (68%)]\tLoss: 8.226717\n",
            "Train Epoch: 51 [2040/2812 (72%)]\tLoss: 21.301954\n",
            "Train Epoch: 51 [2160/2812 (77%)]\tLoss: 22.705164\n",
            "Train Epoch: 51 [2280/2812 (81%)]\tLoss: 11.018633\n",
            "Train Epoch: 51 [2400/2812 (85%)]\tLoss: 5.414327\n",
            "Train Epoch: 51 [2520/2812 (89%)]\tLoss: 11.749582\n",
            "Train Epoch: 51 [2640/2812 (94%)]\tLoss: 1.915141\n",
            "Train Epoch: 51 [2760/2812 (98%)]\tLoss: 13.748713\n",
            "Training Loss: 10.9466 Acc: 50.1067\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5867, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 52/200\n",
            "----------\n",
            "Train Epoch: 52 [0/2812 (0%)]\tLoss: 13.438052\n",
            "Train Epoch: 52 [120/2812 (4%)]\tLoss: 4.309249\n",
            "Train Epoch: 52 [240/2812 (9%)]\tLoss: 13.049124\n",
            "Train Epoch: 52 [360/2812 (13%)]\tLoss: 9.946744\n",
            "Train Epoch: 52 [480/2812 (17%)]\tLoss: 13.948481\n",
            "Train Epoch: 52 [600/2812 (21%)]\tLoss: 1.004878\n",
            "Train Epoch: 52 [720/2812 (26%)]\tLoss: 11.901817\n",
            "Train Epoch: 52 [840/2812 (30%)]\tLoss: 11.145067\n",
            "Train Epoch: 52 [960/2812 (34%)]\tLoss: 27.094778\n",
            "Train Epoch: 52 [1080/2812 (38%)]\tLoss: 10.524343\n",
            "Train Epoch: 52 [1200/2812 (43%)]\tLoss: 6.908996\n",
            "Train Epoch: 52 [1320/2812 (47%)]\tLoss: 19.646038\n",
            "Train Epoch: 52 [1440/2812 (51%)]\tLoss: 13.789589\n",
            "Train Epoch: 52 [1560/2812 (55%)]\tLoss: 14.747818\n",
            "Train Epoch: 52 [1680/2812 (60%)]\tLoss: 19.224066\n",
            "Train Epoch: 52 [1800/2812 (64%)]\tLoss: 3.455840\n",
            "Train Epoch: 52 [1920/2812 (68%)]\tLoss: 8.388417\n",
            "Train Epoch: 52 [2040/2812 (72%)]\tLoss: 6.098660\n",
            "Train Epoch: 52 [2160/2812 (77%)]\tLoss: 5.903482\n",
            "Train Epoch: 52 [2280/2812 (81%)]\tLoss: 11.755548\n",
            "Train Epoch: 52 [2400/2812 (85%)]\tLoss: 33.351631\n",
            "Train Epoch: 52 [2520/2812 (89%)]\tLoss: 15.175847\n",
            "Train Epoch: 52 [2640/2812 (94%)]\tLoss: 0.013040\n",
            "Train Epoch: 52 [2760/2812 (98%)]\tLoss: 10.469347\n",
            "Training Loss: 10.9725 Acc: 50.6401\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5225, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 53/200\n",
            "----------\n",
            "Train Epoch: 53 [0/2812 (0%)]\tLoss: 12.846758\n",
            "Train Epoch: 53 [120/2812 (4%)]\tLoss: 13.183164\n",
            "Train Epoch: 53 [240/2812 (9%)]\tLoss: 19.823713\n",
            "Train Epoch: 53 [360/2812 (13%)]\tLoss: 13.372629\n",
            "Train Epoch: 53 [480/2812 (17%)]\tLoss: 16.583218\n",
            "Train Epoch: 53 [600/2812 (21%)]\tLoss: 18.319155\n",
            "Train Epoch: 53 [720/2812 (26%)]\tLoss: 17.917171\n",
            "Train Epoch: 53 [840/2812 (30%)]\tLoss: 7.619762\n",
            "Train Epoch: 53 [960/2812 (34%)]\tLoss: 6.223224\n",
            "Train Epoch: 53 [1080/2812 (38%)]\tLoss: 5.957760\n",
            "Train Epoch: 53 [1200/2812 (43%)]\tLoss: 6.539767\n",
            "Train Epoch: 53 [1320/2812 (47%)]\tLoss: 11.660733\n",
            "Train Epoch: 53 [1440/2812 (51%)]\tLoss: 10.477076\n",
            "Train Epoch: 53 [1560/2812 (55%)]\tLoss: 11.866439\n",
            "Train Epoch: 53 [1680/2812 (60%)]\tLoss: 12.218904\n",
            "Train Epoch: 53 [1800/2812 (64%)]\tLoss: 8.692000\n",
            "Train Epoch: 53 [1920/2812 (68%)]\tLoss: 8.174410\n",
            "Train Epoch: 53 [2040/2812 (72%)]\tLoss: 20.688000\n",
            "Train Epoch: 53 [2160/2812 (77%)]\tLoss: 9.990481\n",
            "Train Epoch: 53 [2280/2812 (81%)]\tLoss: 13.455905\n",
            "Train Epoch: 53 [2400/2812 (85%)]\tLoss: 7.643903\n",
            "Train Epoch: 53 [2520/2812 (89%)]\tLoss: 10.221275\n",
            "Train Epoch: 53 [2640/2812 (94%)]\tLoss: 11.394247\n",
            "Train Epoch: 53 [2760/2812 (98%)]\tLoss: 14.440557\n",
            "Training Loss: 11.4070 Acc: 48.9687\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5718, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 54/200\n",
            "----------\n",
            "Train Epoch: 54 [0/2812 (0%)]\tLoss: 6.847021\n",
            "Train Epoch: 54 [120/2812 (4%)]\tLoss: 5.451868\n",
            "Train Epoch: 54 [240/2812 (9%)]\tLoss: 25.470417\n",
            "Train Epoch: 54 [360/2812 (13%)]\tLoss: 10.939444\n",
            "Train Epoch: 54 [480/2812 (17%)]\tLoss: 2.500315\n",
            "Train Epoch: 54 [600/2812 (21%)]\tLoss: 8.532388\n",
            "Train Epoch: 54 [720/2812 (26%)]\tLoss: 1.278555\n",
            "Train Epoch: 54 [840/2812 (30%)]\tLoss: 14.682795\n",
            "Train Epoch: 54 [960/2812 (34%)]\tLoss: 1.946773\n",
            "Train Epoch: 54 [1080/2812 (38%)]\tLoss: 11.573506\n",
            "Train Epoch: 54 [1200/2812 (43%)]\tLoss: 9.517402\n",
            "Train Epoch: 54 [1320/2812 (47%)]\tLoss: 5.071923\n",
            "Train Epoch: 54 [1440/2812 (51%)]\tLoss: 19.701649\n",
            "Train Epoch: 54 [1560/2812 (55%)]\tLoss: 19.136707\n",
            "Train Epoch: 54 [1680/2812 (60%)]\tLoss: 14.577373\n",
            "Train Epoch: 54 [1800/2812 (64%)]\tLoss: 13.268019\n",
            "Train Epoch: 54 [1920/2812 (68%)]\tLoss: 10.874998\n",
            "Train Epoch: 54 [2040/2812 (72%)]\tLoss: 12.367325\n",
            "Train Epoch: 54 [2160/2812 (77%)]\tLoss: 16.224674\n",
            "Train Epoch: 54 [2280/2812 (81%)]\tLoss: 8.423717\n",
            "Train Epoch: 54 [2400/2812 (85%)]\tLoss: 13.357160\n",
            "Train Epoch: 54 [2520/2812 (89%)]\tLoss: 9.186522\n",
            "Train Epoch: 54 [2640/2812 (94%)]\tLoss: 19.633354\n",
            "Train Epoch: 54 [2760/2812 (98%)]\tLoss: 11.226023\n",
            "Training Loss: 11.2684 Acc: 50.1422\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5311, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 55/200\n",
            "----------\n",
            "Train Epoch: 55 [0/2812 (0%)]\tLoss: 8.118431\n",
            "Train Epoch: 55 [120/2812 (4%)]\tLoss: 9.503671\n",
            "Train Epoch: 55 [240/2812 (9%)]\tLoss: 10.313704\n",
            "Train Epoch: 55 [360/2812 (13%)]\tLoss: 1.238744\n",
            "Train Epoch: 55 [480/2812 (17%)]\tLoss: 8.469734\n",
            "Train Epoch: 55 [600/2812 (21%)]\tLoss: 12.710443\n",
            "Train Epoch: 55 [720/2812 (26%)]\tLoss: 12.784655\n",
            "Train Epoch: 55 [840/2812 (30%)]\tLoss: 8.973940\n",
            "Train Epoch: 55 [960/2812 (34%)]\tLoss: 8.965012\n",
            "Train Epoch: 55 [1080/2812 (38%)]\tLoss: 10.307833\n",
            "Train Epoch: 55 [1200/2812 (43%)]\tLoss: 10.031301\n",
            "Train Epoch: 55 [1320/2812 (47%)]\tLoss: 15.536380\n",
            "Train Epoch: 55 [1440/2812 (51%)]\tLoss: 14.470076\n",
            "Train Epoch: 55 [1560/2812 (55%)]\tLoss: 12.211988\n",
            "Train Epoch: 55 [1680/2812 (60%)]\tLoss: 14.835843\n",
            "Train Epoch: 55 [1800/2812 (64%)]\tLoss: 11.073523\n",
            "Train Epoch: 55 [1920/2812 (68%)]\tLoss: 5.115913\n",
            "Train Epoch: 55 [2040/2812 (72%)]\tLoss: 10.867215\n",
            "Train Epoch: 55 [2160/2812 (77%)]\tLoss: 9.903079\n",
            "Train Epoch: 55 [2280/2812 (81%)]\tLoss: 2.461780\n",
            "Train Epoch: 55 [2400/2812 (85%)]\tLoss: 7.251256\n",
            "Train Epoch: 55 [2520/2812 (89%)]\tLoss: 5.452834\n",
            "Train Epoch: 55 [2640/2812 (94%)]\tLoss: 5.063712\n",
            "Train Epoch: 55 [2760/2812 (98%)]\tLoss: 10.327224\n",
            "Training Loss: 10.9923 Acc: 50.0711\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5707, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 56/200\n",
            "----------\n",
            "Train Epoch: 56 [0/2812 (0%)]\tLoss: 9.999037\n",
            "Train Epoch: 56 [120/2812 (4%)]\tLoss: 5.122968\n",
            "Train Epoch: 56 [240/2812 (9%)]\tLoss: 14.554767\n",
            "Train Epoch: 56 [360/2812 (13%)]\tLoss: 8.327750\n",
            "Train Epoch: 56 [480/2812 (17%)]\tLoss: 10.906267\n",
            "Train Epoch: 56 [600/2812 (21%)]\tLoss: 11.604485\n",
            "Train Epoch: 56 [720/2812 (26%)]\tLoss: 23.519039\n",
            "Train Epoch: 56 [840/2812 (30%)]\tLoss: 10.180777\n",
            "Train Epoch: 56 [960/2812 (34%)]\tLoss: 23.005026\n",
            "Train Epoch: 56 [1080/2812 (38%)]\tLoss: 20.769987\n",
            "Train Epoch: 56 [1200/2812 (43%)]\tLoss: 14.293703\n",
            "Train Epoch: 56 [1320/2812 (47%)]\tLoss: 10.584453\n",
            "Train Epoch: 56 [1440/2812 (51%)]\tLoss: 3.082138\n",
            "Train Epoch: 56 [1560/2812 (55%)]\tLoss: 14.248570\n",
            "Train Epoch: 56 [1680/2812 (60%)]\tLoss: 17.760569\n",
            "Train Epoch: 56 [1800/2812 (64%)]\tLoss: 12.944628\n",
            "Train Epoch: 56 [1920/2812 (68%)]\tLoss: 10.849812\n",
            "Train Epoch: 56 [2040/2812 (72%)]\tLoss: 16.090742\n",
            "Train Epoch: 56 [2160/2812 (77%)]\tLoss: 3.979424\n",
            "Train Epoch: 56 [2280/2812 (81%)]\tLoss: 10.262362\n",
            "Train Epoch: 56 [2400/2812 (85%)]\tLoss: 17.888451\n",
            "Train Epoch: 56 [2520/2812 (89%)]\tLoss: 8.008389\n",
            "Train Epoch: 56 [2640/2812 (94%)]\tLoss: 14.145895\n",
            "Train Epoch: 56 [2760/2812 (98%)]\tLoss: 15.776030\n",
            "Training Loss: 11.3067 Acc: 50.6401\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5161, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 57/200\n",
            "----------\n",
            "Train Epoch: 57 [0/2812 (0%)]\tLoss: 16.059978\n",
            "Train Epoch: 57 [120/2812 (4%)]\tLoss: 13.338534\n",
            "Train Epoch: 57 [240/2812 (9%)]\tLoss: 13.218721\n",
            "Train Epoch: 57 [360/2812 (13%)]\tLoss: 4.966457\n",
            "Train Epoch: 57 [480/2812 (17%)]\tLoss: 5.555828\n",
            "Train Epoch: 57 [600/2812 (21%)]\tLoss: 6.266324\n",
            "Train Epoch: 57 [720/2812 (26%)]\tLoss: 11.170610\n",
            "Train Epoch: 57 [840/2812 (30%)]\tLoss: 14.625916\n",
            "Train Epoch: 57 [960/2812 (34%)]\tLoss: 17.632689\n",
            "Train Epoch: 57 [1080/2812 (38%)]\tLoss: 12.404220\n",
            "Train Epoch: 57 [1200/2812 (43%)]\tLoss: 12.220717\n",
            "Train Epoch: 57 [1320/2812 (47%)]\tLoss: 19.962788\n",
            "Train Epoch: 57 [1440/2812 (51%)]\tLoss: 12.641080\n",
            "Train Epoch: 57 [1560/2812 (55%)]\tLoss: 4.525302\n",
            "Train Epoch: 57 [1680/2812 (60%)]\tLoss: 25.452663\n",
            "Train Epoch: 57 [1800/2812 (64%)]\tLoss: 15.035707\n",
            "Train Epoch: 57 [1920/2812 (68%)]\tLoss: 5.352527\n",
            "Train Epoch: 57 [2040/2812 (72%)]\tLoss: 11.417838\n",
            "Train Epoch: 57 [2160/2812 (77%)]\tLoss: 13.803615\n",
            "Train Epoch: 57 [2280/2812 (81%)]\tLoss: 4.074128\n",
            "Train Epoch: 57 [2400/2812 (85%)]\tLoss: 1.455375\n",
            "Train Epoch: 57 [2520/2812 (89%)]\tLoss: 13.490352\n",
            "Train Epoch: 57 [2640/2812 (94%)]\tLoss: 8.719996\n",
            "Train Epoch: 57 [2760/2812 (98%)]\tLoss: 4.755654\n",
            "Training Loss: 11.0154 Acc: 51.3514\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5349, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 58/200\n",
            "----------\n",
            "Train Epoch: 58 [0/2812 (0%)]\tLoss: 5.065896\n",
            "Train Epoch: 58 [120/2812 (4%)]\tLoss: 18.740459\n",
            "Train Epoch: 58 [240/2812 (9%)]\tLoss: 19.871510\n",
            "Train Epoch: 58 [360/2812 (13%)]\tLoss: 10.332975\n",
            "Train Epoch: 58 [480/2812 (17%)]\tLoss: 15.543785\n",
            "Train Epoch: 58 [600/2812 (21%)]\tLoss: 16.562460\n",
            "Train Epoch: 58 [720/2812 (26%)]\tLoss: 9.231194\n",
            "Train Epoch: 58 [840/2812 (30%)]\tLoss: 17.549986\n",
            "Train Epoch: 58 [960/2812 (34%)]\tLoss: 18.198093\n",
            "Train Epoch: 58 [1080/2812 (38%)]\tLoss: 22.761076\n",
            "Train Epoch: 58 [1200/2812 (43%)]\tLoss: 5.163540\n",
            "Train Epoch: 58 [1320/2812 (47%)]\tLoss: 2.949926\n",
            "Train Epoch: 58 [1440/2812 (51%)]\tLoss: 4.980527\n",
            "Train Epoch: 58 [1560/2812 (55%)]\tLoss: 17.432146\n",
            "Train Epoch: 58 [1680/2812 (60%)]\tLoss: 13.206146\n",
            "Train Epoch: 58 [1800/2812 (64%)]\tLoss: 14.220401\n",
            "Train Epoch: 58 [1920/2812 (68%)]\tLoss: 14.434972\n",
            "Train Epoch: 58 [2040/2812 (72%)]\tLoss: 16.024454\n",
            "Train Epoch: 58 [2160/2812 (77%)]\tLoss: 9.712564\n",
            "Train Epoch: 58 [2280/2812 (81%)]\tLoss: 21.189705\n",
            "Train Epoch: 58 [2400/2812 (85%)]\tLoss: 16.293844\n",
            "Train Epoch: 58 [2520/2812 (89%)]\tLoss: 4.373502\n",
            "Train Epoch: 58 [2640/2812 (94%)]\tLoss: 13.313065\n",
            "Train Epoch: 58 [2760/2812 (98%)]\tLoss: 4.543509\n",
            "Training Loss: 11.1856 Acc: 50.5690\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6112, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 59/200\n",
            "----------\n",
            "Train Epoch: 59 [0/2812 (0%)]\tLoss: 6.417083\n",
            "Train Epoch: 59 [120/2812 (4%)]\tLoss: 22.069340\n",
            "Train Epoch: 59 [240/2812 (9%)]\tLoss: 16.014160\n",
            "Train Epoch: 59 [360/2812 (13%)]\tLoss: 9.576764\n",
            "Train Epoch: 59 [480/2812 (17%)]\tLoss: 9.237127\n",
            "Train Epoch: 59 [600/2812 (21%)]\tLoss: 6.034738\n",
            "Train Epoch: 59 [720/2812 (26%)]\tLoss: 11.128941\n",
            "Train Epoch: 59 [840/2812 (30%)]\tLoss: 25.058992\n",
            "Train Epoch: 59 [960/2812 (34%)]\tLoss: 5.481970\n",
            "Train Epoch: 59 [1080/2812 (38%)]\tLoss: 10.870639\n",
            "Train Epoch: 59 [1200/2812 (43%)]\tLoss: 13.364011\n",
            "Train Epoch: 59 [1320/2812 (47%)]\tLoss: 18.894497\n",
            "Train Epoch: 59 [1440/2812 (51%)]\tLoss: 6.434134\n",
            "Train Epoch: 59 [1560/2812 (55%)]\tLoss: 16.871208\n",
            "Train Epoch: 59 [1680/2812 (60%)]\tLoss: 19.354717\n",
            "Train Epoch: 59 [1800/2812 (64%)]\tLoss: 10.112164\n",
            "Train Epoch: 59 [1920/2812 (68%)]\tLoss: 10.784456\n",
            "Train Epoch: 59 [2040/2812 (72%)]\tLoss: 19.152756\n",
            "Train Epoch: 59 [2160/2812 (77%)]\tLoss: 16.937901\n",
            "Train Epoch: 59 [2280/2812 (81%)]\tLoss: 5.021914\n",
            "Train Epoch: 59 [2400/2812 (85%)]\tLoss: 6.728918\n",
            "Train Epoch: 59 [2520/2812 (89%)]\tLoss: 3.961074\n",
            "Train Epoch: 59 [2640/2812 (94%)]\tLoss: 10.065608\n",
            "Train Epoch: 59 [2760/2812 (98%)]\tLoss: 3.937039\n",
            "Training Loss: 10.9212 Acc: 49.7155\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6006, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 60/200\n",
            "----------\n",
            "Train Epoch: 60 [0/2812 (0%)]\tLoss: 9.596975\n",
            "Train Epoch: 60 [120/2812 (4%)]\tLoss: 7.319978\n",
            "Train Epoch: 60 [240/2812 (9%)]\tLoss: 1.763663\n",
            "Train Epoch: 60 [360/2812 (13%)]\tLoss: 9.217618\n",
            "Train Epoch: 60 [480/2812 (17%)]\tLoss: 21.883007\n",
            "Train Epoch: 60 [600/2812 (21%)]\tLoss: 13.430956\n",
            "Train Epoch: 60 [720/2812 (26%)]\tLoss: 18.418034\n",
            "Train Epoch: 60 [840/2812 (30%)]\tLoss: 8.274893\n",
            "Train Epoch: 60 [960/2812 (34%)]\tLoss: 14.222201\n",
            "Train Epoch: 60 [1080/2812 (38%)]\tLoss: 7.068497\n",
            "Train Epoch: 60 [1200/2812 (43%)]\tLoss: 2.516563\n",
            "Train Epoch: 60 [1320/2812 (47%)]\tLoss: 20.693207\n",
            "Train Epoch: 60 [1440/2812 (51%)]\tLoss: 32.206902\n",
            "Train Epoch: 60 [1560/2812 (55%)]\tLoss: 12.827870\n",
            "Train Epoch: 60 [1680/2812 (60%)]\tLoss: 4.903334\n",
            "Train Epoch: 60 [1800/2812 (64%)]\tLoss: 11.220279\n",
            "Train Epoch: 60 [1920/2812 (68%)]\tLoss: 6.188682\n",
            "Train Epoch: 60 [2040/2812 (72%)]\tLoss: 4.635894\n",
            "Train Epoch: 60 [2160/2812 (77%)]\tLoss: 16.069529\n",
            "Train Epoch: 60 [2280/2812 (81%)]\tLoss: 13.567606\n",
            "Train Epoch: 60 [2400/2812 (85%)]\tLoss: 11.838446\n",
            "Train Epoch: 60 [2520/2812 (89%)]\tLoss: 8.164996\n",
            "Train Epoch: 60 [2640/2812 (94%)]\tLoss: 15.119028\n",
            "Train Epoch: 60 [2760/2812 (98%)]\tLoss: 16.361183\n",
            "Training Loss: 11.0607 Acc: 50.8890\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6348, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 61/200\n",
            "----------\n",
            "Train Epoch: 61 [0/2812 (0%)]\tLoss: 19.331451\n",
            "Train Epoch: 61 [120/2812 (4%)]\tLoss: 13.255664\n",
            "Train Epoch: 61 [240/2812 (9%)]\tLoss: 14.574816\n",
            "Train Epoch: 61 [360/2812 (13%)]\tLoss: 1.398463\n",
            "Train Epoch: 61 [480/2812 (17%)]\tLoss: 14.665051\n",
            "Train Epoch: 61 [600/2812 (21%)]\tLoss: 14.301653\n",
            "Train Epoch: 61 [720/2812 (26%)]\tLoss: 19.405706\n",
            "Train Epoch: 61 [840/2812 (30%)]\tLoss: 12.639694\n",
            "Train Epoch: 61 [960/2812 (34%)]\tLoss: 6.396978\n",
            "Train Epoch: 61 [1080/2812 (38%)]\tLoss: 8.953238\n",
            "Train Epoch: 61 [1200/2812 (43%)]\tLoss: 12.124082\n",
            "Train Epoch: 61 [1320/2812 (47%)]\tLoss: 16.429440\n",
            "Train Epoch: 61 [1440/2812 (51%)]\tLoss: 5.267888\n",
            "Train Epoch: 61 [1560/2812 (55%)]\tLoss: 13.147169\n",
            "Train Epoch: 61 [1680/2812 (60%)]\tLoss: 7.727187\n",
            "Train Epoch: 61 [1800/2812 (64%)]\tLoss: 15.446010\n",
            "Train Epoch: 61 [1920/2812 (68%)]\tLoss: 8.980683\n",
            "Train Epoch: 61 [2040/2812 (72%)]\tLoss: 24.654715\n",
            "Train Epoch: 61 [2160/2812 (77%)]\tLoss: 16.022045\n",
            "Train Epoch: 61 [2280/2812 (81%)]\tLoss: 14.084355\n",
            "Train Epoch: 61 [2400/2812 (85%)]\tLoss: 9.415275\n",
            "Train Epoch: 61 [2520/2812 (89%)]\tLoss: 12.017149\n",
            "Train Epoch: 61 [2640/2812 (94%)]\tLoss: 14.282115\n",
            "Train Epoch: 61 [2760/2812 (98%)]\tLoss: 16.222027\n",
            "Training Loss: 11.1178 Acc: 49.4310\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5918, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 62/200\n",
            "----------\n",
            "Train Epoch: 62 [0/2812 (0%)]\tLoss: 18.105255\n",
            "Train Epoch: 62 [120/2812 (4%)]\tLoss: 5.287383\n",
            "Train Epoch: 62 [240/2812 (9%)]\tLoss: 25.381235\n",
            "Train Epoch: 62 [360/2812 (13%)]\tLoss: 0.902760\n",
            "Train Epoch: 62 [480/2812 (17%)]\tLoss: 6.956347\n",
            "Train Epoch: 62 [600/2812 (21%)]\tLoss: 9.109456\n",
            "Train Epoch: 62 [720/2812 (26%)]\tLoss: 13.955025\n",
            "Train Epoch: 62 [840/2812 (30%)]\tLoss: 21.200825\n",
            "Train Epoch: 62 [960/2812 (34%)]\tLoss: 11.189674\n",
            "Train Epoch: 62 [1080/2812 (38%)]\tLoss: 5.062763\n",
            "Train Epoch: 62 [1200/2812 (43%)]\tLoss: 2.306513\n",
            "Train Epoch: 62 [1320/2812 (47%)]\tLoss: 10.317213\n",
            "Train Epoch: 62 [1440/2812 (51%)]\tLoss: 10.287087\n",
            "Train Epoch: 62 [1560/2812 (55%)]\tLoss: 4.453158\n",
            "Train Epoch: 62 [1680/2812 (60%)]\tLoss: 13.327324\n",
            "Train Epoch: 62 [1800/2812 (64%)]\tLoss: 4.714881\n",
            "Train Epoch: 62 [1920/2812 (68%)]\tLoss: 12.955879\n",
            "Train Epoch: 62 [2040/2812 (72%)]\tLoss: 20.853733\n",
            "Train Epoch: 62 [2160/2812 (77%)]\tLoss: 15.179379\n",
            "Train Epoch: 62 [2280/2812 (81%)]\tLoss: 13.420385\n",
            "Train Epoch: 62 [2400/2812 (85%)]\tLoss: 8.784589\n",
            "Train Epoch: 62 [2520/2812 (89%)]\tLoss: 25.575079\n",
            "Train Epoch: 62 [2640/2812 (94%)]\tLoss: 3.383022\n",
            "Train Epoch: 62 [2760/2812 (98%)]\tLoss: 6.423988\n",
            "Training Loss: 11.5387 Acc: 51.1380\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5641, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 63/200\n",
            "----------\n",
            "Train Epoch: 63 [0/2812 (0%)]\tLoss: 10.062384\n",
            "Train Epoch: 63 [120/2812 (4%)]\tLoss: 6.038846\n",
            "Train Epoch: 63 [240/2812 (9%)]\tLoss: 16.915243\n",
            "Train Epoch: 63 [360/2812 (13%)]\tLoss: 10.279562\n",
            "Train Epoch: 63 [480/2812 (17%)]\tLoss: 13.812805\n",
            "Train Epoch: 63 [600/2812 (21%)]\tLoss: 0.029673\n",
            "Train Epoch: 63 [720/2812 (26%)]\tLoss: 6.015744\n",
            "Train Epoch: 63 [840/2812 (30%)]\tLoss: 0.645208\n",
            "Train Epoch: 63 [960/2812 (34%)]\tLoss: 2.320216\n",
            "Train Epoch: 63 [1080/2812 (38%)]\tLoss: 15.207149\n",
            "Train Epoch: 63 [1200/2812 (43%)]\tLoss: 11.519687\n",
            "Train Epoch: 63 [1320/2812 (47%)]\tLoss: 4.883006\n",
            "Train Epoch: 63 [1440/2812 (51%)]\tLoss: 12.738260\n",
            "Train Epoch: 63 [1560/2812 (55%)]\tLoss: 12.347557\n",
            "Train Epoch: 63 [1680/2812 (60%)]\tLoss: 9.970769\n",
            "Train Epoch: 63 [1800/2812 (64%)]\tLoss: 5.647522\n",
            "Train Epoch: 63 [1920/2812 (68%)]\tLoss: 6.206595\n",
            "Train Epoch: 63 [2040/2812 (72%)]\tLoss: 18.311823\n",
            "Train Epoch: 63 [2160/2812 (77%)]\tLoss: 24.393625\n",
            "Train Epoch: 63 [2280/2812 (81%)]\tLoss: 10.389174\n",
            "Train Epoch: 63 [2400/2812 (85%)]\tLoss: 12.526970\n",
            "Train Epoch: 63 [2520/2812 (89%)]\tLoss: 6.023380\n",
            "Train Epoch: 63 [2640/2812 (94%)]\tLoss: 6.071027\n",
            "Train Epoch: 63 [2760/2812 (98%)]\tLoss: 16.382282\n",
            "Training Loss: 11.2779 Acc: 49.9644\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5459, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 64/200\n",
            "----------\n",
            "Train Epoch: 64 [0/2812 (0%)]\tLoss: 11.461939\n",
            "Train Epoch: 64 [120/2812 (4%)]\tLoss: 8.825650\n",
            "Train Epoch: 64 [240/2812 (9%)]\tLoss: 11.680346\n",
            "Train Epoch: 64 [360/2812 (13%)]\tLoss: 8.105530\n",
            "Train Epoch: 64 [480/2812 (17%)]\tLoss: 8.828562\n",
            "Train Epoch: 64 [600/2812 (21%)]\tLoss: 18.449966\n",
            "Train Epoch: 64 [720/2812 (26%)]\tLoss: 8.806138\n",
            "Train Epoch: 64 [840/2812 (30%)]\tLoss: 7.822217\n",
            "Train Epoch: 64 [960/2812 (34%)]\tLoss: 8.749859\n",
            "Train Epoch: 64 [1080/2812 (38%)]\tLoss: 6.765800\n",
            "Train Epoch: 64 [1200/2812 (43%)]\tLoss: 4.616183\n",
            "Train Epoch: 64 [1320/2812 (47%)]\tLoss: 2.700168\n",
            "Train Epoch: 64 [1440/2812 (51%)]\tLoss: 7.038282\n",
            "Train Epoch: 64 [1560/2812 (55%)]\tLoss: 15.633944\n",
            "Train Epoch: 64 [1680/2812 (60%)]\tLoss: 12.150312\n",
            "Train Epoch: 64 [1800/2812 (64%)]\tLoss: 12.118283\n",
            "Train Epoch: 64 [1920/2812 (68%)]\tLoss: 7.549378\n",
            "Train Epoch: 64 [2040/2812 (72%)]\tLoss: 10.542363\n",
            "Train Epoch: 64 [2160/2812 (77%)]\tLoss: 8.219908\n",
            "Train Epoch: 64 [2280/2812 (81%)]\tLoss: 5.953345\n",
            "Train Epoch: 64 [2400/2812 (85%)]\tLoss: 4.736388\n",
            "Train Epoch: 64 [2520/2812 (89%)]\tLoss: 15.026396\n",
            "Train Epoch: 64 [2640/2812 (94%)]\tLoss: 12.323498\n",
            "Train Epoch: 64 [2760/2812 (98%)]\tLoss: 13.459448\n",
            "Training Loss: 11.0186 Acc: 51.7070\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6066, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 65/200\n",
            "----------\n",
            "Train Epoch: 65 [0/2812 (0%)]\tLoss: 3.604468\n",
            "Train Epoch: 65 [120/2812 (4%)]\tLoss: 10.242454\n",
            "Train Epoch: 65 [240/2812 (9%)]\tLoss: 9.990575\n",
            "Train Epoch: 65 [360/2812 (13%)]\tLoss: 20.569382\n",
            "Train Epoch: 65 [480/2812 (17%)]\tLoss: 17.092546\n",
            "Train Epoch: 65 [600/2812 (21%)]\tLoss: 22.162022\n",
            "Train Epoch: 65 [720/2812 (26%)]\tLoss: 7.998868\n",
            "Train Epoch: 65 [840/2812 (30%)]\tLoss: 5.815086\n",
            "Train Epoch: 65 [960/2812 (34%)]\tLoss: 7.266448\n",
            "Train Epoch: 65 [1080/2812 (38%)]\tLoss: 8.698398\n",
            "Train Epoch: 65 [1200/2812 (43%)]\tLoss: 10.313354\n",
            "Train Epoch: 65 [1320/2812 (47%)]\tLoss: 18.239269\n",
            "Train Epoch: 65 [1440/2812 (51%)]\tLoss: 14.094981\n",
            "Train Epoch: 65 [1560/2812 (55%)]\tLoss: 10.678057\n",
            "Train Epoch: 65 [1680/2812 (60%)]\tLoss: 9.147587\n",
            "Train Epoch: 65 [1800/2812 (64%)]\tLoss: 11.689447\n",
            "Train Epoch: 65 [1920/2812 (68%)]\tLoss: 11.783288\n",
            "Train Epoch: 65 [2040/2812 (72%)]\tLoss: 20.495886\n",
            "Train Epoch: 65 [2160/2812 (77%)]\tLoss: 2.386530\n",
            "Train Epoch: 65 [2280/2812 (81%)]\tLoss: 24.386341\n",
            "Train Epoch: 65 [2400/2812 (85%)]\tLoss: 11.418322\n",
            "Train Epoch: 65 [2520/2812 (89%)]\tLoss: 10.269700\n",
            "Train Epoch: 65 [2640/2812 (94%)]\tLoss: 15.118402\n",
            "Train Epoch: 65 [2760/2812 (98%)]\tLoss: 12.863844\n",
            "Training Loss: 11.2954 Acc: 49.5377\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5529, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 66/200\n",
            "----------\n",
            "Train Epoch: 66 [0/2812 (0%)]\tLoss: 9.792201\n",
            "Train Epoch: 66 [120/2812 (4%)]\tLoss: 6.536916\n",
            "Train Epoch: 66 [240/2812 (9%)]\tLoss: 5.934949\n",
            "Train Epoch: 66 [360/2812 (13%)]\tLoss: 11.818511\n",
            "Train Epoch: 66 [480/2812 (17%)]\tLoss: 14.912872\n",
            "Train Epoch: 66 [600/2812 (21%)]\tLoss: 14.602377\n",
            "Train Epoch: 66 [720/2812 (26%)]\tLoss: 15.221907\n",
            "Train Epoch: 66 [840/2812 (30%)]\tLoss: 5.427980\n",
            "Train Epoch: 66 [960/2812 (34%)]\tLoss: 18.435202\n",
            "Train Epoch: 66 [1080/2812 (38%)]\tLoss: 6.106601\n",
            "Train Epoch: 66 [1200/2812 (43%)]\tLoss: 4.740413\n",
            "Train Epoch: 66 [1320/2812 (47%)]\tLoss: 1.571232\n",
            "Train Epoch: 66 [1440/2812 (51%)]\tLoss: 14.887861\n",
            "Train Epoch: 66 [1560/2812 (55%)]\tLoss: 6.003561\n",
            "Train Epoch: 66 [1680/2812 (60%)]\tLoss: 13.220316\n",
            "Train Epoch: 66 [1800/2812 (64%)]\tLoss: 7.721932\n",
            "Train Epoch: 66 [1920/2812 (68%)]\tLoss: 12.558840\n",
            "Train Epoch: 66 [2040/2812 (72%)]\tLoss: 12.916600\n",
            "Train Epoch: 66 [2160/2812 (77%)]\tLoss: 10.092396\n",
            "Train Epoch: 66 [2280/2812 (81%)]\tLoss: 13.237654\n",
            "Train Epoch: 66 [2400/2812 (85%)]\tLoss: 11.173063\n",
            "Train Epoch: 66 [2520/2812 (89%)]\tLoss: 7.582382\n",
            "Train Epoch: 66 [2640/2812 (94%)]\tLoss: 13.401919\n",
            "Train Epoch: 66 [2760/2812 (98%)]\tLoss: 17.333416\n",
            "Training Loss: 11.2077 Acc: 49.6088\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5258, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 67/200\n",
            "----------\n",
            "Train Epoch: 67 [0/2812 (0%)]\tLoss: 5.462148\n",
            "Train Epoch: 67 [120/2812 (4%)]\tLoss: 7.094773\n",
            "Train Epoch: 67 [240/2812 (9%)]\tLoss: 13.263270\n",
            "Train Epoch: 67 [360/2812 (13%)]\tLoss: 11.517477\n",
            "Train Epoch: 67 [480/2812 (17%)]\tLoss: 8.677011\n",
            "Train Epoch: 67 [600/2812 (21%)]\tLoss: 22.974279\n",
            "Train Epoch: 67 [720/2812 (26%)]\tLoss: 13.233450\n",
            "Train Epoch: 67 [840/2812 (30%)]\tLoss: 2.347743\n",
            "Train Epoch: 67 [960/2812 (34%)]\tLoss: 5.694580\n",
            "Train Epoch: 67 [1080/2812 (38%)]\tLoss: 22.374430\n",
            "Train Epoch: 67 [1200/2812 (43%)]\tLoss: 10.474571\n",
            "Train Epoch: 67 [1320/2812 (47%)]\tLoss: 18.439938\n",
            "Train Epoch: 67 [1440/2812 (51%)]\tLoss: 13.610998\n",
            "Train Epoch: 67 [1560/2812 (55%)]\tLoss: 26.112299\n",
            "Train Epoch: 67 [1680/2812 (60%)]\tLoss: 8.822829\n",
            "Train Epoch: 67 [1800/2812 (64%)]\tLoss: 10.942251\n",
            "Train Epoch: 67 [1920/2812 (68%)]\tLoss: 6.274951\n",
            "Train Epoch: 67 [2040/2812 (72%)]\tLoss: 13.786043\n",
            "Train Epoch: 67 [2160/2812 (77%)]\tLoss: 11.046053\n",
            "Train Epoch: 67 [2280/2812 (81%)]\tLoss: 9.034427\n",
            "Train Epoch: 67 [2400/2812 (85%)]\tLoss: 23.944027\n",
            "Train Epoch: 67 [2520/2812 (89%)]\tLoss: 9.607450\n",
            "Train Epoch: 67 [2640/2812 (94%)]\tLoss: 1.199609\n",
            "Train Epoch: 67 [2760/2812 (98%)]\tLoss: 6.947922\n",
            "Training Loss: 11.6573 Acc: 48.8265\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5305, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 68/200\n",
            "----------\n",
            "Train Epoch: 68 [0/2812 (0%)]\tLoss: 3.663713\n",
            "Train Epoch: 68 [120/2812 (4%)]\tLoss: 9.941259\n",
            "Train Epoch: 68 [240/2812 (9%)]\tLoss: 5.284997\n",
            "Train Epoch: 68 [360/2812 (13%)]\tLoss: 8.746997\n",
            "Train Epoch: 68 [480/2812 (17%)]\tLoss: 12.602315\n",
            "Train Epoch: 68 [600/2812 (21%)]\tLoss: 6.719897\n",
            "Train Epoch: 68 [720/2812 (26%)]\tLoss: 9.566487\n",
            "Train Epoch: 68 [840/2812 (30%)]\tLoss: 9.563299\n",
            "Train Epoch: 68 [960/2812 (34%)]\tLoss: 12.387051\n",
            "Train Epoch: 68 [1080/2812 (38%)]\tLoss: 6.920583\n",
            "Train Epoch: 68 [1200/2812 (43%)]\tLoss: 19.881744\n",
            "Train Epoch: 68 [1320/2812 (47%)]\tLoss: 17.334080\n",
            "Train Epoch: 68 [1440/2812 (51%)]\tLoss: 6.226954\n",
            "Train Epoch: 68 [1560/2812 (55%)]\tLoss: 11.208801\n",
            "Train Epoch: 68 [1680/2812 (60%)]\tLoss: 9.072597\n",
            "Train Epoch: 68 [1800/2812 (64%)]\tLoss: 15.261119\n",
            "Train Epoch: 68 [1920/2812 (68%)]\tLoss: 13.279254\n",
            "Train Epoch: 68 [2040/2812 (72%)]\tLoss: 2.762277\n",
            "Train Epoch: 68 [2160/2812 (77%)]\tLoss: 16.400042\n",
            "Train Epoch: 68 [2280/2812 (81%)]\tLoss: 8.798172\n",
            "Train Epoch: 68 [2400/2812 (85%)]\tLoss: 16.193047\n",
            "Train Epoch: 68 [2520/2812 (89%)]\tLoss: 21.099508\n",
            "Train Epoch: 68 [2640/2812 (94%)]\tLoss: 30.140039\n",
            "Train Epoch: 68 [2760/2812 (98%)]\tLoss: 12.891195\n",
            "Training Loss: 11.2034 Acc: 49.6444\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5705, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 69/200\n",
            "----------\n",
            "Train Epoch: 69 [0/2812 (0%)]\tLoss: 2.254796\n",
            "Train Epoch: 69 [120/2812 (4%)]\tLoss: 25.055996\n",
            "Train Epoch: 69 [240/2812 (9%)]\tLoss: 21.852972\n",
            "Train Epoch: 69 [360/2812 (13%)]\tLoss: 16.732769\n",
            "Train Epoch: 69 [480/2812 (17%)]\tLoss: 12.959819\n",
            "Train Epoch: 69 [600/2812 (21%)]\tLoss: 2.478680\n",
            "Train Epoch: 69 [720/2812 (26%)]\tLoss: 12.107252\n",
            "Train Epoch: 69 [840/2812 (30%)]\tLoss: 17.304392\n",
            "Train Epoch: 69 [960/2812 (34%)]\tLoss: 10.000911\n",
            "Train Epoch: 69 [1080/2812 (38%)]\tLoss: 6.804194\n",
            "Train Epoch: 69 [1200/2812 (43%)]\tLoss: 4.869294\n",
            "Train Epoch: 69 [1320/2812 (47%)]\tLoss: 22.825634\n",
            "Train Epoch: 69 [1440/2812 (51%)]\tLoss: 0.833823\n",
            "Train Epoch: 69 [1560/2812 (55%)]\tLoss: 13.700851\n",
            "Train Epoch: 69 [1680/2812 (60%)]\tLoss: 8.982239\n",
            "Train Epoch: 69 [1800/2812 (64%)]\tLoss: 7.247888\n",
            "Train Epoch: 69 [1920/2812 (68%)]\tLoss: 14.941328\n",
            "Train Epoch: 69 [2040/2812 (72%)]\tLoss: 14.047832\n",
            "Train Epoch: 69 [2160/2812 (77%)]\tLoss: 5.408236\n",
            "Train Epoch: 69 [2280/2812 (81%)]\tLoss: 4.843005\n",
            "Train Epoch: 69 [2400/2812 (85%)]\tLoss: 9.570515\n",
            "Train Epoch: 69 [2520/2812 (89%)]\tLoss: 19.770340\n",
            "Train Epoch: 69 [2640/2812 (94%)]\tLoss: 11.681979\n",
            "Train Epoch: 69 [2760/2812 (98%)]\tLoss: 12.962912\n",
            "Training Loss: 10.9127 Acc: 51.2802\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5371, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 70/200\n",
            "----------\n",
            "Train Epoch: 70 [0/2812 (0%)]\tLoss: 12.069140\n",
            "Train Epoch: 70 [120/2812 (4%)]\tLoss: 10.387443\n",
            "Train Epoch: 70 [240/2812 (9%)]\tLoss: 13.086906\n",
            "Train Epoch: 70 [360/2812 (13%)]\tLoss: 8.124372\n",
            "Train Epoch: 70 [480/2812 (17%)]\tLoss: 6.937418\n",
            "Train Epoch: 70 [600/2812 (21%)]\tLoss: 8.966322\n",
            "Train Epoch: 70 [720/2812 (26%)]\tLoss: 0.824649\n",
            "Train Epoch: 70 [840/2812 (30%)]\tLoss: 15.495203\n",
            "Train Epoch: 70 [960/2812 (34%)]\tLoss: 3.181317\n",
            "Train Epoch: 70 [1080/2812 (38%)]\tLoss: 20.668388\n",
            "Train Epoch: 70 [1200/2812 (43%)]\tLoss: 7.630057\n",
            "Train Epoch: 70 [1320/2812 (47%)]\tLoss: 15.126387\n",
            "Train Epoch: 70 [1440/2812 (51%)]\tLoss: 11.779428\n",
            "Train Epoch: 70 [1560/2812 (55%)]\tLoss: 28.279480\n",
            "Train Epoch: 70 [1680/2812 (60%)]\tLoss: 19.348419\n",
            "Train Epoch: 70 [1800/2812 (64%)]\tLoss: 15.905638\n",
            "Train Epoch: 70 [1920/2812 (68%)]\tLoss: 6.983520\n",
            "Train Epoch: 70 [2040/2812 (72%)]\tLoss: 7.483397\n",
            "Train Epoch: 70 [2160/2812 (77%)]\tLoss: 5.900748\n",
            "Train Epoch: 70 [2280/2812 (81%)]\tLoss: 11.999981\n",
            "Train Epoch: 70 [2400/2812 (85%)]\tLoss: 11.019889\n",
            "Train Epoch: 70 [2520/2812 (89%)]\tLoss: 11.691889\n",
            "Train Epoch: 70 [2640/2812 (94%)]\tLoss: 1.928995\n",
            "Train Epoch: 70 [2760/2812 (98%)]\tLoss: 7.939000\n",
            "Training Loss: 10.9216 Acc: 50.6046\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6687, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 71/200\n",
            "----------\n",
            "Train Epoch: 71 [0/2812 (0%)]\tLoss: 7.271086\n",
            "Train Epoch: 71 [120/2812 (4%)]\tLoss: 14.075022\n",
            "Train Epoch: 71 [240/2812 (9%)]\tLoss: 9.826836\n",
            "Train Epoch: 71 [360/2812 (13%)]\tLoss: 9.923020\n",
            "Train Epoch: 71 [480/2812 (17%)]\tLoss: 23.358273\n",
            "Train Epoch: 71 [600/2812 (21%)]\tLoss: 3.578186\n",
            "Train Epoch: 71 [720/2812 (26%)]\tLoss: 2.837140\n",
            "Train Epoch: 71 [840/2812 (30%)]\tLoss: 3.612373\n",
            "Train Epoch: 71 [960/2812 (34%)]\tLoss: 5.476376\n",
            "Train Epoch: 71 [1080/2812 (38%)]\tLoss: 19.979221\n",
            "Train Epoch: 71 [1200/2812 (43%)]\tLoss: 10.738070\n",
            "Train Epoch: 71 [1320/2812 (47%)]\tLoss: 3.897559\n",
            "Train Epoch: 71 [1440/2812 (51%)]\tLoss: 8.506708\n",
            "Train Epoch: 71 [1560/2812 (55%)]\tLoss: 25.403151\n",
            "Train Epoch: 71 [1680/2812 (60%)]\tLoss: 6.734474\n",
            "Train Epoch: 71 [1800/2812 (64%)]\tLoss: 19.384092\n",
            "Train Epoch: 71 [1920/2812 (68%)]\tLoss: 15.829855\n",
            "Train Epoch: 71 [2040/2812 (72%)]\tLoss: 13.638756\n",
            "Train Epoch: 71 [2160/2812 (77%)]\tLoss: 4.144300\n",
            "Train Epoch: 71 [2280/2812 (81%)]\tLoss: 18.689842\n",
            "Train Epoch: 71 [2400/2812 (85%)]\tLoss: 9.624276\n",
            "Train Epoch: 71 [2520/2812 (89%)]\tLoss: 14.392197\n",
            "Train Epoch: 71 [2640/2812 (94%)]\tLoss: 3.702855\n",
            "Train Epoch: 71 [2760/2812 (98%)]\tLoss: 3.679616\n",
            "Training Loss: 11.0240 Acc: 48.7909\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6547, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 72/200\n",
            "----------\n",
            "Train Epoch: 72 [0/2812 (0%)]\tLoss: 18.357174\n",
            "Train Epoch: 72 [120/2812 (4%)]\tLoss: 15.998674\n",
            "Train Epoch: 72 [240/2812 (9%)]\tLoss: 18.678633\n",
            "Train Epoch: 72 [360/2812 (13%)]\tLoss: 4.712058\n",
            "Train Epoch: 72 [480/2812 (17%)]\tLoss: 6.112195\n",
            "Train Epoch: 72 [600/2812 (21%)]\tLoss: 2.282087\n",
            "Train Epoch: 72 [720/2812 (26%)]\tLoss: 13.540491\n",
            "Train Epoch: 72 [840/2812 (30%)]\tLoss: 16.398060\n",
            "Train Epoch: 72 [960/2812 (34%)]\tLoss: 20.999397\n",
            "Train Epoch: 72 [1080/2812 (38%)]\tLoss: 9.607882\n",
            "Train Epoch: 72 [1200/2812 (43%)]\tLoss: 3.204876\n",
            "Train Epoch: 72 [1320/2812 (47%)]\tLoss: 21.264040\n",
            "Train Epoch: 72 [1440/2812 (51%)]\tLoss: 10.544421\n",
            "Train Epoch: 72 [1560/2812 (55%)]\tLoss: 5.073960\n",
            "Train Epoch: 72 [1680/2812 (60%)]\tLoss: 6.607270\n",
            "Train Epoch: 72 [1800/2812 (64%)]\tLoss: 13.827296\n",
            "Train Epoch: 72 [1920/2812 (68%)]\tLoss: 6.471850\n",
            "Train Epoch: 72 [2040/2812 (72%)]\tLoss: 4.490457\n",
            "Train Epoch: 72 [2160/2812 (77%)]\tLoss: 8.423779\n",
            "Train Epoch: 72 [2280/2812 (81%)]\tLoss: 11.046575\n",
            "Train Epoch: 72 [2400/2812 (85%)]\tLoss: 19.843031\n",
            "Train Epoch: 72 [2520/2812 (89%)]\tLoss: 2.717989\n",
            "Train Epoch: 72 [2640/2812 (94%)]\tLoss: 22.317499\n",
            "Train Epoch: 72 [2760/2812 (98%)]\tLoss: 12.694255\n",
            "Training Loss: 11.1033 Acc: 49.5733\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5973, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 73/200\n",
            "----------\n",
            "Train Epoch: 73 [0/2812 (0%)]\tLoss: 10.627974\n",
            "Train Epoch: 73 [120/2812 (4%)]\tLoss: 6.697507\n",
            "Train Epoch: 73 [240/2812 (9%)]\tLoss: 1.749629\n",
            "Train Epoch: 73 [360/2812 (13%)]\tLoss: 9.615515\n",
            "Train Epoch: 73 [480/2812 (17%)]\tLoss: 8.523951\n",
            "Train Epoch: 73 [600/2812 (21%)]\tLoss: 6.795364\n",
            "Train Epoch: 73 [720/2812 (26%)]\tLoss: 14.195108\n",
            "Train Epoch: 73 [840/2812 (30%)]\tLoss: 6.896138\n",
            "Train Epoch: 73 [960/2812 (34%)]\tLoss: 13.160663\n",
            "Train Epoch: 73 [1080/2812 (38%)]\tLoss: 10.476782\n",
            "Train Epoch: 73 [1200/2812 (43%)]\tLoss: 29.410421\n",
            "Train Epoch: 73 [1320/2812 (47%)]\tLoss: 18.584715\n",
            "Train Epoch: 73 [1440/2812 (51%)]\tLoss: 25.078945\n",
            "Train Epoch: 73 [1560/2812 (55%)]\tLoss: 12.126094\n",
            "Train Epoch: 73 [1680/2812 (60%)]\tLoss: 22.729862\n",
            "Train Epoch: 73 [1800/2812 (64%)]\tLoss: 12.051497\n",
            "Train Epoch: 73 [1920/2812 (68%)]\tLoss: 2.865961\n",
            "Train Epoch: 73 [2040/2812 (72%)]\tLoss: 8.284316\n",
            "Train Epoch: 73 [2160/2812 (77%)]\tLoss: 8.686609\n",
            "Train Epoch: 73 [2280/2812 (81%)]\tLoss: 9.824841\n",
            "Train Epoch: 73 [2400/2812 (85%)]\tLoss: 14.688601\n",
            "Train Epoch: 73 [2520/2812 (89%)]\tLoss: 4.199014\n",
            "Train Epoch: 73 [2640/2812 (94%)]\tLoss: 3.334653\n",
            "Train Epoch: 73 [2760/2812 (98%)]\tLoss: 12.971379\n",
            "Training Loss: 11.2091 Acc: 50.0000\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5812, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 74/200\n",
            "----------\n",
            "Train Epoch: 74 [0/2812 (0%)]\tLoss: 13.560697\n",
            "Train Epoch: 74 [120/2812 (4%)]\tLoss: 18.862791\n",
            "Train Epoch: 74 [240/2812 (9%)]\tLoss: 15.635106\n",
            "Train Epoch: 74 [360/2812 (13%)]\tLoss: 4.130761\n",
            "Train Epoch: 74 [480/2812 (17%)]\tLoss: 5.502566\n",
            "Train Epoch: 74 [600/2812 (21%)]\tLoss: 17.094738\n",
            "Train Epoch: 74 [720/2812 (26%)]\tLoss: 6.988861\n",
            "Train Epoch: 74 [840/2812 (30%)]\tLoss: 8.812708\n",
            "Train Epoch: 74 [960/2812 (34%)]\tLoss: 11.887900\n",
            "Train Epoch: 74 [1080/2812 (38%)]\tLoss: 6.009108\n",
            "Train Epoch: 74 [1200/2812 (43%)]\tLoss: 6.410428\n",
            "Train Epoch: 74 [1320/2812 (47%)]\tLoss: 7.507782\n",
            "Train Epoch: 74 [1440/2812 (51%)]\tLoss: 13.453562\n",
            "Train Epoch: 74 [1560/2812 (55%)]\tLoss: 9.707202\n",
            "Train Epoch: 74 [1680/2812 (60%)]\tLoss: 4.782876\n",
            "Train Epoch: 74 [1800/2812 (64%)]\tLoss: 8.820639\n",
            "Train Epoch: 74 [1920/2812 (68%)]\tLoss: 7.823213\n",
            "Train Epoch: 74 [2040/2812 (72%)]\tLoss: 10.071060\n",
            "Train Epoch: 74 [2160/2812 (77%)]\tLoss: 18.092396\n",
            "Train Epoch: 74 [2280/2812 (81%)]\tLoss: 12.606533\n",
            "Train Epoch: 74 [2400/2812 (85%)]\tLoss: 11.234290\n",
            "Train Epoch: 74 [2520/2812 (89%)]\tLoss: 7.575271\n",
            "Train Epoch: 74 [2640/2812 (94%)]\tLoss: 15.770233\n",
            "Train Epoch: 74 [2760/2812 (98%)]\tLoss: 6.525989\n",
            "Training Loss: 11.0214 Acc: 50.4623\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5065, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 75/200\n",
            "----------\n",
            "Train Epoch: 75 [0/2812 (0%)]\tLoss: 5.590149\n",
            "Train Epoch: 75 [120/2812 (4%)]\tLoss: 12.045622\n",
            "Train Epoch: 75 [240/2812 (9%)]\tLoss: 10.703666\n",
            "Train Epoch: 75 [360/2812 (13%)]\tLoss: 6.599044\n",
            "Train Epoch: 75 [480/2812 (17%)]\tLoss: 6.576402\n",
            "Train Epoch: 75 [600/2812 (21%)]\tLoss: 5.840343\n",
            "Train Epoch: 75 [720/2812 (26%)]\tLoss: 5.245691\n",
            "Train Epoch: 75 [840/2812 (30%)]\tLoss: 23.402683\n",
            "Train Epoch: 75 [960/2812 (34%)]\tLoss: 15.842331\n",
            "Train Epoch: 75 [1080/2812 (38%)]\tLoss: 11.561987\n",
            "Train Epoch: 75 [1200/2812 (43%)]\tLoss: 11.092326\n",
            "Train Epoch: 75 [1320/2812 (47%)]\tLoss: 7.930383\n",
            "Train Epoch: 75 [1440/2812 (51%)]\tLoss: 16.956196\n",
            "Train Epoch: 75 [1560/2812 (55%)]\tLoss: 18.114697\n",
            "Train Epoch: 75 [1680/2812 (60%)]\tLoss: 6.848134\n",
            "Train Epoch: 75 [1800/2812 (64%)]\tLoss: 10.341039\n",
            "Train Epoch: 75 [1920/2812 (68%)]\tLoss: 13.844213\n",
            "Train Epoch: 75 [2040/2812 (72%)]\tLoss: 14.996686\n",
            "Train Epoch: 75 [2160/2812 (77%)]\tLoss: 7.812521\n",
            "Train Epoch: 75 [2280/2812 (81%)]\tLoss: 9.450188\n",
            "Train Epoch: 75 [2400/2812 (85%)]\tLoss: 8.693354\n",
            "Train Epoch: 75 [2520/2812 (89%)]\tLoss: 7.255830\n",
            "Train Epoch: 75 [2640/2812 (94%)]\tLoss: 8.827071\n",
            "Train Epoch: 75 [2760/2812 (98%)]\tLoss: 11.045561\n",
            "Training Loss: 11.1829 Acc: 49.0754\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5770, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 76/200\n",
            "----------\n",
            "Train Epoch: 76 [0/2812 (0%)]\tLoss: 7.805138\n",
            "Train Epoch: 76 [120/2812 (4%)]\tLoss: 12.138578\n",
            "Train Epoch: 76 [240/2812 (9%)]\tLoss: 13.620348\n",
            "Train Epoch: 76 [360/2812 (13%)]\tLoss: 15.236471\n",
            "Train Epoch: 76 [480/2812 (17%)]\tLoss: 9.667848\n",
            "Train Epoch: 76 [600/2812 (21%)]\tLoss: 10.310850\n",
            "Train Epoch: 76 [720/2812 (26%)]\tLoss: 0.473884\n",
            "Train Epoch: 76 [840/2812 (30%)]\tLoss: 7.159869\n",
            "Train Epoch: 76 [960/2812 (34%)]\tLoss: 11.320496\n",
            "Train Epoch: 76 [1080/2812 (38%)]\tLoss: 17.762291\n",
            "Train Epoch: 76 [1200/2812 (43%)]\tLoss: 5.523928\n",
            "Train Epoch: 76 [1320/2812 (47%)]\tLoss: 25.223539\n",
            "Train Epoch: 76 [1440/2812 (51%)]\tLoss: 15.861613\n",
            "Train Epoch: 76 [1560/2812 (55%)]\tLoss: 10.670921\n",
            "Train Epoch: 76 [1680/2812 (60%)]\tLoss: 7.060216\n",
            "Train Epoch: 76 [1800/2812 (64%)]\tLoss: 13.647512\n",
            "Train Epoch: 76 [1920/2812 (68%)]\tLoss: 8.774360\n",
            "Train Epoch: 76 [2040/2812 (72%)]\tLoss: 8.978601\n",
            "Train Epoch: 76 [2160/2812 (77%)]\tLoss: 12.146722\n",
            "Train Epoch: 76 [2280/2812 (81%)]\tLoss: 17.248241\n",
            "Train Epoch: 76 [2400/2812 (85%)]\tLoss: 3.931795\n",
            "Train Epoch: 76 [2520/2812 (89%)]\tLoss: 13.853928\n",
            "Train Epoch: 76 [2640/2812 (94%)]\tLoss: 19.967476\n",
            "Train Epoch: 76 [2760/2812 (98%)]\tLoss: 7.251354\n",
            "Training Loss: 10.9419 Acc: 50.2845\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6435, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 77/200\n",
            "----------\n",
            "Train Epoch: 77 [0/2812 (0%)]\tLoss: 14.312543\n",
            "Train Epoch: 77 [120/2812 (4%)]\tLoss: 8.814539\n",
            "Train Epoch: 77 [240/2812 (9%)]\tLoss: 23.284409\n",
            "Train Epoch: 77 [360/2812 (13%)]\tLoss: 23.995872\n",
            "Train Epoch: 77 [480/2812 (17%)]\tLoss: 11.328585\n",
            "Train Epoch: 77 [600/2812 (21%)]\tLoss: 16.858686\n",
            "Train Epoch: 77 [720/2812 (26%)]\tLoss: 16.191410\n",
            "Train Epoch: 77 [840/2812 (30%)]\tLoss: 6.933722\n",
            "Train Epoch: 77 [960/2812 (34%)]\tLoss: 10.565512\n",
            "Train Epoch: 77 [1080/2812 (38%)]\tLoss: 9.125227\n",
            "Train Epoch: 77 [1200/2812 (43%)]\tLoss: 3.994422\n",
            "Train Epoch: 77 [1320/2812 (47%)]\tLoss: 10.355124\n",
            "Train Epoch: 77 [1440/2812 (51%)]\tLoss: 6.080497\n",
            "Train Epoch: 77 [1560/2812 (55%)]\tLoss: 29.192566\n",
            "Train Epoch: 77 [1680/2812 (60%)]\tLoss: 9.366544\n",
            "Train Epoch: 77 [1800/2812 (64%)]\tLoss: 20.119411\n",
            "Train Epoch: 77 [1920/2812 (68%)]\tLoss: 9.150017\n",
            "Train Epoch: 77 [2040/2812 (72%)]\tLoss: 9.927401\n",
            "Train Epoch: 77 [2160/2812 (77%)]\tLoss: 7.394847\n",
            "Train Epoch: 77 [2280/2812 (81%)]\tLoss: 11.551976\n",
            "Train Epoch: 77 [2400/2812 (85%)]\tLoss: 12.409189\n",
            "Train Epoch: 77 [2520/2812 (89%)]\tLoss: 21.198395\n",
            "Train Epoch: 77 [2640/2812 (94%)]\tLoss: 4.252891\n",
            "Train Epoch: 77 [2760/2812 (98%)]\tLoss: 4.882108\n",
            "Training Loss: 11.0083 Acc: 50.0000\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5734, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 78/200\n",
            "----------\n",
            "Train Epoch: 78 [0/2812 (0%)]\tLoss: 12.178810\n",
            "Train Epoch: 78 [120/2812 (4%)]\tLoss: 11.413453\n",
            "Train Epoch: 78 [240/2812 (9%)]\tLoss: 8.195452\n",
            "Train Epoch: 78 [360/2812 (13%)]\tLoss: 9.013412\n",
            "Train Epoch: 78 [480/2812 (17%)]\tLoss: 14.619532\n",
            "Train Epoch: 78 [600/2812 (21%)]\tLoss: 6.474187\n",
            "Train Epoch: 78 [720/2812 (26%)]\tLoss: 20.825344\n",
            "Train Epoch: 78 [840/2812 (30%)]\tLoss: 12.383827\n",
            "Train Epoch: 78 [960/2812 (34%)]\tLoss: 9.052882\n",
            "Train Epoch: 78 [1080/2812 (38%)]\tLoss: 12.753403\n",
            "Train Epoch: 78 [1200/2812 (43%)]\tLoss: 13.870564\n",
            "Train Epoch: 78 [1320/2812 (47%)]\tLoss: 17.716711\n",
            "Train Epoch: 78 [1440/2812 (51%)]\tLoss: 5.805357\n",
            "Train Epoch: 78 [1560/2812 (55%)]\tLoss: 12.138730\n",
            "Train Epoch: 78 [1680/2812 (60%)]\tLoss: 10.383575\n",
            "Train Epoch: 78 [1800/2812 (64%)]\tLoss: 10.749727\n",
            "Train Epoch: 78 [1920/2812 (68%)]\tLoss: 17.000683\n",
            "Train Epoch: 78 [2040/2812 (72%)]\tLoss: 18.865170\n",
            "Train Epoch: 78 [2160/2812 (77%)]\tLoss: 13.417730\n",
            "Train Epoch: 78 [2280/2812 (81%)]\tLoss: 0.732862\n",
            "Train Epoch: 78 [2400/2812 (85%)]\tLoss: 23.305664\n",
            "Train Epoch: 78 [2520/2812 (89%)]\tLoss: 7.936442\n",
            "Train Epoch: 78 [2640/2812 (94%)]\tLoss: 12.584417\n",
            "Train Epoch: 78 [2760/2812 (98%)]\tLoss: 9.254612\n",
            "Training Loss: 11.0241 Acc: 50.1422\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5609, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 79/200\n",
            "----------\n",
            "Train Epoch: 79 [0/2812 (0%)]\tLoss: 17.209766\n",
            "Train Epoch: 79 [120/2812 (4%)]\tLoss: 9.740446\n",
            "Train Epoch: 79 [240/2812 (9%)]\tLoss: 6.467721\n",
            "Train Epoch: 79 [360/2812 (13%)]\tLoss: 19.998379\n",
            "Train Epoch: 79 [480/2812 (17%)]\tLoss: 5.183850\n",
            "Train Epoch: 79 [600/2812 (21%)]\tLoss: 10.919394\n",
            "Train Epoch: 79 [720/2812 (26%)]\tLoss: 12.920529\n",
            "Train Epoch: 79 [840/2812 (30%)]\tLoss: 5.240459\n",
            "Train Epoch: 79 [960/2812 (34%)]\tLoss: 23.342512\n",
            "Train Epoch: 79 [1080/2812 (38%)]\tLoss: 15.230875\n",
            "Train Epoch: 79 [1200/2812 (43%)]\tLoss: 4.462687\n",
            "Train Epoch: 79 [1320/2812 (47%)]\tLoss: 12.470877\n",
            "Train Epoch: 79 [1440/2812 (51%)]\tLoss: 14.419807\n",
            "Train Epoch: 79 [1560/2812 (55%)]\tLoss: 13.416308\n",
            "Train Epoch: 79 [1680/2812 (60%)]\tLoss: 10.923738\n",
            "Train Epoch: 79 [1800/2812 (64%)]\tLoss: 24.254284\n",
            "Train Epoch: 79 [1920/2812 (68%)]\tLoss: 26.179211\n",
            "Train Epoch: 79 [2040/2812 (72%)]\tLoss: 2.453366\n",
            "Train Epoch: 79 [2160/2812 (77%)]\tLoss: 20.320921\n",
            "Train Epoch: 79 [2280/2812 (81%)]\tLoss: 9.673719\n",
            "Train Epoch: 79 [2400/2812 (85%)]\tLoss: 15.936383\n",
            "Train Epoch: 79 [2520/2812 (89%)]\tLoss: 5.184447\n",
            "Train Epoch: 79 [2640/2812 (94%)]\tLoss: 11.473545\n",
            "Train Epoch: 79 [2760/2812 (98%)]\tLoss: 8.749655\n",
            "Training Loss: 11.3212 Acc: 50.3912\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6419, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 80/200\n",
            "----------\n",
            "Train Epoch: 80 [0/2812 (0%)]\tLoss: 9.718298\n",
            "Train Epoch: 80 [120/2812 (4%)]\tLoss: 6.228656\n",
            "Train Epoch: 80 [240/2812 (9%)]\tLoss: 16.344687\n",
            "Train Epoch: 80 [360/2812 (13%)]\tLoss: 2.473588\n",
            "Train Epoch: 80 [480/2812 (17%)]\tLoss: 12.260977\n",
            "Train Epoch: 80 [600/2812 (21%)]\tLoss: 3.045507\n",
            "Train Epoch: 80 [720/2812 (26%)]\tLoss: 13.852336\n",
            "Train Epoch: 80 [840/2812 (30%)]\tLoss: 16.501270\n",
            "Train Epoch: 80 [960/2812 (34%)]\tLoss: 19.114285\n",
            "Train Epoch: 80 [1080/2812 (38%)]\tLoss: 8.573878\n",
            "Train Epoch: 80 [1200/2812 (43%)]\tLoss: 15.192862\n",
            "Train Epoch: 80 [1320/2812 (47%)]\tLoss: 6.464522\n",
            "Train Epoch: 80 [1440/2812 (51%)]\tLoss: 8.165120\n",
            "Train Epoch: 80 [1560/2812 (55%)]\tLoss: 3.850910\n",
            "Train Epoch: 80 [1680/2812 (60%)]\tLoss: 9.887899\n",
            "Train Epoch: 80 [1800/2812 (64%)]\tLoss: 8.668953\n",
            "Train Epoch: 80 [1920/2812 (68%)]\tLoss: 8.789316\n",
            "Train Epoch: 80 [2040/2812 (72%)]\tLoss: 17.567453\n",
            "Train Epoch: 80 [2160/2812 (77%)]\tLoss: 17.272556\n",
            "Train Epoch: 80 [2280/2812 (81%)]\tLoss: 8.383169\n",
            "Train Epoch: 80 [2400/2812 (85%)]\tLoss: 5.072804\n",
            "Train Epoch: 80 [2520/2812 (89%)]\tLoss: 15.783022\n",
            "Train Epoch: 80 [2640/2812 (94%)]\tLoss: 3.615117\n",
            "Train Epoch: 80 [2760/2812 (98%)]\tLoss: 17.306376\n",
            "Training Loss: 11.5918 Acc: 49.5377\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5785, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 81/200\n",
            "----------\n",
            "Train Epoch: 81 [0/2812 (0%)]\tLoss: 25.479202\n",
            "Train Epoch: 81 [120/2812 (4%)]\tLoss: 13.151158\n",
            "Train Epoch: 81 [240/2812 (9%)]\tLoss: 11.850907\n",
            "Train Epoch: 81 [360/2812 (13%)]\tLoss: 18.521605\n",
            "Train Epoch: 81 [480/2812 (17%)]\tLoss: 18.942820\n",
            "Train Epoch: 81 [600/2812 (21%)]\tLoss: 17.416012\n",
            "Train Epoch: 81 [720/2812 (26%)]\tLoss: 12.266820\n",
            "Train Epoch: 81 [840/2812 (30%)]\tLoss: 8.845235\n",
            "Train Epoch: 81 [960/2812 (34%)]\tLoss: 7.473039\n",
            "Train Epoch: 81 [1080/2812 (38%)]\tLoss: 6.589700\n",
            "Train Epoch: 81 [1200/2812 (43%)]\tLoss: 23.151623\n",
            "Train Epoch: 81 [1320/2812 (47%)]\tLoss: 4.476483\n",
            "Train Epoch: 81 [1440/2812 (51%)]\tLoss: 9.820199\n",
            "Train Epoch: 81 [1560/2812 (55%)]\tLoss: 5.147569\n",
            "Train Epoch: 81 [1680/2812 (60%)]\tLoss: 15.956609\n",
            "Train Epoch: 81 [1800/2812 (64%)]\tLoss: 12.840151\n",
            "Train Epoch: 81 [1920/2812 (68%)]\tLoss: 14.488802\n",
            "Train Epoch: 81 [2040/2812 (72%)]\tLoss: 5.666297\n",
            "Train Epoch: 81 [2160/2812 (77%)]\tLoss: 10.288011\n",
            "Train Epoch: 81 [2280/2812 (81%)]\tLoss: 15.688864\n",
            "Train Epoch: 81 [2400/2812 (85%)]\tLoss: 8.192862\n",
            "Train Epoch: 81 [2520/2812 (89%)]\tLoss: 6.165280\n",
            "Train Epoch: 81 [2640/2812 (94%)]\tLoss: 3.397400\n",
            "Train Epoch: 81 [2760/2812 (98%)]\tLoss: 4.203908\n",
            "Training Loss: 11.4356 Acc: 49.5377\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6221, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 82/200\n",
            "----------\n",
            "Train Epoch: 82 [0/2812 (0%)]\tLoss: 15.208467\n",
            "Train Epoch: 82 [120/2812 (4%)]\tLoss: 5.176701\n",
            "Train Epoch: 82 [240/2812 (9%)]\tLoss: 14.700232\n",
            "Train Epoch: 82 [360/2812 (13%)]\tLoss: 5.171918\n",
            "Train Epoch: 82 [480/2812 (17%)]\tLoss: 1.369420\n",
            "Train Epoch: 82 [600/2812 (21%)]\tLoss: 14.469294\n",
            "Train Epoch: 82 [720/2812 (26%)]\tLoss: 9.814711\n",
            "Train Epoch: 82 [840/2812 (30%)]\tLoss: 18.535828\n",
            "Train Epoch: 82 [960/2812 (34%)]\tLoss: 15.922148\n",
            "Train Epoch: 82 [1080/2812 (38%)]\tLoss: 5.764871\n",
            "Train Epoch: 82 [1200/2812 (43%)]\tLoss: 8.748663\n",
            "Train Epoch: 82 [1320/2812 (47%)]\tLoss: 24.856100\n",
            "Train Epoch: 82 [1440/2812 (51%)]\tLoss: 15.498232\n",
            "Train Epoch: 82 [1560/2812 (55%)]\tLoss: 8.870466\n",
            "Train Epoch: 82 [1680/2812 (60%)]\tLoss: 5.287176\n",
            "Train Epoch: 82 [1800/2812 (64%)]\tLoss: 4.218065\n",
            "Train Epoch: 82 [1920/2812 (68%)]\tLoss: 14.489285\n",
            "Train Epoch: 82 [2040/2812 (72%)]\tLoss: 14.397818\n",
            "Train Epoch: 82 [2160/2812 (77%)]\tLoss: 17.697613\n",
            "Train Epoch: 82 [2280/2812 (81%)]\tLoss: 14.331177\n",
            "Train Epoch: 82 [2400/2812 (85%)]\tLoss: 9.395510\n",
            "Train Epoch: 82 [2520/2812 (89%)]\tLoss: 2.815071\n",
            "Train Epoch: 82 [2640/2812 (94%)]\tLoss: 18.153790\n",
            "Train Epoch: 82 [2760/2812 (98%)]\tLoss: 5.576203\n",
            "Training Loss: 11.1193 Acc: 51.4225\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5808, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 83/200\n",
            "----------\n",
            "Train Epoch: 83 [0/2812 (0%)]\tLoss: 11.300201\n",
            "Train Epoch: 83 [120/2812 (4%)]\tLoss: 7.799508\n",
            "Train Epoch: 83 [240/2812 (9%)]\tLoss: 18.845844\n",
            "Train Epoch: 83 [360/2812 (13%)]\tLoss: 5.863151\n",
            "Train Epoch: 83 [480/2812 (17%)]\tLoss: 6.702327\n",
            "Train Epoch: 83 [600/2812 (21%)]\tLoss: 12.484729\n",
            "Train Epoch: 83 [720/2812 (26%)]\tLoss: 11.314699\n",
            "Train Epoch: 83 [840/2812 (30%)]\tLoss: 9.173246\n",
            "Train Epoch: 83 [960/2812 (34%)]\tLoss: 10.864599\n",
            "Train Epoch: 83 [1080/2812 (38%)]\tLoss: 3.934356\n",
            "Train Epoch: 83 [1200/2812 (43%)]\tLoss: 16.744473\n",
            "Train Epoch: 83 [1320/2812 (47%)]\tLoss: 15.548587\n",
            "Train Epoch: 83 [1440/2812 (51%)]\tLoss: 11.767123\n",
            "Train Epoch: 83 [1560/2812 (55%)]\tLoss: 13.841795\n",
            "Train Epoch: 83 [1680/2812 (60%)]\tLoss: 11.035408\n",
            "Train Epoch: 83 [1800/2812 (64%)]\tLoss: 13.315161\n",
            "Train Epoch: 83 [1920/2812 (68%)]\tLoss: 27.538107\n",
            "Train Epoch: 83 [2040/2812 (72%)]\tLoss: 30.528757\n",
            "Train Epoch: 83 [2160/2812 (77%)]\tLoss: 18.967007\n",
            "Train Epoch: 83 [2280/2812 (81%)]\tLoss: 13.440387\n",
            "Train Epoch: 83 [2400/2812 (85%)]\tLoss: 18.754692\n",
            "Train Epoch: 83 [2520/2812 (89%)]\tLoss: 14.456644\n",
            "Train Epoch: 83 [2640/2812 (94%)]\tLoss: 10.473585\n",
            "Train Epoch: 83 [2760/2812 (98%)]\tLoss: 20.734844\n",
            "Training Loss: 11.0329 Acc: 50.7468\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5393, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 84/200\n",
            "----------\n",
            "Train Epoch: 84 [0/2812 (0%)]\tLoss: 14.024820\n",
            "Train Epoch: 84 [120/2812 (4%)]\tLoss: 14.159990\n",
            "Train Epoch: 84 [240/2812 (9%)]\tLoss: 13.128812\n",
            "Train Epoch: 84 [360/2812 (13%)]\tLoss: 10.832451\n",
            "Train Epoch: 84 [480/2812 (17%)]\tLoss: 17.601702\n",
            "Train Epoch: 84 [600/2812 (21%)]\tLoss: 10.498884\n",
            "Train Epoch: 84 [720/2812 (26%)]\tLoss: 26.842911\n",
            "Train Epoch: 84 [840/2812 (30%)]\tLoss: 6.805886\n",
            "Train Epoch: 84 [960/2812 (34%)]\tLoss: 3.794379\n",
            "Train Epoch: 84 [1080/2812 (38%)]\tLoss: 11.062988\n",
            "Train Epoch: 84 [1200/2812 (43%)]\tLoss: 10.990931\n",
            "Train Epoch: 84 [1320/2812 (47%)]\tLoss: 13.091535\n",
            "Train Epoch: 84 [1440/2812 (51%)]\tLoss: 3.853900\n",
            "Train Epoch: 84 [1560/2812 (55%)]\tLoss: 4.419460\n",
            "Train Epoch: 84 [1680/2812 (60%)]\tLoss: 10.531561\n",
            "Train Epoch: 84 [1800/2812 (64%)]\tLoss: 8.658503\n",
            "Train Epoch: 84 [1920/2812 (68%)]\tLoss: 12.370620\n",
            "Train Epoch: 84 [2040/2812 (72%)]\tLoss: 15.997671\n",
            "Train Epoch: 84 [2160/2812 (77%)]\tLoss: 17.905119\n",
            "Train Epoch: 84 [2280/2812 (81%)]\tLoss: 5.554276\n",
            "Train Epoch: 84 [2400/2812 (85%)]\tLoss: 9.247670\n",
            "Train Epoch: 84 [2520/2812 (89%)]\tLoss: 5.969901\n",
            "Train Epoch: 84 [2640/2812 (94%)]\tLoss: 17.611715\n",
            "Train Epoch: 84 [2760/2812 (98%)]\tLoss: 13.737398\n",
            "Training Loss: 10.9483 Acc: 49.7866\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5800, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 85/200\n",
            "----------\n",
            "Train Epoch: 85 [0/2812 (0%)]\tLoss: 3.477114\n",
            "Train Epoch: 85 [120/2812 (4%)]\tLoss: 6.718668\n",
            "Train Epoch: 85 [240/2812 (9%)]\tLoss: 9.998526\n",
            "Train Epoch: 85 [360/2812 (13%)]\tLoss: 23.309441\n",
            "Train Epoch: 85 [480/2812 (17%)]\tLoss: 8.648940\n",
            "Train Epoch: 85 [600/2812 (21%)]\tLoss: 9.725283\n",
            "Train Epoch: 85 [720/2812 (26%)]\tLoss: 18.448860\n",
            "Train Epoch: 85 [840/2812 (30%)]\tLoss: 7.342294\n",
            "Train Epoch: 85 [960/2812 (34%)]\tLoss: 5.569372\n",
            "Train Epoch: 85 [1080/2812 (38%)]\tLoss: 4.586295\n",
            "Train Epoch: 85 [1200/2812 (43%)]\tLoss: 13.905398\n",
            "Train Epoch: 85 [1320/2812 (47%)]\tLoss: 9.656855\n",
            "Train Epoch: 85 [1440/2812 (51%)]\tLoss: 12.611794\n",
            "Train Epoch: 85 [1560/2812 (55%)]\tLoss: 16.520885\n",
            "Train Epoch: 85 [1680/2812 (60%)]\tLoss: 4.504932\n",
            "Train Epoch: 85 [1800/2812 (64%)]\tLoss: 19.316132\n",
            "Train Epoch: 85 [1920/2812 (68%)]\tLoss: 11.426463\n",
            "Train Epoch: 85 [2040/2812 (72%)]\tLoss: 14.526789\n",
            "Train Epoch: 85 [2160/2812 (77%)]\tLoss: 6.639567\n",
            "Train Epoch: 85 [2280/2812 (81%)]\tLoss: 16.053659\n",
            "Train Epoch: 85 [2400/2812 (85%)]\tLoss: 18.009670\n",
            "Train Epoch: 85 [2520/2812 (89%)]\tLoss: 18.549810\n",
            "Train Epoch: 85 [2640/2812 (94%)]\tLoss: 16.551699\n",
            "Train Epoch: 85 [2760/2812 (98%)]\tLoss: 23.212460\n",
            "Training Loss: 11.4376 Acc: 49.6799\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5582, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 86/200\n",
            "----------\n",
            "Train Epoch: 86 [0/2812 (0%)]\tLoss: 13.450592\n",
            "Train Epoch: 86 [120/2812 (4%)]\tLoss: 1.537645\n",
            "Train Epoch: 86 [240/2812 (9%)]\tLoss: 14.077003\n",
            "Train Epoch: 86 [360/2812 (13%)]\tLoss: 7.654750\n",
            "Train Epoch: 86 [480/2812 (17%)]\tLoss: 3.379300\n",
            "Train Epoch: 86 [600/2812 (21%)]\tLoss: 12.484152\n",
            "Train Epoch: 86 [720/2812 (26%)]\tLoss: 4.107684\n",
            "Train Epoch: 86 [840/2812 (30%)]\tLoss: 26.174835\n",
            "Train Epoch: 86 [960/2812 (34%)]\tLoss: 5.915932\n",
            "Train Epoch: 86 [1080/2812 (38%)]\tLoss: 6.726344\n",
            "Train Epoch: 86 [1200/2812 (43%)]\tLoss: 10.062037\n",
            "Train Epoch: 86 [1320/2812 (47%)]\tLoss: 6.669597\n",
            "Train Epoch: 86 [1440/2812 (51%)]\tLoss: 11.943805\n",
            "Train Epoch: 86 [1560/2812 (55%)]\tLoss: 21.039822\n",
            "Train Epoch: 86 [1680/2812 (60%)]\tLoss: 11.499365\n",
            "Train Epoch: 86 [1800/2812 (64%)]\tLoss: 11.667047\n",
            "Train Epoch: 86 [1920/2812 (68%)]\tLoss: 3.026907\n",
            "Train Epoch: 86 [2040/2812 (72%)]\tLoss: 17.493410\n",
            "Train Epoch: 86 [2160/2812 (77%)]\tLoss: 14.177362\n",
            "Train Epoch: 86 [2280/2812 (81%)]\tLoss: 7.471729\n",
            "Train Epoch: 86 [2400/2812 (85%)]\tLoss: 13.333025\n",
            "Train Epoch: 86 [2520/2812 (89%)]\tLoss: 6.467032\n",
            "Train Epoch: 86 [2640/2812 (94%)]\tLoss: 8.089195\n",
            "Train Epoch: 86 [2760/2812 (98%)]\tLoss: 10.905718\n",
            "Training Loss: 11.2498 Acc: 49.8222\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5505, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 87/200\n",
            "----------\n",
            "Train Epoch: 87 [0/2812 (0%)]\tLoss: 2.212156\n",
            "Train Epoch: 87 [120/2812 (4%)]\tLoss: 3.354442\n",
            "Train Epoch: 87 [240/2812 (9%)]\tLoss: 14.830533\n",
            "Train Epoch: 87 [360/2812 (13%)]\tLoss: 7.164050\n",
            "Train Epoch: 87 [480/2812 (17%)]\tLoss: 12.465997\n",
            "Train Epoch: 87 [600/2812 (21%)]\tLoss: 8.904694\n",
            "Train Epoch: 87 [720/2812 (26%)]\tLoss: 7.531779\n",
            "Train Epoch: 87 [840/2812 (30%)]\tLoss: 8.733665\n",
            "Train Epoch: 87 [960/2812 (34%)]\tLoss: 10.162343\n",
            "Train Epoch: 87 [1080/2812 (38%)]\tLoss: 12.255924\n",
            "Train Epoch: 87 [1200/2812 (43%)]\tLoss: 5.689805\n",
            "Train Epoch: 87 [1320/2812 (47%)]\tLoss: 5.067730\n",
            "Train Epoch: 87 [1440/2812 (51%)]\tLoss: 17.026100\n",
            "Train Epoch: 87 [1560/2812 (55%)]\tLoss: 12.188484\n",
            "Train Epoch: 87 [1680/2812 (60%)]\tLoss: 8.986575\n",
            "Train Epoch: 87 [1800/2812 (64%)]\tLoss: 8.597751\n",
            "Train Epoch: 87 [1920/2812 (68%)]\tLoss: 12.694637\n",
            "Train Epoch: 87 [2040/2812 (72%)]\tLoss: 17.302025\n",
            "Train Epoch: 87 [2160/2812 (77%)]\tLoss: 14.163800\n",
            "Train Epoch: 87 [2280/2812 (81%)]\tLoss: 5.044271\n",
            "Train Epoch: 87 [2400/2812 (85%)]\tLoss: 20.824797\n",
            "Train Epoch: 87 [2520/2812 (89%)]\tLoss: 9.196271\n",
            "Train Epoch: 87 [2640/2812 (94%)]\tLoss: 3.076441\n",
            "Train Epoch: 87 [2760/2812 (98%)]\tLoss: 7.778792\n",
            "Training Loss: 11.1926 Acc: 51.2802\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5679, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 88/200\n",
            "----------\n",
            "Train Epoch: 88 [0/2812 (0%)]\tLoss: 14.084798\n",
            "Train Epoch: 88 [120/2812 (4%)]\tLoss: 16.114635\n",
            "Train Epoch: 88 [240/2812 (9%)]\tLoss: 19.001558\n",
            "Train Epoch: 88 [360/2812 (13%)]\tLoss: 10.042248\n",
            "Train Epoch: 88 [480/2812 (17%)]\tLoss: 6.634955\n",
            "Train Epoch: 88 [600/2812 (21%)]\tLoss: 8.526420\n",
            "Train Epoch: 88 [720/2812 (26%)]\tLoss: 7.346892\n",
            "Train Epoch: 88 [840/2812 (30%)]\tLoss: 4.724982\n",
            "Train Epoch: 88 [960/2812 (34%)]\tLoss: 4.640615\n",
            "Train Epoch: 88 [1080/2812 (38%)]\tLoss: 9.754006\n",
            "Train Epoch: 88 [1200/2812 (43%)]\tLoss: 12.009504\n",
            "Train Epoch: 88 [1320/2812 (47%)]\tLoss: 12.131109\n",
            "Train Epoch: 88 [1440/2812 (51%)]\tLoss: 6.793028\n",
            "Train Epoch: 88 [1560/2812 (55%)]\tLoss: 20.209517\n",
            "Train Epoch: 88 [1680/2812 (60%)]\tLoss: 13.778135\n",
            "Train Epoch: 88 [1800/2812 (64%)]\tLoss: 5.366028\n",
            "Train Epoch: 88 [1920/2812 (68%)]\tLoss: 23.307087\n",
            "Train Epoch: 88 [2040/2812 (72%)]\tLoss: 11.926708\n",
            "Train Epoch: 88 [2160/2812 (77%)]\tLoss: 6.455595\n",
            "Train Epoch: 88 [2280/2812 (81%)]\tLoss: 3.897385\n",
            "Train Epoch: 88 [2400/2812 (85%)]\tLoss: 9.760879\n",
            "Train Epoch: 88 [2520/2812 (89%)]\tLoss: 17.842590\n",
            "Train Epoch: 88 [2640/2812 (94%)]\tLoss: 6.391259\n",
            "Train Epoch: 88 [2760/2812 (98%)]\tLoss: 14.474260\n",
            "Training Loss: 11.3963 Acc: 49.9289\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5943, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 89/200\n",
            "----------\n",
            "Train Epoch: 89 [0/2812 (0%)]\tLoss: 12.354088\n",
            "Train Epoch: 89 [120/2812 (4%)]\tLoss: 3.286330\n",
            "Train Epoch: 89 [240/2812 (9%)]\tLoss: 18.281179\n",
            "Train Epoch: 89 [360/2812 (13%)]\tLoss: 15.747595\n",
            "Train Epoch: 89 [480/2812 (17%)]\tLoss: 8.146639\n",
            "Train Epoch: 89 [600/2812 (21%)]\tLoss: 10.447083\n",
            "Train Epoch: 89 [720/2812 (26%)]\tLoss: 2.571784\n",
            "Train Epoch: 89 [840/2812 (30%)]\tLoss: 8.974817\n",
            "Train Epoch: 89 [960/2812 (34%)]\tLoss: 8.758918\n",
            "Train Epoch: 89 [1080/2812 (38%)]\tLoss: 8.595945\n",
            "Train Epoch: 89 [1200/2812 (43%)]\tLoss: 5.876695\n",
            "Train Epoch: 89 [1320/2812 (47%)]\tLoss: 14.184141\n",
            "Train Epoch: 89 [1440/2812 (51%)]\tLoss: 20.752499\n",
            "Train Epoch: 89 [1560/2812 (55%)]\tLoss: 8.105583\n",
            "Train Epoch: 89 [1680/2812 (60%)]\tLoss: 21.245535\n",
            "Train Epoch: 89 [1800/2812 (64%)]\tLoss: 7.538430\n",
            "Train Epoch: 89 [1920/2812 (68%)]\tLoss: 14.628473\n",
            "Train Epoch: 89 [2040/2812 (72%)]\tLoss: 22.943798\n",
            "Train Epoch: 89 [2160/2812 (77%)]\tLoss: 18.201929\n",
            "Train Epoch: 89 [2280/2812 (81%)]\tLoss: 13.881392\n",
            "Train Epoch: 89 [2400/2812 (85%)]\tLoss: 10.638080\n",
            "Train Epoch: 89 [2520/2812 (89%)]\tLoss: 8.422694\n",
            "Train Epoch: 89 [2640/2812 (94%)]\tLoss: 9.501509\n",
            "Train Epoch: 89 [2760/2812 (98%)]\tLoss: 11.103537\n",
            "Training Loss: 11.1666 Acc: 49.8222\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6082, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 90/200\n",
            "----------\n",
            "Train Epoch: 90 [0/2812 (0%)]\tLoss: 3.885510\n",
            "Train Epoch: 90 [120/2812 (4%)]\tLoss: 17.427284\n",
            "Train Epoch: 90 [240/2812 (9%)]\tLoss: 15.870776\n",
            "Train Epoch: 90 [360/2812 (13%)]\tLoss: 8.502615\n",
            "Train Epoch: 90 [480/2812 (17%)]\tLoss: 6.364884\n",
            "Train Epoch: 90 [600/2812 (21%)]\tLoss: 5.292101\n",
            "Train Epoch: 90 [720/2812 (26%)]\tLoss: 2.058709\n",
            "Train Epoch: 90 [840/2812 (30%)]\tLoss: 4.790767\n",
            "Train Epoch: 90 [960/2812 (34%)]\tLoss: 9.111022\n",
            "Train Epoch: 90 [1080/2812 (38%)]\tLoss: 9.589959\n",
            "Train Epoch: 90 [1200/2812 (43%)]\tLoss: 6.231529\n",
            "Train Epoch: 90 [1320/2812 (47%)]\tLoss: 20.092371\n",
            "Train Epoch: 90 [1440/2812 (51%)]\tLoss: 12.116239\n",
            "Train Epoch: 90 [1560/2812 (55%)]\tLoss: 16.944592\n",
            "Train Epoch: 90 [1680/2812 (60%)]\tLoss: 10.764725\n",
            "Train Epoch: 90 [1800/2812 (64%)]\tLoss: 12.664106\n",
            "Train Epoch: 90 [1920/2812 (68%)]\tLoss: 5.261796\n",
            "Train Epoch: 90 [2040/2812 (72%)]\tLoss: 19.983459\n",
            "Train Epoch: 90 [2160/2812 (77%)]\tLoss: 15.197657\n",
            "Train Epoch: 90 [2280/2812 (81%)]\tLoss: 14.591949\n",
            "Train Epoch: 90 [2400/2812 (85%)]\tLoss: 14.111394\n",
            "Train Epoch: 90 [2520/2812 (89%)]\tLoss: 5.802895\n",
            "Train Epoch: 90 [2640/2812 (94%)]\tLoss: 10.215235\n",
            "Train Epoch: 90 [2760/2812 (98%)]\tLoss: 7.754122\n",
            "Training Loss: 10.7889 Acc: 50.2134\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6126, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 91/200\n",
            "----------\n",
            "Train Epoch: 91 [0/2812 (0%)]\tLoss: 11.869741\n",
            "Train Epoch: 91 [120/2812 (4%)]\tLoss: 16.448029\n",
            "Train Epoch: 91 [240/2812 (9%)]\tLoss: 14.037671\n",
            "Train Epoch: 91 [360/2812 (13%)]\tLoss: 7.619134\n",
            "Train Epoch: 91 [480/2812 (17%)]\tLoss: 12.678114\n",
            "Train Epoch: 91 [600/2812 (21%)]\tLoss: 6.890617\n",
            "Train Epoch: 91 [720/2812 (26%)]\tLoss: 7.396814\n",
            "Train Epoch: 91 [840/2812 (30%)]\tLoss: 8.155107\n",
            "Train Epoch: 91 [960/2812 (34%)]\tLoss: 5.538884\n",
            "Train Epoch: 91 [1080/2812 (38%)]\tLoss: 18.288309\n",
            "Train Epoch: 91 [1200/2812 (43%)]\tLoss: 19.444689\n",
            "Train Epoch: 91 [1320/2812 (47%)]\tLoss: 5.976485\n",
            "Train Epoch: 91 [1440/2812 (51%)]\tLoss: 4.017848\n",
            "Train Epoch: 91 [1560/2812 (55%)]\tLoss: 4.387945\n",
            "Train Epoch: 91 [1680/2812 (60%)]\tLoss: 1.202291\n",
            "Train Epoch: 91 [1800/2812 (64%)]\tLoss: 14.902723\n",
            "Train Epoch: 91 [1920/2812 (68%)]\tLoss: 10.449086\n",
            "Train Epoch: 91 [2040/2812 (72%)]\tLoss: 0.955084\n",
            "Train Epoch: 91 [2160/2812 (77%)]\tLoss: 17.447357\n",
            "Train Epoch: 91 [2280/2812 (81%)]\tLoss: 8.742640\n",
            "Train Epoch: 91 [2400/2812 (85%)]\tLoss: 10.714613\n",
            "Train Epoch: 91 [2520/2812 (89%)]\tLoss: 6.397363\n",
            "Train Epoch: 91 [2640/2812 (94%)]\tLoss: 11.378877\n",
            "Train Epoch: 91 [2760/2812 (98%)]\tLoss: 17.024624\n",
            "Training Loss: 11.1943 Acc: 49.6799\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6147, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 92/200\n",
            "----------\n",
            "Train Epoch: 92 [0/2812 (0%)]\tLoss: 13.867716\n",
            "Train Epoch: 92 [120/2812 (4%)]\tLoss: 10.385762\n",
            "Train Epoch: 92 [240/2812 (9%)]\tLoss: 9.768024\n",
            "Train Epoch: 92 [360/2812 (13%)]\tLoss: 6.313388\n",
            "Train Epoch: 92 [480/2812 (17%)]\tLoss: 2.681144\n",
            "Train Epoch: 92 [600/2812 (21%)]\tLoss: 8.960664\n",
            "Train Epoch: 92 [720/2812 (26%)]\tLoss: 7.369159\n",
            "Train Epoch: 92 [840/2812 (30%)]\tLoss: 1.485618\n",
            "Train Epoch: 92 [960/2812 (34%)]\tLoss: 8.302513\n",
            "Train Epoch: 92 [1080/2812 (38%)]\tLoss: 5.125160\n",
            "Train Epoch: 92 [1200/2812 (43%)]\tLoss: 25.117973\n",
            "Train Epoch: 92 [1320/2812 (47%)]\tLoss: 4.386150\n",
            "Train Epoch: 92 [1440/2812 (51%)]\tLoss: 4.434119\n",
            "Train Epoch: 92 [1560/2812 (55%)]\tLoss: 7.726510\n",
            "Train Epoch: 92 [1680/2812 (60%)]\tLoss: 12.876826\n",
            "Train Epoch: 92 [1800/2812 (64%)]\tLoss: 13.644821\n",
            "Train Epoch: 92 [1920/2812 (68%)]\tLoss: 9.893633\n",
            "Train Epoch: 92 [2040/2812 (72%)]\tLoss: 10.250972\n",
            "Train Epoch: 92 [2160/2812 (77%)]\tLoss: 15.659792\n",
            "Train Epoch: 92 [2280/2812 (81%)]\tLoss: 11.146162\n",
            "Train Epoch: 92 [2400/2812 (85%)]\tLoss: 11.050117\n",
            "Train Epoch: 92 [2520/2812 (89%)]\tLoss: 16.333569\n",
            "Train Epoch: 92 [2640/2812 (94%)]\tLoss: 9.331542\n",
            "Train Epoch: 92 [2760/2812 (98%)]\tLoss: 10.037302\n",
            "Training Loss: 11.0521 Acc: 50.3912\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6071, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 93/200\n",
            "----------\n",
            "Train Epoch: 93 [0/2812 (0%)]\tLoss: 10.251511\n",
            "Train Epoch: 93 [120/2812 (4%)]\tLoss: 7.222980\n",
            "Train Epoch: 93 [240/2812 (9%)]\tLoss: 9.876106\n",
            "Train Epoch: 93 [360/2812 (13%)]\tLoss: 1.090975\n",
            "Train Epoch: 93 [480/2812 (17%)]\tLoss: 13.848346\n",
            "Train Epoch: 93 [600/2812 (21%)]\tLoss: 2.630604\n",
            "Train Epoch: 93 [720/2812 (26%)]\tLoss: 6.443721\n",
            "Train Epoch: 93 [840/2812 (30%)]\tLoss: 13.871175\n",
            "Train Epoch: 93 [960/2812 (34%)]\tLoss: 9.908140\n",
            "Train Epoch: 93 [1080/2812 (38%)]\tLoss: 10.618627\n",
            "Train Epoch: 93 [1200/2812 (43%)]\tLoss: 13.248125\n",
            "Train Epoch: 93 [1320/2812 (47%)]\tLoss: 10.392748\n",
            "Train Epoch: 93 [1440/2812 (51%)]\tLoss: 24.158270\n",
            "Train Epoch: 93 [1560/2812 (55%)]\tLoss: 12.338941\n",
            "Train Epoch: 93 [1680/2812 (60%)]\tLoss: 5.517292\n",
            "Train Epoch: 93 [1800/2812 (64%)]\tLoss: 14.053798\n",
            "Train Epoch: 93 [1920/2812 (68%)]\tLoss: 4.027011\n",
            "Train Epoch: 93 [2040/2812 (72%)]\tLoss: 21.982180\n",
            "Train Epoch: 93 [2160/2812 (77%)]\tLoss: 5.834637\n",
            "Train Epoch: 93 [2280/2812 (81%)]\tLoss: 17.301144\n",
            "Train Epoch: 93 [2400/2812 (85%)]\tLoss: 10.600235\n",
            "Train Epoch: 93 [2520/2812 (89%)]\tLoss: 27.571491\n",
            "Train Epoch: 93 [2640/2812 (94%)]\tLoss: 4.373726\n",
            "Train Epoch: 93 [2760/2812 (98%)]\tLoss: 11.505322\n",
            "Training Loss: 11.5837 Acc: 49.5733\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5864, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 94/200\n",
            "----------\n",
            "Train Epoch: 94 [0/2812 (0%)]\tLoss: 16.638065\n",
            "Train Epoch: 94 [120/2812 (4%)]\tLoss: 20.006643\n",
            "Train Epoch: 94 [240/2812 (9%)]\tLoss: 13.956614\n",
            "Train Epoch: 94 [360/2812 (13%)]\tLoss: 9.258828\n",
            "Train Epoch: 94 [480/2812 (17%)]\tLoss: 5.909663\n",
            "Train Epoch: 94 [600/2812 (21%)]\tLoss: 0.604735\n",
            "Train Epoch: 94 [720/2812 (26%)]\tLoss: 10.140180\n",
            "Train Epoch: 94 [840/2812 (30%)]\tLoss: 12.444398\n",
            "Train Epoch: 94 [960/2812 (34%)]\tLoss: 8.229599\n",
            "Train Epoch: 94 [1080/2812 (38%)]\tLoss: 7.893497\n",
            "Train Epoch: 94 [1200/2812 (43%)]\tLoss: 10.550979\n",
            "Train Epoch: 94 [1320/2812 (47%)]\tLoss: 21.550404\n",
            "Train Epoch: 94 [1440/2812 (51%)]\tLoss: 6.184537\n",
            "Train Epoch: 94 [1560/2812 (55%)]\tLoss: 14.915884\n",
            "Train Epoch: 94 [1680/2812 (60%)]\tLoss: 1.777035\n",
            "Train Epoch: 94 [1800/2812 (64%)]\tLoss: 23.905416\n",
            "Train Epoch: 94 [1920/2812 (68%)]\tLoss: 7.574994\n",
            "Train Epoch: 94 [2040/2812 (72%)]\tLoss: 10.137673\n",
            "Train Epoch: 94 [2160/2812 (77%)]\tLoss: 10.851544\n",
            "Train Epoch: 94 [2280/2812 (81%)]\tLoss: 5.682109\n",
            "Train Epoch: 94 [2400/2812 (85%)]\tLoss: 16.089251\n",
            "Train Epoch: 94 [2520/2812 (89%)]\tLoss: 11.135622\n",
            "Train Epoch: 94 [2640/2812 (94%)]\tLoss: 10.877176\n",
            "Train Epoch: 94 [2760/2812 (98%)]\tLoss: 3.875844\n",
            "Training Loss: 11.5998 Acc: 49.3954\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5437, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 95/200\n",
            "----------\n",
            "Train Epoch: 95 [0/2812 (0%)]\tLoss: 9.275984\n",
            "Train Epoch: 95 [120/2812 (4%)]\tLoss: 18.817314\n",
            "Train Epoch: 95 [240/2812 (9%)]\tLoss: 4.514454\n",
            "Train Epoch: 95 [360/2812 (13%)]\tLoss: 19.232872\n",
            "Train Epoch: 95 [480/2812 (17%)]\tLoss: 13.482244\n",
            "Train Epoch: 95 [600/2812 (21%)]\tLoss: 10.719186\n",
            "Train Epoch: 95 [720/2812 (26%)]\tLoss: 14.920239\n",
            "Train Epoch: 95 [840/2812 (30%)]\tLoss: 11.943933\n",
            "Train Epoch: 95 [960/2812 (34%)]\tLoss: 9.963433\n",
            "Train Epoch: 95 [1080/2812 (38%)]\tLoss: 12.739610\n",
            "Train Epoch: 95 [1200/2812 (43%)]\tLoss: 16.225977\n",
            "Train Epoch: 95 [1320/2812 (47%)]\tLoss: 10.975836\n",
            "Train Epoch: 95 [1440/2812 (51%)]\tLoss: 22.675682\n",
            "Train Epoch: 95 [1560/2812 (55%)]\tLoss: 26.751226\n",
            "Train Epoch: 95 [1680/2812 (60%)]\tLoss: 12.374692\n",
            "Train Epoch: 95 [1800/2812 (64%)]\tLoss: 10.320391\n",
            "Train Epoch: 95 [1920/2812 (68%)]\tLoss: 11.596117\n",
            "Train Epoch: 95 [2040/2812 (72%)]\tLoss: 2.657382\n",
            "Train Epoch: 95 [2160/2812 (77%)]\tLoss: 28.594961\n",
            "Train Epoch: 95 [2280/2812 (81%)]\tLoss: 12.624665\n",
            "Train Epoch: 95 [2400/2812 (85%)]\tLoss: 3.277641\n",
            "Train Epoch: 95 [2520/2812 (89%)]\tLoss: 8.775610\n",
            "Train Epoch: 95 [2640/2812 (94%)]\tLoss: 15.760073\n",
            "Train Epoch: 95 [2760/2812 (98%)]\tLoss: 13.302969\n",
            "Training Loss: 11.4533 Acc: 50.7112\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6056, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 96/200\n",
            "----------\n",
            "Train Epoch: 96 [0/2812 (0%)]\tLoss: 21.042158\n",
            "Train Epoch: 96 [120/2812 (4%)]\tLoss: 10.269564\n",
            "Train Epoch: 96 [240/2812 (9%)]\tLoss: 13.654089\n",
            "Train Epoch: 96 [360/2812 (13%)]\tLoss: 3.920031\n",
            "Train Epoch: 96 [480/2812 (17%)]\tLoss: 16.026943\n",
            "Train Epoch: 96 [600/2812 (21%)]\tLoss: 5.922781\n",
            "Train Epoch: 96 [720/2812 (26%)]\tLoss: 17.502390\n",
            "Train Epoch: 96 [840/2812 (30%)]\tLoss: 8.219926\n",
            "Train Epoch: 96 [960/2812 (34%)]\tLoss: 12.672771\n",
            "Train Epoch: 96 [1080/2812 (38%)]\tLoss: 8.350546\n",
            "Train Epoch: 96 [1200/2812 (43%)]\tLoss: 9.582729\n",
            "Train Epoch: 96 [1320/2812 (47%)]\tLoss: 16.580530\n",
            "Train Epoch: 96 [1440/2812 (51%)]\tLoss: 12.350060\n",
            "Train Epoch: 96 [1560/2812 (55%)]\tLoss: 6.090978\n",
            "Train Epoch: 96 [1680/2812 (60%)]\tLoss: 12.526506\n",
            "Train Epoch: 96 [1800/2812 (64%)]\tLoss: 4.618416\n",
            "Train Epoch: 96 [1920/2812 (68%)]\tLoss: 3.686464\n",
            "Train Epoch: 96 [2040/2812 (72%)]\tLoss: 9.000597\n",
            "Train Epoch: 96 [2160/2812 (77%)]\tLoss: 7.099693\n",
            "Train Epoch: 96 [2280/2812 (81%)]\tLoss: 4.963656\n",
            "Train Epoch: 96 [2400/2812 (85%)]\tLoss: 3.806477\n",
            "Train Epoch: 96 [2520/2812 (89%)]\tLoss: 10.119241\n",
            "Train Epoch: 96 [2640/2812 (94%)]\tLoss: 4.195626\n",
            "Train Epoch: 96 [2760/2812 (98%)]\tLoss: 3.354583\n",
            "Training Loss: 11.0875 Acc: 49.0398\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5695, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 97/200\n",
            "----------\n",
            "Train Epoch: 97 [0/2812 (0%)]\tLoss: 11.590756\n",
            "Train Epoch: 97 [120/2812 (4%)]\tLoss: 7.414068\n",
            "Train Epoch: 97 [240/2812 (9%)]\tLoss: 15.815921\n",
            "Train Epoch: 97 [360/2812 (13%)]\tLoss: 8.405095\n",
            "Train Epoch: 97 [480/2812 (17%)]\tLoss: 8.401276\n",
            "Train Epoch: 97 [600/2812 (21%)]\tLoss: 16.535452\n",
            "Train Epoch: 97 [720/2812 (26%)]\tLoss: 15.908971\n",
            "Train Epoch: 97 [840/2812 (30%)]\tLoss: 5.970740\n",
            "Train Epoch: 97 [960/2812 (34%)]\tLoss: 11.483603\n",
            "Train Epoch: 97 [1080/2812 (38%)]\tLoss: 21.187654\n",
            "Train Epoch: 97 [1200/2812 (43%)]\tLoss: 4.448264\n",
            "Train Epoch: 97 [1320/2812 (47%)]\tLoss: 11.767324\n",
            "Train Epoch: 97 [1440/2812 (51%)]\tLoss: 13.907690\n",
            "Train Epoch: 97 [1560/2812 (55%)]\tLoss: 28.149389\n",
            "Train Epoch: 97 [1680/2812 (60%)]\tLoss: 10.584160\n",
            "Train Epoch: 97 [1800/2812 (64%)]\tLoss: 11.291335\n",
            "Train Epoch: 97 [1920/2812 (68%)]\tLoss: 13.048635\n",
            "Train Epoch: 97 [2040/2812 (72%)]\tLoss: 11.336355\n",
            "Train Epoch: 97 [2160/2812 (77%)]\tLoss: 0.543689\n",
            "Train Epoch: 97 [2280/2812 (81%)]\tLoss: 8.277102\n",
            "Train Epoch: 97 [2400/2812 (85%)]\tLoss: 13.182180\n",
            "Train Epoch: 97 [2520/2812 (89%)]\tLoss: 6.908762\n",
            "Train Epoch: 97 [2640/2812 (94%)]\tLoss: 14.265162\n",
            "Train Epoch: 97 [2760/2812 (98%)]\tLoss: 20.065777\n",
            "Training Loss: 10.9627 Acc: 50.6046\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5398, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 98/200\n",
            "----------\n",
            "Train Epoch: 98 [0/2812 (0%)]\tLoss: 9.821538\n",
            "Train Epoch: 98 [120/2812 (4%)]\tLoss: 13.155756\n",
            "Train Epoch: 98 [240/2812 (9%)]\tLoss: 21.635235\n",
            "Train Epoch: 98 [360/2812 (13%)]\tLoss: 8.898752\n",
            "Train Epoch: 98 [480/2812 (17%)]\tLoss: 12.133524\n",
            "Train Epoch: 98 [600/2812 (21%)]\tLoss: 8.540818\n",
            "Train Epoch: 98 [720/2812 (26%)]\tLoss: 1.943743\n",
            "Train Epoch: 98 [840/2812 (30%)]\tLoss: 3.346587\n",
            "Train Epoch: 98 [960/2812 (34%)]\tLoss: 12.989756\n",
            "Train Epoch: 98 [1080/2812 (38%)]\tLoss: 9.295732\n",
            "Train Epoch: 98 [1200/2812 (43%)]\tLoss: 18.567554\n",
            "Train Epoch: 98 [1320/2812 (47%)]\tLoss: 12.658134\n",
            "Train Epoch: 98 [1440/2812 (51%)]\tLoss: 29.497730\n",
            "Train Epoch: 98 [1560/2812 (55%)]\tLoss: 8.104807\n",
            "Train Epoch: 98 [1680/2812 (60%)]\tLoss: 7.234026\n",
            "Train Epoch: 98 [1800/2812 (64%)]\tLoss: 5.259718\n",
            "Train Epoch: 98 [1920/2812 (68%)]\tLoss: 7.699656\n",
            "Train Epoch: 98 [2040/2812 (72%)]\tLoss: 5.331320\n",
            "Train Epoch: 98 [2160/2812 (77%)]\tLoss: 9.358473\n",
            "Train Epoch: 98 [2280/2812 (81%)]\tLoss: 10.165440\n",
            "Train Epoch: 98 [2400/2812 (85%)]\tLoss: 17.131956\n",
            "Train Epoch: 98 [2520/2812 (89%)]\tLoss: 16.288006\n",
            "Train Epoch: 98 [2640/2812 (94%)]\tLoss: 8.570272\n",
            "Train Epoch: 98 [2760/2812 (98%)]\tLoss: 16.777891\n",
            "Training Loss: 10.9844 Acc: 50.3201\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5704, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 99/200\n",
            "----------\n",
            "Train Epoch: 99 [0/2812 (0%)]\tLoss: 3.610260\n",
            "Train Epoch: 99 [120/2812 (4%)]\tLoss: 10.510449\n",
            "Train Epoch: 99 [240/2812 (9%)]\tLoss: 4.425306\n",
            "Train Epoch: 99 [360/2812 (13%)]\tLoss: 10.143023\n",
            "Train Epoch: 99 [480/2812 (17%)]\tLoss: 3.269210\n",
            "Train Epoch: 99 [600/2812 (21%)]\tLoss: 21.662754\n",
            "Train Epoch: 99 [720/2812 (26%)]\tLoss: 4.528254\n",
            "Train Epoch: 99 [840/2812 (30%)]\tLoss: 2.541628\n",
            "Train Epoch: 99 [960/2812 (34%)]\tLoss: 6.435426\n",
            "Train Epoch: 99 [1080/2812 (38%)]\tLoss: 6.482084\n",
            "Train Epoch: 99 [1200/2812 (43%)]\tLoss: 20.444031\n",
            "Train Epoch: 99 [1320/2812 (47%)]\tLoss: 16.943172\n",
            "Train Epoch: 99 [1440/2812 (51%)]\tLoss: 9.085238\n",
            "Train Epoch: 99 [1560/2812 (55%)]\tLoss: 14.085630\n",
            "Train Epoch: 99 [1680/2812 (60%)]\tLoss: 8.899103\n",
            "Train Epoch: 99 [1800/2812 (64%)]\tLoss: 16.445831\n",
            "Train Epoch: 99 [1920/2812 (68%)]\tLoss: 2.536357\n",
            "Train Epoch: 99 [2040/2812 (72%)]\tLoss: 0.525055\n",
            "Train Epoch: 99 [2160/2812 (77%)]\tLoss: 0.790528\n",
            "Train Epoch: 99 [2280/2812 (81%)]\tLoss: 18.461494\n",
            "Train Epoch: 99 [2400/2812 (85%)]\tLoss: 13.178988\n",
            "Train Epoch: 99 [2520/2812 (89%)]\tLoss: 12.111921\n",
            "Train Epoch: 99 [2640/2812 (94%)]\tLoss: 6.398876\n",
            "Train Epoch: 99 [2760/2812 (98%)]\tLoss: 9.350840\n",
            "Training Loss: 10.6644 Acc: 50.3912\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5638, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 100/200\n",
            "----------\n",
            "Train Epoch: 100 [0/2812 (0%)]\tLoss: 12.401480\n",
            "Train Epoch: 100 [120/2812 (4%)]\tLoss: 16.789015\n",
            "Train Epoch: 100 [240/2812 (9%)]\tLoss: 10.446493\n",
            "Train Epoch: 100 [360/2812 (13%)]\tLoss: 18.702059\n",
            "Train Epoch: 100 [480/2812 (17%)]\tLoss: 13.949266\n",
            "Train Epoch: 100 [600/2812 (21%)]\tLoss: 11.899904\n",
            "Train Epoch: 100 [720/2812 (26%)]\tLoss: 7.395060\n",
            "Train Epoch: 100 [840/2812 (30%)]\tLoss: 8.645329\n",
            "Train Epoch: 100 [960/2812 (34%)]\tLoss: 8.023237\n",
            "Train Epoch: 100 [1080/2812 (38%)]\tLoss: 15.747136\n",
            "Train Epoch: 100 [1200/2812 (43%)]\tLoss: 10.046301\n",
            "Train Epoch: 100 [1320/2812 (47%)]\tLoss: 15.036880\n",
            "Train Epoch: 100 [1440/2812 (51%)]\tLoss: 17.094959\n",
            "Train Epoch: 100 [1560/2812 (55%)]\tLoss: 5.625556\n",
            "Train Epoch: 100 [1680/2812 (60%)]\tLoss: 22.226944\n",
            "Train Epoch: 100 [1800/2812 (64%)]\tLoss: 4.971906\n",
            "Train Epoch: 100 [1920/2812 (68%)]\tLoss: 9.889380\n",
            "Train Epoch: 100 [2040/2812 (72%)]\tLoss: 13.810466\n",
            "Train Epoch: 100 [2160/2812 (77%)]\tLoss: 22.702076\n",
            "Train Epoch: 100 [2280/2812 (81%)]\tLoss: 16.241646\n",
            "Train Epoch: 100 [2400/2812 (85%)]\tLoss: 7.201550\n",
            "Train Epoch: 100 [2520/2812 (89%)]\tLoss: 8.748926\n",
            "Train Epoch: 100 [2640/2812 (94%)]\tLoss: 2.322709\n",
            "Train Epoch: 100 [2760/2812 (98%)]\tLoss: 18.107597\n",
            "Training Loss: 11.0499 Acc: 50.2489\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5916, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 101/200\n",
            "----------\n",
            "Train Epoch: 101 [0/2812 (0%)]\tLoss: 3.327912\n",
            "Train Epoch: 101 [120/2812 (4%)]\tLoss: 8.870386\n",
            "Train Epoch: 101 [240/2812 (9%)]\tLoss: 13.488894\n",
            "Train Epoch: 101 [360/2812 (13%)]\tLoss: 1.415519\n",
            "Train Epoch: 101 [480/2812 (17%)]\tLoss: 9.317233\n",
            "Train Epoch: 101 [600/2812 (21%)]\tLoss: 15.598970\n",
            "Train Epoch: 101 [720/2812 (26%)]\tLoss: 6.805018\n",
            "Train Epoch: 101 [840/2812 (30%)]\tLoss: 13.538492\n",
            "Train Epoch: 101 [960/2812 (34%)]\tLoss: 1.974086\n",
            "Train Epoch: 101 [1080/2812 (38%)]\tLoss: 9.926851\n",
            "Train Epoch: 101 [1200/2812 (43%)]\tLoss: 18.221382\n",
            "Train Epoch: 101 [1320/2812 (47%)]\tLoss: 3.889883\n",
            "Train Epoch: 101 [1440/2812 (51%)]\tLoss: 12.162771\n",
            "Train Epoch: 101 [1560/2812 (55%)]\tLoss: 14.580223\n",
            "Train Epoch: 101 [1680/2812 (60%)]\tLoss: 4.060355\n",
            "Train Epoch: 101 [1800/2812 (64%)]\tLoss: 7.427939\n",
            "Train Epoch: 101 [1920/2812 (68%)]\tLoss: 6.712058\n",
            "Train Epoch: 101 [2040/2812 (72%)]\tLoss: 12.820981\n",
            "Train Epoch: 101 [2160/2812 (77%)]\tLoss: 15.505293\n",
            "Train Epoch: 101 [2280/2812 (81%)]\tLoss: 12.501639\n",
            "Train Epoch: 101 [2400/2812 (85%)]\tLoss: 8.172889\n",
            "Train Epoch: 101 [2520/2812 (89%)]\tLoss: 6.624284\n",
            "Train Epoch: 101 [2640/2812 (94%)]\tLoss: 11.668264\n",
            "Train Epoch: 101 [2760/2812 (98%)]\tLoss: 15.099924\n",
            "Training Loss: 11.1902 Acc: 49.6444\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6295, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 102/200\n",
            "----------\n",
            "Train Epoch: 102 [0/2812 (0%)]\tLoss: 15.809782\n",
            "Train Epoch: 102 [120/2812 (4%)]\tLoss: 9.853518\n",
            "Train Epoch: 102 [240/2812 (9%)]\tLoss: 7.890841\n",
            "Train Epoch: 102 [360/2812 (13%)]\tLoss: 14.928728\n",
            "Train Epoch: 102 [480/2812 (17%)]\tLoss: 14.735178\n",
            "Train Epoch: 102 [600/2812 (21%)]\tLoss: 9.238182\n",
            "Train Epoch: 102 [720/2812 (26%)]\tLoss: 9.994246\n",
            "Train Epoch: 102 [840/2812 (30%)]\tLoss: 11.288038\n",
            "Train Epoch: 102 [960/2812 (34%)]\tLoss: 14.050972\n",
            "Train Epoch: 102 [1080/2812 (38%)]\tLoss: 11.890217\n",
            "Train Epoch: 102 [1200/2812 (43%)]\tLoss: 0.242133\n",
            "Train Epoch: 102 [1320/2812 (47%)]\tLoss: 10.760286\n",
            "Train Epoch: 102 [1440/2812 (51%)]\tLoss: 6.038698\n",
            "Train Epoch: 102 [1560/2812 (55%)]\tLoss: 6.844370\n",
            "Train Epoch: 102 [1680/2812 (60%)]\tLoss: 12.157495\n",
            "Train Epoch: 102 [1800/2812 (64%)]\tLoss: 13.769549\n",
            "Train Epoch: 102 [1920/2812 (68%)]\tLoss: 12.700668\n",
            "Train Epoch: 102 [2040/2812 (72%)]\tLoss: 4.865869\n",
            "Train Epoch: 102 [2160/2812 (77%)]\tLoss: 10.768354\n",
            "Train Epoch: 102 [2280/2812 (81%)]\tLoss: 12.269945\n",
            "Train Epoch: 102 [2400/2812 (85%)]\tLoss: 12.348211\n",
            "Train Epoch: 102 [2520/2812 (89%)]\tLoss: 17.767643\n",
            "Train Epoch: 102 [2640/2812 (94%)]\tLoss: 10.354918\n",
            "Train Epoch: 102 [2760/2812 (98%)]\tLoss: 9.082851\n",
            "Training Loss: 11.2094 Acc: 49.6444\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5537, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 103/200\n",
            "----------\n",
            "Train Epoch: 103 [0/2812 (0%)]\tLoss: 11.536178\n",
            "Train Epoch: 103 [120/2812 (4%)]\tLoss: 8.605905\n",
            "Train Epoch: 103 [240/2812 (9%)]\tLoss: 2.306653\n",
            "Train Epoch: 103 [360/2812 (13%)]\tLoss: 9.184096\n",
            "Train Epoch: 103 [480/2812 (17%)]\tLoss: 10.965614\n",
            "Train Epoch: 103 [600/2812 (21%)]\tLoss: 11.308400\n",
            "Train Epoch: 103 [720/2812 (26%)]\tLoss: 18.883818\n",
            "Train Epoch: 103 [840/2812 (30%)]\tLoss: 9.648728\n",
            "Train Epoch: 103 [960/2812 (34%)]\tLoss: 13.730306\n",
            "Train Epoch: 103 [1080/2812 (38%)]\tLoss: 25.437336\n",
            "Train Epoch: 103 [1200/2812 (43%)]\tLoss: 4.244954\n",
            "Train Epoch: 103 [1320/2812 (47%)]\tLoss: 7.462427\n",
            "Train Epoch: 103 [1440/2812 (51%)]\tLoss: 11.338763\n",
            "Train Epoch: 103 [1560/2812 (55%)]\tLoss: 14.006775\n",
            "Train Epoch: 103 [1680/2812 (60%)]\tLoss: 5.931599\n",
            "Train Epoch: 103 [1800/2812 (64%)]\tLoss: 15.617453\n",
            "Train Epoch: 103 [1920/2812 (68%)]\tLoss: 18.718765\n",
            "Train Epoch: 103 [2040/2812 (72%)]\tLoss: 20.695797\n",
            "Train Epoch: 103 [2160/2812 (77%)]\tLoss: 11.639354\n",
            "Train Epoch: 103 [2280/2812 (81%)]\tLoss: 8.875695\n",
            "Train Epoch: 103 [2400/2812 (85%)]\tLoss: 9.833176\n",
            "Train Epoch: 103 [2520/2812 (89%)]\tLoss: 5.874609\n",
            "Train Epoch: 103 [2640/2812 (94%)]\tLoss: 15.792587\n",
            "Train Epoch: 103 [2760/2812 (98%)]\tLoss: 8.615372\n",
            "Training Loss: 11.1103 Acc: 50.1422\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5256, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 104/200\n",
            "----------\n",
            "Train Epoch: 104 [0/2812 (0%)]\tLoss: 12.605248\n",
            "Train Epoch: 104 [120/2812 (4%)]\tLoss: 12.137730\n",
            "Train Epoch: 104 [240/2812 (9%)]\tLoss: 3.392358\n",
            "Train Epoch: 104 [360/2812 (13%)]\tLoss: 13.009705\n",
            "Train Epoch: 104 [480/2812 (17%)]\tLoss: 13.482803\n",
            "Train Epoch: 104 [600/2812 (21%)]\tLoss: 5.463862\n",
            "Train Epoch: 104 [720/2812 (26%)]\tLoss: 2.423126\n",
            "Train Epoch: 104 [840/2812 (30%)]\tLoss: 22.805655\n",
            "Train Epoch: 104 [960/2812 (34%)]\tLoss: 4.408563\n",
            "Train Epoch: 104 [1080/2812 (38%)]\tLoss: 2.231699\n",
            "Train Epoch: 104 [1200/2812 (43%)]\tLoss: 19.082386\n",
            "Train Epoch: 104 [1320/2812 (47%)]\tLoss: 10.357851\n",
            "Train Epoch: 104 [1440/2812 (51%)]\tLoss: 15.012738\n",
            "Train Epoch: 104 [1560/2812 (55%)]\tLoss: 2.388515\n",
            "Train Epoch: 104 [1680/2812 (60%)]\tLoss: 6.900455\n",
            "Train Epoch: 104 [1800/2812 (64%)]\tLoss: 10.537760\n",
            "Train Epoch: 104 [1920/2812 (68%)]\tLoss: 3.144701\n",
            "Train Epoch: 104 [2040/2812 (72%)]\tLoss: 4.550902\n",
            "Train Epoch: 104 [2160/2812 (77%)]\tLoss: 7.408845\n",
            "Train Epoch: 104 [2280/2812 (81%)]\tLoss: 4.657834\n",
            "Train Epoch: 104 [2400/2812 (85%)]\tLoss: 13.005694\n",
            "Train Epoch: 104 [2520/2812 (89%)]\tLoss: 7.726060\n",
            "Train Epoch: 104 [2640/2812 (94%)]\tLoss: 12.949957\n",
            "Train Epoch: 104 [2760/2812 (98%)]\tLoss: 6.170150\n",
            "Training Loss: 10.9938 Acc: 50.8535\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5267, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 105/200\n",
            "----------\n",
            "Train Epoch: 105 [0/2812 (0%)]\tLoss: 16.860460\n",
            "Train Epoch: 105 [120/2812 (4%)]\tLoss: 11.785845\n",
            "Train Epoch: 105 [240/2812 (9%)]\tLoss: 9.049927\n",
            "Train Epoch: 105 [360/2812 (13%)]\tLoss: 10.324949\n",
            "Train Epoch: 105 [480/2812 (17%)]\tLoss: 14.100580\n",
            "Train Epoch: 105 [600/2812 (21%)]\tLoss: 10.451223\n",
            "Train Epoch: 105 [720/2812 (26%)]\tLoss: 7.199491\n",
            "Train Epoch: 105 [840/2812 (30%)]\tLoss: 14.493607\n",
            "Train Epoch: 105 [960/2812 (34%)]\tLoss: 12.039887\n",
            "Train Epoch: 105 [1080/2812 (38%)]\tLoss: 6.648231\n",
            "Train Epoch: 105 [1200/2812 (43%)]\tLoss: 11.933870\n",
            "Train Epoch: 105 [1320/2812 (47%)]\tLoss: 10.510609\n",
            "Train Epoch: 105 [1440/2812 (51%)]\tLoss: 11.328213\n",
            "Train Epoch: 105 [1560/2812 (55%)]\tLoss: 7.706175\n",
            "Train Epoch: 105 [1680/2812 (60%)]\tLoss: 16.290464\n",
            "Train Epoch: 105 [1800/2812 (64%)]\tLoss: 11.240511\n",
            "Train Epoch: 105 [1920/2812 (68%)]\tLoss: 19.711155\n",
            "Train Epoch: 105 [2040/2812 (72%)]\tLoss: 11.888132\n",
            "Train Epoch: 105 [2160/2812 (77%)]\tLoss: 10.906064\n",
            "Train Epoch: 105 [2280/2812 (81%)]\tLoss: 9.531561\n",
            "Train Epoch: 105 [2400/2812 (85%)]\tLoss: 18.225521\n",
            "Train Epoch: 105 [2520/2812 (89%)]\tLoss: 1.955999\n",
            "Train Epoch: 105 [2640/2812 (94%)]\tLoss: 5.159826\n",
            "Train Epoch: 105 [2760/2812 (98%)]\tLoss: 9.931269\n",
            "Training Loss: 11.4071 Acc: 50.0711\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5600, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 106/200\n",
            "----------\n",
            "Train Epoch: 106 [0/2812 (0%)]\tLoss: 8.442807\n",
            "Train Epoch: 106 [120/2812 (4%)]\tLoss: 8.812892\n",
            "Train Epoch: 106 [240/2812 (9%)]\tLoss: 9.947195\n",
            "Train Epoch: 106 [360/2812 (13%)]\tLoss: 9.664949\n",
            "Train Epoch: 106 [480/2812 (17%)]\tLoss: 10.773090\n",
            "Train Epoch: 106 [600/2812 (21%)]\tLoss: 7.800141\n",
            "Train Epoch: 106 [720/2812 (26%)]\tLoss: 7.512980\n",
            "Train Epoch: 106 [840/2812 (30%)]\tLoss: 4.893527\n",
            "Train Epoch: 106 [960/2812 (34%)]\tLoss: 12.342155\n",
            "Train Epoch: 106 [1080/2812 (38%)]\tLoss: 7.771495\n",
            "Train Epoch: 106 [1200/2812 (43%)]\tLoss: 13.702138\n",
            "Train Epoch: 106 [1320/2812 (47%)]\tLoss: 15.825015\n",
            "Train Epoch: 106 [1440/2812 (51%)]\tLoss: 5.311170\n",
            "Train Epoch: 106 [1560/2812 (55%)]\tLoss: 8.965396\n",
            "Train Epoch: 106 [1680/2812 (60%)]\tLoss: 4.473104\n",
            "Train Epoch: 106 [1800/2812 (64%)]\tLoss: 9.678704\n",
            "Train Epoch: 106 [1920/2812 (68%)]\tLoss: 14.624173\n",
            "Train Epoch: 106 [2040/2812 (72%)]\tLoss: 3.258047\n",
            "Train Epoch: 106 [2160/2812 (77%)]\tLoss: 2.035218\n",
            "Train Epoch: 106 [2280/2812 (81%)]\tLoss: 15.426016\n",
            "Train Epoch: 106 [2400/2812 (85%)]\tLoss: 16.884089\n",
            "Train Epoch: 106 [2520/2812 (89%)]\tLoss: 7.356471\n",
            "Train Epoch: 106 [2640/2812 (94%)]\tLoss: 7.547700\n",
            "Train Epoch: 106 [2760/2812 (98%)]\tLoss: 10.305887\n",
            "Training Loss: 10.7753 Acc: 50.2489\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6033, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 107/200\n",
            "----------\n",
            "Train Epoch: 107 [0/2812 (0%)]\tLoss: 16.370081\n",
            "Train Epoch: 107 [120/2812 (4%)]\tLoss: 4.540423\n",
            "Train Epoch: 107 [240/2812 (9%)]\tLoss: 3.579026\n",
            "Train Epoch: 107 [360/2812 (13%)]\tLoss: 7.182135\n",
            "Train Epoch: 107 [480/2812 (17%)]\tLoss: 18.228415\n",
            "Train Epoch: 107 [600/2812 (21%)]\tLoss: 9.950527\n",
            "Train Epoch: 107 [720/2812 (26%)]\tLoss: 24.510174\n",
            "Train Epoch: 107 [840/2812 (30%)]\tLoss: 12.341166\n",
            "Train Epoch: 107 [960/2812 (34%)]\tLoss: 9.019382\n",
            "Train Epoch: 107 [1080/2812 (38%)]\tLoss: 17.372955\n",
            "Train Epoch: 107 [1200/2812 (43%)]\tLoss: 21.392017\n",
            "Train Epoch: 107 [1320/2812 (47%)]\tLoss: 8.382723\n",
            "Train Epoch: 107 [1440/2812 (51%)]\tLoss: 6.497892\n",
            "Train Epoch: 107 [1560/2812 (55%)]\tLoss: 26.854603\n",
            "Train Epoch: 107 [1680/2812 (60%)]\tLoss: 12.850125\n",
            "Train Epoch: 107 [1800/2812 (64%)]\tLoss: 7.584249\n",
            "Train Epoch: 107 [1920/2812 (68%)]\tLoss: 33.771690\n",
            "Train Epoch: 107 [2040/2812 (72%)]\tLoss: 5.800466\n",
            "Train Epoch: 107 [2160/2812 (77%)]\tLoss: 8.362287\n",
            "Train Epoch: 107 [2280/2812 (81%)]\tLoss: 11.136523\n",
            "Train Epoch: 107 [2400/2812 (85%)]\tLoss: 9.476968\n",
            "Train Epoch: 107 [2520/2812 (89%)]\tLoss: 11.206533\n",
            "Train Epoch: 107 [2640/2812 (94%)]\tLoss: 15.586111\n",
            "Train Epoch: 107 [2760/2812 (98%)]\tLoss: 6.266541\n",
            "Training Loss: 11.4043 Acc: 49.3599\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6404, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 108/200\n",
            "----------\n",
            "Train Epoch: 108 [0/2812 (0%)]\tLoss: 6.263762\n",
            "Train Epoch: 108 [120/2812 (4%)]\tLoss: 4.967832\n",
            "Train Epoch: 108 [240/2812 (9%)]\tLoss: 4.973977\n",
            "Train Epoch: 108 [360/2812 (13%)]\tLoss: 7.047967\n",
            "Train Epoch: 108 [480/2812 (17%)]\tLoss: 11.519796\n",
            "Train Epoch: 108 [600/2812 (21%)]\tLoss: 6.308956\n",
            "Train Epoch: 108 [720/2812 (26%)]\tLoss: 12.413112\n",
            "Train Epoch: 108 [840/2812 (30%)]\tLoss: 11.252077\n",
            "Train Epoch: 108 [960/2812 (34%)]\tLoss: 17.888906\n",
            "Train Epoch: 108 [1080/2812 (38%)]\tLoss: 7.856412\n",
            "Train Epoch: 108 [1200/2812 (43%)]\tLoss: 12.463956\n",
            "Train Epoch: 108 [1320/2812 (47%)]\tLoss: 5.028760\n",
            "Train Epoch: 108 [1440/2812 (51%)]\tLoss: 24.230743\n",
            "Train Epoch: 108 [1560/2812 (55%)]\tLoss: 20.603004\n",
            "Train Epoch: 108 [1680/2812 (60%)]\tLoss: 9.014110\n",
            "Train Epoch: 108 [1800/2812 (64%)]\tLoss: 16.840164\n",
            "Train Epoch: 108 [1920/2812 (68%)]\tLoss: 17.225739\n",
            "Train Epoch: 108 [2040/2812 (72%)]\tLoss: 2.859767\n",
            "Train Epoch: 108 [2160/2812 (77%)]\tLoss: 24.746067\n",
            "Train Epoch: 108 [2280/2812 (81%)]\tLoss: 14.331830\n",
            "Train Epoch: 108 [2400/2812 (85%)]\tLoss: 12.317402\n",
            "Train Epoch: 108 [2520/2812 (89%)]\tLoss: 8.412860\n",
            "Train Epoch: 108 [2640/2812 (94%)]\tLoss: 14.396994\n",
            "Train Epoch: 108 [2760/2812 (98%)]\tLoss: 11.081247\n",
            "Training Loss: 10.9979 Acc: 49.7155\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5328, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 109/200\n",
            "----------\n",
            "Train Epoch: 109 [0/2812 (0%)]\tLoss: 28.262716\n",
            "Train Epoch: 109 [120/2812 (4%)]\tLoss: 12.359903\n",
            "Train Epoch: 109 [240/2812 (9%)]\tLoss: 16.634506\n",
            "Train Epoch: 109 [360/2812 (13%)]\tLoss: 11.250020\n",
            "Train Epoch: 109 [480/2812 (17%)]\tLoss: 9.181307\n",
            "Train Epoch: 109 [600/2812 (21%)]\tLoss: 18.249454\n",
            "Train Epoch: 109 [720/2812 (26%)]\tLoss: 4.553451\n",
            "Train Epoch: 109 [840/2812 (30%)]\tLoss: 9.944486\n",
            "Train Epoch: 109 [960/2812 (34%)]\tLoss: 4.987840\n",
            "Train Epoch: 109 [1080/2812 (38%)]\tLoss: 20.713177\n",
            "Train Epoch: 109 [1200/2812 (43%)]\tLoss: 2.737047\n",
            "Train Epoch: 109 [1320/2812 (47%)]\tLoss: 3.690999\n",
            "Train Epoch: 109 [1440/2812 (51%)]\tLoss: 1.142030\n",
            "Train Epoch: 109 [1560/2812 (55%)]\tLoss: 10.074128\n",
            "Train Epoch: 109 [1680/2812 (60%)]\tLoss: 19.961143\n",
            "Train Epoch: 109 [1800/2812 (64%)]\tLoss: 5.629478\n",
            "Train Epoch: 109 [1920/2812 (68%)]\tLoss: 3.322247\n",
            "Train Epoch: 109 [2040/2812 (72%)]\tLoss: 7.051850\n",
            "Train Epoch: 109 [2160/2812 (77%)]\tLoss: 6.035043\n",
            "Train Epoch: 109 [2280/2812 (81%)]\tLoss: 7.406985\n",
            "Train Epoch: 109 [2400/2812 (85%)]\tLoss: 20.521961\n",
            "Train Epoch: 109 [2520/2812 (89%)]\tLoss: 14.021959\n",
            "Train Epoch: 109 [2640/2812 (94%)]\tLoss: 4.922202\n",
            "Train Epoch: 109 [2760/2812 (98%)]\tLoss: 15.800555\n",
            "Training Loss: 11.3968 Acc: 50.8535\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5679, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 110/200\n",
            "----------\n",
            "Train Epoch: 110 [0/2812 (0%)]\tLoss: 1.187124\n",
            "Train Epoch: 110 [120/2812 (4%)]\tLoss: 11.985988\n",
            "Train Epoch: 110 [240/2812 (9%)]\tLoss: 11.566534\n",
            "Train Epoch: 110 [360/2812 (13%)]\tLoss: 16.479290\n",
            "Train Epoch: 110 [480/2812 (17%)]\tLoss: 17.426708\n",
            "Train Epoch: 110 [600/2812 (21%)]\tLoss: 10.962087\n",
            "Train Epoch: 110 [720/2812 (26%)]\tLoss: 5.087602\n",
            "Train Epoch: 110 [840/2812 (30%)]\tLoss: 11.710533\n",
            "Train Epoch: 110 [960/2812 (34%)]\tLoss: 20.749905\n",
            "Train Epoch: 110 [1080/2812 (38%)]\tLoss: 4.160370\n",
            "Train Epoch: 110 [1200/2812 (43%)]\tLoss: 17.539516\n",
            "Train Epoch: 110 [1320/2812 (47%)]\tLoss: 9.100918\n",
            "Train Epoch: 110 [1440/2812 (51%)]\tLoss: 17.130861\n",
            "Train Epoch: 110 [1560/2812 (55%)]\tLoss: 9.617395\n",
            "Train Epoch: 110 [1680/2812 (60%)]\tLoss: 13.018735\n",
            "Train Epoch: 110 [1800/2812 (64%)]\tLoss: 10.026157\n",
            "Train Epoch: 110 [1920/2812 (68%)]\tLoss: 7.582661\n",
            "Train Epoch: 110 [2040/2812 (72%)]\tLoss: 9.086268\n",
            "Train Epoch: 110 [2160/2812 (77%)]\tLoss: 14.875221\n",
            "Train Epoch: 110 [2280/2812 (81%)]\tLoss: 10.324015\n",
            "Train Epoch: 110 [2400/2812 (85%)]\tLoss: 16.025805\n",
            "Train Epoch: 110 [2520/2812 (89%)]\tLoss: 11.514103\n",
            "Train Epoch: 110 [2640/2812 (94%)]\tLoss: 12.522795\n",
            "Train Epoch: 110 [2760/2812 (98%)]\tLoss: 11.745058\n",
            "Training Loss: 11.0731 Acc: 50.8890\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5965, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 111/200\n",
            "----------\n",
            "Train Epoch: 111 [0/2812 (0%)]\tLoss: 21.998306\n",
            "Train Epoch: 111 [120/2812 (4%)]\tLoss: 9.453575\n",
            "Train Epoch: 111 [240/2812 (9%)]\tLoss: 6.048785\n",
            "Train Epoch: 111 [360/2812 (13%)]\tLoss: 7.434949\n",
            "Train Epoch: 111 [480/2812 (17%)]\tLoss: 7.692666\n",
            "Train Epoch: 111 [600/2812 (21%)]\tLoss: 16.494308\n",
            "Train Epoch: 111 [720/2812 (26%)]\tLoss: 11.189462\n",
            "Train Epoch: 111 [840/2812 (30%)]\tLoss: 5.882501\n",
            "Train Epoch: 111 [960/2812 (34%)]\tLoss: 30.576645\n",
            "Train Epoch: 111 [1080/2812 (38%)]\tLoss: 23.384769\n",
            "Train Epoch: 111 [1200/2812 (43%)]\tLoss: 6.078198\n",
            "Train Epoch: 111 [1320/2812 (47%)]\tLoss: 11.979283\n",
            "Train Epoch: 111 [1440/2812 (51%)]\tLoss: 5.082088\n",
            "Train Epoch: 111 [1560/2812 (55%)]\tLoss: 5.159736\n",
            "Train Epoch: 111 [1680/2812 (60%)]\tLoss: 13.334149\n",
            "Train Epoch: 111 [1800/2812 (64%)]\tLoss: 10.356263\n",
            "Train Epoch: 111 [1920/2812 (68%)]\tLoss: 4.194888\n",
            "Train Epoch: 111 [2040/2812 (72%)]\tLoss: 6.679080\n",
            "Train Epoch: 111 [2160/2812 (77%)]\tLoss: 22.315756\n",
            "Train Epoch: 111 [2280/2812 (81%)]\tLoss: 10.940008\n",
            "Train Epoch: 111 [2400/2812 (85%)]\tLoss: 10.644788\n",
            "Train Epoch: 111 [2520/2812 (89%)]\tLoss: 21.413662\n",
            "Train Epoch: 111 [2640/2812 (94%)]\tLoss: 8.128979\n",
            "Train Epoch: 111 [2760/2812 (98%)]\tLoss: 14.076483\n",
            "Training Loss: 10.9481 Acc: 50.5690\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5792, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 112/200\n",
            "----------\n",
            "Train Epoch: 112 [0/2812 (0%)]\tLoss: 4.788285\n",
            "Train Epoch: 112 [120/2812 (4%)]\tLoss: 13.165355\n",
            "Train Epoch: 112 [240/2812 (9%)]\tLoss: 7.454888\n",
            "Train Epoch: 112 [360/2812 (13%)]\tLoss: 19.720287\n",
            "Train Epoch: 112 [480/2812 (17%)]\tLoss: 22.641401\n",
            "Train Epoch: 112 [600/2812 (21%)]\tLoss: 5.898731\n",
            "Train Epoch: 112 [720/2812 (26%)]\tLoss: 20.211081\n",
            "Train Epoch: 112 [840/2812 (30%)]\tLoss: 12.209222\n",
            "Train Epoch: 112 [960/2812 (34%)]\tLoss: 11.973644\n",
            "Train Epoch: 112 [1080/2812 (38%)]\tLoss: 7.598010\n",
            "Train Epoch: 112 [1200/2812 (43%)]\tLoss: 10.686769\n",
            "Train Epoch: 112 [1320/2812 (47%)]\tLoss: 16.693256\n",
            "Train Epoch: 112 [1440/2812 (51%)]\tLoss: 9.618555\n",
            "Train Epoch: 112 [1560/2812 (55%)]\tLoss: 4.026731\n",
            "Train Epoch: 112 [1680/2812 (60%)]\tLoss: 2.832114\n",
            "Train Epoch: 112 [1800/2812 (64%)]\tLoss: 9.602431\n",
            "Train Epoch: 112 [1920/2812 (68%)]\tLoss: 8.669999\n",
            "Train Epoch: 112 [2040/2812 (72%)]\tLoss: 22.945108\n",
            "Train Epoch: 112 [2160/2812 (77%)]\tLoss: 10.064421\n",
            "Train Epoch: 112 [2280/2812 (81%)]\tLoss: 5.636214\n",
            "Train Epoch: 112 [2400/2812 (85%)]\tLoss: 11.116819\n",
            "Train Epoch: 112 [2520/2812 (89%)]\tLoss: 18.060339\n",
            "Train Epoch: 112 [2640/2812 (94%)]\tLoss: 3.481810\n",
            "Train Epoch: 112 [2760/2812 (98%)]\tLoss: 20.496792\n",
            "Training Loss: 11.4157 Acc: 49.8222\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5165, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 113/200\n",
            "----------\n",
            "Train Epoch: 113 [0/2812 (0%)]\tLoss: 18.201117\n",
            "Train Epoch: 113 [120/2812 (4%)]\tLoss: 13.084955\n",
            "Train Epoch: 113 [240/2812 (9%)]\tLoss: 11.779147\n",
            "Train Epoch: 113 [360/2812 (13%)]\tLoss: 11.786484\n",
            "Train Epoch: 113 [480/2812 (17%)]\tLoss: 4.165850\n",
            "Train Epoch: 113 [600/2812 (21%)]\tLoss: 10.045417\n",
            "Train Epoch: 113 [720/2812 (26%)]\tLoss: 13.250407\n",
            "Train Epoch: 113 [840/2812 (30%)]\tLoss: 8.126322\n",
            "Train Epoch: 113 [960/2812 (34%)]\tLoss: 14.131892\n",
            "Train Epoch: 113 [1080/2812 (38%)]\tLoss: 6.530579\n",
            "Train Epoch: 113 [1200/2812 (43%)]\tLoss: 19.009670\n",
            "Train Epoch: 113 [1320/2812 (47%)]\tLoss: 10.888404\n",
            "Train Epoch: 113 [1440/2812 (51%)]\tLoss: 5.552658\n",
            "Train Epoch: 113 [1560/2812 (55%)]\tLoss: 10.860967\n",
            "Train Epoch: 113 [1680/2812 (60%)]\tLoss: 46.217373\n",
            "Train Epoch: 113 [1800/2812 (64%)]\tLoss: 8.086805\n",
            "Train Epoch: 113 [1920/2812 (68%)]\tLoss: 8.732054\n",
            "Train Epoch: 113 [2040/2812 (72%)]\tLoss: 15.429538\n",
            "Train Epoch: 113 [2160/2812 (77%)]\tLoss: 10.609467\n",
            "Train Epoch: 113 [2280/2812 (81%)]\tLoss: 15.763690\n",
            "Train Epoch: 113 [2400/2812 (85%)]\tLoss: 24.053947\n",
            "Train Epoch: 113 [2520/2812 (89%)]\tLoss: 4.658163\n",
            "Train Epoch: 113 [2640/2812 (94%)]\tLoss: 19.319342\n",
            "Train Epoch: 113 [2760/2812 (98%)]\tLoss: 13.354425\n",
            "Training Loss: 11.5291 Acc: 48.7198\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6097, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 114/200\n",
            "----------\n",
            "Train Epoch: 114 [0/2812 (0%)]\tLoss: 6.681976\n",
            "Train Epoch: 114 [120/2812 (4%)]\tLoss: 9.297510\n",
            "Train Epoch: 114 [240/2812 (9%)]\tLoss: 11.603760\n",
            "Train Epoch: 114 [360/2812 (13%)]\tLoss: 12.544371\n",
            "Train Epoch: 114 [480/2812 (17%)]\tLoss: 18.412601\n",
            "Train Epoch: 114 [600/2812 (21%)]\tLoss: 9.973289\n",
            "Train Epoch: 114 [720/2812 (26%)]\tLoss: 8.114362\n",
            "Train Epoch: 114 [840/2812 (30%)]\tLoss: 17.385513\n",
            "Train Epoch: 114 [960/2812 (34%)]\tLoss: 5.648170\n",
            "Train Epoch: 114 [1080/2812 (38%)]\tLoss: 7.841605\n",
            "Train Epoch: 114 [1200/2812 (43%)]\tLoss: 5.755834\n",
            "Train Epoch: 114 [1320/2812 (47%)]\tLoss: 11.646249\n",
            "Train Epoch: 114 [1440/2812 (51%)]\tLoss: 14.590335\n",
            "Train Epoch: 114 [1560/2812 (55%)]\tLoss: 7.242027\n",
            "Train Epoch: 114 [1680/2812 (60%)]\tLoss: 11.362635\n",
            "Train Epoch: 114 [1800/2812 (64%)]\tLoss: 13.689413\n",
            "Train Epoch: 114 [1920/2812 (68%)]\tLoss: 19.311703\n",
            "Train Epoch: 114 [2040/2812 (72%)]\tLoss: 8.867143\n",
            "Train Epoch: 114 [2160/2812 (77%)]\tLoss: 11.567978\n",
            "Train Epoch: 114 [2280/2812 (81%)]\tLoss: 7.322573\n",
            "Train Epoch: 114 [2400/2812 (85%)]\tLoss: 14.918829\n",
            "Train Epoch: 114 [2520/2812 (89%)]\tLoss: 18.046495\n",
            "Train Epoch: 114 [2640/2812 (94%)]\tLoss: 15.083471\n",
            "Train Epoch: 114 [2760/2812 (98%)]\tLoss: 10.010775\n",
            "Training Loss: 11.1144 Acc: 49.1465\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5754, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 115/200\n",
            "----------\n",
            "Train Epoch: 115 [0/2812 (0%)]\tLoss: 4.873416\n",
            "Train Epoch: 115 [120/2812 (4%)]\tLoss: 16.530348\n",
            "Train Epoch: 115 [240/2812 (9%)]\tLoss: 6.788133\n",
            "Train Epoch: 115 [360/2812 (13%)]\tLoss: 14.482488\n",
            "Train Epoch: 115 [480/2812 (17%)]\tLoss: 12.977490\n",
            "Train Epoch: 115 [600/2812 (21%)]\tLoss: 11.896088\n",
            "Train Epoch: 115 [720/2812 (26%)]\tLoss: 7.668550\n",
            "Train Epoch: 115 [840/2812 (30%)]\tLoss: 15.491064\n",
            "Train Epoch: 115 [960/2812 (34%)]\tLoss: 19.479359\n",
            "Train Epoch: 115 [1080/2812 (38%)]\tLoss: 10.160467\n",
            "Train Epoch: 115 [1200/2812 (43%)]\tLoss: 10.696611\n",
            "Train Epoch: 115 [1320/2812 (47%)]\tLoss: 9.394012\n",
            "Train Epoch: 115 [1440/2812 (51%)]\tLoss: 13.096312\n",
            "Train Epoch: 115 [1560/2812 (55%)]\tLoss: 7.387555\n",
            "Train Epoch: 115 [1680/2812 (60%)]\tLoss: 10.354031\n",
            "Train Epoch: 115 [1800/2812 (64%)]\tLoss: 7.859456\n",
            "Train Epoch: 115 [1920/2812 (68%)]\tLoss: 12.572234\n",
            "Train Epoch: 115 [2040/2812 (72%)]\tLoss: 11.687062\n",
            "Train Epoch: 115 [2160/2812 (77%)]\tLoss: 10.781713\n",
            "Train Epoch: 115 [2280/2812 (81%)]\tLoss: 16.906681\n",
            "Train Epoch: 115 [2400/2812 (85%)]\tLoss: 13.725584\n",
            "Train Epoch: 115 [2520/2812 (89%)]\tLoss: 24.265219\n",
            "Train Epoch: 115 [2640/2812 (94%)]\tLoss: 3.892385\n",
            "Train Epoch: 115 [2760/2812 (98%)]\tLoss: 14.979053\n",
            "Training Loss: 11.1452 Acc: 49.8578\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5527, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 116/200\n",
            "----------\n",
            "Train Epoch: 116 [0/2812 (0%)]\tLoss: 7.643761\n",
            "Train Epoch: 116 [120/2812 (4%)]\tLoss: 16.239771\n",
            "Train Epoch: 116 [240/2812 (9%)]\tLoss: 9.494258\n",
            "Train Epoch: 116 [360/2812 (13%)]\tLoss: 7.425128\n",
            "Train Epoch: 116 [480/2812 (17%)]\tLoss: 12.394777\n",
            "Train Epoch: 116 [600/2812 (21%)]\tLoss: 4.210730\n",
            "Train Epoch: 116 [720/2812 (26%)]\tLoss: 24.373985\n",
            "Train Epoch: 116 [840/2812 (30%)]\tLoss: 14.127370\n",
            "Train Epoch: 116 [960/2812 (34%)]\tLoss: 16.746155\n",
            "Train Epoch: 116 [1080/2812 (38%)]\tLoss: 2.424941\n",
            "Train Epoch: 116 [1200/2812 (43%)]\tLoss: 17.904867\n",
            "Train Epoch: 116 [1320/2812 (47%)]\tLoss: 12.160662\n",
            "Train Epoch: 116 [1440/2812 (51%)]\tLoss: 11.880037\n",
            "Train Epoch: 116 [1560/2812 (55%)]\tLoss: 10.774527\n",
            "Train Epoch: 116 [1680/2812 (60%)]\tLoss: 11.498178\n",
            "Train Epoch: 116 [1800/2812 (64%)]\tLoss: 0.800787\n",
            "Train Epoch: 116 [1920/2812 (68%)]\tLoss: 25.758350\n",
            "Train Epoch: 116 [2040/2812 (72%)]\tLoss: 17.460981\n",
            "Train Epoch: 116 [2160/2812 (77%)]\tLoss: 7.537397\n",
            "Train Epoch: 116 [2280/2812 (81%)]\tLoss: 9.533571\n",
            "Train Epoch: 116 [2400/2812 (85%)]\tLoss: 8.791349\n",
            "Train Epoch: 116 [2520/2812 (89%)]\tLoss: 7.378993\n",
            "Train Epoch: 116 [2640/2812 (94%)]\tLoss: 15.072606\n",
            "Train Epoch: 116 [2760/2812 (98%)]\tLoss: 21.830561\n",
            "Training Loss: 11.2530 Acc: 48.9331\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5782, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 117/200\n",
            "----------\n",
            "Train Epoch: 117 [0/2812 (0%)]\tLoss: 8.800035\n",
            "Train Epoch: 117 [120/2812 (4%)]\tLoss: 10.901747\n",
            "Train Epoch: 117 [240/2812 (9%)]\tLoss: 7.134080\n",
            "Train Epoch: 117 [360/2812 (13%)]\tLoss: 13.131841\n",
            "Train Epoch: 117 [480/2812 (17%)]\tLoss: 5.183929\n",
            "Train Epoch: 117 [600/2812 (21%)]\tLoss: 9.887587\n",
            "Train Epoch: 117 [720/2812 (26%)]\tLoss: 9.641264\n",
            "Train Epoch: 117 [840/2812 (30%)]\tLoss: 11.836950\n",
            "Train Epoch: 117 [960/2812 (34%)]\tLoss: 7.316468\n",
            "Train Epoch: 117 [1080/2812 (38%)]\tLoss: 5.219817\n",
            "Train Epoch: 117 [1200/2812 (43%)]\tLoss: 4.321773\n",
            "Train Epoch: 117 [1320/2812 (47%)]\tLoss: 16.024891\n",
            "Train Epoch: 117 [1440/2812 (51%)]\tLoss: 10.052039\n",
            "Train Epoch: 117 [1560/2812 (55%)]\tLoss: 7.834887\n",
            "Train Epoch: 117 [1680/2812 (60%)]\tLoss: 24.671967\n",
            "Train Epoch: 117 [1800/2812 (64%)]\tLoss: 14.409968\n",
            "Train Epoch: 117 [1920/2812 (68%)]\tLoss: 5.912653\n",
            "Train Epoch: 117 [2040/2812 (72%)]\tLoss: 22.747744\n",
            "Train Epoch: 117 [2160/2812 (77%)]\tLoss: 3.038537\n",
            "Train Epoch: 117 [2280/2812 (81%)]\tLoss: 9.128924\n",
            "Train Epoch: 117 [2400/2812 (85%)]\tLoss: 11.287155\n",
            "Train Epoch: 117 [2520/2812 (89%)]\tLoss: 11.483660\n",
            "Train Epoch: 117 [2640/2812 (94%)]\tLoss: 8.653471\n",
            "Train Epoch: 117 [2760/2812 (98%)]\tLoss: 8.438416\n",
            "Training Loss: 10.9810 Acc: 50.8890\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5972, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 118/200\n",
            "----------\n",
            "Train Epoch: 118 [0/2812 (0%)]\tLoss: 7.858174\n",
            "Train Epoch: 118 [120/2812 (4%)]\tLoss: 5.690047\n",
            "Train Epoch: 118 [240/2812 (9%)]\tLoss: 26.179010\n",
            "Train Epoch: 118 [360/2812 (13%)]\tLoss: 7.299323\n",
            "Train Epoch: 118 [480/2812 (17%)]\tLoss: 17.882092\n",
            "Train Epoch: 118 [600/2812 (21%)]\tLoss: 6.985449\n",
            "Train Epoch: 118 [720/2812 (26%)]\tLoss: 12.274881\n",
            "Train Epoch: 118 [840/2812 (30%)]\tLoss: 12.225044\n",
            "Train Epoch: 118 [960/2812 (34%)]\tLoss: 18.936409\n",
            "Train Epoch: 118 [1080/2812 (38%)]\tLoss: 6.972609\n",
            "Train Epoch: 118 [1200/2812 (43%)]\tLoss: 15.889856\n",
            "Train Epoch: 118 [1320/2812 (47%)]\tLoss: 9.568329\n",
            "Train Epoch: 118 [1440/2812 (51%)]\tLoss: 14.269145\n",
            "Train Epoch: 118 [1560/2812 (55%)]\tLoss: 6.798542\n",
            "Train Epoch: 118 [1680/2812 (60%)]\tLoss: 17.517445\n",
            "Train Epoch: 118 [1800/2812 (64%)]\tLoss: 4.935163\n",
            "Train Epoch: 118 [1920/2812 (68%)]\tLoss: 8.363976\n",
            "Train Epoch: 118 [2040/2812 (72%)]\tLoss: 6.460725\n",
            "Train Epoch: 118 [2160/2812 (77%)]\tLoss: 17.092934\n",
            "Train Epoch: 118 [2280/2812 (81%)]\tLoss: 9.525513\n",
            "Train Epoch: 118 [2400/2812 (85%)]\tLoss: 9.308902\n",
            "Train Epoch: 118 [2520/2812 (89%)]\tLoss: 11.154790\n",
            "Train Epoch: 118 [2640/2812 (94%)]\tLoss: 8.473149\n",
            "Train Epoch: 118 [2760/2812 (98%)]\tLoss: 16.838066\n",
            "Training Loss: 11.2776 Acc: 49.4310\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5991, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 119/200\n",
            "----------\n",
            "Train Epoch: 119 [0/2812 (0%)]\tLoss: 8.858370\n",
            "Train Epoch: 119 [120/2812 (4%)]\tLoss: 11.137227\n",
            "Train Epoch: 119 [240/2812 (9%)]\tLoss: 6.422948\n",
            "Train Epoch: 119 [360/2812 (13%)]\tLoss: 11.456810\n",
            "Train Epoch: 119 [480/2812 (17%)]\tLoss: 12.174387\n",
            "Train Epoch: 119 [600/2812 (21%)]\tLoss: 11.270663\n",
            "Train Epoch: 119 [720/2812 (26%)]\tLoss: 17.001802\n",
            "Train Epoch: 119 [840/2812 (30%)]\tLoss: 6.978602\n",
            "Train Epoch: 119 [960/2812 (34%)]\tLoss: 14.284628\n",
            "Train Epoch: 119 [1080/2812 (38%)]\tLoss: 13.941493\n",
            "Train Epoch: 119 [1200/2812 (43%)]\tLoss: 20.378967\n",
            "Train Epoch: 119 [1320/2812 (47%)]\tLoss: 11.380203\n",
            "Train Epoch: 119 [1440/2812 (51%)]\tLoss: 2.817665\n",
            "Train Epoch: 119 [1560/2812 (55%)]\tLoss: 5.176487\n",
            "Train Epoch: 119 [1680/2812 (60%)]\tLoss: 2.130478\n",
            "Train Epoch: 119 [1800/2812 (64%)]\tLoss: 6.058882\n",
            "Train Epoch: 119 [1920/2812 (68%)]\tLoss: 8.796670\n",
            "Train Epoch: 119 [2040/2812 (72%)]\tLoss: 3.458031\n",
            "Train Epoch: 119 [2160/2812 (77%)]\tLoss: 6.654706\n",
            "Train Epoch: 119 [2280/2812 (81%)]\tLoss: 3.616493\n",
            "Train Epoch: 119 [2400/2812 (85%)]\tLoss: 11.474959\n",
            "Train Epoch: 119 [2520/2812 (89%)]\tLoss: 11.148516\n",
            "Train Epoch: 119 [2640/2812 (94%)]\tLoss: 11.744812\n",
            "Train Epoch: 119 [2760/2812 (98%)]\tLoss: 18.935947\n",
            "Training Loss: 10.9703 Acc: 50.5690\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5424, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 120/200\n",
            "----------\n",
            "Train Epoch: 120 [0/2812 (0%)]\tLoss: 10.623377\n",
            "Train Epoch: 120 [120/2812 (4%)]\tLoss: 10.250811\n",
            "Train Epoch: 120 [240/2812 (9%)]\tLoss: 9.321188\n",
            "Train Epoch: 120 [360/2812 (13%)]\tLoss: 8.560569\n",
            "Train Epoch: 120 [480/2812 (17%)]\tLoss: 9.852483\n",
            "Train Epoch: 120 [600/2812 (21%)]\tLoss: 8.674666\n",
            "Train Epoch: 120 [720/2812 (26%)]\tLoss: 14.875175\n",
            "Train Epoch: 120 [840/2812 (30%)]\tLoss: 3.066760\n",
            "Train Epoch: 120 [960/2812 (34%)]\tLoss: 10.642501\n",
            "Train Epoch: 120 [1080/2812 (38%)]\tLoss: 14.082952\n",
            "Train Epoch: 120 [1200/2812 (43%)]\tLoss: 12.660130\n",
            "Train Epoch: 120 [1320/2812 (47%)]\tLoss: 22.881821\n",
            "Train Epoch: 120 [1440/2812 (51%)]\tLoss: 6.697161\n",
            "Train Epoch: 120 [1560/2812 (55%)]\tLoss: 9.521078\n",
            "Train Epoch: 120 [1680/2812 (60%)]\tLoss: 14.811984\n",
            "Train Epoch: 120 [1800/2812 (64%)]\tLoss: 10.093252\n",
            "Train Epoch: 120 [1920/2812 (68%)]\tLoss: 2.030348\n",
            "Train Epoch: 120 [2040/2812 (72%)]\tLoss: 15.363861\n",
            "Train Epoch: 120 [2160/2812 (77%)]\tLoss: 20.653912\n",
            "Train Epoch: 120 [2280/2812 (81%)]\tLoss: 6.538797\n",
            "Train Epoch: 120 [2400/2812 (85%)]\tLoss: 19.725677\n",
            "Train Epoch: 120 [2520/2812 (89%)]\tLoss: 7.642266\n",
            "Train Epoch: 120 [2640/2812 (94%)]\tLoss: 4.844688\n",
            "Train Epoch: 120 [2760/2812 (98%)]\tLoss: 11.258791\n",
            "Training Loss: 11.3998 Acc: 49.5021\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5745, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 121/200\n",
            "----------\n",
            "Train Epoch: 121 [0/2812 (0%)]\tLoss: 10.632830\n",
            "Train Epoch: 121 [120/2812 (4%)]\tLoss: 9.219885\n",
            "Train Epoch: 121 [240/2812 (9%)]\tLoss: 7.859807\n",
            "Train Epoch: 121 [360/2812 (13%)]\tLoss: 7.359998\n",
            "Train Epoch: 121 [480/2812 (17%)]\tLoss: 15.076553\n",
            "Train Epoch: 121 [600/2812 (21%)]\tLoss: 17.373688\n",
            "Train Epoch: 121 [720/2812 (26%)]\tLoss: 12.094788\n",
            "Train Epoch: 121 [840/2812 (30%)]\tLoss: 12.529958\n",
            "Train Epoch: 121 [960/2812 (34%)]\tLoss: 9.072812\n",
            "Train Epoch: 121 [1080/2812 (38%)]\tLoss: 5.378551\n",
            "Train Epoch: 121 [1200/2812 (43%)]\tLoss: 27.516560\n",
            "Train Epoch: 121 [1320/2812 (47%)]\tLoss: 6.151379\n",
            "Train Epoch: 121 [1440/2812 (51%)]\tLoss: 12.360456\n",
            "Train Epoch: 121 [1560/2812 (55%)]\tLoss: 1.813754\n",
            "Train Epoch: 121 [1680/2812 (60%)]\tLoss: 6.417872\n",
            "Train Epoch: 121 [1800/2812 (64%)]\tLoss: 13.057446\n",
            "Train Epoch: 121 [1920/2812 (68%)]\tLoss: 7.810133\n",
            "Train Epoch: 121 [2040/2812 (72%)]\tLoss: 15.267630\n",
            "Train Epoch: 121 [2160/2812 (77%)]\tLoss: 3.125729\n",
            "Train Epoch: 121 [2280/2812 (81%)]\tLoss: 12.483800\n",
            "Train Epoch: 121 [2400/2812 (85%)]\tLoss: 15.772494\n",
            "Train Epoch: 121 [2520/2812 (89%)]\tLoss: 7.538840\n",
            "Train Epoch: 121 [2640/2812 (94%)]\tLoss: 9.531116\n",
            "Train Epoch: 121 [2760/2812 (98%)]\tLoss: 10.098909\n",
            "Training Loss: 11.3047 Acc: 50.1778\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5678, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 122/200\n",
            "----------\n",
            "Train Epoch: 122 [0/2812 (0%)]\tLoss: 12.364336\n",
            "Train Epoch: 122 [120/2812 (4%)]\tLoss: 12.925852\n",
            "Train Epoch: 122 [240/2812 (9%)]\tLoss: 12.780993\n",
            "Train Epoch: 122 [360/2812 (13%)]\tLoss: 13.344406\n",
            "Train Epoch: 122 [480/2812 (17%)]\tLoss: 11.257357\n",
            "Train Epoch: 122 [600/2812 (21%)]\tLoss: 7.235167\n",
            "Train Epoch: 122 [720/2812 (26%)]\tLoss: 10.215975\n",
            "Train Epoch: 122 [840/2812 (30%)]\tLoss: 6.003580\n",
            "Train Epoch: 122 [960/2812 (34%)]\tLoss: 11.021499\n",
            "Train Epoch: 122 [1080/2812 (38%)]\tLoss: 5.691469\n",
            "Train Epoch: 122 [1200/2812 (43%)]\tLoss: 18.580042\n",
            "Train Epoch: 122 [1320/2812 (47%)]\tLoss: 2.565968\n",
            "Train Epoch: 122 [1440/2812 (51%)]\tLoss: 20.736492\n",
            "Train Epoch: 122 [1560/2812 (55%)]\tLoss: 2.336418\n",
            "Train Epoch: 122 [1680/2812 (60%)]\tLoss: 5.488961\n",
            "Train Epoch: 122 [1800/2812 (64%)]\tLoss: 8.283526\n",
            "Train Epoch: 122 [1920/2812 (68%)]\tLoss: 14.281992\n",
            "Train Epoch: 122 [2040/2812 (72%)]\tLoss: 2.561600\n",
            "Train Epoch: 122 [2160/2812 (77%)]\tLoss: 7.421934\n",
            "Train Epoch: 122 [2280/2812 (81%)]\tLoss: 5.691067\n",
            "Train Epoch: 122 [2400/2812 (85%)]\tLoss: 15.474752\n",
            "Train Epoch: 122 [2520/2812 (89%)]\tLoss: 3.387604\n",
            "Train Epoch: 122 [2640/2812 (94%)]\tLoss: 13.168242\n",
            "Train Epoch: 122 [2760/2812 (98%)]\tLoss: 16.912701\n",
            "Training Loss: 10.9505 Acc: 49.2176\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6468, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 123/200\n",
            "----------\n",
            "Train Epoch: 123 [0/2812 (0%)]\tLoss: 16.171179\n",
            "Train Epoch: 123 [120/2812 (4%)]\tLoss: 5.781764\n",
            "Train Epoch: 123 [240/2812 (9%)]\tLoss: 17.119757\n",
            "Train Epoch: 123 [360/2812 (13%)]\tLoss: 4.581620\n",
            "Train Epoch: 123 [480/2812 (17%)]\tLoss: 5.839543\n",
            "Train Epoch: 123 [600/2812 (21%)]\tLoss: 11.693341\n",
            "Train Epoch: 123 [720/2812 (26%)]\tLoss: 18.304308\n",
            "Train Epoch: 123 [840/2812 (30%)]\tLoss: 18.341007\n",
            "Train Epoch: 123 [960/2812 (34%)]\tLoss: 12.079527\n",
            "Train Epoch: 123 [1080/2812 (38%)]\tLoss: 14.450600\n",
            "Train Epoch: 123 [1200/2812 (43%)]\tLoss: 7.717941\n",
            "Train Epoch: 123 [1320/2812 (47%)]\tLoss: 10.598158\n",
            "Train Epoch: 123 [1440/2812 (51%)]\tLoss: 22.061630\n",
            "Train Epoch: 123 [1560/2812 (55%)]\tLoss: 13.897568\n",
            "Train Epoch: 123 [1680/2812 (60%)]\tLoss: 7.047403\n",
            "Train Epoch: 123 [1800/2812 (64%)]\tLoss: 6.489186\n",
            "Train Epoch: 123 [1920/2812 (68%)]\tLoss: 15.739653\n",
            "Train Epoch: 123 [2040/2812 (72%)]\tLoss: 12.139328\n",
            "Train Epoch: 123 [2160/2812 (77%)]\tLoss: 4.808488\n",
            "Train Epoch: 123 [2280/2812 (81%)]\tLoss: 5.707820\n",
            "Train Epoch: 123 [2400/2812 (85%)]\tLoss: 15.531973\n",
            "Train Epoch: 123 [2520/2812 (89%)]\tLoss: 6.816397\n",
            "Train Epoch: 123 [2640/2812 (94%)]\tLoss: 5.875214\n",
            "Train Epoch: 123 [2760/2812 (98%)]\tLoss: 12.032074\n",
            "Training Loss: 10.9905 Acc: 50.7824\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5925, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 124/200\n",
            "----------\n",
            "Train Epoch: 124 [0/2812 (0%)]\tLoss: 3.763917\n",
            "Train Epoch: 124 [120/2812 (4%)]\tLoss: 4.567079\n",
            "Train Epoch: 124 [240/2812 (9%)]\tLoss: 5.524638\n",
            "Train Epoch: 124 [360/2812 (13%)]\tLoss: 4.757846\n",
            "Train Epoch: 124 [480/2812 (17%)]\tLoss: 17.000492\n",
            "Train Epoch: 124 [600/2812 (21%)]\tLoss: 4.181554\n",
            "Train Epoch: 124 [720/2812 (26%)]\tLoss: 11.861476\n",
            "Train Epoch: 124 [840/2812 (30%)]\tLoss: 15.696295\n",
            "Train Epoch: 124 [960/2812 (34%)]\tLoss: 10.280074\n",
            "Train Epoch: 124 [1080/2812 (38%)]\tLoss: 16.697996\n",
            "Train Epoch: 124 [1200/2812 (43%)]\tLoss: 10.101812\n",
            "Train Epoch: 124 [1320/2812 (47%)]\tLoss: 24.202404\n",
            "Train Epoch: 124 [1440/2812 (51%)]\tLoss: 6.835248\n",
            "Train Epoch: 124 [1560/2812 (55%)]\tLoss: 12.375414\n",
            "Train Epoch: 124 [1680/2812 (60%)]\tLoss: 8.054815\n",
            "Train Epoch: 124 [1800/2812 (64%)]\tLoss: 15.110207\n",
            "Train Epoch: 124 [1920/2812 (68%)]\tLoss: 8.843336\n",
            "Train Epoch: 124 [2040/2812 (72%)]\tLoss: 6.462756\n",
            "Train Epoch: 124 [2160/2812 (77%)]\tLoss: 22.411367\n",
            "Train Epoch: 124 [2280/2812 (81%)]\tLoss: 9.310701\n",
            "Train Epoch: 124 [2400/2812 (85%)]\tLoss: 5.524402\n",
            "Train Epoch: 124 [2520/2812 (89%)]\tLoss: 8.873268\n",
            "Train Epoch: 124 [2640/2812 (94%)]\tLoss: 7.957282\n",
            "Train Epoch: 124 [2760/2812 (98%)]\tLoss: 5.877881\n",
            "Training Loss: 11.1663 Acc: 49.6088\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5426, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 125/200\n",
            "----------\n",
            "Train Epoch: 125 [0/2812 (0%)]\tLoss: 7.358125\n",
            "Train Epoch: 125 [120/2812 (4%)]\tLoss: 4.316873\n",
            "Train Epoch: 125 [240/2812 (9%)]\tLoss: 7.525596\n",
            "Train Epoch: 125 [360/2812 (13%)]\tLoss: 19.293148\n",
            "Train Epoch: 125 [480/2812 (17%)]\tLoss: 9.898404\n",
            "Train Epoch: 125 [600/2812 (21%)]\tLoss: 10.408707\n",
            "Train Epoch: 125 [720/2812 (26%)]\tLoss: 6.333868\n",
            "Train Epoch: 125 [840/2812 (30%)]\tLoss: 10.974820\n",
            "Train Epoch: 125 [960/2812 (34%)]\tLoss: 7.173886\n",
            "Train Epoch: 125 [1080/2812 (38%)]\tLoss: 10.781398\n",
            "Train Epoch: 125 [1200/2812 (43%)]\tLoss: 11.792929\n",
            "Train Epoch: 125 [1320/2812 (47%)]\tLoss: 16.858723\n",
            "Train Epoch: 125 [1440/2812 (51%)]\tLoss: 10.021047\n",
            "Train Epoch: 125 [1560/2812 (55%)]\tLoss: 2.024429\n",
            "Train Epoch: 125 [1680/2812 (60%)]\tLoss: 3.019864\n",
            "Train Epoch: 125 [1800/2812 (64%)]\tLoss: 6.900500\n",
            "Train Epoch: 125 [1920/2812 (68%)]\tLoss: 8.590281\n",
            "Train Epoch: 125 [2040/2812 (72%)]\tLoss: 8.134736\n",
            "Train Epoch: 125 [2160/2812 (77%)]\tLoss: 13.664240\n",
            "Train Epoch: 125 [2280/2812 (81%)]\tLoss: 12.051069\n",
            "Train Epoch: 125 [2400/2812 (85%)]\tLoss: 12.747871\n",
            "Train Epoch: 125 [2520/2812 (89%)]\tLoss: 5.870820\n",
            "Train Epoch: 125 [2640/2812 (94%)]\tLoss: 12.392948\n",
            "Train Epoch: 125 [2760/2812 (98%)]\tLoss: 10.563597\n",
            "Training Loss: 11.2675 Acc: 49.2176\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5692, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 126/200\n",
            "----------\n",
            "Train Epoch: 126 [0/2812 (0%)]\tLoss: 13.409864\n",
            "Train Epoch: 126 [120/2812 (4%)]\tLoss: 5.280231\n",
            "Train Epoch: 126 [240/2812 (9%)]\tLoss: 5.247920\n",
            "Train Epoch: 126 [360/2812 (13%)]\tLoss: 10.477801\n",
            "Train Epoch: 126 [480/2812 (17%)]\tLoss: 3.444570\n",
            "Train Epoch: 126 [600/2812 (21%)]\tLoss: 9.131540\n",
            "Train Epoch: 126 [720/2812 (26%)]\tLoss: 16.785427\n",
            "Train Epoch: 126 [840/2812 (30%)]\tLoss: 18.248959\n",
            "Train Epoch: 126 [960/2812 (34%)]\tLoss: 9.514666\n",
            "Train Epoch: 126 [1080/2812 (38%)]\tLoss: 5.101439\n",
            "Train Epoch: 126 [1200/2812 (43%)]\tLoss: 16.273264\n",
            "Train Epoch: 126 [1320/2812 (47%)]\tLoss: 8.573364\n",
            "Train Epoch: 126 [1440/2812 (51%)]\tLoss: 19.642246\n",
            "Train Epoch: 126 [1560/2812 (55%)]\tLoss: 5.803292\n",
            "Train Epoch: 126 [1680/2812 (60%)]\tLoss: 11.119202\n",
            "Train Epoch: 126 [1800/2812 (64%)]\tLoss: 10.567945\n",
            "Train Epoch: 126 [1920/2812 (68%)]\tLoss: 11.305276\n",
            "Train Epoch: 126 [2040/2812 (72%)]\tLoss: 23.338945\n",
            "Train Epoch: 126 [2160/2812 (77%)]\tLoss: 15.488040\n",
            "Train Epoch: 126 [2280/2812 (81%)]\tLoss: 7.947415\n",
            "Train Epoch: 126 [2400/2812 (85%)]\tLoss: 13.011225\n",
            "Train Epoch: 126 [2520/2812 (89%)]\tLoss: 12.772676\n",
            "Train Epoch: 126 [2640/2812 (94%)]\tLoss: 2.719883\n",
            "Train Epoch: 126 [2760/2812 (98%)]\tLoss: 9.335605\n",
            "Training Loss: 10.8205 Acc: 51.2447\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5535, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 127/200\n",
            "----------\n",
            "Train Epoch: 127 [0/2812 (0%)]\tLoss: 5.009002\n",
            "Train Epoch: 127 [120/2812 (4%)]\tLoss: 21.598465\n",
            "Train Epoch: 127 [240/2812 (9%)]\tLoss: 12.925077\n",
            "Train Epoch: 127 [360/2812 (13%)]\tLoss: 10.005682\n",
            "Train Epoch: 127 [480/2812 (17%)]\tLoss: 20.566257\n",
            "Train Epoch: 127 [600/2812 (21%)]\tLoss: 6.471826\n",
            "Train Epoch: 127 [720/2812 (26%)]\tLoss: 22.087038\n",
            "Train Epoch: 127 [840/2812 (30%)]\tLoss: 11.850557\n",
            "Train Epoch: 127 [960/2812 (34%)]\tLoss: 20.224422\n",
            "Train Epoch: 127 [1080/2812 (38%)]\tLoss: 4.767164\n",
            "Train Epoch: 127 [1200/2812 (43%)]\tLoss: 16.440939\n",
            "Train Epoch: 127 [1320/2812 (47%)]\tLoss: 13.338697\n",
            "Train Epoch: 127 [1440/2812 (51%)]\tLoss: 14.125296\n",
            "Train Epoch: 127 [1560/2812 (55%)]\tLoss: 18.552073\n",
            "Train Epoch: 127 [1680/2812 (60%)]\tLoss: 9.758663\n",
            "Train Epoch: 127 [1800/2812 (64%)]\tLoss: 12.143614\n",
            "Train Epoch: 127 [1920/2812 (68%)]\tLoss: 12.888380\n",
            "Train Epoch: 127 [2040/2812 (72%)]\tLoss: 8.523996\n",
            "Train Epoch: 127 [2160/2812 (77%)]\tLoss: 8.145372\n",
            "Train Epoch: 127 [2280/2812 (81%)]\tLoss: 5.647960\n",
            "Train Epoch: 127 [2400/2812 (85%)]\tLoss: 12.927019\n",
            "Train Epoch: 127 [2520/2812 (89%)]\tLoss: 5.668500\n",
            "Train Epoch: 127 [2640/2812 (94%)]\tLoss: 8.037965\n",
            "Train Epoch: 127 [2760/2812 (98%)]\tLoss: 17.926323\n",
            "Training Loss: 11.5454 Acc: 49.9289\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5457, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 128/200\n",
            "----------\n",
            "Train Epoch: 128 [0/2812 (0%)]\tLoss: 5.146710\n",
            "Train Epoch: 128 [120/2812 (4%)]\tLoss: 4.844147\n",
            "Train Epoch: 128 [240/2812 (9%)]\tLoss: 15.512479\n",
            "Train Epoch: 128 [360/2812 (13%)]\tLoss: 10.661412\n",
            "Train Epoch: 128 [480/2812 (17%)]\tLoss: 5.830987\n",
            "Train Epoch: 128 [600/2812 (21%)]\tLoss: 1.955207\n",
            "Train Epoch: 128 [720/2812 (26%)]\tLoss: 7.574960\n",
            "Train Epoch: 128 [840/2812 (30%)]\tLoss: 9.310788\n",
            "Train Epoch: 128 [960/2812 (34%)]\tLoss: 6.891985\n",
            "Train Epoch: 128 [1080/2812 (38%)]\tLoss: 26.561462\n",
            "Train Epoch: 128 [1200/2812 (43%)]\tLoss: 14.945943\n",
            "Train Epoch: 128 [1320/2812 (47%)]\tLoss: 12.191016\n",
            "Train Epoch: 128 [1440/2812 (51%)]\tLoss: 4.514127\n",
            "Train Epoch: 128 [1560/2812 (55%)]\tLoss: 8.838179\n",
            "Train Epoch: 128 [1680/2812 (60%)]\tLoss: 5.992324\n",
            "Train Epoch: 128 [1800/2812 (64%)]\tLoss: 16.283447\n",
            "Train Epoch: 128 [1920/2812 (68%)]\tLoss: 9.203283\n",
            "Train Epoch: 128 [2040/2812 (72%)]\tLoss: 10.522178\n",
            "Train Epoch: 128 [2160/2812 (77%)]\tLoss: 10.045452\n",
            "Train Epoch: 128 [2280/2812 (81%)]\tLoss: 3.846629\n",
            "Train Epoch: 128 [2400/2812 (85%)]\tLoss: 12.284587\n",
            "Train Epoch: 128 [2520/2812 (89%)]\tLoss: 7.308782\n",
            "Train Epoch: 128 [2640/2812 (94%)]\tLoss: 18.820345\n",
            "Train Epoch: 128 [2760/2812 (98%)]\tLoss: 3.116544\n",
            "Training Loss: 11.1598 Acc: 49.7866\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5443, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 129/200\n",
            "----------\n",
            "Train Epoch: 129 [0/2812 (0%)]\tLoss: 13.776858\n",
            "Train Epoch: 129 [120/2812 (4%)]\tLoss: 15.610263\n",
            "Train Epoch: 129 [240/2812 (9%)]\tLoss: 7.346570\n",
            "Train Epoch: 129 [360/2812 (13%)]\tLoss: 10.184502\n",
            "Train Epoch: 129 [480/2812 (17%)]\tLoss: 10.535814\n",
            "Train Epoch: 129 [600/2812 (21%)]\tLoss: 17.143461\n",
            "Train Epoch: 129 [720/2812 (26%)]\tLoss: 16.199575\n",
            "Train Epoch: 129 [840/2812 (30%)]\tLoss: 4.656490\n",
            "Train Epoch: 129 [960/2812 (34%)]\tLoss: 6.510333\n",
            "Train Epoch: 129 [1080/2812 (38%)]\tLoss: 2.199459\n",
            "Train Epoch: 129 [1200/2812 (43%)]\tLoss: 13.772150\n",
            "Train Epoch: 129 [1320/2812 (47%)]\tLoss: 12.510160\n",
            "Train Epoch: 129 [1440/2812 (51%)]\tLoss: 22.849792\n",
            "Train Epoch: 129 [1560/2812 (55%)]\tLoss: 14.523842\n",
            "Train Epoch: 129 [1680/2812 (60%)]\tLoss: 23.403625\n",
            "Train Epoch: 129 [1800/2812 (64%)]\tLoss: 12.813471\n",
            "Train Epoch: 129 [1920/2812 (68%)]\tLoss: 6.488816\n",
            "Train Epoch: 129 [2040/2812 (72%)]\tLoss: 22.279613\n",
            "Train Epoch: 129 [2160/2812 (77%)]\tLoss: 13.558563\n",
            "Train Epoch: 129 [2280/2812 (81%)]\tLoss: 16.017033\n",
            "Train Epoch: 129 [2400/2812 (85%)]\tLoss: 13.541875\n",
            "Train Epoch: 129 [2520/2812 (89%)]\tLoss: 15.562884\n",
            "Train Epoch: 129 [2640/2812 (94%)]\tLoss: 11.491473\n",
            "Train Epoch: 129 [2760/2812 (98%)]\tLoss: 9.991041\n",
            "Training Loss: 11.4510 Acc: 49.9644\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6113, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 130/200\n",
            "----------\n",
            "Train Epoch: 130 [0/2812 (0%)]\tLoss: 12.541578\n",
            "Train Epoch: 130 [120/2812 (4%)]\tLoss: 14.335879\n",
            "Train Epoch: 130 [240/2812 (9%)]\tLoss: 2.437957\n",
            "Train Epoch: 130 [360/2812 (13%)]\tLoss: 10.000426\n",
            "Train Epoch: 130 [480/2812 (17%)]\tLoss: 15.388278\n",
            "Train Epoch: 130 [600/2812 (21%)]\tLoss: 10.160023\n",
            "Train Epoch: 130 [720/2812 (26%)]\tLoss: 9.784180\n",
            "Train Epoch: 130 [840/2812 (30%)]\tLoss: 14.742243\n",
            "Train Epoch: 130 [960/2812 (34%)]\tLoss: 16.319574\n",
            "Train Epoch: 130 [1080/2812 (38%)]\tLoss: 5.497424\n",
            "Train Epoch: 130 [1200/2812 (43%)]\tLoss: 9.264324\n",
            "Train Epoch: 130 [1320/2812 (47%)]\tLoss: 26.223166\n",
            "Train Epoch: 130 [1440/2812 (51%)]\tLoss: 5.591363\n",
            "Train Epoch: 130 [1560/2812 (55%)]\tLoss: 19.638449\n",
            "Train Epoch: 130 [1680/2812 (60%)]\tLoss: 8.841432\n",
            "Train Epoch: 130 [1800/2812 (64%)]\tLoss: 9.779047\n",
            "Train Epoch: 130 [1920/2812 (68%)]\tLoss: 5.427949\n",
            "Train Epoch: 130 [2040/2812 (72%)]\tLoss: 12.064742\n",
            "Train Epoch: 130 [2160/2812 (77%)]\tLoss: 6.166468\n",
            "Train Epoch: 130 [2280/2812 (81%)]\tLoss: 10.622877\n",
            "Train Epoch: 130 [2400/2812 (85%)]\tLoss: 7.378277\n",
            "Train Epoch: 130 [2520/2812 (89%)]\tLoss: 3.808115\n",
            "Train Epoch: 130 [2640/2812 (94%)]\tLoss: 5.679085\n",
            "Train Epoch: 130 [2760/2812 (98%)]\tLoss: 5.603559\n",
            "Training Loss: 11.1105 Acc: 51.2091\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5870, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 131/200\n",
            "----------\n",
            "Train Epoch: 131 [0/2812 (0%)]\tLoss: 13.230472\n",
            "Train Epoch: 131 [120/2812 (4%)]\tLoss: 13.521014\n",
            "Train Epoch: 131 [240/2812 (9%)]\tLoss: 15.037043\n",
            "Train Epoch: 131 [360/2812 (13%)]\tLoss: 6.801326\n",
            "Train Epoch: 131 [480/2812 (17%)]\tLoss: 13.608203\n",
            "Train Epoch: 131 [600/2812 (21%)]\tLoss: 9.832645\n",
            "Train Epoch: 131 [720/2812 (26%)]\tLoss: 13.776060\n",
            "Train Epoch: 131 [840/2812 (30%)]\tLoss: 14.603900\n",
            "Train Epoch: 131 [960/2812 (34%)]\tLoss: 7.241957\n",
            "Train Epoch: 131 [1080/2812 (38%)]\tLoss: 9.726506\n",
            "Train Epoch: 131 [1200/2812 (43%)]\tLoss: 6.254149\n",
            "Train Epoch: 131 [1320/2812 (47%)]\tLoss: 16.646046\n",
            "Train Epoch: 131 [1440/2812 (51%)]\tLoss: 15.071413\n",
            "Train Epoch: 131 [1560/2812 (55%)]\tLoss: 18.323690\n",
            "Train Epoch: 131 [1680/2812 (60%)]\tLoss: 8.492904\n",
            "Train Epoch: 131 [1800/2812 (64%)]\tLoss: 15.260350\n",
            "Train Epoch: 131 [1920/2812 (68%)]\tLoss: 17.953989\n",
            "Train Epoch: 131 [2040/2812 (72%)]\tLoss: 8.471278\n",
            "Train Epoch: 131 [2160/2812 (77%)]\tLoss: 3.846344\n",
            "Train Epoch: 131 [2280/2812 (81%)]\tLoss: 11.263887\n",
            "Train Epoch: 131 [2400/2812 (85%)]\tLoss: 8.229260\n",
            "Train Epoch: 131 [2520/2812 (89%)]\tLoss: 17.990820\n",
            "Train Epoch: 131 [2640/2812 (94%)]\tLoss: 17.512243\n",
            "Train Epoch: 131 [2760/2812 (98%)]\tLoss: 5.396212\n",
            "Training Loss: 11.1111 Acc: 49.0398\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5257, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 132/200\n",
            "----------\n",
            "Train Epoch: 132 [0/2812 (0%)]\tLoss: 14.412428\n",
            "Train Epoch: 132 [120/2812 (4%)]\tLoss: 12.227323\n",
            "Train Epoch: 132 [240/2812 (9%)]\tLoss: 7.910505\n",
            "Train Epoch: 132 [360/2812 (13%)]\tLoss: 8.482882\n",
            "Train Epoch: 132 [480/2812 (17%)]\tLoss: 9.489116\n",
            "Train Epoch: 132 [600/2812 (21%)]\tLoss: 8.561571\n",
            "Train Epoch: 132 [720/2812 (26%)]\tLoss: 5.714113\n",
            "Train Epoch: 132 [840/2812 (30%)]\tLoss: 15.429436\n",
            "Train Epoch: 132 [960/2812 (34%)]\tLoss: 23.654903\n",
            "Train Epoch: 132 [1080/2812 (38%)]\tLoss: 17.092075\n",
            "Train Epoch: 132 [1200/2812 (43%)]\tLoss: 1.050970\n",
            "Train Epoch: 132 [1320/2812 (47%)]\tLoss: 3.164452\n",
            "Train Epoch: 132 [1440/2812 (51%)]\tLoss: 9.396093\n",
            "Train Epoch: 132 [1560/2812 (55%)]\tLoss: 7.463791\n",
            "Train Epoch: 132 [1680/2812 (60%)]\tLoss: 4.961400\n",
            "Train Epoch: 132 [1800/2812 (64%)]\tLoss: 3.315610\n",
            "Train Epoch: 132 [1920/2812 (68%)]\tLoss: 6.881810\n",
            "Train Epoch: 132 [2040/2812 (72%)]\tLoss: 10.256161\n",
            "Train Epoch: 132 [2160/2812 (77%)]\tLoss: 16.291286\n",
            "Train Epoch: 132 [2280/2812 (81%)]\tLoss: 30.728306\n",
            "Train Epoch: 132 [2400/2812 (85%)]\tLoss: 5.706147\n",
            "Train Epoch: 132 [2520/2812 (89%)]\tLoss: 19.081579\n",
            "Train Epoch: 132 [2640/2812 (94%)]\tLoss: 22.319288\n",
            "Train Epoch: 132 [2760/2812 (98%)]\tLoss: 22.371107\n",
            "Training Loss: 11.3072 Acc: 51.1024\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5532, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 133/200\n",
            "----------\n",
            "Train Epoch: 133 [0/2812 (0%)]\tLoss: 14.396779\n",
            "Train Epoch: 133 [120/2812 (4%)]\tLoss: 22.910801\n",
            "Train Epoch: 133 [240/2812 (9%)]\tLoss: 4.930603\n",
            "Train Epoch: 133 [360/2812 (13%)]\tLoss: 8.622720\n",
            "Train Epoch: 133 [480/2812 (17%)]\tLoss: 13.483607\n",
            "Train Epoch: 133 [600/2812 (21%)]\tLoss: 5.927979\n",
            "Train Epoch: 133 [720/2812 (26%)]\tLoss: 5.405735\n",
            "Train Epoch: 133 [840/2812 (30%)]\tLoss: 7.527959\n",
            "Train Epoch: 133 [960/2812 (34%)]\tLoss: 20.675362\n",
            "Train Epoch: 133 [1080/2812 (38%)]\tLoss: 5.516449\n",
            "Train Epoch: 133 [1200/2812 (43%)]\tLoss: 12.795211\n",
            "Train Epoch: 133 [1320/2812 (47%)]\tLoss: 10.287379\n",
            "Train Epoch: 133 [1440/2812 (51%)]\tLoss: 5.300480\n",
            "Train Epoch: 133 [1560/2812 (55%)]\tLoss: 17.006842\n",
            "Train Epoch: 133 [1680/2812 (60%)]\tLoss: 17.439734\n",
            "Train Epoch: 133 [1800/2812 (64%)]\tLoss: 4.118562\n",
            "Train Epoch: 133 [1920/2812 (68%)]\tLoss: 0.242341\n",
            "Train Epoch: 133 [2040/2812 (72%)]\tLoss: 8.014956\n",
            "Train Epoch: 133 [2160/2812 (77%)]\tLoss: 5.044559\n",
            "Train Epoch: 133 [2280/2812 (81%)]\tLoss: 13.426645\n",
            "Train Epoch: 133 [2400/2812 (85%)]\tLoss: 8.185305\n",
            "Train Epoch: 133 [2520/2812 (89%)]\tLoss: 6.749709\n",
            "Train Epoch: 133 [2640/2812 (94%)]\tLoss: 16.064051\n",
            "Train Epoch: 133 [2760/2812 (98%)]\tLoss: 18.457584\n",
            "Training Loss: 11.2775 Acc: 49.7511\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6036, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 134/200\n",
            "----------\n",
            "Train Epoch: 134 [0/2812 (0%)]\tLoss: 16.014767\n",
            "Train Epoch: 134 [120/2812 (4%)]\tLoss: 9.546938\n",
            "Train Epoch: 134 [240/2812 (9%)]\tLoss: 8.536264\n",
            "Train Epoch: 134 [360/2812 (13%)]\tLoss: 19.284481\n",
            "Train Epoch: 134 [480/2812 (17%)]\tLoss: 7.333247\n",
            "Train Epoch: 134 [600/2812 (21%)]\tLoss: 14.098394\n",
            "Train Epoch: 134 [720/2812 (26%)]\tLoss: 8.697229\n",
            "Train Epoch: 134 [840/2812 (30%)]\tLoss: 6.309205\n",
            "Train Epoch: 134 [960/2812 (34%)]\tLoss: 11.627145\n",
            "Train Epoch: 134 [1080/2812 (38%)]\tLoss: 15.872278\n",
            "Train Epoch: 134 [1200/2812 (43%)]\tLoss: 13.357855\n",
            "Train Epoch: 134 [1320/2812 (47%)]\tLoss: 11.179125\n",
            "Train Epoch: 134 [1440/2812 (51%)]\tLoss: 12.440820\n",
            "Train Epoch: 134 [1560/2812 (55%)]\tLoss: 15.401815\n",
            "Train Epoch: 134 [1680/2812 (60%)]\tLoss: 10.893811\n",
            "Train Epoch: 134 [1800/2812 (64%)]\tLoss: 11.550121\n",
            "Train Epoch: 134 [1920/2812 (68%)]\tLoss: 4.594883\n",
            "Train Epoch: 134 [2040/2812 (72%)]\tLoss: 10.861089\n",
            "Train Epoch: 134 [2160/2812 (77%)]\tLoss: 9.300519\n",
            "Train Epoch: 134 [2280/2812 (81%)]\tLoss: 11.435107\n",
            "Train Epoch: 134 [2400/2812 (85%)]\tLoss: 13.499593\n",
            "Train Epoch: 134 [2520/2812 (89%)]\tLoss: 19.577023\n",
            "Train Epoch: 134 [2640/2812 (94%)]\tLoss: 6.225612\n",
            "Train Epoch: 134 [2760/2812 (98%)]\tLoss: 10.496541\n",
            "Training Loss: 11.3120 Acc: 49.5733\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5681, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 135/200\n",
            "----------\n",
            "Train Epoch: 135 [0/2812 (0%)]\tLoss: 15.407221\n",
            "Train Epoch: 135 [120/2812 (4%)]\tLoss: 10.935316\n",
            "Train Epoch: 135 [240/2812 (9%)]\tLoss: 12.336205\n",
            "Train Epoch: 135 [360/2812 (13%)]\tLoss: 11.543421\n",
            "Train Epoch: 135 [480/2812 (17%)]\tLoss: 15.750864\n",
            "Train Epoch: 135 [600/2812 (21%)]\tLoss: 5.402413\n",
            "Train Epoch: 135 [720/2812 (26%)]\tLoss: 7.684772\n",
            "Train Epoch: 135 [840/2812 (30%)]\tLoss: 17.325497\n",
            "Train Epoch: 135 [960/2812 (34%)]\tLoss: 7.780476\n",
            "Train Epoch: 135 [1080/2812 (38%)]\tLoss: 0.751815\n",
            "Train Epoch: 135 [1200/2812 (43%)]\tLoss: 11.308432\n",
            "Train Epoch: 135 [1320/2812 (47%)]\tLoss: 19.875542\n",
            "Train Epoch: 135 [1440/2812 (51%)]\tLoss: 6.044524\n",
            "Train Epoch: 135 [1560/2812 (55%)]\tLoss: 4.392785\n",
            "Train Epoch: 135 [1680/2812 (60%)]\tLoss: 26.074421\n",
            "Train Epoch: 135 [1800/2812 (64%)]\tLoss: 14.818347\n",
            "Train Epoch: 135 [1920/2812 (68%)]\tLoss: 5.556273\n",
            "Train Epoch: 135 [2040/2812 (72%)]\tLoss: 16.224354\n",
            "Train Epoch: 135 [2160/2812 (77%)]\tLoss: 11.624452\n",
            "Train Epoch: 135 [2280/2812 (81%)]\tLoss: 6.577765\n",
            "Train Epoch: 135 [2400/2812 (85%)]\tLoss: 7.581914\n",
            "Train Epoch: 135 [2520/2812 (89%)]\tLoss: 6.256467\n",
            "Train Epoch: 135 [2640/2812 (94%)]\tLoss: 20.288328\n",
            "Train Epoch: 135 [2760/2812 (98%)]\tLoss: 12.996160\n",
            "Training Loss: 10.4947 Acc: 50.6401\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6112, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 136/200\n",
            "----------\n",
            "Train Epoch: 136 [0/2812 (0%)]\tLoss: 6.373869\n",
            "Train Epoch: 136 [120/2812 (4%)]\tLoss: 1.095263\n",
            "Train Epoch: 136 [240/2812 (9%)]\tLoss: 7.180230\n",
            "Train Epoch: 136 [360/2812 (13%)]\tLoss: 3.710779\n",
            "Train Epoch: 136 [480/2812 (17%)]\tLoss: 21.139509\n",
            "Train Epoch: 136 [600/2812 (21%)]\tLoss: 4.627092\n",
            "Train Epoch: 136 [720/2812 (26%)]\tLoss: 9.605087\n",
            "Train Epoch: 136 [840/2812 (30%)]\tLoss: 6.827782\n",
            "Train Epoch: 136 [960/2812 (34%)]\tLoss: 17.253160\n",
            "Train Epoch: 136 [1080/2812 (38%)]\tLoss: 5.443489\n",
            "Train Epoch: 136 [1200/2812 (43%)]\tLoss: 18.189848\n",
            "Train Epoch: 136 [1320/2812 (47%)]\tLoss: 5.131451\n",
            "Train Epoch: 136 [1440/2812 (51%)]\tLoss: 5.725741\n",
            "Train Epoch: 136 [1560/2812 (55%)]\tLoss: 13.894429\n",
            "Train Epoch: 136 [1680/2812 (60%)]\tLoss: 20.126720\n",
            "Train Epoch: 136 [1800/2812 (64%)]\tLoss: 8.471762\n",
            "Train Epoch: 136 [1920/2812 (68%)]\tLoss: 26.273691\n",
            "Train Epoch: 136 [2040/2812 (72%)]\tLoss: 12.421012\n",
            "Train Epoch: 136 [2160/2812 (77%)]\tLoss: 8.847508\n",
            "Train Epoch: 136 [2280/2812 (81%)]\tLoss: 18.256645\n",
            "Train Epoch: 136 [2400/2812 (85%)]\tLoss: 9.712575\n",
            "Train Epoch: 136 [2520/2812 (89%)]\tLoss: 16.207764\n",
            "Train Epoch: 136 [2640/2812 (94%)]\tLoss: 13.474874\n",
            "Train Epoch: 136 [2760/2812 (98%)]\tLoss: 3.362696\n",
            "Training Loss: 11.2626 Acc: 50.6401\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5441, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 137/200\n",
            "----------\n",
            "Train Epoch: 137 [0/2812 (0%)]\tLoss: 10.334919\n",
            "Train Epoch: 137 [120/2812 (4%)]\tLoss: 18.206783\n",
            "Train Epoch: 137 [240/2812 (9%)]\tLoss: 8.052784\n",
            "Train Epoch: 137 [360/2812 (13%)]\tLoss: 5.980536\n",
            "Train Epoch: 137 [480/2812 (17%)]\tLoss: 1.317352\n",
            "Train Epoch: 137 [600/2812 (21%)]\tLoss: 12.066092\n",
            "Train Epoch: 137 [720/2812 (26%)]\tLoss: 10.675354\n",
            "Train Epoch: 137 [840/2812 (30%)]\tLoss: 8.703230\n",
            "Train Epoch: 137 [960/2812 (34%)]\tLoss: 6.645477\n",
            "Train Epoch: 137 [1080/2812 (38%)]\tLoss: 9.033165\n",
            "Train Epoch: 137 [1200/2812 (43%)]\tLoss: 9.022885\n",
            "Train Epoch: 137 [1320/2812 (47%)]\tLoss: 7.613331\n",
            "Train Epoch: 137 [1440/2812 (51%)]\tLoss: 13.971373\n",
            "Train Epoch: 137 [1560/2812 (55%)]\tLoss: 4.727564\n",
            "Train Epoch: 137 [1680/2812 (60%)]\tLoss: 17.186556\n",
            "Train Epoch: 137 [1800/2812 (64%)]\tLoss: 11.599787\n",
            "Train Epoch: 137 [1920/2812 (68%)]\tLoss: 9.331381\n",
            "Train Epoch: 137 [2040/2812 (72%)]\tLoss: 6.071632\n",
            "Train Epoch: 137 [2160/2812 (77%)]\tLoss: 11.455317\n",
            "Train Epoch: 137 [2280/2812 (81%)]\tLoss: 10.315912\n",
            "Train Epoch: 137 [2400/2812 (85%)]\tLoss: 7.649058\n",
            "Train Epoch: 137 [2520/2812 (89%)]\tLoss: 6.936650\n",
            "Train Epoch: 137 [2640/2812 (94%)]\tLoss: 9.829034\n",
            "Train Epoch: 137 [2760/2812 (98%)]\tLoss: 1.229293\n",
            "Training Loss: 11.0639 Acc: 50.8890\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6034, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 138/200\n",
            "----------\n",
            "Train Epoch: 138 [0/2812 (0%)]\tLoss: 7.615558\n",
            "Train Epoch: 138 [120/2812 (4%)]\tLoss: 8.548421\n",
            "Train Epoch: 138 [240/2812 (9%)]\tLoss: 9.288107\n",
            "Train Epoch: 138 [360/2812 (13%)]\tLoss: 6.477656\n",
            "Train Epoch: 138 [480/2812 (17%)]\tLoss: 13.831404\n",
            "Train Epoch: 138 [600/2812 (21%)]\tLoss: 13.217566\n",
            "Train Epoch: 138 [720/2812 (26%)]\tLoss: 23.777241\n",
            "Train Epoch: 138 [840/2812 (30%)]\tLoss: 13.423930\n",
            "Train Epoch: 138 [960/2812 (34%)]\tLoss: 16.789827\n",
            "Train Epoch: 138 [1080/2812 (38%)]\tLoss: 5.871389\n",
            "Train Epoch: 138 [1200/2812 (43%)]\tLoss: 8.538882\n",
            "Train Epoch: 138 [1320/2812 (47%)]\tLoss: 13.737938\n",
            "Train Epoch: 138 [1440/2812 (51%)]\tLoss: 2.379049\n",
            "Train Epoch: 138 [1560/2812 (55%)]\tLoss: 5.695394\n",
            "Train Epoch: 138 [1680/2812 (60%)]\tLoss: 12.671232\n",
            "Train Epoch: 138 [1800/2812 (64%)]\tLoss: 6.318220\n",
            "Train Epoch: 138 [1920/2812 (68%)]\tLoss: 11.571959\n",
            "Train Epoch: 138 [2040/2812 (72%)]\tLoss: 10.895304\n",
            "Train Epoch: 138 [2160/2812 (77%)]\tLoss: 5.705181\n",
            "Train Epoch: 138 [2280/2812 (81%)]\tLoss: 6.065230\n",
            "Train Epoch: 138 [2400/2812 (85%)]\tLoss: 11.131077\n",
            "Train Epoch: 138 [2520/2812 (89%)]\tLoss: 12.189935\n",
            "Train Epoch: 138 [2640/2812 (94%)]\tLoss: 14.473869\n",
            "Train Epoch: 138 [2760/2812 (98%)]\tLoss: 9.482527\n",
            "Training Loss: 11.1793 Acc: 50.0356\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5696, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 139/200\n",
            "----------\n",
            "Train Epoch: 139 [0/2812 (0%)]\tLoss: 5.901084\n",
            "Train Epoch: 139 [120/2812 (4%)]\tLoss: 5.681841\n",
            "Train Epoch: 139 [240/2812 (9%)]\tLoss: 12.149129\n",
            "Train Epoch: 139 [360/2812 (13%)]\tLoss: 11.471363\n",
            "Train Epoch: 139 [480/2812 (17%)]\tLoss: 7.188531\n",
            "Train Epoch: 139 [600/2812 (21%)]\tLoss: 9.410791\n",
            "Train Epoch: 139 [720/2812 (26%)]\tLoss: 12.589491\n",
            "Train Epoch: 139 [840/2812 (30%)]\tLoss: 8.117554\n",
            "Train Epoch: 139 [960/2812 (34%)]\tLoss: 6.617047\n",
            "Train Epoch: 139 [1080/2812 (38%)]\tLoss: 9.518311\n",
            "Train Epoch: 139 [1200/2812 (43%)]\tLoss: 12.283895\n",
            "Train Epoch: 139 [1320/2812 (47%)]\tLoss: 9.764018\n",
            "Train Epoch: 139 [1440/2812 (51%)]\tLoss: 18.269342\n",
            "Train Epoch: 139 [1560/2812 (55%)]\tLoss: 16.569965\n",
            "Train Epoch: 139 [1680/2812 (60%)]\tLoss: 11.077389\n",
            "Train Epoch: 139 [1800/2812 (64%)]\tLoss: 13.041479\n",
            "Train Epoch: 139 [1920/2812 (68%)]\tLoss: 3.122784\n",
            "Train Epoch: 139 [2040/2812 (72%)]\tLoss: 4.591299\n",
            "Train Epoch: 139 [2160/2812 (77%)]\tLoss: 11.467697\n",
            "Train Epoch: 139 [2280/2812 (81%)]\tLoss: 14.340906\n",
            "Train Epoch: 139 [2400/2812 (85%)]\tLoss: 5.703046\n",
            "Train Epoch: 139 [2520/2812 (89%)]\tLoss: 6.510423\n",
            "Train Epoch: 139 [2640/2812 (94%)]\tLoss: 9.924309\n",
            "Train Epoch: 139 [2760/2812 (98%)]\tLoss: 8.534009\n",
            "Training Loss: 11.3106 Acc: 50.3201\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5353, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 140/200\n",
            "----------\n",
            "Train Epoch: 140 [0/2812 (0%)]\tLoss: 12.661896\n",
            "Train Epoch: 140 [120/2812 (4%)]\tLoss: 20.773817\n",
            "Train Epoch: 140 [240/2812 (9%)]\tLoss: 19.952932\n",
            "Train Epoch: 140 [360/2812 (13%)]\tLoss: 15.682817\n",
            "Train Epoch: 140 [480/2812 (17%)]\tLoss: 12.445105\n",
            "Train Epoch: 140 [600/2812 (21%)]\tLoss: 3.898888\n",
            "Train Epoch: 140 [720/2812 (26%)]\tLoss: 3.512044\n",
            "Train Epoch: 140 [840/2812 (30%)]\tLoss: 17.725307\n",
            "Train Epoch: 140 [960/2812 (34%)]\tLoss: 13.183456\n",
            "Train Epoch: 140 [1080/2812 (38%)]\tLoss: 2.209641\n",
            "Train Epoch: 140 [1200/2812 (43%)]\tLoss: 15.039522\n",
            "Train Epoch: 140 [1320/2812 (47%)]\tLoss: 6.537352\n",
            "Train Epoch: 140 [1440/2812 (51%)]\tLoss: 13.926849\n",
            "Train Epoch: 140 [1560/2812 (55%)]\tLoss: 9.627281\n",
            "Train Epoch: 140 [1680/2812 (60%)]\tLoss: 7.733435\n",
            "Train Epoch: 140 [1800/2812 (64%)]\tLoss: 5.761533\n",
            "Train Epoch: 140 [1920/2812 (68%)]\tLoss: 18.671986\n",
            "Train Epoch: 140 [2040/2812 (72%)]\tLoss: 4.320605\n",
            "Train Epoch: 140 [2160/2812 (77%)]\tLoss: 9.456337\n",
            "Train Epoch: 140 [2280/2812 (81%)]\tLoss: 29.161615\n",
            "Train Epoch: 140 [2400/2812 (85%)]\tLoss: 7.223432\n",
            "Train Epoch: 140 [2520/2812 (89%)]\tLoss: 10.151899\n",
            "Train Epoch: 140 [2640/2812 (94%)]\tLoss: 17.651188\n",
            "Train Epoch: 140 [2760/2812 (98%)]\tLoss: 13.726529\n",
            "Training Loss: 11.3615 Acc: 49.3243\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5477, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 141/200\n",
            "----------\n",
            "Train Epoch: 141 [0/2812 (0%)]\tLoss: 14.369934\n",
            "Train Epoch: 141 [120/2812 (4%)]\tLoss: 7.206355\n",
            "Train Epoch: 141 [240/2812 (9%)]\tLoss: 9.698435\n",
            "Train Epoch: 141 [360/2812 (13%)]\tLoss: 11.876710\n",
            "Train Epoch: 141 [480/2812 (17%)]\tLoss: 13.398892\n",
            "Train Epoch: 141 [600/2812 (21%)]\tLoss: 11.395442\n",
            "Train Epoch: 141 [720/2812 (26%)]\tLoss: 18.544283\n",
            "Train Epoch: 141 [840/2812 (30%)]\tLoss: 8.773133\n",
            "Train Epoch: 141 [960/2812 (34%)]\tLoss: 17.257710\n",
            "Train Epoch: 141 [1080/2812 (38%)]\tLoss: 13.391406\n",
            "Train Epoch: 141 [1200/2812 (43%)]\tLoss: 16.112625\n",
            "Train Epoch: 141 [1320/2812 (47%)]\tLoss: 3.237219\n",
            "Train Epoch: 141 [1440/2812 (51%)]\tLoss: 9.723127\n",
            "Train Epoch: 141 [1560/2812 (55%)]\tLoss: 17.769430\n",
            "Train Epoch: 141 [1680/2812 (60%)]\tLoss: 5.459568\n",
            "Train Epoch: 141 [1800/2812 (64%)]\tLoss: 11.342253\n",
            "Train Epoch: 141 [1920/2812 (68%)]\tLoss: 16.045223\n",
            "Train Epoch: 141 [2040/2812 (72%)]\tLoss: 11.095137\n",
            "Train Epoch: 141 [2160/2812 (77%)]\tLoss: 19.310675\n",
            "Train Epoch: 141 [2280/2812 (81%)]\tLoss: 5.812087\n",
            "Train Epoch: 141 [2400/2812 (85%)]\tLoss: 15.904864\n",
            "Train Epoch: 141 [2520/2812 (89%)]\tLoss: 9.378963\n",
            "Train Epoch: 141 [2640/2812 (94%)]\tLoss: 11.459084\n",
            "Train Epoch: 141 [2760/2812 (98%)]\tLoss: 8.731949\n",
            "Training Loss: 11.0887 Acc: 51.7425\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6079, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 142/200\n",
            "----------\n",
            "Train Epoch: 142 [0/2812 (0%)]\tLoss: 7.238346\n",
            "Train Epoch: 142 [120/2812 (4%)]\tLoss: 16.418228\n",
            "Train Epoch: 142 [240/2812 (9%)]\tLoss: 7.328653\n",
            "Train Epoch: 142 [360/2812 (13%)]\tLoss: 13.684624\n",
            "Train Epoch: 142 [480/2812 (17%)]\tLoss: 17.577724\n",
            "Train Epoch: 142 [600/2812 (21%)]\tLoss: 0.679161\n",
            "Train Epoch: 142 [720/2812 (26%)]\tLoss: 7.568258\n",
            "Train Epoch: 142 [840/2812 (30%)]\tLoss: 2.855869\n",
            "Train Epoch: 142 [960/2812 (34%)]\tLoss: 24.233974\n",
            "Train Epoch: 142 [1080/2812 (38%)]\tLoss: 6.387979\n",
            "Train Epoch: 142 [1200/2812 (43%)]\tLoss: 16.149048\n",
            "Train Epoch: 142 [1320/2812 (47%)]\tLoss: 6.802064\n",
            "Train Epoch: 142 [1440/2812 (51%)]\tLoss: 5.086896\n",
            "Train Epoch: 142 [1560/2812 (55%)]\tLoss: 9.603298\n",
            "Train Epoch: 142 [1680/2812 (60%)]\tLoss: 13.678022\n",
            "Train Epoch: 142 [1800/2812 (64%)]\tLoss: 5.566329\n",
            "Train Epoch: 142 [1920/2812 (68%)]\tLoss: 16.121220\n",
            "Train Epoch: 142 [2040/2812 (72%)]\tLoss: 7.427846\n",
            "Train Epoch: 142 [2160/2812 (77%)]\tLoss: 4.152313\n",
            "Train Epoch: 142 [2280/2812 (81%)]\tLoss: 22.460438\n",
            "Train Epoch: 142 [2400/2812 (85%)]\tLoss: 7.944186\n",
            "Train Epoch: 142 [2520/2812 (89%)]\tLoss: 7.386118\n",
            "Train Epoch: 142 [2640/2812 (94%)]\tLoss: 6.594714\n",
            "Train Epoch: 142 [2760/2812 (98%)]\tLoss: 20.811131\n",
            "Training Loss: 11.2664 Acc: 50.8890\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5795, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 143/200\n",
            "----------\n",
            "Train Epoch: 143 [0/2812 (0%)]\tLoss: 16.887926\n",
            "Train Epoch: 143 [120/2812 (4%)]\tLoss: 6.282388\n",
            "Train Epoch: 143 [240/2812 (9%)]\tLoss: 20.399128\n",
            "Train Epoch: 143 [360/2812 (13%)]\tLoss: 18.080423\n",
            "Train Epoch: 143 [480/2812 (17%)]\tLoss: 5.943169\n",
            "Train Epoch: 143 [600/2812 (21%)]\tLoss: 11.497024\n",
            "Train Epoch: 143 [720/2812 (26%)]\tLoss: 13.857843\n",
            "Train Epoch: 143 [840/2812 (30%)]\tLoss: 19.556776\n",
            "Train Epoch: 143 [960/2812 (34%)]\tLoss: 3.730770\n",
            "Train Epoch: 143 [1080/2812 (38%)]\tLoss: 11.379783\n",
            "Train Epoch: 143 [1200/2812 (43%)]\tLoss: 7.378214\n",
            "Train Epoch: 143 [1320/2812 (47%)]\tLoss: 7.693826\n",
            "Train Epoch: 143 [1440/2812 (51%)]\tLoss: 1.430961\n",
            "Train Epoch: 143 [1560/2812 (55%)]\tLoss: 6.266216\n",
            "Train Epoch: 143 [1680/2812 (60%)]\tLoss: 10.166509\n",
            "Train Epoch: 143 [1800/2812 (64%)]\tLoss: 12.591738\n",
            "Train Epoch: 143 [1920/2812 (68%)]\tLoss: 16.147564\n",
            "Train Epoch: 143 [2040/2812 (72%)]\tLoss: 4.945709\n",
            "Train Epoch: 143 [2160/2812 (77%)]\tLoss: 34.193394\n",
            "Train Epoch: 143 [2280/2812 (81%)]\tLoss: 11.518521\n",
            "Train Epoch: 143 [2400/2812 (85%)]\tLoss: 15.511354\n",
            "Train Epoch: 143 [2520/2812 (89%)]\tLoss: 14.906634\n",
            "Train Epoch: 143 [2640/2812 (94%)]\tLoss: 15.849025\n",
            "Train Epoch: 143 [2760/2812 (98%)]\tLoss: 6.498489\n",
            "Training Loss: 11.0452 Acc: 48.9687\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6098, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 144/200\n",
            "----------\n",
            "Train Epoch: 144 [0/2812 (0%)]\tLoss: 10.241945\n",
            "Train Epoch: 144 [120/2812 (4%)]\tLoss: 11.940306\n",
            "Train Epoch: 144 [240/2812 (9%)]\tLoss: 11.383623\n",
            "Train Epoch: 144 [360/2812 (13%)]\tLoss: 10.947673\n",
            "Train Epoch: 144 [480/2812 (17%)]\tLoss: 9.245908\n",
            "Train Epoch: 144 [600/2812 (21%)]\tLoss: 18.883514\n",
            "Train Epoch: 144 [720/2812 (26%)]\tLoss: 16.475492\n",
            "Train Epoch: 144 [840/2812 (30%)]\tLoss: 11.700832\n",
            "Train Epoch: 144 [960/2812 (34%)]\tLoss: 8.624972\n",
            "Train Epoch: 144 [1080/2812 (38%)]\tLoss: 1.996970\n",
            "Train Epoch: 144 [1200/2812 (43%)]\tLoss: 17.838287\n",
            "Train Epoch: 144 [1320/2812 (47%)]\tLoss: 19.211838\n",
            "Train Epoch: 144 [1440/2812 (51%)]\tLoss: 8.701673\n",
            "Train Epoch: 144 [1560/2812 (55%)]\tLoss: 23.005764\n",
            "Train Epoch: 144 [1680/2812 (60%)]\tLoss: 16.320200\n",
            "Train Epoch: 144 [1800/2812 (64%)]\tLoss: 6.792264\n",
            "Train Epoch: 144 [1920/2812 (68%)]\tLoss: 11.774746\n",
            "Train Epoch: 144 [2040/2812 (72%)]\tLoss: 20.228704\n",
            "Train Epoch: 144 [2160/2812 (77%)]\tLoss: 12.660925\n",
            "Train Epoch: 144 [2280/2812 (81%)]\tLoss: 15.001867\n",
            "Train Epoch: 144 [2400/2812 (85%)]\tLoss: 24.766714\n",
            "Train Epoch: 144 [2520/2812 (89%)]\tLoss: 12.992912\n",
            "Train Epoch: 144 [2640/2812 (94%)]\tLoss: 15.980021\n",
            "Train Epoch: 144 [2760/2812 (98%)]\tLoss: 9.944654\n",
            "Training Loss: 11.2608 Acc: 50.6401\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5782, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 145/200\n",
            "----------\n",
            "Train Epoch: 145 [0/2812 (0%)]\tLoss: 16.979252\n",
            "Train Epoch: 145 [120/2812 (4%)]\tLoss: 8.868054\n",
            "Train Epoch: 145 [240/2812 (9%)]\tLoss: 6.108937\n",
            "Train Epoch: 145 [360/2812 (13%)]\tLoss: 11.664812\n",
            "Train Epoch: 145 [480/2812 (17%)]\tLoss: 7.444905\n",
            "Train Epoch: 145 [600/2812 (21%)]\tLoss: 9.602390\n",
            "Train Epoch: 145 [720/2812 (26%)]\tLoss: 9.988455\n",
            "Train Epoch: 145 [840/2812 (30%)]\tLoss: 19.991341\n",
            "Train Epoch: 145 [960/2812 (34%)]\tLoss: 10.001622\n",
            "Train Epoch: 145 [1080/2812 (38%)]\tLoss: 5.556495\n",
            "Train Epoch: 145 [1200/2812 (43%)]\tLoss: 6.621976\n",
            "Train Epoch: 145 [1320/2812 (47%)]\tLoss: 23.588343\n",
            "Train Epoch: 145 [1440/2812 (51%)]\tLoss: 4.043416\n",
            "Train Epoch: 145 [1560/2812 (55%)]\tLoss: 4.726941\n",
            "Train Epoch: 145 [1680/2812 (60%)]\tLoss: 13.628708\n",
            "Train Epoch: 145 [1800/2812 (64%)]\tLoss: 16.691011\n",
            "Train Epoch: 145 [1920/2812 (68%)]\tLoss: 7.370531\n",
            "Train Epoch: 145 [2040/2812 (72%)]\tLoss: 6.980460\n",
            "Train Epoch: 145 [2160/2812 (77%)]\tLoss: 18.461567\n",
            "Train Epoch: 145 [2280/2812 (81%)]\tLoss: 7.407400\n",
            "Train Epoch: 145 [2400/2812 (85%)]\tLoss: 7.384112\n",
            "Train Epoch: 145 [2520/2812 (89%)]\tLoss: 11.930055\n",
            "Train Epoch: 145 [2640/2812 (94%)]\tLoss: 5.024356\n",
            "Train Epoch: 145 [2760/2812 (98%)]\tLoss: 5.429315\n",
            "Training Loss: 11.3252 Acc: 50.3912\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5328, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 146/200\n",
            "----------\n",
            "Train Epoch: 146 [0/2812 (0%)]\tLoss: 9.209191\n",
            "Train Epoch: 146 [120/2812 (4%)]\tLoss: 12.259238\n",
            "Train Epoch: 146 [240/2812 (9%)]\tLoss: 10.982077\n",
            "Train Epoch: 146 [360/2812 (13%)]\tLoss: 7.271755\n",
            "Train Epoch: 146 [480/2812 (17%)]\tLoss: 9.109454\n",
            "Train Epoch: 146 [600/2812 (21%)]\tLoss: 11.163872\n",
            "Train Epoch: 146 [720/2812 (26%)]\tLoss: 8.383570\n",
            "Train Epoch: 146 [840/2812 (30%)]\tLoss: 10.987869\n",
            "Train Epoch: 146 [960/2812 (34%)]\tLoss: 19.360481\n",
            "Train Epoch: 146 [1080/2812 (38%)]\tLoss: 11.880091\n",
            "Train Epoch: 146 [1200/2812 (43%)]\tLoss: 3.742111\n",
            "Train Epoch: 146 [1320/2812 (47%)]\tLoss: 4.113098\n",
            "Train Epoch: 146 [1440/2812 (51%)]\tLoss: 11.000072\n",
            "Train Epoch: 146 [1560/2812 (55%)]\tLoss: 10.269572\n",
            "Train Epoch: 146 [1680/2812 (60%)]\tLoss: 13.693805\n",
            "Train Epoch: 146 [1800/2812 (64%)]\tLoss: 10.275072\n",
            "Train Epoch: 146 [1920/2812 (68%)]\tLoss: 16.967127\n",
            "Train Epoch: 146 [2040/2812 (72%)]\tLoss: 12.303305\n",
            "Train Epoch: 146 [2160/2812 (77%)]\tLoss: 9.057090\n",
            "Train Epoch: 146 [2280/2812 (81%)]\tLoss: 16.557446\n",
            "Train Epoch: 146 [2400/2812 (85%)]\tLoss: 7.848489\n",
            "Train Epoch: 146 [2520/2812 (89%)]\tLoss: 8.319937\n",
            "Train Epoch: 146 [2640/2812 (94%)]\tLoss: 9.014160\n",
            "Train Epoch: 146 [2760/2812 (98%)]\tLoss: 11.299036\n",
            "Training Loss: 11.0723 Acc: 50.0711\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5809, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 147/200\n",
            "----------\n",
            "Train Epoch: 147 [0/2812 (0%)]\tLoss: 18.224977\n",
            "Train Epoch: 147 [120/2812 (4%)]\tLoss: 8.094447\n",
            "Train Epoch: 147 [240/2812 (9%)]\tLoss: 8.362229\n",
            "Train Epoch: 147 [360/2812 (13%)]\tLoss: 8.835517\n",
            "Train Epoch: 147 [480/2812 (17%)]\tLoss: 10.805559\n",
            "Train Epoch: 147 [600/2812 (21%)]\tLoss: 18.122696\n",
            "Train Epoch: 147 [720/2812 (26%)]\tLoss: 12.821413\n",
            "Train Epoch: 147 [840/2812 (30%)]\tLoss: 14.564619\n",
            "Train Epoch: 147 [960/2812 (34%)]\tLoss: 21.036808\n",
            "Train Epoch: 147 [1080/2812 (38%)]\tLoss: 1.539127\n",
            "Train Epoch: 147 [1200/2812 (43%)]\tLoss: 5.615433\n",
            "Train Epoch: 147 [1320/2812 (47%)]\tLoss: 13.323184\n",
            "Train Epoch: 147 [1440/2812 (51%)]\tLoss: 17.435949\n",
            "Train Epoch: 147 [1560/2812 (55%)]\tLoss: 17.172491\n",
            "Train Epoch: 147 [1680/2812 (60%)]\tLoss: 8.824303\n",
            "Train Epoch: 147 [1800/2812 (64%)]\tLoss: 14.252241\n",
            "Train Epoch: 147 [1920/2812 (68%)]\tLoss: 6.982608\n",
            "Train Epoch: 147 [2040/2812 (72%)]\tLoss: 2.788062\n",
            "Train Epoch: 147 [2160/2812 (77%)]\tLoss: 11.933947\n",
            "Train Epoch: 147 [2280/2812 (81%)]\tLoss: 4.045335\n",
            "Train Epoch: 147 [2400/2812 (85%)]\tLoss: 11.899837\n",
            "Train Epoch: 147 [2520/2812 (89%)]\tLoss: 12.315130\n",
            "Train Epoch: 147 [2640/2812 (94%)]\tLoss: 7.977658\n",
            "Train Epoch: 147 [2760/2812 (98%)]\tLoss: 14.494257\n",
            "Training Loss: 11.4556 Acc: 49.4666\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5562, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 148/200\n",
            "----------\n",
            "Train Epoch: 148 [0/2812 (0%)]\tLoss: 5.951163\n",
            "Train Epoch: 148 [120/2812 (4%)]\tLoss: 8.246574\n",
            "Train Epoch: 148 [240/2812 (9%)]\tLoss: 10.771364\n",
            "Train Epoch: 148 [360/2812 (13%)]\tLoss: 6.012711\n",
            "Train Epoch: 148 [480/2812 (17%)]\tLoss: 11.865675\n",
            "Train Epoch: 148 [600/2812 (21%)]\tLoss: 3.952859\n",
            "Train Epoch: 148 [720/2812 (26%)]\tLoss: 6.750805\n",
            "Train Epoch: 148 [840/2812 (30%)]\tLoss: 10.808653\n",
            "Train Epoch: 148 [960/2812 (34%)]\tLoss: 8.278303\n",
            "Train Epoch: 148 [1080/2812 (38%)]\tLoss: 8.880411\n",
            "Train Epoch: 148 [1200/2812 (43%)]\tLoss: 8.400342\n",
            "Train Epoch: 148 [1320/2812 (47%)]\tLoss: 10.586688\n",
            "Train Epoch: 148 [1440/2812 (51%)]\tLoss: 9.267811\n",
            "Train Epoch: 148 [1560/2812 (55%)]\tLoss: 8.973035\n",
            "Train Epoch: 148 [1680/2812 (60%)]\tLoss: 5.772367\n",
            "Train Epoch: 148 [1800/2812 (64%)]\tLoss: 4.836984\n",
            "Train Epoch: 148 [1920/2812 (68%)]\tLoss: 15.477278\n",
            "Train Epoch: 148 [2040/2812 (72%)]\tLoss: 11.523507\n",
            "Train Epoch: 148 [2160/2812 (77%)]\tLoss: 8.259999\n",
            "Train Epoch: 148 [2280/2812 (81%)]\tLoss: 5.887327\n",
            "Train Epoch: 148 [2400/2812 (85%)]\tLoss: 18.866341\n",
            "Train Epoch: 148 [2520/2812 (89%)]\tLoss: 7.697327\n",
            "Train Epoch: 148 [2640/2812 (94%)]\tLoss: 11.816623\n",
            "Train Epoch: 148 [2760/2812 (98%)]\tLoss: 7.810582\n",
            "Training Loss: 11.2556 Acc: 50.2134\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5472, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 149/200\n",
            "----------\n",
            "Train Epoch: 149 [0/2812 (0%)]\tLoss: 1.782440\n",
            "Train Epoch: 149 [120/2812 (4%)]\tLoss: 10.530665\n",
            "Train Epoch: 149 [240/2812 (9%)]\tLoss: 10.515578\n",
            "Train Epoch: 149 [360/2812 (13%)]\tLoss: 14.198248\n",
            "Train Epoch: 149 [480/2812 (17%)]\tLoss: 5.215049\n",
            "Train Epoch: 149 [600/2812 (21%)]\tLoss: 15.252069\n",
            "Train Epoch: 149 [720/2812 (26%)]\tLoss: 10.199052\n",
            "Train Epoch: 149 [840/2812 (30%)]\tLoss: 18.320288\n",
            "Train Epoch: 149 [960/2812 (34%)]\tLoss: 2.312788\n",
            "Train Epoch: 149 [1080/2812 (38%)]\tLoss: 13.574392\n",
            "Train Epoch: 149 [1200/2812 (43%)]\tLoss: 6.314398\n",
            "Train Epoch: 149 [1320/2812 (47%)]\tLoss: 12.544946\n",
            "Train Epoch: 149 [1440/2812 (51%)]\tLoss: 12.034669\n",
            "Train Epoch: 149 [1560/2812 (55%)]\tLoss: 4.315120\n",
            "Train Epoch: 149 [1680/2812 (60%)]\tLoss: 9.305589\n",
            "Train Epoch: 149 [1800/2812 (64%)]\tLoss: 16.896961\n",
            "Train Epoch: 149 [1920/2812 (68%)]\tLoss: 11.694525\n",
            "Train Epoch: 149 [2040/2812 (72%)]\tLoss: 4.533332\n",
            "Train Epoch: 149 [2160/2812 (77%)]\tLoss: 9.771012\n",
            "Train Epoch: 149 [2280/2812 (81%)]\tLoss: 17.395081\n",
            "Train Epoch: 149 [2400/2812 (85%)]\tLoss: 15.394653\n",
            "Train Epoch: 149 [2520/2812 (89%)]\tLoss: 6.921932\n",
            "Train Epoch: 149 [2640/2812 (94%)]\tLoss: 10.929368\n",
            "Train Epoch: 149 [2760/2812 (98%)]\tLoss: 12.907475\n",
            "Training Loss: 11.1518 Acc: 50.1422\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6582, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 150/200\n",
            "----------\n",
            "Train Epoch: 150 [0/2812 (0%)]\tLoss: 25.004105\n",
            "Train Epoch: 150 [120/2812 (4%)]\tLoss: 9.171446\n",
            "Train Epoch: 150 [240/2812 (9%)]\tLoss: 5.678331\n",
            "Train Epoch: 150 [360/2812 (13%)]\tLoss: 10.130400\n",
            "Train Epoch: 150 [480/2812 (17%)]\tLoss: 10.650860\n",
            "Train Epoch: 150 [600/2812 (21%)]\tLoss: 10.958368\n",
            "Train Epoch: 150 [720/2812 (26%)]\tLoss: 11.440522\n",
            "Train Epoch: 150 [840/2812 (30%)]\tLoss: 7.668017\n",
            "Train Epoch: 150 [960/2812 (34%)]\tLoss: 5.533265\n",
            "Train Epoch: 150 [1080/2812 (38%)]\tLoss: 15.474457\n",
            "Train Epoch: 150 [1200/2812 (43%)]\tLoss: 14.486981\n",
            "Train Epoch: 150 [1320/2812 (47%)]\tLoss: 10.558932\n",
            "Train Epoch: 150 [1440/2812 (51%)]\tLoss: 10.591022\n",
            "Train Epoch: 150 [1560/2812 (55%)]\tLoss: 5.915302\n",
            "Train Epoch: 150 [1680/2812 (60%)]\tLoss: 8.370705\n",
            "Train Epoch: 150 [1800/2812 (64%)]\tLoss: 15.261464\n",
            "Train Epoch: 150 [1920/2812 (68%)]\tLoss: 5.346480\n",
            "Train Epoch: 150 [2040/2812 (72%)]\tLoss: 8.138063\n",
            "Train Epoch: 150 [2160/2812 (77%)]\tLoss: 12.798416\n",
            "Train Epoch: 150 [2280/2812 (81%)]\tLoss: 17.240040\n",
            "Train Epoch: 150 [2400/2812 (85%)]\tLoss: 7.029642\n",
            "Train Epoch: 150 [2520/2812 (89%)]\tLoss: 16.208130\n",
            "Train Epoch: 150 [2640/2812 (94%)]\tLoss: 15.071439\n",
            "Train Epoch: 150 [2760/2812 (98%)]\tLoss: 8.500422\n",
            "Training Loss: 10.7311 Acc: 50.4267\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5400, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 151/200\n",
            "----------\n",
            "Train Epoch: 151 [0/2812 (0%)]\tLoss: 6.644757\n",
            "Train Epoch: 151 [120/2812 (4%)]\tLoss: 9.310832\n",
            "Train Epoch: 151 [240/2812 (9%)]\tLoss: 10.546659\n",
            "Train Epoch: 151 [360/2812 (13%)]\tLoss: 14.672682\n",
            "Train Epoch: 151 [480/2812 (17%)]\tLoss: 11.731196\n",
            "Train Epoch: 151 [600/2812 (21%)]\tLoss: 8.706522\n",
            "Train Epoch: 151 [720/2812 (26%)]\tLoss: 21.945904\n",
            "Train Epoch: 151 [840/2812 (30%)]\tLoss: 10.970792\n",
            "Train Epoch: 151 [960/2812 (34%)]\tLoss: 3.632600\n",
            "Train Epoch: 151 [1080/2812 (38%)]\tLoss: 7.676051\n",
            "Train Epoch: 151 [1200/2812 (43%)]\tLoss: 25.335262\n",
            "Train Epoch: 151 [1320/2812 (47%)]\tLoss: 11.720106\n",
            "Train Epoch: 151 [1440/2812 (51%)]\tLoss: 5.561042\n",
            "Train Epoch: 151 [1560/2812 (55%)]\tLoss: 17.847803\n",
            "Train Epoch: 151 [1680/2812 (60%)]\tLoss: 6.226821\n",
            "Train Epoch: 151 [1800/2812 (64%)]\tLoss: 14.769076\n",
            "Train Epoch: 151 [1920/2812 (68%)]\tLoss: 3.277219\n",
            "Train Epoch: 151 [2040/2812 (72%)]\tLoss: 6.385371\n",
            "Train Epoch: 151 [2160/2812 (77%)]\tLoss: 3.024269\n",
            "Train Epoch: 151 [2280/2812 (81%)]\tLoss: 3.293663\n",
            "Train Epoch: 151 [2400/2812 (85%)]\tLoss: 18.821667\n",
            "Train Epoch: 151 [2520/2812 (89%)]\tLoss: 4.551593\n",
            "Train Epoch: 151 [2640/2812 (94%)]\tLoss: 8.295137\n",
            "Train Epoch: 151 [2760/2812 (98%)]\tLoss: 7.886899\n",
            "Training Loss: 11.3416 Acc: 49.9289\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6575, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 152/200\n",
            "----------\n",
            "Train Epoch: 152 [0/2812 (0%)]\tLoss: 4.995019\n",
            "Train Epoch: 152 [120/2812 (4%)]\tLoss: 12.993668\n",
            "Train Epoch: 152 [240/2812 (9%)]\tLoss: 14.894079\n",
            "Train Epoch: 152 [360/2812 (13%)]\tLoss: 10.282141\n",
            "Train Epoch: 152 [480/2812 (17%)]\tLoss: 5.820323\n",
            "Train Epoch: 152 [600/2812 (21%)]\tLoss: 3.328955\n",
            "Train Epoch: 152 [720/2812 (26%)]\tLoss: 13.633486\n",
            "Train Epoch: 152 [840/2812 (30%)]\tLoss: 17.366734\n",
            "Train Epoch: 152 [960/2812 (34%)]\tLoss: 4.597429\n",
            "Train Epoch: 152 [1080/2812 (38%)]\tLoss: 12.917879\n",
            "Train Epoch: 152 [1200/2812 (43%)]\tLoss: 12.008569\n",
            "Train Epoch: 152 [1320/2812 (47%)]\tLoss: 8.139885\n",
            "Train Epoch: 152 [1440/2812 (51%)]\tLoss: 13.507230\n",
            "Train Epoch: 152 [1560/2812 (55%)]\tLoss: 3.842138\n",
            "Train Epoch: 152 [1680/2812 (60%)]\tLoss: 4.821311\n",
            "Train Epoch: 152 [1800/2812 (64%)]\tLoss: 7.400542\n",
            "Train Epoch: 152 [1920/2812 (68%)]\tLoss: 12.801135\n",
            "Train Epoch: 152 [2040/2812 (72%)]\tLoss: 16.841387\n",
            "Train Epoch: 152 [2160/2812 (77%)]\tLoss: 19.724905\n",
            "Train Epoch: 152 [2280/2812 (81%)]\tLoss: 14.083357\n",
            "Train Epoch: 152 [2400/2812 (85%)]\tLoss: 11.691833\n",
            "Train Epoch: 152 [2520/2812 (89%)]\tLoss: 16.595556\n",
            "Train Epoch: 152 [2640/2812 (94%)]\tLoss: 6.335303\n",
            "Train Epoch: 152 [2760/2812 (98%)]\tLoss: 5.214678\n",
            "Training Loss: 11.3267 Acc: 49.8578\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6254, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 153/200\n",
            "----------\n",
            "Train Epoch: 153 [0/2812 (0%)]\tLoss: 16.639080\n",
            "Train Epoch: 153 [120/2812 (4%)]\tLoss: 9.671839\n",
            "Train Epoch: 153 [240/2812 (9%)]\tLoss: 5.204455\n",
            "Train Epoch: 153 [360/2812 (13%)]\tLoss: 19.952400\n",
            "Train Epoch: 153 [480/2812 (17%)]\tLoss: 6.874743\n",
            "Train Epoch: 153 [600/2812 (21%)]\tLoss: 7.634382\n",
            "Train Epoch: 153 [720/2812 (26%)]\tLoss: 4.814145\n",
            "Train Epoch: 153 [840/2812 (30%)]\tLoss: 15.418291\n",
            "Train Epoch: 153 [960/2812 (34%)]\tLoss: 10.929979\n",
            "Train Epoch: 153 [1080/2812 (38%)]\tLoss: 11.365550\n",
            "Train Epoch: 153 [1200/2812 (43%)]\tLoss: 4.735069\n",
            "Train Epoch: 153 [1320/2812 (47%)]\tLoss: 17.086697\n",
            "Train Epoch: 153 [1440/2812 (51%)]\tLoss: 19.049791\n",
            "Train Epoch: 153 [1560/2812 (55%)]\tLoss: 6.267619\n",
            "Train Epoch: 153 [1680/2812 (60%)]\tLoss: 9.877903\n",
            "Train Epoch: 153 [1800/2812 (64%)]\tLoss: 1.784935\n",
            "Train Epoch: 153 [1920/2812 (68%)]\tLoss: 8.677732\n",
            "Train Epoch: 153 [2040/2812 (72%)]\tLoss: 6.485986\n",
            "Train Epoch: 153 [2160/2812 (77%)]\tLoss: 5.388898\n",
            "Train Epoch: 153 [2280/2812 (81%)]\tLoss: 19.366821\n",
            "Train Epoch: 153 [2400/2812 (85%)]\tLoss: 13.483278\n",
            "Train Epoch: 153 [2520/2812 (89%)]\tLoss: 4.466960\n",
            "Train Epoch: 153 [2640/2812 (94%)]\tLoss: 8.638810\n",
            "Train Epoch: 153 [2760/2812 (98%)]\tLoss: 17.851007\n",
            "Training Loss: 11.1066 Acc: 49.1110\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5753, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 154/200\n",
            "----------\n",
            "Train Epoch: 154 [0/2812 (0%)]\tLoss: 7.241939\n",
            "Train Epoch: 154 [120/2812 (4%)]\tLoss: 10.042837\n",
            "Train Epoch: 154 [240/2812 (9%)]\tLoss: 8.100102\n",
            "Train Epoch: 154 [360/2812 (13%)]\tLoss: 12.210948\n",
            "Train Epoch: 154 [480/2812 (17%)]\tLoss: 6.145314\n",
            "Train Epoch: 154 [600/2812 (21%)]\tLoss: 11.285579\n",
            "Train Epoch: 154 [720/2812 (26%)]\tLoss: 23.837420\n",
            "Train Epoch: 154 [840/2812 (30%)]\tLoss: 8.033829\n",
            "Train Epoch: 154 [960/2812 (34%)]\tLoss: 2.871239\n",
            "Train Epoch: 154 [1080/2812 (38%)]\tLoss: 4.206563\n",
            "Train Epoch: 154 [1200/2812 (43%)]\tLoss: 14.201851\n",
            "Train Epoch: 154 [1320/2812 (47%)]\tLoss: 3.090991\n",
            "Train Epoch: 154 [1440/2812 (51%)]\tLoss: 9.644881\n",
            "Train Epoch: 154 [1560/2812 (55%)]\tLoss: 10.491024\n",
            "Train Epoch: 154 [1680/2812 (60%)]\tLoss: 9.407645\n",
            "Train Epoch: 154 [1800/2812 (64%)]\tLoss: 12.836322\n",
            "Train Epoch: 154 [1920/2812 (68%)]\tLoss: 0.835921\n",
            "Train Epoch: 154 [2040/2812 (72%)]\tLoss: 7.035628\n",
            "Train Epoch: 154 [2160/2812 (77%)]\tLoss: 8.815010\n",
            "Train Epoch: 154 [2280/2812 (81%)]\tLoss: 11.434125\n",
            "Train Epoch: 154 [2400/2812 (85%)]\tLoss: 4.312098\n",
            "Train Epoch: 154 [2520/2812 (89%)]\tLoss: 13.484668\n",
            "Train Epoch: 154 [2640/2812 (94%)]\tLoss: 13.558431\n",
            "Train Epoch: 154 [2760/2812 (98%)]\tLoss: 14.946520\n",
            "Training Loss: 10.9918 Acc: 51.4225\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5766, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 155/200\n",
            "----------\n",
            "Train Epoch: 155 [0/2812 (0%)]\tLoss: 19.436203\n",
            "Train Epoch: 155 [120/2812 (4%)]\tLoss: 12.115531\n",
            "Train Epoch: 155 [240/2812 (9%)]\tLoss: 4.467917\n",
            "Train Epoch: 155 [360/2812 (13%)]\tLoss: 6.747560\n",
            "Train Epoch: 155 [480/2812 (17%)]\tLoss: 15.032423\n",
            "Train Epoch: 155 [600/2812 (21%)]\tLoss: 10.148131\n",
            "Train Epoch: 155 [720/2812 (26%)]\tLoss: 16.867016\n",
            "Train Epoch: 155 [840/2812 (30%)]\tLoss: 14.121359\n",
            "Train Epoch: 155 [960/2812 (34%)]\tLoss: 22.781271\n",
            "Train Epoch: 155 [1080/2812 (38%)]\tLoss: 10.524845\n",
            "Train Epoch: 155 [1200/2812 (43%)]\tLoss: 10.844419\n",
            "Train Epoch: 155 [1320/2812 (47%)]\tLoss: 10.921298\n",
            "Train Epoch: 155 [1440/2812 (51%)]\tLoss: 10.344780\n",
            "Train Epoch: 155 [1560/2812 (55%)]\tLoss: 21.304333\n",
            "Train Epoch: 155 [1680/2812 (60%)]\tLoss: 26.294992\n",
            "Train Epoch: 155 [1800/2812 (64%)]\tLoss: 8.795286\n",
            "Train Epoch: 155 [1920/2812 (68%)]\tLoss: 16.713114\n",
            "Train Epoch: 155 [2040/2812 (72%)]\tLoss: 9.081273\n",
            "Train Epoch: 155 [2160/2812 (77%)]\tLoss: 12.662629\n",
            "Train Epoch: 155 [2280/2812 (81%)]\tLoss: 15.301353\n",
            "Train Epoch: 155 [2400/2812 (85%)]\tLoss: 5.986723\n",
            "Train Epoch: 155 [2520/2812 (89%)]\tLoss: 10.558906\n",
            "Train Epoch: 155 [2640/2812 (94%)]\tLoss: 13.958998\n",
            "Train Epoch: 155 [2760/2812 (98%)]\tLoss: 11.146634\n",
            "Training Loss: 11.0363 Acc: 48.6131\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5681, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 156/200\n",
            "----------\n",
            "Train Epoch: 156 [0/2812 (0%)]\tLoss: 8.528397\n",
            "Train Epoch: 156 [120/2812 (4%)]\tLoss: 6.026555\n",
            "Train Epoch: 156 [240/2812 (9%)]\tLoss: 5.226162\n",
            "Train Epoch: 156 [360/2812 (13%)]\tLoss: 11.359800\n",
            "Train Epoch: 156 [480/2812 (17%)]\tLoss: 11.021161\n",
            "Train Epoch: 156 [600/2812 (21%)]\tLoss: 12.703311\n",
            "Train Epoch: 156 [720/2812 (26%)]\tLoss: 3.667911\n",
            "Train Epoch: 156 [840/2812 (30%)]\tLoss: 7.842488\n",
            "Train Epoch: 156 [960/2812 (34%)]\tLoss: 1.361760\n",
            "Train Epoch: 156 [1080/2812 (38%)]\tLoss: 12.568838\n",
            "Train Epoch: 156 [1200/2812 (43%)]\tLoss: 5.359712\n",
            "Train Epoch: 156 [1320/2812 (47%)]\tLoss: 8.516905\n",
            "Train Epoch: 156 [1440/2812 (51%)]\tLoss: 3.217746\n",
            "Train Epoch: 156 [1560/2812 (55%)]\tLoss: 17.460030\n",
            "Train Epoch: 156 [1680/2812 (60%)]\tLoss: 5.421626\n",
            "Train Epoch: 156 [1800/2812 (64%)]\tLoss: 7.908633\n",
            "Train Epoch: 156 [1920/2812 (68%)]\tLoss: 9.407639\n",
            "Train Epoch: 156 [2040/2812 (72%)]\tLoss: 8.385402\n",
            "Train Epoch: 156 [2160/2812 (77%)]\tLoss: 3.983181\n",
            "Train Epoch: 156 [2280/2812 (81%)]\tLoss: 6.665958\n",
            "Train Epoch: 156 [2400/2812 (85%)]\tLoss: 6.963522\n",
            "Train Epoch: 156 [2520/2812 (89%)]\tLoss: 12.743352\n",
            "Train Epoch: 156 [2640/2812 (94%)]\tLoss: 8.013546\n",
            "Train Epoch: 156 [2760/2812 (98%)]\tLoss: 12.667150\n",
            "Training Loss: 11.2675 Acc: 49.5377\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5191, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 157/200\n",
            "----------\n",
            "Train Epoch: 157 [0/2812 (0%)]\tLoss: 17.359318\n",
            "Train Epoch: 157 [120/2812 (4%)]\tLoss: 11.841566\n",
            "Train Epoch: 157 [240/2812 (9%)]\tLoss: 21.193531\n",
            "Train Epoch: 157 [360/2812 (13%)]\tLoss: 11.559378\n",
            "Train Epoch: 157 [480/2812 (17%)]\tLoss: 9.668263\n",
            "Train Epoch: 157 [600/2812 (21%)]\tLoss: 16.419949\n",
            "Train Epoch: 157 [720/2812 (26%)]\tLoss: 5.870801\n",
            "Train Epoch: 157 [840/2812 (30%)]\tLoss: 16.348560\n",
            "Train Epoch: 157 [960/2812 (34%)]\tLoss: 16.581171\n",
            "Train Epoch: 157 [1080/2812 (38%)]\tLoss: 24.719622\n",
            "Train Epoch: 157 [1200/2812 (43%)]\tLoss: 5.707505\n",
            "Train Epoch: 157 [1320/2812 (47%)]\tLoss: 9.670436\n",
            "Train Epoch: 157 [1440/2812 (51%)]\tLoss: 19.621613\n",
            "Train Epoch: 157 [1560/2812 (55%)]\tLoss: 18.873222\n",
            "Train Epoch: 157 [1680/2812 (60%)]\tLoss: 4.458559\n",
            "Train Epoch: 157 [1800/2812 (64%)]\tLoss: 15.993704\n",
            "Train Epoch: 157 [1920/2812 (68%)]\tLoss: 10.094278\n",
            "Train Epoch: 157 [2040/2812 (72%)]\tLoss: 13.336268\n",
            "Train Epoch: 157 [2160/2812 (77%)]\tLoss: 30.293283\n",
            "Train Epoch: 157 [2280/2812 (81%)]\tLoss: 10.340552\n",
            "Train Epoch: 157 [2400/2812 (85%)]\tLoss: 11.924179\n",
            "Train Epoch: 157 [2520/2812 (89%)]\tLoss: 17.130518\n",
            "Train Epoch: 157 [2640/2812 (94%)]\tLoss: 6.960458\n",
            "Train Epoch: 157 [2760/2812 (98%)]\tLoss: 13.111254\n",
            "Training Loss: 11.2127 Acc: 49.1465\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5844, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 158/200\n",
            "----------\n",
            "Train Epoch: 158 [0/2812 (0%)]\tLoss: 16.300360\n",
            "Train Epoch: 158 [120/2812 (4%)]\tLoss: 12.402575\n",
            "Train Epoch: 158 [240/2812 (9%)]\tLoss: 4.450592\n",
            "Train Epoch: 158 [360/2812 (13%)]\tLoss: 12.982712\n",
            "Train Epoch: 158 [480/2812 (17%)]\tLoss: 7.764224\n",
            "Train Epoch: 158 [600/2812 (21%)]\tLoss: 15.044592\n",
            "Train Epoch: 158 [720/2812 (26%)]\tLoss: 17.966534\n",
            "Train Epoch: 158 [840/2812 (30%)]\tLoss: 13.178049\n",
            "Train Epoch: 158 [960/2812 (34%)]\tLoss: 4.890038\n",
            "Train Epoch: 158 [1080/2812 (38%)]\tLoss: 21.076509\n",
            "Train Epoch: 158 [1200/2812 (43%)]\tLoss: 9.563812\n",
            "Train Epoch: 158 [1320/2812 (47%)]\tLoss: 8.014296\n",
            "Train Epoch: 158 [1440/2812 (51%)]\tLoss: 7.970998\n",
            "Train Epoch: 158 [1560/2812 (55%)]\tLoss: 13.096553\n",
            "Train Epoch: 158 [1680/2812 (60%)]\tLoss: 8.310545\n",
            "Train Epoch: 158 [1800/2812 (64%)]\tLoss: 3.765468\n",
            "Train Epoch: 158 [1920/2812 (68%)]\tLoss: 8.444424\n",
            "Train Epoch: 158 [2040/2812 (72%)]\tLoss: 8.771548\n",
            "Train Epoch: 158 [2160/2812 (77%)]\tLoss: 3.884834\n",
            "Train Epoch: 158 [2280/2812 (81%)]\tLoss: 17.535069\n",
            "Train Epoch: 158 [2400/2812 (85%)]\tLoss: 15.170079\n",
            "Train Epoch: 158 [2520/2812 (89%)]\tLoss: 13.265444\n",
            "Train Epoch: 158 [2640/2812 (94%)]\tLoss: 14.567366\n",
            "Train Epoch: 158 [2760/2812 (98%)]\tLoss: 4.329246\n",
            "Training Loss: 10.9121 Acc: 51.2447\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5825, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 159/200\n",
            "----------\n",
            "Train Epoch: 159 [0/2812 (0%)]\tLoss: 10.787483\n",
            "Train Epoch: 159 [120/2812 (4%)]\tLoss: 3.837806\n",
            "Train Epoch: 159 [240/2812 (9%)]\tLoss: 5.815572\n",
            "Train Epoch: 159 [360/2812 (13%)]\tLoss: 7.130002\n",
            "Train Epoch: 159 [480/2812 (17%)]\tLoss: 10.423696\n",
            "Train Epoch: 159 [600/2812 (21%)]\tLoss: 4.210606\n",
            "Train Epoch: 159 [720/2812 (26%)]\tLoss: 11.099367\n",
            "Train Epoch: 159 [840/2812 (30%)]\tLoss: 24.661341\n",
            "Train Epoch: 159 [960/2812 (34%)]\tLoss: 19.984364\n",
            "Train Epoch: 159 [1080/2812 (38%)]\tLoss: 5.719414\n",
            "Train Epoch: 159 [1200/2812 (43%)]\tLoss: 12.486206\n",
            "Train Epoch: 159 [1320/2812 (47%)]\tLoss: 8.530264\n",
            "Train Epoch: 159 [1440/2812 (51%)]\tLoss: 14.068132\n",
            "Train Epoch: 159 [1560/2812 (55%)]\tLoss: 3.349171\n",
            "Train Epoch: 159 [1680/2812 (60%)]\tLoss: 14.710790\n",
            "Train Epoch: 159 [1800/2812 (64%)]\tLoss: 10.910849\n",
            "Train Epoch: 159 [1920/2812 (68%)]\tLoss: 7.855840\n",
            "Train Epoch: 159 [2040/2812 (72%)]\tLoss: 5.132449\n",
            "Train Epoch: 159 [2160/2812 (77%)]\tLoss: 13.095233\n",
            "Train Epoch: 159 [2280/2812 (81%)]\tLoss: 19.029999\n",
            "Train Epoch: 159 [2400/2812 (85%)]\tLoss: 7.418569\n",
            "Train Epoch: 159 [2520/2812 (89%)]\tLoss: 10.677025\n",
            "Train Epoch: 159 [2640/2812 (94%)]\tLoss: 0.000502\n",
            "Train Epoch: 159 [2760/2812 (98%)]\tLoss: 6.186223\n",
            "Training Loss: 11.0466 Acc: 50.7468\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5936, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 160/200\n",
            "----------\n",
            "Train Epoch: 160 [0/2812 (0%)]\tLoss: 19.079514\n",
            "Train Epoch: 160 [120/2812 (4%)]\tLoss: 7.546060\n",
            "Train Epoch: 160 [240/2812 (9%)]\tLoss: 7.530488\n",
            "Train Epoch: 160 [360/2812 (13%)]\tLoss: 7.068492\n",
            "Train Epoch: 160 [480/2812 (17%)]\tLoss: 11.744243\n",
            "Train Epoch: 160 [600/2812 (21%)]\tLoss: 20.793131\n",
            "Train Epoch: 160 [720/2812 (26%)]\tLoss: 7.333763\n",
            "Train Epoch: 160 [840/2812 (30%)]\tLoss: 9.524041\n",
            "Train Epoch: 160 [960/2812 (34%)]\tLoss: 25.695496\n",
            "Train Epoch: 160 [1080/2812 (38%)]\tLoss: 4.588327\n",
            "Train Epoch: 160 [1200/2812 (43%)]\tLoss: 18.021322\n",
            "Train Epoch: 160 [1320/2812 (47%)]\tLoss: 8.026753\n",
            "Train Epoch: 160 [1440/2812 (51%)]\tLoss: 5.143726\n",
            "Train Epoch: 160 [1560/2812 (55%)]\tLoss: 19.554874\n",
            "Train Epoch: 160 [1680/2812 (60%)]\tLoss: 8.985120\n",
            "Train Epoch: 160 [1800/2812 (64%)]\tLoss: 10.192730\n",
            "Train Epoch: 160 [1920/2812 (68%)]\tLoss: 10.713102\n",
            "Train Epoch: 160 [2040/2812 (72%)]\tLoss: 7.444472\n",
            "Train Epoch: 160 [2160/2812 (77%)]\tLoss: 15.707280\n",
            "Train Epoch: 160 [2280/2812 (81%)]\tLoss: 2.014445\n",
            "Train Epoch: 160 [2400/2812 (85%)]\tLoss: 15.316078\n",
            "Train Epoch: 160 [2520/2812 (89%)]\tLoss: 7.649104\n",
            "Train Epoch: 160 [2640/2812 (94%)]\tLoss: 6.679994\n",
            "Train Epoch: 160 [2760/2812 (98%)]\tLoss: 6.707214\n",
            "Training Loss: 11.3717 Acc: 49.3954\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6230, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 161/200\n",
            "----------\n",
            "Train Epoch: 161 [0/2812 (0%)]\tLoss: 1.517516\n",
            "Train Epoch: 161 [120/2812 (4%)]\tLoss: 23.723940\n",
            "Train Epoch: 161 [240/2812 (9%)]\tLoss: 7.322596\n",
            "Train Epoch: 161 [360/2812 (13%)]\tLoss: 16.594166\n",
            "Train Epoch: 161 [480/2812 (17%)]\tLoss: 10.844036\n",
            "Train Epoch: 161 [600/2812 (21%)]\tLoss: 11.315858\n",
            "Train Epoch: 161 [720/2812 (26%)]\tLoss: 17.863583\n",
            "Train Epoch: 161 [840/2812 (30%)]\tLoss: 9.664266\n",
            "Train Epoch: 161 [960/2812 (34%)]\tLoss: 12.161791\n",
            "Train Epoch: 161 [1080/2812 (38%)]\tLoss: 10.362138\n",
            "Train Epoch: 161 [1200/2812 (43%)]\tLoss: 14.544398\n",
            "Train Epoch: 161 [1320/2812 (47%)]\tLoss: 13.990390\n",
            "Train Epoch: 161 [1440/2812 (51%)]\tLoss: 2.469419\n",
            "Train Epoch: 161 [1560/2812 (55%)]\tLoss: 6.588251\n",
            "Train Epoch: 161 [1680/2812 (60%)]\tLoss: 10.904172\n",
            "Train Epoch: 161 [1800/2812 (64%)]\tLoss: 7.806980\n",
            "Train Epoch: 161 [1920/2812 (68%)]\tLoss: 16.531475\n",
            "Train Epoch: 161 [2040/2812 (72%)]\tLoss: 8.186499\n",
            "Train Epoch: 161 [2160/2812 (77%)]\tLoss: 7.398798\n",
            "Train Epoch: 161 [2280/2812 (81%)]\tLoss: 9.353778\n",
            "Train Epoch: 161 [2400/2812 (85%)]\tLoss: 5.354143\n",
            "Train Epoch: 161 [2520/2812 (89%)]\tLoss: 9.804804\n",
            "Train Epoch: 161 [2640/2812 (94%)]\tLoss: 1.965838\n",
            "Train Epoch: 161 [2760/2812 (98%)]\tLoss: 13.199896\n",
            "Training Loss: 11.0870 Acc: 50.0000\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6237, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 162/200\n",
            "----------\n",
            "Train Epoch: 162 [0/2812 (0%)]\tLoss: 23.062286\n",
            "Train Epoch: 162 [120/2812 (4%)]\tLoss: 19.288937\n",
            "Train Epoch: 162 [240/2812 (9%)]\tLoss: 21.248753\n",
            "Train Epoch: 162 [360/2812 (13%)]\tLoss: 9.805804\n",
            "Train Epoch: 162 [480/2812 (17%)]\tLoss: 10.426353\n",
            "Train Epoch: 162 [600/2812 (21%)]\tLoss: 6.735205\n",
            "Train Epoch: 162 [720/2812 (26%)]\tLoss: 0.427229\n",
            "Train Epoch: 162 [840/2812 (30%)]\tLoss: 5.046791\n",
            "Train Epoch: 162 [960/2812 (34%)]\tLoss: 14.898130\n",
            "Train Epoch: 162 [1080/2812 (38%)]\tLoss: 1.681034\n",
            "Train Epoch: 162 [1200/2812 (43%)]\tLoss: 9.665470\n",
            "Train Epoch: 162 [1320/2812 (47%)]\tLoss: 18.581331\n",
            "Train Epoch: 162 [1440/2812 (51%)]\tLoss: 2.617865\n",
            "Train Epoch: 162 [1560/2812 (55%)]\tLoss: 1.673349\n",
            "Train Epoch: 162 [1680/2812 (60%)]\tLoss: 2.106338\n",
            "Train Epoch: 162 [1800/2812 (64%)]\tLoss: 5.222322\n",
            "Train Epoch: 162 [1920/2812 (68%)]\tLoss: 11.913634\n",
            "Train Epoch: 162 [2040/2812 (72%)]\tLoss: 8.621909\n",
            "Train Epoch: 162 [2160/2812 (77%)]\tLoss: 11.025167\n",
            "Train Epoch: 162 [2280/2812 (81%)]\tLoss: 16.065718\n",
            "Train Epoch: 162 [2400/2812 (85%)]\tLoss: 17.524750\n",
            "Train Epoch: 162 [2520/2812 (89%)]\tLoss: 8.018307\n",
            "Train Epoch: 162 [2640/2812 (94%)]\tLoss: 16.163113\n",
            "Train Epoch: 162 [2760/2812 (98%)]\tLoss: 15.022967\n",
            "Training Loss: 10.9182 Acc: 50.1778\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5950, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 163/200\n",
            "----------\n",
            "Train Epoch: 163 [0/2812 (0%)]\tLoss: 3.440960\n",
            "Train Epoch: 163 [120/2812 (4%)]\tLoss: 20.889444\n",
            "Train Epoch: 163 [240/2812 (9%)]\tLoss: 9.191263\n",
            "Train Epoch: 163 [360/2812 (13%)]\tLoss: 4.482865\n",
            "Train Epoch: 163 [480/2812 (17%)]\tLoss: 11.893370\n",
            "Train Epoch: 163 [600/2812 (21%)]\tLoss: 11.127771\n",
            "Train Epoch: 163 [720/2812 (26%)]\tLoss: 10.104796\n",
            "Train Epoch: 163 [840/2812 (30%)]\tLoss: 9.868254\n",
            "Train Epoch: 163 [960/2812 (34%)]\tLoss: 8.474801\n",
            "Train Epoch: 163 [1080/2812 (38%)]\tLoss: 3.111917\n",
            "Train Epoch: 163 [1200/2812 (43%)]\tLoss: 17.081715\n",
            "Train Epoch: 163 [1320/2812 (47%)]\tLoss: 11.830782\n",
            "Train Epoch: 163 [1440/2812 (51%)]\tLoss: 9.320108\n",
            "Train Epoch: 163 [1560/2812 (55%)]\tLoss: 13.658342\n",
            "Train Epoch: 163 [1680/2812 (60%)]\tLoss: 7.073827\n",
            "Train Epoch: 163 [1800/2812 (64%)]\tLoss: 16.338274\n",
            "Train Epoch: 163 [1920/2812 (68%)]\tLoss: 8.504578\n",
            "Train Epoch: 163 [2040/2812 (72%)]\tLoss: 12.584549\n",
            "Train Epoch: 163 [2160/2812 (77%)]\tLoss: 6.495843\n",
            "Train Epoch: 163 [2280/2812 (81%)]\tLoss: 8.981201\n",
            "Train Epoch: 163 [2400/2812 (85%)]\tLoss: 4.508220\n",
            "Train Epoch: 163 [2520/2812 (89%)]\tLoss: 13.287607\n",
            "Train Epoch: 163 [2640/2812 (94%)]\tLoss: 13.218889\n",
            "Train Epoch: 163 [2760/2812 (98%)]\tLoss: 3.178174\n",
            "Training Loss: 10.6577 Acc: 50.4267\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6036, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 164/200\n",
            "----------\n",
            "Train Epoch: 164 [0/2812 (0%)]\tLoss: 9.266974\n",
            "Train Epoch: 164 [120/2812 (4%)]\tLoss: 8.894113\n",
            "Train Epoch: 164 [240/2812 (9%)]\tLoss: 16.533264\n",
            "Train Epoch: 164 [360/2812 (13%)]\tLoss: 20.432064\n",
            "Train Epoch: 164 [480/2812 (17%)]\tLoss: 12.393667\n",
            "Train Epoch: 164 [600/2812 (21%)]\tLoss: 14.282782\n",
            "Train Epoch: 164 [720/2812 (26%)]\tLoss: 12.361402\n",
            "Train Epoch: 164 [840/2812 (30%)]\tLoss: 11.856279\n",
            "Train Epoch: 164 [960/2812 (34%)]\tLoss: 4.346532\n",
            "Train Epoch: 164 [1080/2812 (38%)]\tLoss: 20.045803\n",
            "Train Epoch: 164 [1200/2812 (43%)]\tLoss: 6.905322\n",
            "Train Epoch: 164 [1320/2812 (47%)]\tLoss: 9.570150\n",
            "Train Epoch: 164 [1440/2812 (51%)]\tLoss: 18.414310\n",
            "Train Epoch: 164 [1560/2812 (55%)]\tLoss: 8.511813\n",
            "Train Epoch: 164 [1680/2812 (60%)]\tLoss: 6.210956\n",
            "Train Epoch: 164 [1800/2812 (64%)]\tLoss: 20.781734\n",
            "Train Epoch: 164 [1920/2812 (68%)]\tLoss: 15.238757\n",
            "Train Epoch: 164 [2040/2812 (72%)]\tLoss: 18.677853\n",
            "Train Epoch: 164 [2160/2812 (77%)]\tLoss: 4.909505\n",
            "Train Epoch: 164 [2280/2812 (81%)]\tLoss: 9.155806\n",
            "Train Epoch: 164 [2400/2812 (85%)]\tLoss: 11.370333\n",
            "Train Epoch: 164 [2520/2812 (89%)]\tLoss: 9.598528\n",
            "Train Epoch: 164 [2640/2812 (94%)]\tLoss: 11.854935\n",
            "Train Epoch: 164 [2760/2812 (98%)]\tLoss: 11.315630\n",
            "Training Loss: 11.2114 Acc: 49.8222\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6089, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 165/200\n",
            "----------\n",
            "Train Epoch: 165 [0/2812 (0%)]\tLoss: 3.265059\n",
            "Train Epoch: 165 [120/2812 (4%)]\tLoss: 13.920163\n",
            "Train Epoch: 165 [240/2812 (9%)]\tLoss: 4.635499\n",
            "Train Epoch: 165 [360/2812 (13%)]\tLoss: 8.218595\n",
            "Train Epoch: 165 [480/2812 (17%)]\tLoss: 1.721120\n",
            "Train Epoch: 165 [600/2812 (21%)]\tLoss: 8.615606\n",
            "Train Epoch: 165 [720/2812 (26%)]\tLoss: 13.388309\n",
            "Train Epoch: 165 [840/2812 (30%)]\tLoss: 14.712843\n",
            "Train Epoch: 165 [960/2812 (34%)]\tLoss: 16.689020\n",
            "Train Epoch: 165 [1080/2812 (38%)]\tLoss: 12.171422\n",
            "Train Epoch: 165 [1200/2812 (43%)]\tLoss: 15.385701\n",
            "Train Epoch: 165 [1320/2812 (47%)]\tLoss: 3.382884\n",
            "Train Epoch: 165 [1440/2812 (51%)]\tLoss: 4.925198\n",
            "Train Epoch: 165 [1560/2812 (55%)]\tLoss: 9.412392\n",
            "Train Epoch: 165 [1680/2812 (60%)]\tLoss: 9.761604\n",
            "Train Epoch: 165 [1800/2812 (64%)]\tLoss: 18.952459\n",
            "Train Epoch: 165 [1920/2812 (68%)]\tLoss: 11.679225\n",
            "Train Epoch: 165 [2040/2812 (72%)]\tLoss: 14.148249\n",
            "Train Epoch: 165 [2160/2812 (77%)]\tLoss: 4.737654\n",
            "Train Epoch: 165 [2280/2812 (81%)]\tLoss: 2.253353\n",
            "Train Epoch: 165 [2400/2812 (85%)]\tLoss: 5.190097\n",
            "Train Epoch: 165 [2520/2812 (89%)]\tLoss: 2.445655\n",
            "Train Epoch: 165 [2640/2812 (94%)]\tLoss: 25.774164\n",
            "Train Epoch: 165 [2760/2812 (98%)]\tLoss: 11.653498\n",
            "Training Loss: 11.0089 Acc: 49.5021\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5900, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 166/200\n",
            "----------\n",
            "Train Epoch: 166 [0/2812 (0%)]\tLoss: 7.282134\n",
            "Train Epoch: 166 [120/2812 (4%)]\tLoss: 5.871174\n",
            "Train Epoch: 166 [240/2812 (9%)]\tLoss: 3.821142\n",
            "Train Epoch: 166 [360/2812 (13%)]\tLoss: 8.915019\n",
            "Train Epoch: 166 [480/2812 (17%)]\tLoss: 20.874695\n",
            "Train Epoch: 166 [600/2812 (21%)]\tLoss: 4.867858\n",
            "Train Epoch: 166 [720/2812 (26%)]\tLoss: 13.363237\n",
            "Train Epoch: 166 [840/2812 (30%)]\tLoss: 5.306552\n",
            "Train Epoch: 166 [960/2812 (34%)]\tLoss: 12.572066\n",
            "Train Epoch: 166 [1080/2812 (38%)]\tLoss: 25.941467\n",
            "Train Epoch: 166 [1200/2812 (43%)]\tLoss: 15.586426\n",
            "Train Epoch: 166 [1320/2812 (47%)]\tLoss: 9.621425\n",
            "Train Epoch: 166 [1440/2812 (51%)]\tLoss: 12.716366\n",
            "Train Epoch: 166 [1560/2812 (55%)]\tLoss: 12.140882\n",
            "Train Epoch: 166 [1680/2812 (60%)]\tLoss: 17.603483\n",
            "Train Epoch: 166 [1800/2812 (64%)]\tLoss: 18.407843\n",
            "Train Epoch: 166 [1920/2812 (68%)]\tLoss: 4.218089\n",
            "Train Epoch: 166 [2040/2812 (72%)]\tLoss: 8.081344\n",
            "Train Epoch: 166 [2160/2812 (77%)]\tLoss: 12.787542\n",
            "Train Epoch: 166 [2280/2812 (81%)]\tLoss: 11.531351\n",
            "Train Epoch: 166 [2400/2812 (85%)]\tLoss: 6.194388\n",
            "Train Epoch: 166 [2520/2812 (89%)]\tLoss: 16.382807\n",
            "Train Epoch: 166 [2640/2812 (94%)]\tLoss: 13.201098\n",
            "Train Epoch: 166 [2760/2812 (98%)]\tLoss: 13.323422\n",
            "Training Loss: 11.2315 Acc: 50.2134\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5806, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 167/200\n",
            "----------\n",
            "Train Epoch: 167 [0/2812 (0%)]\tLoss: 18.113770\n",
            "Train Epoch: 167 [120/2812 (4%)]\tLoss: 12.724761\n",
            "Train Epoch: 167 [240/2812 (9%)]\tLoss: 11.002893\n",
            "Train Epoch: 167 [360/2812 (13%)]\tLoss: 5.805018\n",
            "Train Epoch: 167 [480/2812 (17%)]\tLoss: 6.158556\n",
            "Train Epoch: 167 [600/2812 (21%)]\tLoss: 8.932455\n",
            "Train Epoch: 167 [720/2812 (26%)]\tLoss: 5.654894\n",
            "Train Epoch: 167 [840/2812 (30%)]\tLoss: 13.240316\n",
            "Train Epoch: 167 [960/2812 (34%)]\tLoss: 3.811928\n",
            "Train Epoch: 167 [1080/2812 (38%)]\tLoss: 7.529914\n",
            "Train Epoch: 167 [1200/2812 (43%)]\tLoss: 12.920649\n",
            "Train Epoch: 167 [1320/2812 (47%)]\tLoss: 3.388077\n",
            "Train Epoch: 167 [1440/2812 (51%)]\tLoss: 7.991427\n",
            "Train Epoch: 167 [1560/2812 (55%)]\tLoss: 3.004919\n",
            "Train Epoch: 167 [1680/2812 (60%)]\tLoss: 6.897098\n",
            "Train Epoch: 167 [1800/2812 (64%)]\tLoss: 1.557983\n",
            "Train Epoch: 167 [1920/2812 (68%)]\tLoss: 7.032164\n",
            "Train Epoch: 167 [2040/2812 (72%)]\tLoss: 3.563644\n",
            "Train Epoch: 167 [2160/2812 (77%)]\tLoss: 5.631263\n",
            "Train Epoch: 167 [2280/2812 (81%)]\tLoss: 8.437170\n",
            "Train Epoch: 167 [2400/2812 (85%)]\tLoss: 7.663274\n",
            "Train Epoch: 167 [2520/2812 (89%)]\tLoss: 1.113840\n",
            "Train Epoch: 167 [2640/2812 (94%)]\tLoss: 12.969320\n",
            "Train Epoch: 167 [2760/2812 (98%)]\tLoss: 11.176772\n",
            "Training Loss: 11.2197 Acc: 49.7511\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5438, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 168/200\n",
            "----------\n",
            "Train Epoch: 168 [0/2812 (0%)]\tLoss: 15.698977\n",
            "Train Epoch: 168 [120/2812 (4%)]\tLoss: 11.036328\n",
            "Train Epoch: 168 [240/2812 (9%)]\tLoss: 16.862644\n",
            "Train Epoch: 168 [360/2812 (13%)]\tLoss: 2.726296\n",
            "Train Epoch: 168 [480/2812 (17%)]\tLoss: 10.313796\n",
            "Train Epoch: 168 [600/2812 (21%)]\tLoss: 10.420534\n",
            "Train Epoch: 168 [720/2812 (26%)]\tLoss: 6.164561\n",
            "Train Epoch: 168 [840/2812 (30%)]\tLoss: 15.275047\n",
            "Train Epoch: 168 [960/2812 (34%)]\tLoss: 9.017203\n",
            "Train Epoch: 168 [1080/2812 (38%)]\tLoss: 7.648234\n",
            "Train Epoch: 168 [1200/2812 (43%)]\tLoss: 2.053888\n",
            "Train Epoch: 168 [1320/2812 (47%)]\tLoss: 13.759504\n",
            "Train Epoch: 168 [1440/2812 (51%)]\tLoss: 15.633232\n",
            "Train Epoch: 168 [1560/2812 (55%)]\tLoss: 6.902667\n",
            "Train Epoch: 168 [1680/2812 (60%)]\tLoss: 15.130826\n",
            "Train Epoch: 168 [1800/2812 (64%)]\tLoss: 12.365345\n",
            "Train Epoch: 168 [1920/2812 (68%)]\tLoss: 4.506434\n",
            "Train Epoch: 168 [2040/2812 (72%)]\tLoss: 3.878167\n",
            "Train Epoch: 168 [2160/2812 (77%)]\tLoss: 12.945215\n",
            "Train Epoch: 168 [2280/2812 (81%)]\tLoss: 7.844395\n",
            "Train Epoch: 168 [2400/2812 (85%)]\tLoss: 17.563526\n",
            "Train Epoch: 168 [2520/2812 (89%)]\tLoss: 10.166462\n",
            "Train Epoch: 168 [2640/2812 (94%)]\tLoss: 6.814512\n",
            "Train Epoch: 168 [2760/2812 (98%)]\tLoss: 20.667187\n",
            "Training Loss: 10.7576 Acc: 50.2134\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5897, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 169/200\n",
            "----------\n",
            "Train Epoch: 169 [0/2812 (0%)]\tLoss: 12.291423\n",
            "Train Epoch: 169 [120/2812 (4%)]\tLoss: 4.847079\n",
            "Train Epoch: 169 [240/2812 (9%)]\tLoss: 12.952719\n",
            "Train Epoch: 169 [360/2812 (13%)]\tLoss: 9.127011\n",
            "Train Epoch: 169 [480/2812 (17%)]\tLoss: 11.310823\n",
            "Train Epoch: 169 [600/2812 (21%)]\tLoss: 6.377659\n",
            "Train Epoch: 169 [720/2812 (26%)]\tLoss: 5.581948\n",
            "Train Epoch: 169 [840/2812 (30%)]\tLoss: 7.311686\n",
            "Train Epoch: 169 [960/2812 (34%)]\tLoss: 1.460991\n",
            "Train Epoch: 169 [1080/2812 (38%)]\tLoss: 18.997562\n",
            "Train Epoch: 169 [1200/2812 (43%)]\tLoss: 11.190120\n",
            "Train Epoch: 169 [1320/2812 (47%)]\tLoss: 24.573887\n",
            "Train Epoch: 169 [1440/2812 (51%)]\tLoss: 28.220409\n",
            "Train Epoch: 169 [1560/2812 (55%)]\tLoss: 13.167346\n",
            "Train Epoch: 169 [1680/2812 (60%)]\tLoss: 7.471065\n",
            "Train Epoch: 169 [1800/2812 (64%)]\tLoss: 7.049430\n",
            "Train Epoch: 169 [1920/2812 (68%)]\tLoss: 10.452363\n",
            "Train Epoch: 169 [2040/2812 (72%)]\tLoss: 2.682819\n",
            "Train Epoch: 169 [2160/2812 (77%)]\tLoss: 10.461641\n",
            "Train Epoch: 169 [2280/2812 (81%)]\tLoss: 10.263968\n",
            "Train Epoch: 169 [2400/2812 (85%)]\tLoss: 4.813375\n",
            "Train Epoch: 169 [2520/2812 (89%)]\tLoss: 12.434070\n",
            "Train Epoch: 169 [2640/2812 (94%)]\tLoss: 6.029054\n",
            "Train Epoch: 169 [2760/2812 (98%)]\tLoss: 10.935259\n",
            "Training Loss: 11.3385 Acc: 48.5420\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5351, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 170/200\n",
            "----------\n",
            "Train Epoch: 170 [0/2812 (0%)]\tLoss: 7.318971\n",
            "Train Epoch: 170 [120/2812 (4%)]\tLoss: 8.000557\n",
            "Train Epoch: 170 [240/2812 (9%)]\tLoss: 1.500468\n",
            "Train Epoch: 170 [360/2812 (13%)]\tLoss: 7.258493\n",
            "Train Epoch: 170 [480/2812 (17%)]\tLoss: 8.153265\n",
            "Train Epoch: 170 [600/2812 (21%)]\tLoss: 23.453114\n",
            "Train Epoch: 170 [720/2812 (26%)]\tLoss: 5.767653\n",
            "Train Epoch: 170 [840/2812 (30%)]\tLoss: 8.933652\n",
            "Train Epoch: 170 [960/2812 (34%)]\tLoss: 13.863586\n",
            "Train Epoch: 170 [1080/2812 (38%)]\tLoss: 12.823515\n",
            "Train Epoch: 170 [1200/2812 (43%)]\tLoss: 13.922290\n",
            "Train Epoch: 170 [1320/2812 (47%)]\tLoss: 7.042857\n",
            "Train Epoch: 170 [1440/2812 (51%)]\tLoss: 15.746199\n",
            "Train Epoch: 170 [1560/2812 (55%)]\tLoss: 6.553182\n",
            "Train Epoch: 170 [1680/2812 (60%)]\tLoss: 15.970224\n",
            "Train Epoch: 170 [1800/2812 (64%)]\tLoss: 15.051590\n",
            "Train Epoch: 170 [1920/2812 (68%)]\tLoss: 9.084003\n",
            "Train Epoch: 170 [2040/2812 (72%)]\tLoss: 28.531078\n",
            "Train Epoch: 170 [2160/2812 (77%)]\tLoss: 6.394792\n",
            "Train Epoch: 170 [2280/2812 (81%)]\tLoss: 10.609055\n",
            "Train Epoch: 170 [2400/2812 (85%)]\tLoss: 14.871431\n",
            "Train Epoch: 170 [2520/2812 (89%)]\tLoss: 6.318517\n",
            "Train Epoch: 170 [2640/2812 (94%)]\tLoss: 15.691736\n",
            "Train Epoch: 170 [2760/2812 (98%)]\tLoss: 18.226721\n",
            "Training Loss: 11.1887 Acc: 50.5690\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5520, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 171/200\n",
            "----------\n",
            "Train Epoch: 171 [0/2812 (0%)]\tLoss: 7.873315\n",
            "Train Epoch: 171 [120/2812 (4%)]\tLoss: 9.369154\n",
            "Train Epoch: 171 [240/2812 (9%)]\tLoss: 17.519964\n",
            "Train Epoch: 171 [360/2812 (13%)]\tLoss: 13.137598\n",
            "Train Epoch: 171 [480/2812 (17%)]\tLoss: 5.431094\n",
            "Train Epoch: 171 [600/2812 (21%)]\tLoss: 13.590466\n",
            "Train Epoch: 171 [720/2812 (26%)]\tLoss: 10.895914\n",
            "Train Epoch: 171 [840/2812 (30%)]\tLoss: 7.186774\n",
            "Train Epoch: 171 [960/2812 (34%)]\tLoss: 7.640723\n",
            "Train Epoch: 171 [1080/2812 (38%)]\tLoss: 9.606756\n",
            "Train Epoch: 171 [1200/2812 (43%)]\tLoss: 7.686906\n",
            "Train Epoch: 171 [1320/2812 (47%)]\tLoss: 9.677431\n",
            "Train Epoch: 171 [1440/2812 (51%)]\tLoss: 9.659369\n",
            "Train Epoch: 171 [1560/2812 (55%)]\tLoss: 10.003481\n",
            "Train Epoch: 171 [1680/2812 (60%)]\tLoss: 18.863592\n",
            "Train Epoch: 171 [1800/2812 (64%)]\tLoss: 6.295861\n",
            "Train Epoch: 171 [1920/2812 (68%)]\tLoss: 12.514188\n",
            "Train Epoch: 171 [2040/2812 (72%)]\tLoss: 20.009748\n",
            "Train Epoch: 171 [2160/2812 (77%)]\tLoss: 20.906456\n",
            "Train Epoch: 171 [2280/2812 (81%)]\tLoss: 2.625188\n",
            "Train Epoch: 171 [2400/2812 (85%)]\tLoss: 7.041174\n",
            "Train Epoch: 171 [2520/2812 (89%)]\tLoss: 12.117185\n",
            "Train Epoch: 171 [2640/2812 (94%)]\tLoss: 14.109576\n",
            "Train Epoch: 171 [2760/2812 (98%)]\tLoss: 10.981965\n",
            "Training Loss: 11.1458 Acc: 49.1821\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6162, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 172/200\n",
            "----------\n",
            "Train Epoch: 172 [0/2812 (0%)]\tLoss: 10.435221\n",
            "Train Epoch: 172 [120/2812 (4%)]\tLoss: 16.013578\n",
            "Train Epoch: 172 [240/2812 (9%)]\tLoss: 7.378285\n",
            "Train Epoch: 172 [360/2812 (13%)]\tLoss: 11.624583\n",
            "Train Epoch: 172 [480/2812 (17%)]\tLoss: 10.577640\n",
            "Train Epoch: 172 [600/2812 (21%)]\tLoss: 6.224958\n",
            "Train Epoch: 172 [720/2812 (26%)]\tLoss: 17.739887\n",
            "Train Epoch: 172 [840/2812 (30%)]\tLoss: 2.729804\n",
            "Train Epoch: 172 [960/2812 (34%)]\tLoss: 3.383822\n",
            "Train Epoch: 172 [1080/2812 (38%)]\tLoss: 8.175301\n",
            "Train Epoch: 172 [1200/2812 (43%)]\tLoss: 8.546091\n",
            "Train Epoch: 172 [1320/2812 (47%)]\tLoss: 17.911489\n",
            "Train Epoch: 172 [1440/2812 (51%)]\tLoss: 15.485861\n",
            "Train Epoch: 172 [1560/2812 (55%)]\tLoss: 19.739925\n",
            "Train Epoch: 172 [1680/2812 (60%)]\tLoss: 13.213971\n",
            "Train Epoch: 172 [1800/2812 (64%)]\tLoss: 7.857638\n",
            "Train Epoch: 172 [1920/2812 (68%)]\tLoss: 9.376490\n",
            "Train Epoch: 172 [2040/2812 (72%)]\tLoss: 4.788665\n",
            "Train Epoch: 172 [2160/2812 (77%)]\tLoss: 17.677826\n",
            "Train Epoch: 172 [2280/2812 (81%)]\tLoss: 19.903439\n",
            "Train Epoch: 172 [2400/2812 (85%)]\tLoss: 11.129936\n",
            "Train Epoch: 172 [2520/2812 (89%)]\tLoss: 14.018393\n",
            "Train Epoch: 172 [2640/2812 (94%)]\tLoss: 12.465371\n",
            "Train Epoch: 172 [2760/2812 (98%)]\tLoss: 23.236763\n",
            "Training Loss: 11.0794 Acc: 49.4666\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5817, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 173/200\n",
            "----------\n",
            "Train Epoch: 173 [0/2812 (0%)]\tLoss: 11.363272\n",
            "Train Epoch: 173 [120/2812 (4%)]\tLoss: 3.701907\n",
            "Train Epoch: 173 [240/2812 (9%)]\tLoss: 9.026799\n",
            "Train Epoch: 173 [360/2812 (13%)]\tLoss: 4.471587\n",
            "Train Epoch: 173 [480/2812 (17%)]\tLoss: 6.641642\n",
            "Train Epoch: 173 [600/2812 (21%)]\tLoss: 3.856529\n",
            "Train Epoch: 173 [720/2812 (26%)]\tLoss: 13.804662\n",
            "Train Epoch: 173 [840/2812 (30%)]\tLoss: 11.874218\n",
            "Train Epoch: 173 [960/2812 (34%)]\tLoss: 19.061062\n",
            "Train Epoch: 173 [1080/2812 (38%)]\tLoss: 13.207193\n",
            "Train Epoch: 173 [1200/2812 (43%)]\tLoss: 6.194039\n",
            "Train Epoch: 173 [1320/2812 (47%)]\tLoss: 8.225701\n",
            "Train Epoch: 173 [1440/2812 (51%)]\tLoss: 3.758939\n",
            "Train Epoch: 173 [1560/2812 (55%)]\tLoss: 13.181625\n",
            "Train Epoch: 173 [1680/2812 (60%)]\tLoss: 4.810647\n",
            "Train Epoch: 173 [1800/2812 (64%)]\tLoss: 12.941309\n",
            "Train Epoch: 173 [1920/2812 (68%)]\tLoss: 9.642692\n",
            "Train Epoch: 173 [2040/2812 (72%)]\tLoss: 3.691266\n",
            "Train Epoch: 173 [2160/2812 (77%)]\tLoss: 7.593398\n",
            "Train Epoch: 173 [2280/2812 (81%)]\tLoss: 3.634520\n",
            "Train Epoch: 173 [2400/2812 (85%)]\tLoss: 5.924195\n",
            "Train Epoch: 173 [2520/2812 (89%)]\tLoss: 10.524390\n",
            "Train Epoch: 173 [2640/2812 (94%)]\tLoss: 13.951322\n",
            "Train Epoch: 173 [2760/2812 (98%)]\tLoss: 10.700076\n",
            "Training Loss: 11.5319 Acc: 48.9331\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5778, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 174/200\n",
            "----------\n",
            "Train Epoch: 174 [0/2812 (0%)]\tLoss: 3.501227\n",
            "Train Epoch: 174 [120/2812 (4%)]\tLoss: 10.550261\n",
            "Train Epoch: 174 [240/2812 (9%)]\tLoss: 15.053503\n",
            "Train Epoch: 174 [360/2812 (13%)]\tLoss: 13.665563\n",
            "Train Epoch: 174 [480/2812 (17%)]\tLoss: 10.625998\n",
            "Train Epoch: 174 [600/2812 (21%)]\tLoss: 2.496929\n",
            "Train Epoch: 174 [720/2812 (26%)]\tLoss: 6.088182\n",
            "Train Epoch: 174 [840/2812 (30%)]\tLoss: 12.405077\n",
            "Train Epoch: 174 [960/2812 (34%)]\tLoss: 3.270027\n",
            "Train Epoch: 174 [1080/2812 (38%)]\tLoss: 7.583095\n",
            "Train Epoch: 174 [1200/2812 (43%)]\tLoss: 11.748260\n",
            "Train Epoch: 174 [1320/2812 (47%)]\tLoss: 11.120328\n",
            "Train Epoch: 174 [1440/2812 (51%)]\tLoss: 11.963537\n",
            "Train Epoch: 174 [1560/2812 (55%)]\tLoss: 22.471472\n",
            "Train Epoch: 174 [1680/2812 (60%)]\tLoss: 10.006085\n",
            "Train Epoch: 174 [1800/2812 (64%)]\tLoss: 16.022610\n",
            "Train Epoch: 174 [1920/2812 (68%)]\tLoss: 6.662678\n",
            "Train Epoch: 174 [2040/2812 (72%)]\tLoss: 16.441872\n",
            "Train Epoch: 174 [2160/2812 (77%)]\tLoss: 9.086138\n",
            "Train Epoch: 174 [2280/2812 (81%)]\tLoss: 12.022667\n",
            "Train Epoch: 174 [2400/2812 (85%)]\tLoss: 22.210394\n",
            "Train Epoch: 174 [2520/2812 (89%)]\tLoss: 10.172055\n",
            "Train Epoch: 174 [2640/2812 (94%)]\tLoss: 16.509174\n",
            "Train Epoch: 174 [2760/2812 (98%)]\tLoss: 12.734661\n",
            "Training Loss: 11.1121 Acc: 48.8976\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5622, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 175/200\n",
            "----------\n",
            "Train Epoch: 175 [0/2812 (0%)]\tLoss: 10.743552\n",
            "Train Epoch: 175 [120/2812 (4%)]\tLoss: 7.888101\n",
            "Train Epoch: 175 [240/2812 (9%)]\tLoss: 10.258213\n",
            "Train Epoch: 175 [360/2812 (13%)]\tLoss: 11.023516\n",
            "Train Epoch: 175 [480/2812 (17%)]\tLoss: 9.768654\n",
            "Train Epoch: 175 [600/2812 (21%)]\tLoss: 14.920110\n",
            "Train Epoch: 175 [720/2812 (26%)]\tLoss: 8.333109\n",
            "Train Epoch: 175 [840/2812 (30%)]\tLoss: 13.460231\n",
            "Train Epoch: 175 [960/2812 (34%)]\tLoss: 4.746369\n",
            "Train Epoch: 175 [1080/2812 (38%)]\tLoss: 28.492468\n",
            "Train Epoch: 175 [1200/2812 (43%)]\tLoss: 10.438848\n",
            "Train Epoch: 175 [1320/2812 (47%)]\tLoss: 7.029599\n",
            "Train Epoch: 175 [1440/2812 (51%)]\tLoss: 8.675997\n",
            "Train Epoch: 175 [1560/2812 (55%)]\tLoss: 4.264977\n",
            "Train Epoch: 175 [1680/2812 (60%)]\tLoss: 3.598629\n",
            "Train Epoch: 175 [1800/2812 (64%)]\tLoss: 9.984881\n",
            "Train Epoch: 175 [1920/2812 (68%)]\tLoss: 11.257824\n",
            "Train Epoch: 175 [2040/2812 (72%)]\tLoss: 6.302858\n",
            "Train Epoch: 175 [2160/2812 (77%)]\tLoss: 11.757174\n",
            "Train Epoch: 175 [2280/2812 (81%)]\tLoss: 12.745384\n",
            "Train Epoch: 175 [2400/2812 (85%)]\tLoss: 12.417434\n",
            "Train Epoch: 175 [2520/2812 (89%)]\tLoss: 13.474821\n",
            "Train Epoch: 175 [2640/2812 (94%)]\tLoss: 15.877123\n",
            "Train Epoch: 175 [2760/2812 (98%)]\tLoss: 11.087034\n",
            "Training Loss: 11.0720 Acc: 49.7866\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5791, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 176/200\n",
            "----------\n",
            "Train Epoch: 176 [0/2812 (0%)]\tLoss: 9.954371\n",
            "Train Epoch: 176 [120/2812 (4%)]\tLoss: 14.471062\n",
            "Train Epoch: 176 [240/2812 (9%)]\tLoss: 6.049369\n",
            "Train Epoch: 176 [360/2812 (13%)]\tLoss: 15.421259\n",
            "Train Epoch: 176 [480/2812 (17%)]\tLoss: 9.374490\n",
            "Train Epoch: 176 [600/2812 (21%)]\tLoss: 3.894479\n",
            "Train Epoch: 176 [720/2812 (26%)]\tLoss: 8.628467\n",
            "Train Epoch: 176 [840/2812 (30%)]\tLoss: 19.361683\n",
            "Train Epoch: 176 [960/2812 (34%)]\tLoss: 10.267764\n",
            "Train Epoch: 176 [1080/2812 (38%)]\tLoss: 9.346926\n",
            "Train Epoch: 176 [1200/2812 (43%)]\tLoss: 9.762621\n",
            "Train Epoch: 176 [1320/2812 (47%)]\tLoss: 7.989379\n",
            "Train Epoch: 176 [1440/2812 (51%)]\tLoss: 11.881665\n",
            "Train Epoch: 176 [1560/2812 (55%)]\tLoss: 9.088148\n",
            "Train Epoch: 176 [1680/2812 (60%)]\tLoss: 17.044567\n",
            "Train Epoch: 176 [1800/2812 (64%)]\tLoss: 6.366957\n",
            "Train Epoch: 176 [1920/2812 (68%)]\tLoss: 16.268230\n",
            "Train Epoch: 176 [2040/2812 (72%)]\tLoss: 9.046218\n",
            "Train Epoch: 176 [2160/2812 (77%)]\tLoss: 12.901334\n",
            "Train Epoch: 176 [2280/2812 (81%)]\tLoss: 1.958003\n",
            "Train Epoch: 176 [2400/2812 (85%)]\tLoss: 8.914727\n",
            "Train Epoch: 176 [2520/2812 (89%)]\tLoss: 11.217031\n",
            "Train Epoch: 176 [2640/2812 (94%)]\tLoss: 13.586413\n",
            "Train Epoch: 176 [2760/2812 (98%)]\tLoss: 21.407080\n",
            "Training Loss: 10.9383 Acc: 49.8933\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6064, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 177/200\n",
            "----------\n",
            "Train Epoch: 177 [0/2812 (0%)]\tLoss: 11.536408\n",
            "Train Epoch: 177 [120/2812 (4%)]\tLoss: 9.805274\n",
            "Train Epoch: 177 [240/2812 (9%)]\tLoss: 7.280132\n",
            "Train Epoch: 177 [360/2812 (13%)]\tLoss: 7.254359\n",
            "Train Epoch: 177 [480/2812 (17%)]\tLoss: 14.329622\n",
            "Train Epoch: 177 [600/2812 (21%)]\tLoss: 3.420006\n",
            "Train Epoch: 177 [720/2812 (26%)]\tLoss: 10.522245\n",
            "Train Epoch: 177 [840/2812 (30%)]\tLoss: 11.095319\n",
            "Train Epoch: 177 [960/2812 (34%)]\tLoss: 8.415418\n",
            "Train Epoch: 177 [1080/2812 (38%)]\tLoss: 2.509419\n",
            "Train Epoch: 177 [1200/2812 (43%)]\tLoss: 9.927100\n",
            "Train Epoch: 177 [1320/2812 (47%)]\tLoss: 4.908326\n",
            "Train Epoch: 177 [1440/2812 (51%)]\tLoss: 6.202071\n",
            "Train Epoch: 177 [1560/2812 (55%)]\tLoss: 10.891713\n",
            "Train Epoch: 177 [1680/2812 (60%)]\tLoss: 7.994618\n",
            "Train Epoch: 177 [1800/2812 (64%)]\tLoss: 0.567655\n",
            "Train Epoch: 177 [1920/2812 (68%)]\tLoss: 10.798205\n",
            "Train Epoch: 177 [2040/2812 (72%)]\tLoss: 19.747469\n",
            "Train Epoch: 177 [2160/2812 (77%)]\tLoss: 12.255163\n",
            "Train Epoch: 177 [2280/2812 (81%)]\tLoss: 8.014256\n",
            "Train Epoch: 177 [2400/2812 (85%)]\tLoss: 8.312129\n",
            "Train Epoch: 177 [2520/2812 (89%)]\tLoss: 16.049545\n",
            "Train Epoch: 177 [2640/2812 (94%)]\tLoss: 26.968456\n",
            "Train Epoch: 177 [2760/2812 (98%)]\tLoss: 4.541391\n",
            "Training Loss: 10.8348 Acc: 50.3912\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5838, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 178/200\n",
            "----------\n",
            "Train Epoch: 178 [0/2812 (0%)]\tLoss: 8.491362\n",
            "Train Epoch: 178 [120/2812 (4%)]\tLoss: 3.726985\n",
            "Train Epoch: 178 [240/2812 (9%)]\tLoss: 6.606110\n",
            "Train Epoch: 178 [360/2812 (13%)]\tLoss: 13.042974\n",
            "Train Epoch: 178 [480/2812 (17%)]\tLoss: 6.850925\n",
            "Train Epoch: 178 [600/2812 (21%)]\tLoss: 4.706249\n",
            "Train Epoch: 178 [720/2812 (26%)]\tLoss: 11.965061\n",
            "Train Epoch: 178 [840/2812 (30%)]\tLoss: 15.643491\n",
            "Train Epoch: 178 [960/2812 (34%)]\tLoss: 16.986275\n",
            "Train Epoch: 178 [1080/2812 (38%)]\tLoss: 10.667013\n",
            "Train Epoch: 178 [1200/2812 (43%)]\tLoss: 8.873405\n",
            "Train Epoch: 178 [1320/2812 (47%)]\tLoss: 10.027015\n",
            "Train Epoch: 178 [1440/2812 (51%)]\tLoss: 12.045713\n",
            "Train Epoch: 178 [1560/2812 (55%)]\tLoss: 10.116645\n",
            "Train Epoch: 178 [1680/2812 (60%)]\tLoss: 16.984432\n",
            "Train Epoch: 178 [1800/2812 (64%)]\tLoss: 11.144445\n",
            "Train Epoch: 178 [1920/2812 (68%)]\tLoss: 11.769754\n",
            "Train Epoch: 178 [2040/2812 (72%)]\tLoss: 4.343653\n",
            "Train Epoch: 178 [2160/2812 (77%)]\tLoss: 17.374020\n",
            "Train Epoch: 178 [2280/2812 (81%)]\tLoss: 11.918226\n",
            "Train Epoch: 178 [2400/2812 (85%)]\tLoss: 5.738334\n",
            "Train Epoch: 178 [2520/2812 (89%)]\tLoss: 19.492340\n",
            "Train Epoch: 178 [2640/2812 (94%)]\tLoss: 17.769272\n",
            "Train Epoch: 178 [2760/2812 (98%)]\tLoss: 10.582273\n",
            "Training Loss: 10.9747 Acc: 50.4979\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5949, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 179/200\n",
            "----------\n",
            "Train Epoch: 179 [0/2812 (0%)]\tLoss: 23.949757\n",
            "Train Epoch: 179 [120/2812 (4%)]\tLoss: 5.908544\n",
            "Train Epoch: 179 [240/2812 (9%)]\tLoss: 14.460546\n",
            "Train Epoch: 179 [360/2812 (13%)]\tLoss: 16.230625\n",
            "Train Epoch: 179 [480/2812 (17%)]\tLoss: 14.069437\n",
            "Train Epoch: 179 [600/2812 (21%)]\tLoss: 4.835382\n",
            "Train Epoch: 179 [720/2812 (26%)]\tLoss: 9.255163\n",
            "Train Epoch: 179 [840/2812 (30%)]\tLoss: 9.426017\n",
            "Train Epoch: 179 [960/2812 (34%)]\tLoss: 5.313057\n",
            "Train Epoch: 179 [1080/2812 (38%)]\tLoss: 15.808016\n",
            "Train Epoch: 179 [1200/2812 (43%)]\tLoss: 6.009032\n",
            "Train Epoch: 179 [1320/2812 (47%)]\tLoss: 18.558159\n",
            "Train Epoch: 179 [1440/2812 (51%)]\tLoss: 6.140022\n",
            "Train Epoch: 179 [1560/2812 (55%)]\tLoss: 10.991282\n",
            "Train Epoch: 179 [1680/2812 (60%)]\tLoss: 20.054514\n",
            "Train Epoch: 179 [1800/2812 (64%)]\tLoss: 8.873193\n",
            "Train Epoch: 179 [1920/2812 (68%)]\tLoss: 20.265585\n",
            "Train Epoch: 179 [2040/2812 (72%)]\tLoss: 8.350519\n",
            "Train Epoch: 179 [2160/2812 (77%)]\tLoss: 16.661699\n",
            "Train Epoch: 179 [2280/2812 (81%)]\tLoss: 3.582957\n",
            "Train Epoch: 179 [2400/2812 (85%)]\tLoss: 8.021250\n",
            "Train Epoch: 179 [2520/2812 (89%)]\tLoss: 11.111162\n",
            "Train Epoch: 179 [2640/2812 (94%)]\tLoss: 8.641954\n",
            "Train Epoch: 179 [2760/2812 (98%)]\tLoss: 5.469979\n",
            "Training Loss: 10.9633 Acc: 49.8933\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5815, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 180/200\n",
            "----------\n",
            "Train Epoch: 180 [0/2812 (0%)]\tLoss: 17.649261\n",
            "Train Epoch: 180 [120/2812 (4%)]\tLoss: 8.765085\n",
            "Train Epoch: 180 [240/2812 (9%)]\tLoss: 9.797568\n",
            "Train Epoch: 180 [360/2812 (13%)]\tLoss: 14.819956\n",
            "Train Epoch: 180 [480/2812 (17%)]\tLoss: 14.546298\n",
            "Train Epoch: 180 [600/2812 (21%)]\tLoss: 6.204875\n",
            "Train Epoch: 180 [720/2812 (26%)]\tLoss: 7.637412\n",
            "Train Epoch: 180 [840/2812 (30%)]\tLoss: 9.490785\n",
            "Train Epoch: 180 [960/2812 (34%)]\tLoss: 6.858874\n",
            "Train Epoch: 180 [1080/2812 (38%)]\tLoss: 11.468483\n",
            "Train Epoch: 180 [1200/2812 (43%)]\tLoss: 14.838768\n",
            "Train Epoch: 180 [1320/2812 (47%)]\tLoss: 8.738708\n",
            "Train Epoch: 180 [1440/2812 (51%)]\tLoss: 16.567278\n",
            "Train Epoch: 180 [1560/2812 (55%)]\tLoss: 9.561918\n",
            "Train Epoch: 180 [1680/2812 (60%)]\tLoss: 6.660820\n",
            "Train Epoch: 180 [1800/2812 (64%)]\tLoss: 15.683563\n",
            "Train Epoch: 180 [1920/2812 (68%)]\tLoss: 12.927274\n",
            "Train Epoch: 180 [2040/2812 (72%)]\tLoss: 3.652436\n",
            "Train Epoch: 180 [2160/2812 (77%)]\tLoss: 14.501170\n",
            "Train Epoch: 180 [2280/2812 (81%)]\tLoss: 17.330252\n",
            "Train Epoch: 180 [2400/2812 (85%)]\tLoss: 10.064502\n",
            "Train Epoch: 180 [2520/2812 (89%)]\tLoss: 11.502457\n",
            "Train Epoch: 180 [2640/2812 (94%)]\tLoss: 2.771350\n",
            "Train Epoch: 180 [2760/2812 (98%)]\tLoss: 6.280812\n",
            "Training Loss: 11.1043 Acc: 50.0711\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5377, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 181/200\n",
            "----------\n",
            "Train Epoch: 181 [0/2812 (0%)]\tLoss: 19.902225\n",
            "Train Epoch: 181 [120/2812 (4%)]\tLoss: 7.537500\n",
            "Train Epoch: 181 [240/2812 (9%)]\tLoss: 9.845972\n",
            "Train Epoch: 181 [360/2812 (13%)]\tLoss: 4.391250\n",
            "Train Epoch: 181 [480/2812 (17%)]\tLoss: 11.238837\n",
            "Train Epoch: 181 [600/2812 (21%)]\tLoss: 4.942491\n",
            "Train Epoch: 181 [720/2812 (26%)]\tLoss: 12.981852\n",
            "Train Epoch: 181 [840/2812 (30%)]\tLoss: 9.237925\n",
            "Train Epoch: 181 [960/2812 (34%)]\tLoss: 3.890899\n",
            "Train Epoch: 181 [1080/2812 (38%)]\tLoss: 12.225986\n",
            "Train Epoch: 181 [1200/2812 (43%)]\tLoss: 13.445549\n",
            "Train Epoch: 181 [1320/2812 (47%)]\tLoss: 14.533887\n",
            "Train Epoch: 181 [1440/2812 (51%)]\tLoss: 2.822985\n",
            "Train Epoch: 181 [1560/2812 (55%)]\tLoss: 18.302118\n",
            "Train Epoch: 181 [1680/2812 (60%)]\tLoss: 9.161705\n",
            "Train Epoch: 181 [1800/2812 (64%)]\tLoss: 10.396525\n",
            "Train Epoch: 181 [1920/2812 (68%)]\tLoss: 4.542806\n",
            "Train Epoch: 181 [2040/2812 (72%)]\tLoss: 7.282540\n",
            "Train Epoch: 181 [2160/2812 (77%)]\tLoss: 14.578827\n",
            "Train Epoch: 181 [2280/2812 (81%)]\tLoss: 16.720577\n",
            "Train Epoch: 181 [2400/2812 (85%)]\tLoss: 5.362595\n",
            "Train Epoch: 181 [2520/2812 (89%)]\tLoss: 14.720728\n",
            "Train Epoch: 181 [2640/2812 (94%)]\tLoss: 9.317104\n",
            "Train Epoch: 181 [2760/2812 (98%)]\tLoss: 12.536043\n",
            "Training Loss: 11.3110 Acc: 49.2888\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6403, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 182/200\n",
            "----------\n",
            "Train Epoch: 182 [0/2812 (0%)]\tLoss: 3.396441\n",
            "Train Epoch: 182 [120/2812 (4%)]\tLoss: 8.776394\n",
            "Train Epoch: 182 [240/2812 (9%)]\tLoss: 17.000170\n",
            "Train Epoch: 182 [360/2812 (13%)]\tLoss: 10.536194\n",
            "Train Epoch: 182 [480/2812 (17%)]\tLoss: 17.507500\n",
            "Train Epoch: 182 [600/2812 (21%)]\tLoss: 9.592688\n",
            "Train Epoch: 182 [720/2812 (26%)]\tLoss: 9.033317\n",
            "Train Epoch: 182 [840/2812 (30%)]\tLoss: 8.101202\n",
            "Train Epoch: 182 [960/2812 (34%)]\tLoss: 8.009247\n",
            "Train Epoch: 182 [1080/2812 (38%)]\tLoss: 15.098404\n",
            "Train Epoch: 182 [1200/2812 (43%)]\tLoss: 17.458889\n",
            "Train Epoch: 182 [1320/2812 (47%)]\tLoss: 10.428628\n",
            "Train Epoch: 182 [1440/2812 (51%)]\tLoss: 14.582644\n",
            "Train Epoch: 182 [1560/2812 (55%)]\tLoss: 10.112414\n",
            "Train Epoch: 182 [1680/2812 (60%)]\tLoss: 6.770669\n",
            "Train Epoch: 182 [1800/2812 (64%)]\tLoss: 11.735243\n",
            "Train Epoch: 182 [1920/2812 (68%)]\tLoss: 13.543242\n",
            "Train Epoch: 182 [2040/2812 (72%)]\tLoss: 11.652007\n",
            "Train Epoch: 182 [2160/2812 (77%)]\tLoss: 17.056252\n",
            "Train Epoch: 182 [2280/2812 (81%)]\tLoss: 6.814059\n",
            "Train Epoch: 182 [2400/2812 (85%)]\tLoss: 4.806551\n",
            "Train Epoch: 182 [2520/2812 (89%)]\tLoss: 14.693399\n",
            "Train Epoch: 182 [2640/2812 (94%)]\tLoss: 14.802870\n",
            "Train Epoch: 182 [2760/2812 (98%)]\tLoss: 21.092386\n",
            "Training Loss: 11.2079 Acc: 49.8578\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5480, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 183/200\n",
            "----------\n",
            "Train Epoch: 183 [0/2812 (0%)]\tLoss: 12.410146\n",
            "Train Epoch: 183 [120/2812 (4%)]\tLoss: 2.545249\n",
            "Train Epoch: 183 [240/2812 (9%)]\tLoss: 8.759929\n",
            "Train Epoch: 183 [360/2812 (13%)]\tLoss: 21.059168\n",
            "Train Epoch: 183 [480/2812 (17%)]\tLoss: 8.767302\n",
            "Train Epoch: 183 [600/2812 (21%)]\tLoss: 14.730710\n",
            "Train Epoch: 183 [720/2812 (26%)]\tLoss: 3.700741\n",
            "Train Epoch: 183 [840/2812 (30%)]\tLoss: 9.456611\n",
            "Train Epoch: 183 [960/2812 (34%)]\tLoss: 3.638091\n",
            "Train Epoch: 183 [1080/2812 (38%)]\tLoss: 15.626234\n",
            "Train Epoch: 183 [1200/2812 (43%)]\tLoss: 15.218534\n",
            "Train Epoch: 183 [1320/2812 (47%)]\tLoss: 4.245601\n",
            "Train Epoch: 183 [1440/2812 (51%)]\tLoss: 6.188481\n",
            "Train Epoch: 183 [1560/2812 (55%)]\tLoss: 6.553064\n",
            "Train Epoch: 183 [1680/2812 (60%)]\tLoss: 13.793569\n",
            "Train Epoch: 183 [1800/2812 (64%)]\tLoss: 14.681421\n",
            "Train Epoch: 183 [1920/2812 (68%)]\tLoss: 6.907365\n",
            "Train Epoch: 183 [2040/2812 (72%)]\tLoss: 9.865542\n",
            "Train Epoch: 183 [2160/2812 (77%)]\tLoss: 12.620090\n",
            "Train Epoch: 183 [2280/2812 (81%)]\tLoss: 9.481157\n",
            "Train Epoch: 183 [2400/2812 (85%)]\tLoss: 7.842638\n",
            "Train Epoch: 183 [2520/2812 (89%)]\tLoss: 14.189344\n",
            "Train Epoch: 183 [2640/2812 (94%)]\tLoss: 16.734739\n",
            "Train Epoch: 183 [2760/2812 (98%)]\tLoss: 9.817166\n",
            "Training Loss: 11.2162 Acc: 49.7866\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5146, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 184/200\n",
            "----------\n",
            "Train Epoch: 184 [0/2812 (0%)]\tLoss: 15.662448\n",
            "Train Epoch: 184 [120/2812 (4%)]\tLoss: 11.279351\n",
            "Train Epoch: 184 [240/2812 (9%)]\tLoss: 1.873030\n",
            "Train Epoch: 184 [360/2812 (13%)]\tLoss: 2.861786\n",
            "Train Epoch: 184 [480/2812 (17%)]\tLoss: 5.634051\n",
            "Train Epoch: 184 [600/2812 (21%)]\tLoss: 2.823213\n",
            "Train Epoch: 184 [720/2812 (26%)]\tLoss: 7.345950\n",
            "Train Epoch: 184 [840/2812 (30%)]\tLoss: 16.957001\n",
            "Train Epoch: 184 [960/2812 (34%)]\tLoss: 5.511456\n",
            "Train Epoch: 184 [1080/2812 (38%)]\tLoss: 6.343719\n",
            "Train Epoch: 184 [1200/2812 (43%)]\tLoss: 4.133049\n",
            "Train Epoch: 184 [1320/2812 (47%)]\tLoss: 6.751860\n",
            "Train Epoch: 184 [1440/2812 (51%)]\tLoss: 5.800765\n",
            "Train Epoch: 184 [1560/2812 (55%)]\tLoss: 5.781775\n",
            "Train Epoch: 184 [1680/2812 (60%)]\tLoss: 3.735166\n",
            "Train Epoch: 184 [1800/2812 (64%)]\tLoss: 21.930954\n",
            "Train Epoch: 184 [1920/2812 (68%)]\tLoss: 17.646191\n",
            "Train Epoch: 184 [2040/2812 (72%)]\tLoss: 8.528050\n",
            "Train Epoch: 184 [2160/2812 (77%)]\tLoss: 5.186838\n",
            "Train Epoch: 184 [2280/2812 (81%)]\tLoss: 13.700022\n",
            "Train Epoch: 184 [2400/2812 (85%)]\tLoss: 6.215218\n",
            "Train Epoch: 184 [2520/2812 (89%)]\tLoss: 7.404883\n",
            "Train Epoch: 184 [2640/2812 (94%)]\tLoss: 8.798938\n",
            "Train Epoch: 184 [2760/2812 (98%)]\tLoss: 23.439413\n",
            "Training Loss: 11.2108 Acc: 49.5377\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5436, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 185/200\n",
            "----------\n",
            "Train Epoch: 185 [0/2812 (0%)]\tLoss: 6.055496\n",
            "Train Epoch: 185 [120/2812 (4%)]\tLoss: 1.474360\n",
            "Train Epoch: 185 [240/2812 (9%)]\tLoss: 19.363810\n",
            "Train Epoch: 185 [360/2812 (13%)]\tLoss: 12.100595\n",
            "Train Epoch: 185 [480/2812 (17%)]\tLoss: 14.290283\n",
            "Train Epoch: 185 [600/2812 (21%)]\tLoss: 3.108675\n",
            "Train Epoch: 185 [720/2812 (26%)]\tLoss: 8.199865\n",
            "Train Epoch: 185 [840/2812 (30%)]\tLoss: 4.485089\n",
            "Train Epoch: 185 [960/2812 (34%)]\tLoss: 3.336738\n",
            "Train Epoch: 185 [1080/2812 (38%)]\tLoss: 11.961209\n",
            "Train Epoch: 185 [1200/2812 (43%)]\tLoss: 13.159309\n",
            "Train Epoch: 185 [1320/2812 (47%)]\tLoss: 6.321792\n",
            "Train Epoch: 185 [1440/2812 (51%)]\tLoss: 4.395819\n",
            "Train Epoch: 185 [1560/2812 (55%)]\tLoss: 21.905184\n",
            "Train Epoch: 185 [1680/2812 (60%)]\tLoss: 9.332290\n",
            "Train Epoch: 185 [1800/2812 (64%)]\tLoss: 16.930296\n",
            "Train Epoch: 185 [1920/2812 (68%)]\tLoss: 10.597631\n",
            "Train Epoch: 185 [2040/2812 (72%)]\tLoss: 2.701500\n",
            "Train Epoch: 185 [2160/2812 (77%)]\tLoss: 6.985805\n",
            "Train Epoch: 185 [2280/2812 (81%)]\tLoss: 4.838782\n",
            "Train Epoch: 185 [2400/2812 (85%)]\tLoss: 5.328223\n",
            "Train Epoch: 185 [2520/2812 (89%)]\tLoss: 5.155468\n",
            "Train Epoch: 185 [2640/2812 (94%)]\tLoss: 17.340096\n",
            "Train Epoch: 185 [2760/2812 (98%)]\tLoss: 23.742859\n",
            "Training Loss: 11.0476 Acc: 50.7112\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5679, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 186/200\n",
            "----------\n",
            "Train Epoch: 186 [0/2812 (0%)]\tLoss: 12.518085\n",
            "Train Epoch: 186 [120/2812 (4%)]\tLoss: 11.273968\n",
            "Train Epoch: 186 [240/2812 (9%)]\tLoss: 8.229439\n",
            "Train Epoch: 186 [360/2812 (13%)]\tLoss: 10.943466\n",
            "Train Epoch: 186 [480/2812 (17%)]\tLoss: 7.288694\n",
            "Train Epoch: 186 [600/2812 (21%)]\tLoss: 23.723339\n",
            "Train Epoch: 186 [720/2812 (26%)]\tLoss: 15.524397\n",
            "Train Epoch: 186 [840/2812 (30%)]\tLoss: 15.893237\n",
            "Train Epoch: 186 [960/2812 (34%)]\tLoss: 8.838511\n",
            "Train Epoch: 186 [1080/2812 (38%)]\tLoss: 21.948816\n",
            "Train Epoch: 186 [1200/2812 (43%)]\tLoss: 11.293951\n",
            "Train Epoch: 186 [1320/2812 (47%)]\tLoss: 7.045692\n",
            "Train Epoch: 186 [1440/2812 (51%)]\tLoss: 6.533862\n",
            "Train Epoch: 186 [1560/2812 (55%)]\tLoss: 17.460526\n",
            "Train Epoch: 186 [1680/2812 (60%)]\tLoss: 16.296787\n",
            "Train Epoch: 186 [1800/2812 (64%)]\tLoss: 15.073456\n",
            "Train Epoch: 186 [1920/2812 (68%)]\tLoss: 5.204085\n",
            "Train Epoch: 186 [2040/2812 (72%)]\tLoss: 5.080886\n",
            "Train Epoch: 186 [2160/2812 (77%)]\tLoss: 8.034056\n",
            "Train Epoch: 186 [2280/2812 (81%)]\tLoss: 19.758547\n",
            "Train Epoch: 186 [2400/2812 (85%)]\tLoss: 15.466600\n",
            "Train Epoch: 186 [2520/2812 (89%)]\tLoss: 4.821463\n",
            "Train Epoch: 186 [2640/2812 (94%)]\tLoss: 22.834387\n",
            "Train Epoch: 186 [2760/2812 (98%)]\tLoss: 4.001252\n",
            "Training Loss: 11.0119 Acc: 50.9246\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5817, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 187/200\n",
            "----------\n",
            "Train Epoch: 187 [0/2812 (0%)]\tLoss: 10.894680\n",
            "Train Epoch: 187 [120/2812 (4%)]\tLoss: 15.348726\n",
            "Train Epoch: 187 [240/2812 (9%)]\tLoss: 10.899755\n",
            "Train Epoch: 187 [360/2812 (13%)]\tLoss: 8.794672\n",
            "Train Epoch: 187 [480/2812 (17%)]\tLoss: 6.477479\n",
            "Train Epoch: 187 [600/2812 (21%)]\tLoss: 10.745207\n",
            "Train Epoch: 187 [720/2812 (26%)]\tLoss: 18.498110\n",
            "Train Epoch: 187 [840/2812 (30%)]\tLoss: 8.035958\n",
            "Train Epoch: 187 [960/2812 (34%)]\tLoss: 7.263113\n",
            "Train Epoch: 187 [1080/2812 (38%)]\tLoss: 17.564045\n",
            "Train Epoch: 187 [1200/2812 (43%)]\tLoss: 20.435244\n",
            "Train Epoch: 187 [1320/2812 (47%)]\tLoss: 13.856573\n",
            "Train Epoch: 187 [1440/2812 (51%)]\tLoss: 21.684055\n",
            "Train Epoch: 187 [1560/2812 (55%)]\tLoss: 7.812287\n",
            "Train Epoch: 187 [1680/2812 (60%)]\tLoss: 5.174671\n",
            "Train Epoch: 187 [1800/2812 (64%)]\tLoss: 15.675664\n",
            "Train Epoch: 187 [1920/2812 (68%)]\tLoss: 5.374719\n",
            "Train Epoch: 187 [2040/2812 (72%)]\tLoss: 8.994195\n",
            "Train Epoch: 187 [2160/2812 (77%)]\tLoss: 12.686232\n",
            "Train Epoch: 187 [2280/2812 (81%)]\tLoss: 6.515535\n",
            "Train Epoch: 187 [2400/2812 (85%)]\tLoss: 4.460923\n",
            "Train Epoch: 187 [2520/2812 (89%)]\tLoss: 6.451833\n",
            "Train Epoch: 187 [2640/2812 (94%)]\tLoss: 13.725644\n",
            "Train Epoch: 187 [2760/2812 (98%)]\tLoss: 4.729668\n",
            "Training Loss: 10.8235 Acc: 50.7824\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5527, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 188/200\n",
            "----------\n",
            "Train Epoch: 188 [0/2812 (0%)]\tLoss: 5.117616\n",
            "Train Epoch: 188 [120/2812 (4%)]\tLoss: 6.759908\n",
            "Train Epoch: 188 [240/2812 (9%)]\tLoss: 4.780997\n",
            "Train Epoch: 188 [360/2812 (13%)]\tLoss: 13.656967\n",
            "Train Epoch: 188 [480/2812 (17%)]\tLoss: 0.152366\n",
            "Train Epoch: 188 [600/2812 (21%)]\tLoss: 7.046670\n",
            "Train Epoch: 188 [720/2812 (26%)]\tLoss: 13.155241\n",
            "Train Epoch: 188 [840/2812 (30%)]\tLoss: 5.973216\n",
            "Train Epoch: 188 [960/2812 (34%)]\tLoss: 3.432244\n",
            "Train Epoch: 188 [1080/2812 (38%)]\tLoss: 18.873508\n",
            "Train Epoch: 188 [1200/2812 (43%)]\tLoss: 14.484926\n",
            "Train Epoch: 188 [1320/2812 (47%)]\tLoss: 13.323804\n",
            "Train Epoch: 188 [1440/2812 (51%)]\tLoss: 10.271236\n",
            "Train Epoch: 188 [1560/2812 (55%)]\tLoss: 16.706951\n",
            "Train Epoch: 188 [1680/2812 (60%)]\tLoss: 20.439457\n",
            "Train Epoch: 188 [1800/2812 (64%)]\tLoss: 12.705705\n",
            "Train Epoch: 188 [1920/2812 (68%)]\tLoss: 11.852373\n",
            "Train Epoch: 188 [2040/2812 (72%)]\tLoss: 4.720957\n",
            "Train Epoch: 188 [2160/2812 (77%)]\tLoss: 11.137152\n",
            "Train Epoch: 188 [2280/2812 (81%)]\tLoss: 13.870084\n",
            "Train Epoch: 188 [2400/2812 (85%)]\tLoss: 15.413608\n",
            "Train Epoch: 188 [2520/2812 (89%)]\tLoss: 11.063990\n",
            "Train Epoch: 188 [2640/2812 (94%)]\tLoss: 6.818217\n",
            "Train Epoch: 188 [2760/2812 (98%)]\tLoss: 7.951480\n",
            "Training Loss: 11.3619 Acc: 49.7866\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5607, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 189/200\n",
            "----------\n",
            "Train Epoch: 189 [0/2812 (0%)]\tLoss: 2.328866\n",
            "Train Epoch: 189 [120/2812 (4%)]\tLoss: 7.761181\n",
            "Train Epoch: 189 [240/2812 (9%)]\tLoss: 12.796075\n",
            "Train Epoch: 189 [360/2812 (13%)]\tLoss: 12.023529\n",
            "Train Epoch: 189 [480/2812 (17%)]\tLoss: 2.334151\n",
            "Train Epoch: 189 [600/2812 (21%)]\tLoss: 4.834567\n",
            "Train Epoch: 189 [720/2812 (26%)]\tLoss: 11.604756\n",
            "Train Epoch: 189 [840/2812 (30%)]\tLoss: 9.899600\n",
            "Train Epoch: 189 [960/2812 (34%)]\tLoss: 8.148425\n",
            "Train Epoch: 189 [1080/2812 (38%)]\tLoss: 18.900236\n",
            "Train Epoch: 189 [1200/2812 (43%)]\tLoss: 4.826917\n",
            "Train Epoch: 189 [1320/2812 (47%)]\tLoss: 5.774454\n",
            "Train Epoch: 189 [1440/2812 (51%)]\tLoss: 15.719089\n",
            "Train Epoch: 189 [1560/2812 (55%)]\tLoss: 15.693814\n",
            "Train Epoch: 189 [1680/2812 (60%)]\tLoss: 3.271423\n",
            "Train Epoch: 189 [1800/2812 (64%)]\tLoss: 6.417801\n",
            "Train Epoch: 189 [1920/2812 (68%)]\tLoss: 5.992599\n",
            "Train Epoch: 189 [2040/2812 (72%)]\tLoss: 13.592984\n",
            "Train Epoch: 189 [2160/2812 (77%)]\tLoss: 9.284895\n",
            "Train Epoch: 189 [2280/2812 (81%)]\tLoss: 10.980509\n",
            "Train Epoch: 189 [2400/2812 (85%)]\tLoss: 3.631200\n",
            "Train Epoch: 189 [2520/2812 (89%)]\tLoss: 12.724321\n",
            "Train Epoch: 189 [2640/2812 (94%)]\tLoss: 7.446795\n",
            "Train Epoch: 189 [2760/2812 (98%)]\tLoss: 8.414427\n",
            "Training Loss: 11.1426 Acc: 50.8179\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5641, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 190/200\n",
            "----------\n",
            "Train Epoch: 190 [0/2812 (0%)]\tLoss: 7.355216\n",
            "Train Epoch: 190 [120/2812 (4%)]\tLoss: 26.666946\n",
            "Train Epoch: 190 [240/2812 (9%)]\tLoss: 16.747540\n",
            "Train Epoch: 190 [360/2812 (13%)]\tLoss: 3.420232\n",
            "Train Epoch: 190 [480/2812 (17%)]\tLoss: 12.749298\n",
            "Train Epoch: 190 [600/2812 (21%)]\tLoss: 11.504600\n",
            "Train Epoch: 190 [720/2812 (26%)]\tLoss: 13.484787\n",
            "Train Epoch: 190 [840/2812 (30%)]\tLoss: 15.277720\n",
            "Train Epoch: 190 [960/2812 (34%)]\tLoss: 11.739748\n",
            "Train Epoch: 190 [1080/2812 (38%)]\tLoss: 5.334838\n",
            "Train Epoch: 190 [1200/2812 (43%)]\tLoss: 18.443592\n",
            "Train Epoch: 190 [1320/2812 (47%)]\tLoss: 9.084311\n",
            "Train Epoch: 190 [1440/2812 (51%)]\tLoss: 6.625276\n",
            "Train Epoch: 190 [1560/2812 (55%)]\tLoss: 0.704362\n",
            "Train Epoch: 190 [1680/2812 (60%)]\tLoss: 7.721171\n",
            "Train Epoch: 190 [1800/2812 (64%)]\tLoss: 14.022534\n",
            "Train Epoch: 190 [1920/2812 (68%)]\tLoss: 10.735315\n",
            "Train Epoch: 190 [2040/2812 (72%)]\tLoss: 7.268590\n",
            "Train Epoch: 190 [2160/2812 (77%)]\tLoss: 10.971944\n",
            "Train Epoch: 190 [2280/2812 (81%)]\tLoss: 5.270952\n",
            "Train Epoch: 190 [2400/2812 (85%)]\tLoss: 39.380325\n",
            "Train Epoch: 190 [2520/2812 (89%)]\tLoss: 20.472099\n",
            "Train Epoch: 190 [2640/2812 (94%)]\tLoss: 6.291820\n",
            "Train Epoch: 190 [2760/2812 (98%)]\tLoss: 11.459408\n",
            "Training Loss: 11.2311 Acc: 51.1380\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5997, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 191/200\n",
            "----------\n",
            "Train Epoch: 191 [0/2812 (0%)]\tLoss: 15.308340\n",
            "Train Epoch: 191 [120/2812 (4%)]\tLoss: 12.343799\n",
            "Train Epoch: 191 [240/2812 (9%)]\tLoss: 17.577778\n",
            "Train Epoch: 191 [360/2812 (13%)]\tLoss: 7.164252\n",
            "Train Epoch: 191 [480/2812 (17%)]\tLoss: 10.200576\n",
            "Train Epoch: 191 [600/2812 (21%)]\tLoss: 2.163638\n",
            "Train Epoch: 191 [720/2812 (26%)]\tLoss: 12.264381\n",
            "Train Epoch: 191 [840/2812 (30%)]\tLoss: 17.208834\n",
            "Train Epoch: 191 [960/2812 (34%)]\tLoss: 6.451093\n",
            "Train Epoch: 191 [1080/2812 (38%)]\tLoss: 5.916048\n",
            "Train Epoch: 191 [1200/2812 (43%)]\tLoss: 6.108239\n",
            "Train Epoch: 191 [1320/2812 (47%)]\tLoss: 14.691383\n",
            "Train Epoch: 191 [1440/2812 (51%)]\tLoss: 8.216055\n",
            "Train Epoch: 191 [1560/2812 (55%)]\tLoss: 9.609936\n",
            "Train Epoch: 191 [1680/2812 (60%)]\tLoss: 8.946201\n",
            "Train Epoch: 191 [1800/2812 (64%)]\tLoss: 0.355453\n",
            "Train Epoch: 191 [1920/2812 (68%)]\tLoss: 18.414415\n",
            "Train Epoch: 191 [2040/2812 (72%)]\tLoss: 13.486490\n",
            "Train Epoch: 191 [2160/2812 (77%)]\tLoss: 15.142591\n",
            "Train Epoch: 191 [2280/2812 (81%)]\tLoss: 17.688898\n",
            "Train Epoch: 191 [2400/2812 (85%)]\tLoss: 8.277379\n",
            "Train Epoch: 191 [2520/2812 (89%)]\tLoss: 8.905222\n",
            "Train Epoch: 191 [2640/2812 (94%)]\tLoss: 18.969601\n",
            "Train Epoch: 191 [2760/2812 (98%)]\tLoss: 6.597517\n",
            "Training Loss: 10.8120 Acc: 50.5334\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6578, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 192/200\n",
            "----------\n",
            "Train Epoch: 192 [0/2812 (0%)]\tLoss: 13.724890\n",
            "Train Epoch: 192 [120/2812 (4%)]\tLoss: 6.107422\n",
            "Train Epoch: 192 [240/2812 (9%)]\tLoss: 9.630297\n",
            "Train Epoch: 192 [360/2812 (13%)]\tLoss: 6.556603\n",
            "Train Epoch: 192 [480/2812 (17%)]\tLoss: 5.231218\n",
            "Train Epoch: 192 [600/2812 (21%)]\tLoss: 10.394166\n",
            "Train Epoch: 192 [720/2812 (26%)]\tLoss: 4.317763\n",
            "Train Epoch: 192 [840/2812 (30%)]\tLoss: 14.273295\n",
            "Train Epoch: 192 [960/2812 (34%)]\tLoss: 12.392217\n",
            "Train Epoch: 192 [1080/2812 (38%)]\tLoss: 5.398253\n",
            "Train Epoch: 192 [1200/2812 (43%)]\tLoss: 3.049350\n",
            "Train Epoch: 192 [1320/2812 (47%)]\tLoss: 5.773696\n",
            "Train Epoch: 192 [1440/2812 (51%)]\tLoss: 20.794210\n",
            "Train Epoch: 192 [1560/2812 (55%)]\tLoss: 8.058647\n",
            "Train Epoch: 192 [1680/2812 (60%)]\tLoss: 18.123724\n",
            "Train Epoch: 192 [1800/2812 (64%)]\tLoss: 8.804169\n",
            "Train Epoch: 192 [1920/2812 (68%)]\tLoss: 17.585859\n",
            "Train Epoch: 192 [2040/2812 (72%)]\tLoss: 11.562319\n",
            "Train Epoch: 192 [2160/2812 (77%)]\tLoss: 21.964626\n",
            "Train Epoch: 192 [2280/2812 (81%)]\tLoss: 4.353159\n",
            "Train Epoch: 192 [2400/2812 (85%)]\tLoss: 19.241575\n",
            "Train Epoch: 192 [2520/2812 (89%)]\tLoss: 15.234657\n",
            "Train Epoch: 192 [2640/2812 (94%)]\tLoss: 7.666698\n",
            "Train Epoch: 192 [2760/2812 (98%)]\tLoss: 16.899355\n",
            "Training Loss: 10.9886 Acc: 50.2845\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5920, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 193/200\n",
            "----------\n",
            "Train Epoch: 193 [0/2812 (0%)]\tLoss: 4.255939\n",
            "Train Epoch: 193 [120/2812 (4%)]\tLoss: 16.345924\n",
            "Train Epoch: 193 [240/2812 (9%)]\tLoss: 13.462341\n",
            "Train Epoch: 193 [360/2812 (13%)]\tLoss: 8.402818\n",
            "Train Epoch: 193 [480/2812 (17%)]\tLoss: 18.177250\n",
            "Train Epoch: 193 [600/2812 (21%)]\tLoss: 3.130461\n",
            "Train Epoch: 193 [720/2812 (26%)]\tLoss: 10.860380\n",
            "Train Epoch: 193 [840/2812 (30%)]\tLoss: 5.115727\n",
            "Train Epoch: 193 [960/2812 (34%)]\tLoss: 11.371367\n",
            "Train Epoch: 193 [1080/2812 (38%)]\tLoss: 13.941813\n",
            "Train Epoch: 193 [1200/2812 (43%)]\tLoss: 6.129031\n",
            "Train Epoch: 193 [1320/2812 (47%)]\tLoss: 16.916710\n",
            "Train Epoch: 193 [1440/2812 (51%)]\tLoss: 9.020697\n",
            "Train Epoch: 193 [1560/2812 (55%)]\tLoss: 7.393888\n",
            "Train Epoch: 193 [1680/2812 (60%)]\tLoss: 16.430153\n",
            "Train Epoch: 193 [1800/2812 (64%)]\tLoss: 20.553356\n",
            "Train Epoch: 193 [1920/2812 (68%)]\tLoss: 15.793668\n",
            "Train Epoch: 193 [2040/2812 (72%)]\tLoss: 8.593107\n",
            "Train Epoch: 193 [2160/2812 (77%)]\tLoss: 8.472339\n",
            "Train Epoch: 193 [2280/2812 (81%)]\tLoss: 6.707422\n",
            "Train Epoch: 193 [2400/2812 (85%)]\tLoss: 13.556328\n",
            "Train Epoch: 193 [2520/2812 (89%)]\tLoss: 26.513895\n",
            "Train Epoch: 193 [2640/2812 (94%)]\tLoss: 14.017485\n",
            "Train Epoch: 193 [2760/2812 (98%)]\tLoss: 4.864254\n",
            "Training Loss: 10.9427 Acc: 49.6088\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6082, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 194/200\n",
            "----------\n",
            "Train Epoch: 194 [0/2812 (0%)]\tLoss: 21.006992\n",
            "Train Epoch: 194 [120/2812 (4%)]\tLoss: 8.933115\n",
            "Train Epoch: 194 [240/2812 (9%)]\tLoss: 10.454517\n",
            "Train Epoch: 194 [360/2812 (13%)]\tLoss: 4.406926\n",
            "Train Epoch: 194 [480/2812 (17%)]\tLoss: 6.206694\n",
            "Train Epoch: 194 [600/2812 (21%)]\tLoss: 8.253834\n",
            "Train Epoch: 194 [720/2812 (26%)]\tLoss: 4.390868\n",
            "Train Epoch: 194 [840/2812 (30%)]\tLoss: 2.646354\n",
            "Train Epoch: 194 [960/2812 (34%)]\tLoss: 10.667279\n",
            "Train Epoch: 194 [1080/2812 (38%)]\tLoss: 13.904279\n",
            "Train Epoch: 194 [1200/2812 (43%)]\tLoss: 12.586201\n",
            "Train Epoch: 194 [1320/2812 (47%)]\tLoss: 12.027832\n",
            "Train Epoch: 194 [1440/2812 (51%)]\tLoss: 8.236337\n",
            "Train Epoch: 194 [1560/2812 (55%)]\tLoss: 6.165797\n",
            "Train Epoch: 194 [1680/2812 (60%)]\tLoss: 18.853203\n",
            "Train Epoch: 194 [1800/2812 (64%)]\tLoss: 12.539667\n",
            "Train Epoch: 194 [1920/2812 (68%)]\tLoss: 10.984917\n",
            "Train Epoch: 194 [2040/2812 (72%)]\tLoss: 0.063135\n",
            "Train Epoch: 194 [2160/2812 (77%)]\tLoss: 3.655737\n",
            "Train Epoch: 194 [2280/2812 (81%)]\tLoss: 12.360838\n",
            "Train Epoch: 194 [2400/2812 (85%)]\tLoss: 10.997501\n",
            "Train Epoch: 194 [2520/2812 (89%)]\tLoss: 8.605873\n",
            "Train Epoch: 194 [2640/2812 (94%)]\tLoss: 8.323077\n",
            "Train Epoch: 194 [2760/2812 (98%)]\tLoss: 7.311522\n",
            "Training Loss: 10.9004 Acc: 50.1422\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5777, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 195/200\n",
            "----------\n",
            "Train Epoch: 195 [0/2812 (0%)]\tLoss: 7.253253\n",
            "Train Epoch: 195 [120/2812 (4%)]\tLoss: 16.845327\n",
            "Train Epoch: 195 [240/2812 (9%)]\tLoss: 13.421677\n",
            "Train Epoch: 195 [360/2812 (13%)]\tLoss: 18.749283\n",
            "Train Epoch: 195 [480/2812 (17%)]\tLoss: 5.237638\n",
            "Train Epoch: 195 [600/2812 (21%)]\tLoss: 14.973765\n",
            "Train Epoch: 195 [720/2812 (26%)]\tLoss: 13.258276\n",
            "Train Epoch: 195 [840/2812 (30%)]\tLoss: 16.784206\n",
            "Train Epoch: 195 [960/2812 (34%)]\tLoss: 20.084652\n",
            "Train Epoch: 195 [1080/2812 (38%)]\tLoss: 18.208311\n",
            "Train Epoch: 195 [1200/2812 (43%)]\tLoss: 8.419022\n",
            "Train Epoch: 195 [1320/2812 (47%)]\tLoss: 13.977509\n",
            "Train Epoch: 195 [1440/2812 (51%)]\tLoss: 18.257040\n",
            "Train Epoch: 195 [1560/2812 (55%)]\tLoss: 7.229181\n",
            "Train Epoch: 195 [1680/2812 (60%)]\tLoss: 5.689256\n",
            "Train Epoch: 195 [1800/2812 (64%)]\tLoss: 11.025655\n",
            "Train Epoch: 195 [1920/2812 (68%)]\tLoss: 8.815462\n",
            "Train Epoch: 195 [2040/2812 (72%)]\tLoss: 14.322573\n",
            "Train Epoch: 195 [2160/2812 (77%)]\tLoss: 12.752180\n",
            "Train Epoch: 195 [2280/2812 (81%)]\tLoss: 18.559914\n",
            "Train Epoch: 195 [2400/2812 (85%)]\tLoss: 10.200749\n",
            "Train Epoch: 195 [2520/2812 (89%)]\tLoss: 8.788359\n",
            "Train Epoch: 195 [2640/2812 (94%)]\tLoss: 16.446598\n",
            "Train Epoch: 195 [2760/2812 (98%)]\tLoss: 26.408365\n",
            "Training Loss: 11.2466 Acc: 49.2532\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5450, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 196/200\n",
            "----------\n",
            "Train Epoch: 196 [0/2812 (0%)]\tLoss: 2.062627\n",
            "Train Epoch: 196 [120/2812 (4%)]\tLoss: 1.862981\n",
            "Train Epoch: 196 [240/2812 (9%)]\tLoss: 15.284480\n",
            "Train Epoch: 196 [360/2812 (13%)]\tLoss: 16.316086\n",
            "Train Epoch: 196 [480/2812 (17%)]\tLoss: 11.423759\n",
            "Train Epoch: 196 [600/2812 (21%)]\tLoss: 9.589528\n",
            "Train Epoch: 196 [720/2812 (26%)]\tLoss: 10.689695\n",
            "Train Epoch: 196 [840/2812 (30%)]\tLoss: 11.106803\n",
            "Train Epoch: 196 [960/2812 (34%)]\tLoss: 6.871406\n",
            "Train Epoch: 196 [1080/2812 (38%)]\tLoss: 17.886425\n",
            "Train Epoch: 196 [1200/2812 (43%)]\tLoss: 5.579606\n",
            "Train Epoch: 196 [1320/2812 (47%)]\tLoss: 1.725958\n",
            "Train Epoch: 196 [1440/2812 (51%)]\tLoss: 13.812136\n",
            "Train Epoch: 196 [1560/2812 (55%)]\tLoss: 13.383657\n",
            "Train Epoch: 196 [1680/2812 (60%)]\tLoss: 13.884630\n",
            "Train Epoch: 196 [1800/2812 (64%)]\tLoss: 11.371479\n",
            "Train Epoch: 196 [1920/2812 (68%)]\tLoss: 9.080834\n",
            "Train Epoch: 196 [2040/2812 (72%)]\tLoss: 11.661771\n",
            "Train Epoch: 196 [2160/2812 (77%)]\tLoss: 14.619049\n",
            "Train Epoch: 196 [2280/2812 (81%)]\tLoss: 7.055570\n",
            "Train Epoch: 196 [2400/2812 (85%)]\tLoss: 15.080826\n",
            "Train Epoch: 196 [2520/2812 (89%)]\tLoss: 4.890518\n",
            "Train Epoch: 196 [2640/2812 (94%)]\tLoss: 11.970293\n",
            "Train Epoch: 196 [2760/2812 (98%)]\tLoss: 13.681595\n",
            "Training Loss: 11.1181 Acc: 48.6131\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5204, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 197/200\n",
            "----------\n",
            "Train Epoch: 197 [0/2812 (0%)]\tLoss: 5.067472\n",
            "Train Epoch: 197 [120/2812 (4%)]\tLoss: 1.836339\n",
            "Train Epoch: 197 [240/2812 (9%)]\tLoss: 9.038724\n",
            "Train Epoch: 197 [360/2812 (13%)]\tLoss: 10.525052\n",
            "Train Epoch: 197 [480/2812 (17%)]\tLoss: 17.988056\n",
            "Train Epoch: 197 [600/2812 (21%)]\tLoss: 19.168644\n",
            "Train Epoch: 197 [720/2812 (26%)]\tLoss: 13.426290\n",
            "Train Epoch: 197 [840/2812 (30%)]\tLoss: 5.389309\n",
            "Train Epoch: 197 [960/2812 (34%)]\tLoss: 9.312821\n",
            "Train Epoch: 197 [1080/2812 (38%)]\tLoss: 22.709173\n",
            "Train Epoch: 197 [1200/2812 (43%)]\tLoss: 0.283305\n",
            "Train Epoch: 197 [1320/2812 (47%)]\tLoss: 15.383853\n",
            "Train Epoch: 197 [1440/2812 (51%)]\tLoss: 3.112490\n",
            "Train Epoch: 197 [1560/2812 (55%)]\tLoss: 4.119032\n",
            "Train Epoch: 197 [1680/2812 (60%)]\tLoss: 10.040206\n",
            "Train Epoch: 197 [1800/2812 (64%)]\tLoss: 15.113306\n",
            "Train Epoch: 197 [1920/2812 (68%)]\tLoss: 13.437357\n",
            "Train Epoch: 197 [2040/2812 (72%)]\tLoss: 8.052976\n",
            "Train Epoch: 197 [2160/2812 (77%)]\tLoss: 15.557503\n",
            "Train Epoch: 197 [2280/2812 (81%)]\tLoss: 15.319855\n",
            "Train Epoch: 197 [2400/2812 (85%)]\tLoss: 4.568571\n",
            "Train Epoch: 197 [2520/2812 (89%)]\tLoss: 23.863344\n",
            "Train Epoch: 197 [2640/2812 (94%)]\tLoss: 21.074574\n",
            "Train Epoch: 197 [2760/2812 (98%)]\tLoss: 12.527001\n",
            "Training Loss: 11.2724 Acc: 51.0313\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5940, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 198/200\n",
            "----------\n",
            "Train Epoch: 198 [0/2812 (0%)]\tLoss: 10.850743\n",
            "Train Epoch: 198 [120/2812 (4%)]\tLoss: 4.468787\n",
            "Train Epoch: 198 [240/2812 (9%)]\tLoss: 14.176463\n",
            "Train Epoch: 198 [360/2812 (13%)]\tLoss: 6.755566\n",
            "Train Epoch: 198 [480/2812 (17%)]\tLoss: 10.868746\n",
            "Train Epoch: 198 [600/2812 (21%)]\tLoss: 8.673926\n",
            "Train Epoch: 198 [720/2812 (26%)]\tLoss: 12.140199\n",
            "Train Epoch: 198 [840/2812 (30%)]\tLoss: 11.853666\n",
            "Train Epoch: 198 [960/2812 (34%)]\tLoss: 2.681995\n",
            "Train Epoch: 198 [1080/2812 (38%)]\tLoss: 19.179819\n",
            "Train Epoch: 198 [1200/2812 (43%)]\tLoss: 15.656130\n",
            "Train Epoch: 198 [1320/2812 (47%)]\tLoss: 7.805898\n",
            "Train Epoch: 198 [1440/2812 (51%)]\tLoss: 9.061354\n",
            "Train Epoch: 198 [1560/2812 (55%)]\tLoss: 6.455260\n",
            "Train Epoch: 198 [1680/2812 (60%)]\tLoss: 8.070518\n",
            "Train Epoch: 198 [1800/2812 (64%)]\tLoss: 20.089405\n",
            "Train Epoch: 198 [1920/2812 (68%)]\tLoss: 14.008924\n",
            "Train Epoch: 198 [2040/2812 (72%)]\tLoss: 8.571685\n",
            "Train Epoch: 198 [2160/2812 (77%)]\tLoss: 14.848145\n",
            "Train Epoch: 198 [2280/2812 (81%)]\tLoss: 16.143040\n",
            "Train Epoch: 198 [2400/2812 (85%)]\tLoss: 12.357643\n",
            "Train Epoch: 198 [2520/2812 (89%)]\tLoss: 1.523795\n",
            "Train Epoch: 198 [2640/2812 (94%)]\tLoss: 18.733383\n",
            "Train Epoch: 198 [2760/2812 (98%)]\tLoss: 11.400599\n",
            "Training Loss: 11.0512 Acc: 49.1465\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.5917, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 199/200\n",
            "----------\n",
            "Train Epoch: 199 [0/2812 (0%)]\tLoss: 10.056183\n",
            "Train Epoch: 199 [120/2812 (4%)]\tLoss: 11.903189\n",
            "Train Epoch: 199 [240/2812 (9%)]\tLoss: 9.681843\n",
            "Train Epoch: 199 [360/2812 (13%)]\tLoss: 19.076719\n",
            "Train Epoch: 199 [480/2812 (17%)]\tLoss: 10.916898\n",
            "Train Epoch: 199 [600/2812 (21%)]\tLoss: 11.088621\n",
            "Train Epoch: 199 [720/2812 (26%)]\tLoss: 4.534382\n",
            "Train Epoch: 199 [840/2812 (30%)]\tLoss: 10.731831\n",
            "Train Epoch: 199 [960/2812 (34%)]\tLoss: 8.370114\n",
            "Train Epoch: 199 [1080/2812 (38%)]\tLoss: 9.010093\n",
            "Train Epoch: 199 [1200/2812 (43%)]\tLoss: 13.746986\n",
            "Train Epoch: 199 [1320/2812 (47%)]\tLoss: 7.523689\n",
            "Train Epoch: 199 [1440/2812 (51%)]\tLoss: 9.384916\n",
            "Train Epoch: 199 [1560/2812 (55%)]\tLoss: 6.391519\n",
            "Train Epoch: 199 [1680/2812 (60%)]\tLoss: 8.462172\n",
            "Train Epoch: 199 [1800/2812 (64%)]\tLoss: 15.399051\n",
            "Train Epoch: 199 [1920/2812 (68%)]\tLoss: 10.579407\n",
            "Train Epoch: 199 [2040/2812 (72%)]\tLoss: 11.716186\n",
            "Train Epoch: 199 [2160/2812 (77%)]\tLoss: 8.022084\n",
            "Train Epoch: 199 [2280/2812 (81%)]\tLoss: 10.865376\n",
            "Train Epoch: 199 [2400/2812 (85%)]\tLoss: 5.984312\n",
            "Train Epoch: 199 [2520/2812 (89%)]\tLoss: 8.965780\n",
            "Train Epoch: 199 [2640/2812 (94%)]\tLoss: 6.464051\n",
            "Train Epoch: 199 [2760/2812 (98%)]\tLoss: 14.910837\n",
            "Training Loss: 10.8348 Acc: 50.7824\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6183, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 200/200\n",
            "----------\n",
            "Train Epoch: 200 [0/2812 (0%)]\tLoss: 23.609715\n",
            "Train Epoch: 200 [120/2812 (4%)]\tLoss: 12.417045\n",
            "Train Epoch: 200 [240/2812 (9%)]\tLoss: 9.466173\n",
            "Train Epoch: 200 [360/2812 (13%)]\tLoss: 6.567132\n",
            "Train Epoch: 200 [480/2812 (17%)]\tLoss: 18.222719\n",
            "Train Epoch: 200 [600/2812 (21%)]\tLoss: 7.585227\n",
            "Train Epoch: 200 [720/2812 (26%)]\tLoss: 9.512045\n",
            "Train Epoch: 200 [840/2812 (30%)]\tLoss: 4.797431\n",
            "Train Epoch: 200 [960/2812 (34%)]\tLoss: 8.434385\n",
            "Train Epoch: 200 [1080/2812 (38%)]\tLoss: 3.815675\n",
            "Train Epoch: 200 [1200/2812 (43%)]\tLoss: 10.546997\n",
            "Train Epoch: 200 [1320/2812 (47%)]\tLoss: 20.831514\n",
            "Train Epoch: 200 [1440/2812 (51%)]\tLoss: 23.311031\n",
            "Train Epoch: 200 [1560/2812 (55%)]\tLoss: 8.762735\n",
            "Train Epoch: 200 [1680/2812 (60%)]\tLoss: 21.901175\n",
            "Train Epoch: 200 [1800/2812 (64%)]\tLoss: 8.650518\n",
            "Train Epoch: 200 [1920/2812 (68%)]\tLoss: 14.796313\n",
            "Train Epoch: 200 [2040/2812 (72%)]\tLoss: 9.038946\n",
            "Train Epoch: 200 [2160/2812 (77%)]\tLoss: 16.408848\n",
            "Train Epoch: 200 [2280/2812 (81%)]\tLoss: 17.640888\n",
            "Train Epoch: 200 [2400/2812 (85%)]\tLoss: 10.025377\n",
            "Train Epoch: 200 [2520/2812 (89%)]\tLoss: 10.024604\n",
            "Train Epoch: 200 [2640/2812 (94%)]\tLoss: 13.463201\n",
            "Train Epoch: 200 [2760/2812 (98%)]\tLoss: 22.634211\n",
            "Training Loss: 11.3051 Acc: 50.2489\n",
            "length of validation loader:  90\n",
            "\n",
            "Validation set: Average loss: 0.6348, Accuracy: 486/891 (54.545%)\n",
            "\n",
            "Training complete in 74m 35s\n",
            "\n",
            "Best validation accuracy=54.6577%\n",
            "length of test loader:  98\n",
            "\n",
            "Test set: Average loss: 0.1796, Accuracy: 488/972 (50.206%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoMKNVuu5QAH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "# modified from main.py https://github.com/zhangrong1722/CheXNet-Pytorch\n",
        "\n",
        "def plt_roc(test_y, probas_y, plot_micro=False, plot_macro=False):\n",
        "    assert isinstance(test_y, list) and isinstance(probas_y, list), 'the type of input must be list'\n",
        "    skplt.metrics.plot_roc(test_y, probas_y, plot_micro=plot_micro, plot_macro=plot_macro)\n",
        "    plt.savefig('roc_auc_curve.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "###########################################\n",
        "# Define confusion matrix and ROC visualization functions\n",
        "# from https://colab.research.google.com/drive/1ISfhxFDntfOos7cOeT7swduSqzLEqyFn#scrollTo=UiKRYOWPfhJs\n",
        "\n",
        "def plot_confusion_matrix(cm, classes=None,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues,\n",
        "                          cv=10):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "   \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"\\nNormalized confusion matrix\")\n",
        "    else:\n",
        "        print('\\nConfusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    if classes:\n",
        "        tick_marks = np.arange(len(classes))\n",
        "        plt.xticks(tick_marks, classes, rotation=45)\n",
        "        plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 1.5\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.locator_params(nbins=2)\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOd0ZL829ce1"
      },
      "source": [
        "best_model_preds = pd.read_csv('best_val_model_predictions.csv')\n",
        "pred_y = best_model_preds['pred_y'].values\n",
        "test_y = best_model_preds['test_y'].values\n",
        "probas_y = [s.replace('[', '').replace(']', '').split(', ') for s in best_model_preds['probas_y'].values]\n",
        "probas_y = [[float(t[0]), float(t[1])] for t in probas_y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXCwPEYx9ZeC",
        "outputId": "f7d79876-f4e0-4229-d4cb-3a3c207751af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion = confusion_matrix(pred_y, test_y)\n",
        "plot_confusion_matrix(confusion,\n",
        "                      classes=['hc', 'sz'],\n",
        "                      title='Confusion matrix')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion matrix, without normalization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgit09GQHyJ4",
        "outputId": "545b9bec-46f7-4177-d991-a77cd913013b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "!pip install scikit_plot\n",
        "import scikitplot as skplt\n",
        "plt_roc(list(test_y), list(probas_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit_plot in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit_plot) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit_plot) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit_plot) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit_plot) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.9->scikit_plot) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit_plot) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit_plot) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit_plot) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit_plot) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit_plot) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ive-YKE_7E0k",
        "outputId": "fa200ab9-2cec-49f9-90bd-82ab4969b921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "metrics = pd.read_csv('metrics_by_epoch.csv')\n",
        "metrics.head()\n",
        "#TODO chart these values\n",
        "\n",
        "metrics[['train_loss', 'val_loss']].plot(figsize=(10,5), title='Train and Validation Loss over Epochs')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f29ef74f080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYjx8J6sPJT4",
        "outputId": "961fcd9e-a681-41b9-f17c-836c829ba51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "metrics[['train_acc', 'val_acc']].plot(figsize=(10,5), title='Train and Validation Accuracy over Epochs')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2a0042cf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjnh7lPC01OT",
        "outputId": "c873a9b6-7e8c-4409-9b3b-34549f54b3c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "auc = roc_auc_score(test_y, pred_y)\n",
        "print('AUC score for validation set: ', auc)\n",
        "\n",
        "\n",
        "f1_macro = f1_score(test_y, pred_y, average='macro')\n",
        "f1_micro = f1_score(test_y, pred_y, average='micro')\n",
        "\n",
        "print('F1 score (average=macro): {}     F1 score (average=micro): {}'.format(f1_macro, f1_micro))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for validation set:  0.5014403292181069\n",
            "F1 score (average=macro): 0.35788594913948113     F1 score (average=micro): 0.5465768799102132\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
