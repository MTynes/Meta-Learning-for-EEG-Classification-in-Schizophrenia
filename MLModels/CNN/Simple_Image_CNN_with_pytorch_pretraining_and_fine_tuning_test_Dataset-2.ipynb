{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Simple Image CNN with pytorch pretraining and fine-tuning - test MSU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IulYndEgkpMu"
      },
      "source": [
        "#############################\n",
        "## For this version, training is done with two classes of mini-imagenet,\n",
        "## further training / fine tuning is done with the second EEG dataset (MSU)\n",
        "## The 1st dataset, EEG of Sz is split into a validation and test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMxAxj4Lyjkq",
        "outputId": "df6b0d71-e9b8-4a5f-a2c4-d35dfc080cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->scikit-plot) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ds2tvhWyEs9",
        "outputId": "15604799-dd8c-4bfc-e1cb-b779277f6c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# To improve the speed of setting up, retrieve only the files for the two groups used in training\n",
        "# Swap with the line below to get the entire dataset as a zip file\n",
        "# gdown.download('https://drive.google.com/uc?id=1-QTtycxsVNeym17zrMBSZCAAtEZEs05p', '/content/miniimagenet.zip', quiet=False)\n",
        "\n",
        "gdown.download('https://drive.google.com/uc?id=1CZeMPRt4OZGJL_xQNfgi5evJW1PpA77l', '/content/miniimagenet.zip', quiet=False) # selected groups only\n",
        "images_directory = '/content/miniimagenet/images/'\n",
        "if not os.path.exists(images_directory):\n",
        "  os.makedirs(images_directory) \n",
        "!unzip -qq /content/miniimagenet.zip -d {images_directory}\n",
        "\n",
        "\n",
        "# get the CSV with the list of all file names\n",
        "mini_imagenet_file_list_csv = '/content/all_imagenet_file_names.csv'\n",
        "gdown.download('https://drive.google.com/uc?id=1-1JiyyEC6JlnEi0H0x-JKIGEKjdI_Nea', mini_imagenet_file_list_csv, quiet=False)\n",
        "file_list = pd.read_csv(mini_imagenet_file_list_csv)\n",
        "\n",
        "mini_imagenet_file_list = os.listdir(images_directory) #to exclude the directories created next\n",
        "selected_groups = ['n01532829', 'n01558993']\n",
        "for group_name in selected_groups:\n",
        "  group_file = '/content/miniimagenet/images/' +  group_name\n",
        "  if not os.path.isdir(group_file):\n",
        "    os.makedirs(group_file)\n",
        "samples_miniimagenet = file_list[file_list['label'].isin(selected_groups)].groupby('label').first()\n",
        "\n",
        "# Other options for group pairs\n",
        "# n01532829, n01558993\n",
        "# n02108551, n02108915\n",
        "\n",
        "for file in mini_imagenet_file_list:\n",
        "  group = file[:9]\n",
        "  file_dst = '/content/miniimagenet/images/{}/{}'.format(group, file)\n",
        "  shutil.copyfile(images_directory + file, file_dst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CZeMPRt4OZGJL_xQNfgi5evJW1PpA77l\n",
            "To: /content/miniimagenet.zip\n",
            "59.8MB [00:01, 55.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-1JiyyEC6JlnEi0H0x-JKIGEKjdI_Nea\n",
            "To: /content/all_imagenet_file_names.csv\n",
            "2.27MB [00:00, 110MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P6yjksbyGJ8",
        "outputId": "b5c11f61-bbdf-49b4-f3c8-8e49b8d9f164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Get the MSU EEG spectrograms zip file and unzip it\n",
        "eeg_image_directory = '/content/eeg_sz_spectrograms'\n",
        "\n",
        "gdown.download('https://drive.google.com/uc?id=1CQwVM0OpOKAhfk6qvgbGHV8OLguYH_qJ', '{}.zip'.format(eeg_image_directory), quiet=False) \n",
        "\n",
        "!unzip -qq {eeg_image_directory}.zip -d {eeg_image_directory}\n",
        "\n",
        "# rename \n",
        "\n",
        "dl_link = '{}/content/drive/My Drive/ML Projects/data/MSU.ru__gen_data_5s_70pct_overlap_-_fractional_noverlap_all_channels_sml_all_participants_v2'.format(eeg_image_directory)\n",
        "\n",
        "!mv \"{dl_link}/hc\" {eeg_image_directory}\n",
        "!mv \"{dl_link}/sz\" {eeg_image_directory}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CQwVM0OpOKAhfk6qvgbGHV8OLguYH_qJ\n",
            "To: /content/eeg_sz_spectrograms.zip\n",
            "118MB [00:00, 226MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5mT1trFuxKP",
        "outputId": "6981fbca-a164-48b4-be4e-1be00894d039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Get the spectrograms zip file for the fine tuning step\n",
        "# For this version of the program, we attempt to use spectrograms from a different EEG dataset to fine-tune the program. \n",
        "# The first EEG dataset will still be used for testing\n",
        "\n",
        "fine_tuning_image_directory = '/content/fine_tuning_eeg_spectrograms'\n",
        "gdown.download('https://drive.google.com/uc?id=1WZ1yIFE2bng0McnY_4UBJHqTttsXTTNX', '{}.zip'.format(fine_tuning_image_directory), quiet=False) \n",
        "!unzip -qq {fine_tuning_image_directory}.zip -d {fine_tuning_image_directory}\n",
        "\n",
        "# rename \n",
        "\n",
        "ft_dl_link = '{}/gen_data_20s_70pct_overlap_-_high_nfft_all_channels_sml/'.format(fine_tuning_image_directory)\n",
        "\n",
        "!mv \"{ft_dl_link}/hc\" {fine_tuning_image_directory}\n",
        "!mv \"{ft_dl_link}/sz\" {fine_tuning_image_directory}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WZ1yIFE2bng0McnY_4UBJHqTttsXTTNX\n",
            "To: /content/fine_tuning_eeg_spectrograms.zip\n",
            "44.2MB [00:00, 152MB/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iMjz3c7cFL_"
      },
      "source": [
        "#sorted([s.split('_')[0] for s in os.listdir(fine_tuning_image_directory + '/' + 'sz') ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv07AtSyvLv3",
        "outputId": "fd60ad1d-93d0-4419-bb9f-33fb7dd96fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "# Use MSU for validation and testing\n",
        "# Extract files from an eeg_sz spectrogram directory where files are saved by subject\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "\n",
        "rand_seed = 1\n",
        "random.seed(1)\n",
        "\n",
        "# List of raw patient file IDs that should be skipped based on categorization as outliers\n",
        "ignore_list = []\n",
        "hc_subject_ids = ['hc' + str(i) for i in range(38) if \"h{:02}\".format(i) not in ignore_list] \n",
        "\n",
        "#There are 45 Sz participants. Select 38 of those to match with the control group\n",
        "rand = random.Random(1)\n",
        "sz_subject_id_range = [i for i in range(45) if \"s{:02}\".format(i) not in ignore_list]\n",
        "sz_subject_ids = rand.sample(sz_subject_id_range, k=38) \n",
        "sz_subject_ids = ['sz' + str(i) for i in sz_subject_ids]\n",
        "\n",
        "all_subject_ids = np.concatenate([hc_subject_ids, sz_subject_ids], axis=0)\n",
        "validate_hc, test_hc = train_test_split(hc_subject_ids, test_size=0.5, random_state=rand_seed)\n",
        "validate_sz, test_sz = train_test_split(sz_subject_ids, test_size=0.5, random_state=rand_seed)\n",
        "\n",
        "validation_ids = np.concatenate([validate_hc, validate_sz])  # unused\n",
        "test_ids = np.concatenate([test_hc, test_sz]) \n",
        "\n",
        "\n",
        "print('\\nSubjects assigned to groups using sklearn.model_selection.train_test_split')\n",
        "print('Test group: ', \", \".join(test_ids), \"\\n\")\n",
        "print('Validation group: ', \", \".join(validation_ids), \"\\n\")\n",
        "\n",
        "  \n",
        "\n",
        "from shutil import copyfile\n",
        "import pandas as pd\n",
        "import os \n",
        "\n",
        "\n",
        "test_images_output_directory = 'all_test_images'\n",
        "validation_images_output_directory = 'all_validation_images'\n",
        "\n",
        "if not os.path.exists(test_images_output_directory):\n",
        "    os.mkdir(test_images_output_directory)\n",
        "if not os.path.exists(validation_images_output_directory):\n",
        "    os.mkdir(validation_images_output_directory)\n",
        "\n",
        "\n",
        "\n",
        "# Note: CSV is only used for MAML and Prototypical networks\n",
        "def gen_csv_and_copy_sz_files(image_dir, img_output_dir, participant_ids, output_name, split_with_csv=False):\n",
        "    subdir_data = []\n",
        "    for group in ['hc', 'sz']: #['Healthy_Control', 'Sz_Patient']:\n",
        "        for pid in os.listdir(image_dir + '/' + group): # by participant IDs\n",
        "            if pid in participant_ids:\n",
        "              for file in os.listdir(image_dir + '/' + group + '/' + pid):\n",
        "                file_data = {'filename': file, 'label': group}\n",
        "                subdir_data.append(file_data)\n",
        "                destination = img_output_dir + '/' + file if split_with_csv else  '{}/{}/{}'.format(img_output_dir, group, file)\n",
        "                if not os.path.exists('{}/{}'.format(img_output_dir, group)):\n",
        "                  os.makedirs('{}/{}'.format(img_output_dir, group))\n",
        "                copyfile(image_dir + '/' + group + '/' + pid + '/' + file,  destination )\n",
        "    if split_with_csv:\n",
        "      pd.DataFrame(subdir_data).to_csv(img_output_dir + '/' + output_name)\n",
        "    return pd.DataFrame(subdir_data)\n",
        "\n",
        "\n",
        "df = gen_csv_and_copy_sz_files(image_dir=eeg_image_directory, \n",
        "                                img_output_dir=test_images_output_directory,\n",
        "                                participant_ids=test_ids,\n",
        "                               split_with_csv=False,\n",
        "                                output_name= 'test.csv')\n",
        "df = gen_csv_and_copy_sz_files(image_dir=eeg_image_directory, \n",
        "                                img_output_dir=validation_images_output_directory,\n",
        "                                participant_ids=validation_ids, \n",
        "                               split_with_csv=False,\n",
        "                                output_name= 'val.csv')\n",
        "print(df.head())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Subjects assigned to groups using sklearn.model_selection.train_test_split\n",
            "Test group:  hc2, hc29, hc3, hc22, hc25, hc27, hc21, hc35, hc19, hc24, hc30, hc17, hc28, hc34, hc31, hc26, hc4, hc14, hc10, sz4, sz41, sz16, sz40, sz10, sz21, sz44, sz15, sz22, sz3, sz27, sz38, sz17, sz37, sz34, sz26, sz7, sz35, sz6 \n",
            "\n",
            "Validation group:  hc33, hc23, hc32, hc20, hc18, hc6, hc13, hc7, hc36, hc1, hc16, hc0, hc15, hc5, hc11, hc9, hc8, hc12, hc37, sz20, sz18, sz29, sz14, sz0, sz28, sz43, sz30, sz23, sz36, sz33, sz8, sz19, sz31, sz39, sz13, sz24, sz1, sz11 \n",
            "\n",
            "     filename label\n",
            "0   hc6_2.png    hc\n",
            "1  hc6_16.png    hc\n",
            "2  hc6_33.png    hc\n",
            "3  hc6_22.png    hc\n",
            "4   hc6_9.png    hc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kc-elftvmlL",
        "outputId": "156a458b-d08d-426f-ec7a-45f4e449149a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "###########################\n",
        "### Process second training set (fine tuning set)\n",
        "\n",
        "# Extract files from an eeg_sz spectrogram directory where files are saved by subject\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# List of raw patient file IDs that should be skipped based on categorization as outliers\n",
        "ft_ignore_list = ['h09', 'h10', 's10', 's11', 's12']\n",
        "ft_hc_subject_ids = ['hc' + str(i) for i in range(14) if \"h{:02}\".format(i) not in ft_ignore_list] \n",
        "ft_sz_subject_ids = ['sz' + str(i) for i in range(14) if \"s{:02}\".format(i) not in ft_ignore_list] \n",
        "ft_all_subject_ids = np.concatenate([ft_hc_subject_ids, ft_sz_subject_ids], axis=0)\n",
        "\n",
        "ft_images_output_directory = '/content/all_fine_tuning_images'\n",
        "\n",
        "if not os.path.exists(ft_images_output_directory):\n",
        "    os.mkdir(ft_images_output_directory)\n",
        "\n",
        "print('\\nAll subjects assigned to training group for fine tuning')\n",
        "print(ft_all_subject_ids)\n",
        "\n",
        "ids = { 'test': test_ids}\n",
        "  \n",
        "\n",
        "\n",
        "ft_df = gen_csv_and_copy_sz_files(image_dir=fine_tuning_image_directory, \n",
        "                                img_output_dir=ft_images_output_directory,\n",
        "                                participant_ids=ft_all_subject_ids, \n",
        "                                split_with_csv = False,\n",
        "                                output_name= 'train.csv')\n",
        "print(ft_df.head())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "All subjects assigned to training group for fine tuning\n",
            "['hc0' 'hc1' 'hc2' 'hc3' 'hc4' 'hc5' 'hc6' 'hc7' 'hc8' 'hc11' 'hc12'\n",
            " 'hc13' 'sz0' 'sz1' 'sz2' 'sz3' 'sz4' 'sz5' 'sz6' 'sz7' 'sz8' 'sz9' 'sz13']\n",
            "     filename label\n",
            "0  hc6_56.png    hc\n",
            "1   hc6_2.png    hc\n",
            "2  hc6_39.png    hc\n",
            "3  hc6_49.png    hc\n",
            "4  hc6_46.png    hc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeMr_7-5vLVF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvaJEQT_pLbP"
      },
      "source": [
        "#!wget https://github.com/WinAIML/schizophrenia/blob/master/MLModels/CNN/cnn_pytorch.py -o main.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGdjsKKZFFsg",
        "outputId": "17be10ea-30a0-44da-a7f9-f9947bc95a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "%cd /content\n",
        "\n",
        "#!git clone https://github.com/zhangrong1722/CheXNet-Pytorch.git binaryCNN\n",
        "\n",
        "gdown.download('https://drive.google.com/uc?id=1c1ADbwdNBxmN9jjzhcaCIIN5fD3BDCAc', 'main.py', quiet=False) \n",
        "\n",
        "train_directory ='/content/miniimagenet/images'\n",
        "test_directory ='/content/all_test_images'\n",
        "validation_directory = '/content/all_validation_images'\n",
        "fine_tuning_directory ='/content/all_fine_tuning_images'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1c1ADbwdNBxmN9jjzhcaCIIN5fD3BDCAc\n",
            "To: /content/main.py\n",
            "100%|██████████| 16.5k/16.5k [00:00<00:00, 13.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S50C3upOTx5P",
        "outputId": "1cf252df-387e-4e58-d8d1-012f26c05253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python main.py  --train_dir {train_directory} --fine_tuning_dir {fine_tuning_directory} --validation_dir {validation_directory} --test_dir {test_directory} --epochs 200 --fine_tuning_epochs 200\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Mode: main training cycle   Epoch 178/200\n",
            "----------\n",
            "Train Epoch: 178 [0/1200 (0%)]\tLoss: 0.000033\n",
            "Train Epoch: 178 [120/1200 (10%)]\tLoss: 0.000001\n",
            "Train Epoch: 178 [240/1200 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 178 [360/1200 (30%)]\tLoss: 0.000052\n",
            "Train Epoch: 178 [480/1200 (40%)]\tLoss: 0.000001\n",
            "Train Epoch: 178 [600/1200 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 178 [720/1200 (60%)]\tLoss: 0.010935\n",
            "Train Epoch: 178 [840/1200 (70%)]\tLoss: 0.000043\n",
            "Train Epoch: 178 [960/1200 (80%)]\tLoss: 0.000092\n",
            "Train Epoch: 178 [1080/1200 (90%)]\tLoss: 0.000432\n",
            "Training Loss: 0.0003 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2642, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 179/200\n",
            "----------\n",
            "Train Epoch: 179 [0/1200 (0%)]\tLoss: 0.000003\n",
            "Train Epoch: 179 [120/1200 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 179 [240/1200 (20%)]\tLoss: 0.021959\n",
            "Train Epoch: 179 [360/1200 (30%)]\tLoss: 0.000007\n",
            "Train Epoch: 179 [480/1200 (40%)]\tLoss: 0.000008\n",
            "Train Epoch: 179 [600/1200 (50%)]\tLoss: 0.000007\n",
            "Train Epoch: 179 [720/1200 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 179 [840/1200 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 179 [960/1200 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 179 [1080/1200 (90%)]\tLoss: 0.000000\n",
            "Training Loss: 0.0011 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2502, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 180/200\n",
            "----------\n",
            "Train Epoch: 180 [0/1200 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 180 [120/1200 (10%)]\tLoss: 0.000003\n",
            "Train Epoch: 180 [240/1200 (20%)]\tLoss: 0.000167\n",
            "Train Epoch: 180 [360/1200 (30%)]\tLoss: 0.000004\n",
            "Train Epoch: 180 [480/1200 (40%)]\tLoss: 0.000851\n",
            "Train Epoch: 180 [600/1200 (50%)]\tLoss: 0.000009\n",
            "Train Epoch: 180 [720/1200 (60%)]\tLoss: 0.010559\n",
            "Train Epoch: 180 [840/1200 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 180 [960/1200 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 180 [1080/1200 (90%)]\tLoss: 0.000003\n",
            "Training Loss: 0.0024 Acc: 99.9167\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2483, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 181/200\n",
            "----------\n",
            "Train Epoch: 181 [0/1200 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 181 [120/1200 (10%)]\tLoss: 0.000135\n",
            "Train Epoch: 181 [240/1200 (20%)]\tLoss: 0.000070\n",
            "Train Epoch: 181 [360/1200 (30%)]\tLoss: 0.006552\n",
            "Train Epoch: 181 [480/1200 (40%)]\tLoss: 0.000011\n",
            "Train Epoch: 181 [600/1200 (50%)]\tLoss: 0.001039\n",
            "Train Epoch: 181 [720/1200 (60%)]\tLoss: 0.000003\n",
            "Train Epoch: 181 [840/1200 (70%)]\tLoss: 0.000003\n",
            "Train Epoch: 181 [960/1200 (80%)]\tLoss: 0.000043\n",
            "Train Epoch: 181 [1080/1200 (90%)]\tLoss: 0.000003\n",
            "Training Loss: 0.0005 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2505, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 182/200\n",
            "----------\n",
            "Train Epoch: 182 [0/1200 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 182 [120/1200 (10%)]\tLoss: 0.000009\n",
            "Train Epoch: 182 [240/1200 (20%)]\tLoss: 0.000001\n",
            "Train Epoch: 182 [360/1200 (30%)]\tLoss: 0.000327\n",
            "Train Epoch: 182 [480/1200 (40%)]\tLoss: 0.000312\n",
            "Train Epoch: 182 [600/1200 (50%)]\tLoss: 0.000044\n",
            "Train Epoch: 182 [720/1200 (60%)]\tLoss: 0.004810\n",
            "Train Epoch: 182 [840/1200 (70%)]\tLoss: 0.000231\n",
            "Train Epoch: 182 [960/1200 (80%)]\tLoss: 0.000002\n",
            "Train Epoch: 182 [1080/1200 (90%)]\tLoss: 0.001077\n",
            "Training Loss: 0.0010 Acc: 99.9167\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2623, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 183/200\n",
            "----------\n",
            "Train Epoch: 183 [0/1200 (0%)]\tLoss: 0.000038\n",
            "Train Epoch: 183 [120/1200 (10%)]\tLoss: 0.000090\n",
            "Train Epoch: 183 [240/1200 (20%)]\tLoss: 0.002238\n",
            "Train Epoch: 183 [360/1200 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 183 [480/1200 (40%)]\tLoss: 0.000010\n",
            "Train Epoch: 183 [600/1200 (50%)]\tLoss: 0.000004\n",
            "Train Epoch: 183 [720/1200 (60%)]\tLoss: 0.000001\n",
            "Train Epoch: 183 [840/1200 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 183 [960/1200 (80%)]\tLoss: 0.000052\n",
            "Train Epoch: 183 [1080/1200 (90%)]\tLoss: 0.000001\n",
            "Training Loss: 0.0002 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3022, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 184/200\n",
            "----------\n",
            "Train Epoch: 184 [0/1200 (0%)]\tLoss: 0.000221\n",
            "Train Epoch: 184 [120/1200 (10%)]\tLoss: 0.000038\n",
            "Train Epoch: 184 [240/1200 (20%)]\tLoss: 0.000168\n",
            "Train Epoch: 184 [360/1200 (30%)]\tLoss: 0.000005\n",
            "Train Epoch: 184 [480/1200 (40%)]\tLoss: 0.000013\n",
            "Train Epoch: 184 [600/1200 (50%)]\tLoss: 0.000003\n",
            "Train Epoch: 184 [720/1200 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 184 [840/1200 (70%)]\tLoss: 0.000091\n",
            "Train Epoch: 184 [960/1200 (80%)]\tLoss: 0.008069\n",
            "Train Epoch: 184 [1080/1200 (90%)]\tLoss: 0.000050\n",
            "Training Loss: 0.0003 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2511, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 185/200\n",
            "----------\n",
            "Train Epoch: 185 [0/1200 (0%)]\tLoss: 0.000043\n",
            "Train Epoch: 185 [120/1200 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 185 [240/1200 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 185 [360/1200 (30%)]\tLoss: 0.000007\n",
            "Train Epoch: 185 [480/1200 (40%)]\tLoss: 0.000002\n",
            "Train Epoch: 185 [600/1200 (50%)]\tLoss: 0.000030\n",
            "Train Epoch: 185 [720/1200 (60%)]\tLoss: 0.000006\n",
            "Train Epoch: 185 [840/1200 (70%)]\tLoss: 0.000890\n",
            "Train Epoch: 185 [960/1200 (80%)]\tLoss: 0.000001\n",
            "Train Epoch: 185 [1080/1200 (90%)]\tLoss: 0.001173\n",
            "Training Loss: 0.0003 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2382, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 186/200\n",
            "----------\n",
            "Train Epoch: 186 [0/1200 (0%)]\tLoss: 0.000016\n",
            "Train Epoch: 186 [120/1200 (10%)]\tLoss: 0.000002\n",
            "Train Epoch: 186 [240/1200 (20%)]\tLoss: 0.000061\n",
            "Train Epoch: 186 [360/1200 (30%)]\tLoss: 0.000695\n",
            "Train Epoch: 186 [480/1200 (40%)]\tLoss: 0.000317\n",
            "Train Epoch: 186 [600/1200 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 186 [720/1200 (60%)]\tLoss: 0.000100\n",
            "Train Epoch: 186 [840/1200 (70%)]\tLoss: 0.000001\n",
            "Train Epoch: 186 [960/1200 (80%)]\tLoss: 0.000002\n",
            "Train Epoch: 186 [1080/1200 (90%)]\tLoss: 0.000135\n",
            "Training Loss: 0.0002 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2828, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 187/200\n",
            "----------\n",
            "Train Epoch: 187 [0/1200 (0%)]\tLoss: 0.000008\n",
            "Train Epoch: 187 [120/1200 (10%)]\tLoss: 0.005655\n",
            "Train Epoch: 187 [240/1200 (20%)]\tLoss: 0.000251\n",
            "Train Epoch: 187 [360/1200 (30%)]\tLoss: 0.000290\n",
            "Train Epoch: 187 [480/1200 (40%)]\tLoss: 0.000011\n",
            "Train Epoch: 187 [600/1200 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 187 [720/1200 (60%)]\tLoss: 0.000002\n",
            "Train Epoch: 187 [840/1200 (70%)]\tLoss: 0.000066\n",
            "Train Epoch: 187 [960/1200 (80%)]\tLoss: 0.000298\n",
            "Train Epoch: 187 [1080/1200 (90%)]\tLoss: 0.000003\n",
            "Training Loss: 0.0016 Acc: 99.9167\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2164, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 188/200\n",
            "----------\n",
            "Train Epoch: 188 [0/1200 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 188 [120/1200 (10%)]\tLoss: 0.000057\n",
            "Train Epoch: 188 [240/1200 (20%)]\tLoss: 0.000148\n",
            "Train Epoch: 188 [360/1200 (30%)]\tLoss: 0.000028\n",
            "Train Epoch: 188 [480/1200 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 188 [600/1200 (50%)]\tLoss: 0.000001\n",
            "Train Epoch: 188 [720/1200 (60%)]\tLoss: 0.000057\n",
            "Train Epoch: 188 [840/1200 (70%)]\tLoss: 0.000071\n",
            "Train Epoch: 188 [960/1200 (80%)]\tLoss: 0.000002\n",
            "Train Epoch: 188 [1080/1200 (90%)]\tLoss: 0.000502\n",
            "Training Loss: 0.0003 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2663, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 189/200\n",
            "----------\n",
            "Train Epoch: 189 [0/1200 (0%)]\tLoss: 0.000021\n",
            "Train Epoch: 189 [120/1200 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 189 [240/1200 (20%)]\tLoss: 0.000176\n",
            "Train Epoch: 189 [360/1200 (30%)]\tLoss: 0.000772\n",
            "Train Epoch: 189 [480/1200 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 189 [600/1200 (50%)]\tLoss: 0.000003\n",
            "Train Epoch: 189 [720/1200 (60%)]\tLoss: 0.000006\n",
            "Train Epoch: 189 [840/1200 (70%)]\tLoss: 0.000043\n",
            "Train Epoch: 189 [960/1200 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 189 [1080/1200 (90%)]\tLoss: 0.000012\n",
            "Training Loss: 0.0007 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2625, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 190/200\n",
            "----------\n",
            "Train Epoch: 190 [0/1200 (0%)]\tLoss: 0.001951\n",
            "Train Epoch: 190 [120/1200 (10%)]\tLoss: 0.000022\n",
            "Train Epoch: 190 [240/1200 (20%)]\tLoss: 0.000018\n",
            "Train Epoch: 190 [360/1200 (30%)]\tLoss: 0.000003\n",
            "Train Epoch: 190 [480/1200 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 190 [600/1200 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 190 [720/1200 (60%)]\tLoss: 0.000038\n",
            "Train Epoch: 190 [840/1200 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 190 [960/1200 (80%)]\tLoss: 0.011470\n",
            "Train Epoch: 190 [1080/1200 (90%)]\tLoss: 0.000000\n",
            "Training Loss: 0.0006 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2710, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 191/200\n",
            "----------\n",
            "Train Epoch: 191 [0/1200 (0%)]\tLoss: 0.000192\n",
            "Train Epoch: 191 [120/1200 (10%)]\tLoss: 0.000009\n",
            "Train Epoch: 191 [240/1200 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 191 [360/1200 (30%)]\tLoss: 0.000012\n",
            "Train Epoch: 191 [480/1200 (40%)]\tLoss: 0.000037\n",
            "Train Epoch: 191 [600/1200 (50%)]\tLoss: 0.000007\n",
            "Train Epoch: 191 [720/1200 (60%)]\tLoss: 0.000828\n",
            "Train Epoch: 191 [840/1200 (70%)]\tLoss: 0.000007\n",
            "Train Epoch: 191 [960/1200 (80%)]\tLoss: 0.000002\n",
            "Train Epoch: 191 [1080/1200 (90%)]\tLoss: 0.000049\n",
            "Training Loss: 0.0012 Acc: 99.9167\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2756, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 192/200\n",
            "----------\n",
            "Train Epoch: 192 [0/1200 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 192 [120/1200 (10%)]\tLoss: 0.000003\n",
            "Train Epoch: 192 [240/1200 (20%)]\tLoss: 0.000125\n",
            "Train Epoch: 192 [360/1200 (30%)]\tLoss: 0.000001\n",
            "Train Epoch: 192 [480/1200 (40%)]\tLoss: 0.000003\n",
            "Train Epoch: 192 [600/1200 (50%)]\tLoss: 0.036408\n",
            "Train Epoch: 192 [720/1200 (60%)]\tLoss: 0.000003\n",
            "Train Epoch: 192 [840/1200 (70%)]\tLoss: 0.002361\n",
            "Train Epoch: 192 [960/1200 (80%)]\tLoss: 0.000025\n",
            "Train Epoch: 192 [1080/1200 (90%)]\tLoss: 0.000078\n",
            "Training Loss: 0.0018 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2714, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 193/200\n",
            "----------\n",
            "Train Epoch: 193 [0/1200 (0%)]\tLoss: 0.000704\n",
            "Train Epoch: 193 [120/1200 (10%)]\tLoss: 0.000007\n",
            "Train Epoch: 193 [240/1200 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 193 [360/1200 (30%)]\tLoss: 0.000003\n",
            "Train Epoch: 193 [480/1200 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 193 [600/1200 (50%)]\tLoss: 0.000009\n",
            "Train Epoch: 193 [720/1200 (60%)]\tLoss: 0.000031\n",
            "Train Epoch: 193 [840/1200 (70%)]\tLoss: 0.000017\n",
            "Train Epoch: 193 [960/1200 (80%)]\tLoss: 0.000002\n",
            "Train Epoch: 193 [1080/1200 (90%)]\tLoss: 0.000095\n",
            "Training Loss: 0.0002 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2961, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 194/200\n",
            "----------\n",
            "Train Epoch: 194 [0/1200 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 194 [120/1200 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 194 [240/1200 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 194 [360/1200 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 194 [480/1200 (40%)]\tLoss: 0.001059\n",
            "Train Epoch: 194 [600/1200 (50%)]\tLoss: 0.000001\n",
            "Train Epoch: 194 [720/1200 (60%)]\tLoss: 0.000011\n",
            "Train Epoch: 194 [840/1200 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 194 [960/1200 (80%)]\tLoss: 0.000703\n",
            "Train Epoch: 194 [1080/1200 (90%)]\tLoss: 0.000007\n",
            "Training Loss: 0.0028 Acc: 99.9167\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3142, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 195/200\n",
            "----------\n",
            "Train Epoch: 195 [0/1200 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 195 [120/1200 (10%)]\tLoss: 0.000001\n",
            "Train Epoch: 195 [240/1200 (20%)]\tLoss: 0.000201\n",
            "Train Epoch: 195 [360/1200 (30%)]\tLoss: 0.000021\n",
            "Train Epoch: 195 [480/1200 (40%)]\tLoss: 0.000014\n",
            "Train Epoch: 195 [600/1200 (50%)]\tLoss: 0.000022\n",
            "Train Epoch: 195 [720/1200 (60%)]\tLoss: 0.003344\n",
            "Train Epoch: 195 [840/1200 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 195 [960/1200 (80%)]\tLoss: 0.000001\n",
            "Train Epoch: 195 [1080/1200 (90%)]\tLoss: 0.000005\n",
            "Training Loss: 0.0025 Acc: 99.8333\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2830, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 196/200\n",
            "----------\n",
            "Train Epoch: 196 [0/1200 (0%)]\tLoss: 0.000011\n",
            "Train Epoch: 196 [120/1200 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 196 [240/1200 (20%)]\tLoss: 0.000410\n",
            "Train Epoch: 196 [360/1200 (30%)]\tLoss: 0.000005\n",
            "Train Epoch: 196 [480/1200 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 196 [600/1200 (50%)]\tLoss: 0.000251\n",
            "Train Epoch: 196 [720/1200 (60%)]\tLoss: 0.000001\n",
            "Train Epoch: 196 [840/1200 (70%)]\tLoss: 0.000154\n",
            "Train Epoch: 196 [960/1200 (80%)]\tLoss: 0.000131\n",
            "Train Epoch: 196 [1080/1200 (90%)]\tLoss: 0.000002\n",
            "Training Loss: 0.0011 Acc: 99.9167\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2812, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 197/200\n",
            "----------\n",
            "Train Epoch: 197 [0/1200 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 197 [120/1200 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 197 [240/1200 (20%)]\tLoss: 0.000135\n",
            "Train Epoch: 197 [360/1200 (30%)]\tLoss: 0.000021\n",
            "Train Epoch: 197 [480/1200 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 197 [600/1200 (50%)]\tLoss: 0.000076\n",
            "Train Epoch: 197 [720/1200 (60%)]\tLoss: 0.000001\n",
            "Train Epoch: 197 [840/1200 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 197 [960/1200 (80%)]\tLoss: 0.006211\n",
            "Train Epoch: 197 [1080/1200 (90%)]\tLoss: 0.000133\n",
            "Training Loss: 0.0008 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2724, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 198/200\n",
            "----------\n",
            "Train Epoch: 198 [0/1200 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 198 [120/1200 (10%)]\tLoss: 0.000002\n",
            "Train Epoch: 198 [240/1200 (20%)]\tLoss: 0.000006\n",
            "Train Epoch: 198 [360/1200 (30%)]\tLoss: 0.000002\n",
            "Train Epoch: 198 [480/1200 (40%)]\tLoss: 0.000030\n",
            "Train Epoch: 198 [600/1200 (50%)]\tLoss: 0.000006\n",
            "Train Epoch: 198 [720/1200 (60%)]\tLoss: 0.000182\n",
            "Train Epoch: 198 [840/1200 (70%)]\tLoss: 0.002699\n",
            "Train Epoch: 198 [960/1200 (80%)]\tLoss: 0.000204\n",
            "Train Epoch: 198 [1080/1200 (90%)]\tLoss: 0.000103\n",
            "Training Loss: 0.0026 Acc: 99.9167\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2757, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 199/200\n",
            "----------\n",
            "Train Epoch: 199 [0/1200 (0%)]\tLoss: 0.000323\n",
            "Train Epoch: 199 [120/1200 (10%)]\tLoss: 0.000047\n",
            "Train Epoch: 199 [240/1200 (20%)]\tLoss: 0.000122\n",
            "Train Epoch: 199 [360/1200 (30%)]\tLoss: 0.000029\n",
            "Train Epoch: 199 [480/1200 (40%)]\tLoss: 0.000006\n",
            "Train Epoch: 199 [600/1200 (50%)]\tLoss: 0.000059\n",
            "Train Epoch: 199 [720/1200 (60%)]\tLoss: 0.000171\n",
            "Train Epoch: 199 [840/1200 (70%)]\tLoss: 0.000222\n",
            "Train Epoch: 199 [960/1200 (80%)]\tLoss: 0.004162\n",
            "Train Epoch: 199 [1080/1200 (90%)]\tLoss: 0.000000\n",
            "Training Loss: 0.0011 Acc: 100.0000\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2608, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: main training cycle   Epoch 200/200\n",
            "----------\n",
            "Train Epoch: 200 [0/1200 (0%)]\tLoss: 0.000013\n",
            "Train Epoch: 200 [120/1200 (10%)]\tLoss: 0.000003\n",
            "Train Epoch: 200 [240/1200 (20%)]\tLoss: 0.000804\n",
            "Train Epoch: 200 [360/1200 (30%)]\tLoss: 0.000037\n",
            "Train Epoch: 200 [480/1200 (40%)]\tLoss: 0.000021\n",
            "Train Epoch: 200 [600/1200 (50%)]\tLoss: 0.000021\n",
            "Train Epoch: 200 [720/1200 (60%)]\tLoss: 0.000032\n",
            "Train Epoch: 200 [840/1200 (70%)]\tLoss: 0.000171\n",
            "Train Epoch: 200 [960/1200 (80%)]\tLoss: 0.000005\n",
            "Train Epoch: 200 [1080/1200 (90%)]\tLoss: 0.000020\n",
            "Training Loss: 0.0015 Acc: 99.9167\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2227, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 1/200\n",
            "----------\n",
            "Train Epoch: 1 [0/1863 (0%)]\tLoss: 2.074195\n",
            "Train Epoch: 1 [120/1863 (6%)]\tLoss: 8.339249\n",
            "Train Epoch: 1 [240/1863 (13%)]\tLoss: 11.542028\n",
            "Train Epoch: 1 [360/1863 (19%)]\tLoss: 11.171091\n",
            "Train Epoch: 1 [480/1863 (26%)]\tLoss: 12.022974\n",
            "Train Epoch: 1 [600/1863 (32%)]\tLoss: 9.739299\n",
            "Train Epoch: 1 [720/1863 (39%)]\tLoss: 17.728094\n",
            "Train Epoch: 1 [840/1863 (45%)]\tLoss: 11.253286\n",
            "Train Epoch: 1 [960/1863 (51%)]\tLoss: 18.308964\n",
            "Train Epoch: 1 [1080/1863 (58%)]\tLoss: 14.142481\n",
            "Train Epoch: 1 [1200/1863 (64%)]\tLoss: 14.304586\n",
            "Train Epoch: 1 [1320/1863 (71%)]\tLoss: 13.177088\n",
            "Train Epoch: 1 [1440/1863 (77%)]\tLoss: 10.723546\n",
            "Train Epoch: 1 [1560/1863 (83%)]\tLoss: 31.395096\n",
            "Train Epoch: 1 [1680/1863 (90%)]\tLoss: 9.503857\n",
            "Train Epoch: 1 [1800/1863 (96%)]\tLoss: 14.079294\n",
            "Training Loss: 11.0231 Acc: 51.3151\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4551, Accuracy: 719/1406 (51.138%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 2/200\n",
            "----------\n",
            "Train Epoch: 2 [0/1863 (0%)]\tLoss: 13.361987\n",
            "Train Epoch: 2 [120/1863 (6%)]\tLoss: 6.892285\n",
            "Train Epoch: 2 [240/1863 (13%)]\tLoss: 4.031595\n",
            "Train Epoch: 2 [360/1863 (19%)]\tLoss: 15.074286\n",
            "Train Epoch: 2 [480/1863 (26%)]\tLoss: 4.527560\n",
            "Train Epoch: 2 [600/1863 (32%)]\tLoss: 11.276108\n",
            "Train Epoch: 2 [720/1863 (39%)]\tLoss: 9.614512\n",
            "Train Epoch: 2 [840/1863 (45%)]\tLoss: 6.380402\n",
            "Train Epoch: 2 [960/1863 (51%)]\tLoss: 8.910189\n",
            "Train Epoch: 2 [1080/1863 (58%)]\tLoss: 27.124874\n",
            "Train Epoch: 2 [1200/1863 (64%)]\tLoss: 3.312992\n",
            "Train Epoch: 2 [1320/1863 (71%)]\tLoss: 16.294170\n",
            "Train Epoch: 2 [1440/1863 (77%)]\tLoss: 7.611831\n",
            "Train Epoch: 2 [1560/1863 (83%)]\tLoss: 16.562428\n",
            "Train Epoch: 2 [1680/1863 (90%)]\tLoss: 7.690066\n",
            "Train Epoch: 2 [1800/1863 (96%)]\tLoss: 13.017581\n",
            "Training Loss: 11.2819 Acc: 50.5099\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5640, Accuracy: 734/1406 (52.205%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 3/200\n",
            "----------\n",
            "Train Epoch: 3 [0/1863 (0%)]\tLoss: 17.521481\n",
            "Train Epoch: 3 [120/1863 (6%)]\tLoss: 12.821440\n",
            "Train Epoch: 3 [240/1863 (13%)]\tLoss: 7.375442\n",
            "Train Epoch: 3 [360/1863 (19%)]\tLoss: 11.176023\n",
            "Train Epoch: 3 [480/1863 (26%)]\tLoss: 6.649489\n",
            "Train Epoch: 3 [600/1863 (32%)]\tLoss: 16.838364\n",
            "Train Epoch: 3 [720/1863 (39%)]\tLoss: 17.993835\n",
            "Train Epoch: 3 [840/1863 (45%)]\tLoss: 9.048970\n",
            "Train Epoch: 3 [960/1863 (51%)]\tLoss: 13.443835\n",
            "Train Epoch: 3 [1080/1863 (58%)]\tLoss: 3.620247\n",
            "Train Epoch: 3 [1200/1863 (64%)]\tLoss: 7.507007\n",
            "Train Epoch: 3 [1320/1863 (71%)]\tLoss: 3.222404\n",
            "Train Epoch: 3 [1440/1863 (77%)]\tLoss: 5.922135\n",
            "Train Epoch: 3 [1560/1863 (83%)]\tLoss: 15.783859\n",
            "Train Epoch: 3 [1680/1863 (90%)]\tLoss: 10.956667\n",
            "Train Epoch: 3 [1800/1863 (96%)]\tLoss: 6.092926\n",
            "Training Loss: 11.1847 Acc: 51.2614\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3707, Accuracy: 824/1406 (58.606%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 4/200\n",
            "----------\n",
            "Train Epoch: 4 [0/1863 (0%)]\tLoss: 7.448499\n",
            "Train Epoch: 4 [120/1863 (6%)]\tLoss: 2.563179\n",
            "Train Epoch: 4 [240/1863 (13%)]\tLoss: 10.455492\n",
            "Train Epoch: 4 [360/1863 (19%)]\tLoss: 1.032200\n",
            "Train Epoch: 4 [480/1863 (26%)]\tLoss: 18.121746\n",
            "Train Epoch: 4 [600/1863 (32%)]\tLoss: 15.926356\n",
            "Train Epoch: 4 [720/1863 (39%)]\tLoss: 21.969360\n",
            "Train Epoch: 4 [840/1863 (45%)]\tLoss: 4.049110\n",
            "Train Epoch: 4 [960/1863 (51%)]\tLoss: 6.684609\n",
            "Train Epoch: 4 [1080/1863 (58%)]\tLoss: 9.270159\n",
            "Train Epoch: 4 [1200/1863 (64%)]\tLoss: 3.987228\n",
            "Train Epoch: 4 [1320/1863 (71%)]\tLoss: 7.599835\n",
            "Train Epoch: 4 [1440/1863 (77%)]\tLoss: 10.384127\n",
            "Train Epoch: 4 [1560/1863 (83%)]\tLoss: 11.397553\n",
            "Train Epoch: 4 [1680/1863 (90%)]\tLoss: 8.455867\n",
            "Train Epoch: 4 [1800/1863 (96%)]\tLoss: 7.241499\n",
            "Training Loss: 11.3884 Acc: 50.4563\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6446, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 5/200\n",
            "----------\n",
            "Train Epoch: 5 [0/1863 (0%)]\tLoss: 12.952728\n",
            "Train Epoch: 5 [120/1863 (6%)]\tLoss: 11.029494\n",
            "Train Epoch: 5 [240/1863 (13%)]\tLoss: 4.912457\n",
            "Train Epoch: 5 [360/1863 (19%)]\tLoss: 15.782164\n",
            "Train Epoch: 5 [480/1863 (26%)]\tLoss: 19.039707\n",
            "Train Epoch: 5 [600/1863 (32%)]\tLoss: 1.720894\n",
            "Train Epoch: 5 [720/1863 (39%)]\tLoss: 6.915072\n",
            "Train Epoch: 5 [840/1863 (45%)]\tLoss: 15.636217\n",
            "Train Epoch: 5 [960/1863 (51%)]\tLoss: 4.107349\n",
            "Train Epoch: 5 [1080/1863 (58%)]\tLoss: 5.578976\n",
            "Train Epoch: 5 [1200/1863 (64%)]\tLoss: 14.391104\n",
            "Train Epoch: 5 [1320/1863 (71%)]\tLoss: 3.598640\n",
            "Train Epoch: 5 [1440/1863 (77%)]\tLoss: 6.230124\n",
            "Train Epoch: 5 [1560/1863 (83%)]\tLoss: 21.041340\n",
            "Train Epoch: 5 [1680/1863 (90%)]\tLoss: 8.844410\n",
            "Train Epoch: 5 [1800/1863 (96%)]\tLoss: 20.313688\n",
            "Training Loss: 11.5501 Acc: 50.2415\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6303, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 6/200\n",
            "----------\n",
            "Train Epoch: 6 [0/1863 (0%)]\tLoss: 18.207760\n",
            "Train Epoch: 6 [120/1863 (6%)]\tLoss: 7.705653\n",
            "Train Epoch: 6 [240/1863 (13%)]\tLoss: 24.018721\n",
            "Train Epoch: 6 [360/1863 (19%)]\tLoss: 25.820850\n",
            "Train Epoch: 6 [480/1863 (26%)]\tLoss: 11.024936\n",
            "Train Epoch: 6 [600/1863 (32%)]\tLoss: 17.558922\n",
            "Train Epoch: 6 [720/1863 (39%)]\tLoss: 9.393908\n",
            "Train Epoch: 6 [840/1863 (45%)]\tLoss: 8.961085\n",
            "Train Epoch: 6 [960/1863 (51%)]\tLoss: 5.309764\n",
            "Train Epoch: 6 [1080/1863 (58%)]\tLoss: 11.336751\n",
            "Train Epoch: 6 [1200/1863 (64%)]\tLoss: 11.586587\n",
            "Train Epoch: 6 [1320/1863 (71%)]\tLoss: 13.473509\n",
            "Train Epoch: 6 [1440/1863 (77%)]\tLoss: 7.564626\n",
            "Train Epoch: 6 [1560/1863 (83%)]\tLoss: 24.409664\n",
            "Train Epoch: 6 [1680/1863 (90%)]\tLoss: 9.770306\n",
            "Train Epoch: 6 [1800/1863 (96%)]\tLoss: 8.962513\n",
            "Training Loss: 10.7228 Acc: 51.1541\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5462, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 7/200\n",
            "----------\n",
            "Train Epoch: 7 [0/1863 (0%)]\tLoss: 17.185312\n",
            "Train Epoch: 7 [120/1863 (6%)]\tLoss: 12.258493\n",
            "Train Epoch: 7 [240/1863 (13%)]\tLoss: 3.338964\n",
            "Train Epoch: 7 [360/1863 (19%)]\tLoss: 6.772220\n",
            "Train Epoch: 7 [480/1863 (26%)]\tLoss: 9.578047\n",
            "Train Epoch: 7 [600/1863 (32%)]\tLoss: 11.663053\n",
            "Train Epoch: 7 [720/1863 (39%)]\tLoss: 7.046781\n",
            "Train Epoch: 7 [840/1863 (45%)]\tLoss: 15.157187\n",
            "Train Epoch: 7 [960/1863 (51%)]\tLoss: 2.847107\n",
            "Train Epoch: 7 [1080/1863 (58%)]\tLoss: 25.974527\n",
            "Train Epoch: 7 [1200/1863 (64%)]\tLoss: 15.471853\n",
            "Train Epoch: 7 [1320/1863 (71%)]\tLoss: 11.951177\n",
            "Train Epoch: 7 [1440/1863 (77%)]\tLoss: 12.468931\n",
            "Train Epoch: 7 [1560/1863 (83%)]\tLoss: 5.218515\n",
            "Train Epoch: 7 [1680/1863 (90%)]\tLoss: 17.835369\n",
            "Train Epoch: 7 [1800/1863 (96%)]\tLoss: 4.908124\n",
            "Training Loss: 10.6298 Acc: 50.9930\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6023, Accuracy: 719/1406 (51.138%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 8/200\n",
            "----------\n",
            "Train Epoch: 8 [0/1863 (0%)]\tLoss: 26.606684\n",
            "Train Epoch: 8 [120/1863 (6%)]\tLoss: 11.434422\n",
            "Train Epoch: 8 [240/1863 (13%)]\tLoss: 8.184381\n",
            "Train Epoch: 8 [360/1863 (19%)]\tLoss: 9.307309\n",
            "Train Epoch: 8 [480/1863 (26%)]\tLoss: 10.498147\n",
            "Train Epoch: 8 [600/1863 (32%)]\tLoss: 5.024093\n",
            "Train Epoch: 8 [720/1863 (39%)]\tLoss: 9.985779\n",
            "Train Epoch: 8 [840/1863 (45%)]\tLoss: 8.899631\n",
            "Train Epoch: 8 [960/1863 (51%)]\tLoss: 11.242978\n",
            "Train Epoch: 8 [1080/1863 (58%)]\tLoss: 8.254372\n",
            "Train Epoch: 8 [1200/1863 (64%)]\tLoss: 9.781950\n",
            "Train Epoch: 8 [1320/1863 (71%)]\tLoss: 5.448844\n",
            "Train Epoch: 8 [1440/1863 (77%)]\tLoss: 11.674875\n",
            "Train Epoch: 8 [1560/1863 (83%)]\tLoss: 8.693387\n",
            "Train Epoch: 8 [1680/1863 (90%)]\tLoss: 6.020468\n",
            "Train Epoch: 8 [1800/1863 (96%)]\tLoss: 10.386620\n",
            "Training Loss: 10.7658 Acc: 50.4026\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6438, Accuracy: 706/1406 (50.213%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 9/200\n",
            "----------\n",
            "Train Epoch: 9 [0/1863 (0%)]\tLoss: 6.001132\n",
            "Train Epoch: 9 [120/1863 (6%)]\tLoss: 8.680283\n",
            "Train Epoch: 9 [240/1863 (13%)]\tLoss: 23.703703\n",
            "Train Epoch: 9 [360/1863 (19%)]\tLoss: 22.431837\n",
            "Train Epoch: 9 [480/1863 (26%)]\tLoss: 15.018829\n",
            "Train Epoch: 9 [600/1863 (32%)]\tLoss: 13.438753\n",
            "Train Epoch: 9 [720/1863 (39%)]\tLoss: 20.598566\n",
            "Train Epoch: 9 [840/1863 (45%)]\tLoss: 8.561012\n",
            "Train Epoch: 9 [960/1863 (51%)]\tLoss: 13.736730\n",
            "Train Epoch: 9 [1080/1863 (58%)]\tLoss: 12.778868\n",
            "Train Epoch: 9 [1200/1863 (64%)]\tLoss: 4.913359\n",
            "Train Epoch: 9 [1320/1863 (71%)]\tLoss: 14.394442\n",
            "Train Epoch: 9 [1440/1863 (77%)]\tLoss: 9.929448\n",
            "Train Epoch: 9 [1560/1863 (83%)]\tLoss: 10.324236\n",
            "Train Epoch: 9 [1680/1863 (90%)]\tLoss: 13.178484\n",
            "Train Epoch: 9 [1800/1863 (96%)]\tLoss: 19.954472\n",
            "Training Loss: 11.2190 Acc: 51.0467\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3477, Accuracy: 762/1406 (54.196%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 10/200\n",
            "----------\n",
            "Train Epoch: 10 [0/1863 (0%)]\tLoss: 4.763896\n",
            "Train Epoch: 10 [120/1863 (6%)]\tLoss: 4.764420\n",
            "Train Epoch: 10 [240/1863 (13%)]\tLoss: 15.882825\n",
            "Train Epoch: 10 [360/1863 (19%)]\tLoss: 1.649460\n",
            "Train Epoch: 10 [480/1863 (26%)]\tLoss: 8.279745\n",
            "Train Epoch: 10 [600/1863 (32%)]\tLoss: 11.694048\n",
            "Train Epoch: 10 [720/1863 (39%)]\tLoss: 5.861819\n",
            "Train Epoch: 10 [840/1863 (45%)]\tLoss: 16.891521\n",
            "Train Epoch: 10 [960/1863 (51%)]\tLoss: 3.833009\n",
            "Train Epoch: 10 [1080/1863 (58%)]\tLoss: 2.419512\n",
            "Train Epoch: 10 [1200/1863 (64%)]\tLoss: 10.420669\n",
            "Train Epoch: 10 [1320/1863 (71%)]\tLoss: 15.410907\n",
            "Train Epoch: 10 [1440/1863 (77%)]\tLoss: 11.649992\n",
            "Train Epoch: 10 [1560/1863 (83%)]\tLoss: 13.176175\n",
            "Train Epoch: 10 [1680/1863 (90%)]\tLoss: 1.909798\n",
            "Train Epoch: 10 [1800/1863 (96%)]\tLoss: 6.405884\n",
            "Training Loss: 11.1810 Acc: 49.6511\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6556, Accuracy: 707/1406 (50.284%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 11/200\n",
            "----------\n",
            "Train Epoch: 11 [0/1863 (0%)]\tLoss: 3.143356\n",
            "Train Epoch: 11 [120/1863 (6%)]\tLoss: 11.913101\n",
            "Train Epoch: 11 [240/1863 (13%)]\tLoss: 8.367567\n",
            "Train Epoch: 11 [360/1863 (19%)]\tLoss: 21.832661\n",
            "Train Epoch: 11 [480/1863 (26%)]\tLoss: 22.097412\n",
            "Train Epoch: 11 [600/1863 (32%)]\tLoss: 13.852598\n",
            "Train Epoch: 11 [720/1863 (39%)]\tLoss: 11.891361\n",
            "Train Epoch: 11 [840/1863 (45%)]\tLoss: 4.209718\n",
            "Train Epoch: 11 [960/1863 (51%)]\tLoss: 10.847441\n",
            "Train Epoch: 11 [1080/1863 (58%)]\tLoss: 18.694580\n",
            "Train Epoch: 11 [1200/1863 (64%)]\tLoss: 26.072781\n",
            "Train Epoch: 11 [1320/1863 (71%)]\tLoss: 23.018192\n",
            "Train Epoch: 11 [1440/1863 (77%)]\tLoss: 5.662360\n",
            "Train Epoch: 11 [1560/1863 (83%)]\tLoss: 6.126377\n",
            "Train Epoch: 11 [1680/1863 (90%)]\tLoss: 19.369022\n",
            "Train Epoch: 11 [1800/1863 (96%)]\tLoss: 8.283788\n",
            "Training Loss: 11.8927 Acc: 50.2952\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4762, Accuracy: 706/1406 (50.213%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 12/200\n",
            "----------\n",
            "Train Epoch: 12 [0/1863 (0%)]\tLoss: 2.199726\n",
            "Train Epoch: 12 [120/1863 (6%)]\tLoss: 3.845668\n",
            "Train Epoch: 12 [240/1863 (13%)]\tLoss: 17.471924\n",
            "Train Epoch: 12 [360/1863 (19%)]\tLoss: 18.021709\n",
            "Train Epoch: 12 [480/1863 (26%)]\tLoss: 18.438660\n",
            "Train Epoch: 12 [600/1863 (32%)]\tLoss: 7.075655\n",
            "Train Epoch: 12 [720/1863 (39%)]\tLoss: 10.144713\n",
            "Train Epoch: 12 [840/1863 (45%)]\tLoss: 6.873544\n",
            "Train Epoch: 12 [960/1863 (51%)]\tLoss: 7.698027\n",
            "Train Epoch: 12 [1080/1863 (58%)]\tLoss: 10.751357\n",
            "Train Epoch: 12 [1200/1863 (64%)]\tLoss: 19.715351\n",
            "Train Epoch: 12 [1320/1863 (71%)]\tLoss: 3.237121\n",
            "Train Epoch: 12 [1440/1863 (77%)]\tLoss: 4.952511\n",
            "Train Epoch: 12 [1560/1863 (83%)]\tLoss: 2.869199\n",
            "Train Epoch: 12 [1680/1863 (90%)]\tLoss: 7.275895\n",
            "Train Epoch: 12 [1800/1863 (96%)]\tLoss: 8.830812\n",
            "Training Loss: 11.1124 Acc: 50.1342\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5763, Accuracy: 741/1406 (52.703%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 13/200\n",
            "----------\n",
            "Train Epoch: 13 [0/1863 (0%)]\tLoss: 13.933263\n",
            "Train Epoch: 13 [120/1863 (6%)]\tLoss: 9.940782\n",
            "Train Epoch: 13 [240/1863 (13%)]\tLoss: 6.427432\n",
            "Train Epoch: 13 [360/1863 (19%)]\tLoss: 16.151945\n",
            "Train Epoch: 13 [480/1863 (26%)]\tLoss: 10.590758\n",
            "Train Epoch: 13 [600/1863 (32%)]\tLoss: 9.332639\n",
            "Train Epoch: 13 [720/1863 (39%)]\tLoss: 6.210910\n",
            "Train Epoch: 13 [840/1863 (45%)]\tLoss: 19.641863\n",
            "Train Epoch: 13 [960/1863 (51%)]\tLoss: 10.559038\n",
            "Train Epoch: 13 [1080/1863 (58%)]\tLoss: 17.343090\n",
            "Train Epoch: 13 [1200/1863 (64%)]\tLoss: 6.587058\n",
            "Train Epoch: 13 [1320/1863 (71%)]\tLoss: 3.880373\n",
            "Train Epoch: 13 [1440/1863 (77%)]\tLoss: 13.010084\n",
            "Train Epoch: 13 [1560/1863 (83%)]\tLoss: 3.525033\n",
            "Train Epoch: 13 [1680/1863 (90%)]\tLoss: 2.424556\n",
            "Train Epoch: 13 [1800/1863 (96%)]\tLoss: 16.017179\n",
            "Training Loss: 11.4675 Acc: 50.0805\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5511, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 14/200\n",
            "----------\n",
            "Train Epoch: 14 [0/1863 (0%)]\tLoss: 6.807107\n",
            "Train Epoch: 14 [120/1863 (6%)]\tLoss: 19.226816\n",
            "Train Epoch: 14 [240/1863 (13%)]\tLoss: 18.028234\n",
            "Train Epoch: 14 [360/1863 (19%)]\tLoss: 7.418066\n",
            "Train Epoch: 14 [480/1863 (26%)]\tLoss: 12.942545\n",
            "Train Epoch: 14 [600/1863 (32%)]\tLoss: 14.442861\n",
            "Train Epoch: 14 [720/1863 (39%)]\tLoss: 9.321612\n",
            "Train Epoch: 14 [840/1863 (45%)]\tLoss: 12.197805\n",
            "Train Epoch: 14 [960/1863 (51%)]\tLoss: 5.440456\n",
            "Train Epoch: 14 [1080/1863 (58%)]\tLoss: 13.308894\n",
            "Train Epoch: 14 [1200/1863 (64%)]\tLoss: 9.413300\n",
            "Train Epoch: 14 [1320/1863 (71%)]\tLoss: 8.130455\n",
            "Train Epoch: 14 [1440/1863 (77%)]\tLoss: 10.460338\n",
            "Train Epoch: 14 [1560/1863 (83%)]\tLoss: 17.702225\n",
            "Train Epoch: 14 [1680/1863 (90%)]\tLoss: 7.739427\n",
            "Train Epoch: 14 [1800/1863 (96%)]\tLoss: 9.793416\n",
            "Training Loss: 11.1101 Acc: 50.7246\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6978, Accuracy: 721/1406 (51.280%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 15/200\n",
            "----------\n",
            "Train Epoch: 15 [0/1863 (0%)]\tLoss: 13.770085\n",
            "Train Epoch: 15 [120/1863 (6%)]\tLoss: 3.064483\n",
            "Train Epoch: 15 [240/1863 (13%)]\tLoss: 15.252573\n",
            "Train Epoch: 15 [360/1863 (19%)]\tLoss: 18.767420\n",
            "Train Epoch: 15 [480/1863 (26%)]\tLoss: 8.028883\n",
            "Train Epoch: 15 [600/1863 (32%)]\tLoss: 12.319331\n",
            "Train Epoch: 15 [720/1863 (39%)]\tLoss: 2.688697\n",
            "Train Epoch: 15 [840/1863 (45%)]\tLoss: 17.718361\n",
            "Train Epoch: 15 [960/1863 (51%)]\tLoss: 6.184609\n",
            "Train Epoch: 15 [1080/1863 (58%)]\tLoss: 15.047420\n",
            "Train Epoch: 15 [1200/1863 (64%)]\tLoss: 14.111305\n",
            "Train Epoch: 15 [1320/1863 (71%)]\tLoss: 11.208548\n",
            "Train Epoch: 15 [1440/1863 (77%)]\tLoss: 22.502590\n",
            "Train Epoch: 15 [1560/1863 (83%)]\tLoss: 5.440689\n",
            "Train Epoch: 15 [1680/1863 (90%)]\tLoss: 11.102926\n",
            "Train Epoch: 15 [1800/1863 (96%)]\tLoss: 4.278470\n",
            "Training Loss: 11.4291 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4880, Accuracy: 749/1406 (53.272%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 16/200\n",
            "----------\n",
            "Train Epoch: 16 [0/1863 (0%)]\tLoss: 3.725820\n",
            "Train Epoch: 16 [120/1863 (6%)]\tLoss: 13.749306\n",
            "Train Epoch: 16 [240/1863 (13%)]\tLoss: 27.489658\n",
            "Train Epoch: 16 [360/1863 (19%)]\tLoss: 13.591398\n",
            "Train Epoch: 16 [480/1863 (26%)]\tLoss: 18.579426\n",
            "Train Epoch: 16 [600/1863 (32%)]\tLoss: 19.707964\n",
            "Train Epoch: 16 [720/1863 (39%)]\tLoss: 15.251913\n",
            "Train Epoch: 16 [840/1863 (45%)]\tLoss: 2.812873\n",
            "Train Epoch: 16 [960/1863 (51%)]\tLoss: 11.430094\n",
            "Train Epoch: 16 [1080/1863 (58%)]\tLoss: 4.557639\n",
            "Train Epoch: 16 [1200/1863 (64%)]\tLoss: 18.794125\n",
            "Train Epoch: 16 [1320/1863 (71%)]\tLoss: 21.690918\n",
            "Train Epoch: 16 [1440/1863 (77%)]\tLoss: 6.743525\n",
            "Train Epoch: 16 [1560/1863 (83%)]\tLoss: 11.517777\n",
            "Train Epoch: 16 [1680/1863 (90%)]\tLoss: 9.859076\n",
            "Train Epoch: 16 [1800/1863 (96%)]\tLoss: 9.353807\n",
            "Training Loss: 10.9240 Acc: 50.5099\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4788, Accuracy: 730/1406 (51.920%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 17/200\n",
            "----------\n",
            "Train Epoch: 17 [0/1863 (0%)]\tLoss: 5.081127\n",
            "Train Epoch: 17 [120/1863 (6%)]\tLoss: 13.030039\n",
            "Train Epoch: 17 [240/1863 (13%)]\tLoss: 14.924883\n",
            "Train Epoch: 17 [360/1863 (19%)]\tLoss: 15.189626\n",
            "Train Epoch: 17 [480/1863 (26%)]\tLoss: 7.128802\n",
            "Train Epoch: 17 [600/1863 (32%)]\tLoss: 28.803614\n",
            "Train Epoch: 17 [720/1863 (39%)]\tLoss: 14.002718\n",
            "Train Epoch: 17 [840/1863 (45%)]\tLoss: 13.557843\n",
            "Train Epoch: 17 [960/1863 (51%)]\tLoss: 6.949064\n",
            "Train Epoch: 17 [1080/1863 (58%)]\tLoss: 31.760046\n",
            "Train Epoch: 17 [1200/1863 (64%)]\tLoss: 11.870810\n",
            "Train Epoch: 17 [1320/1863 (71%)]\tLoss: 14.237729\n",
            "Train Epoch: 17 [1440/1863 (77%)]\tLoss: 4.941253\n",
            "Train Epoch: 17 [1560/1863 (83%)]\tLoss: 21.820066\n",
            "Train Epoch: 17 [1680/1863 (90%)]\tLoss: 6.075093\n",
            "Train Epoch: 17 [1800/1863 (96%)]\tLoss: 12.066193\n",
            "Training Loss: 10.9963 Acc: 51.5298\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3519, Accuracy: 745/1406 (52.987%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 18/200\n",
            "----------\n",
            "Train Epoch: 18 [0/1863 (0%)]\tLoss: 15.347064\n",
            "Train Epoch: 18 [120/1863 (6%)]\tLoss: 12.943350\n",
            "Train Epoch: 18 [240/1863 (13%)]\tLoss: 15.572931\n",
            "Train Epoch: 18 [360/1863 (19%)]\tLoss: 4.648787\n",
            "Train Epoch: 18 [480/1863 (26%)]\tLoss: 16.858267\n",
            "Train Epoch: 18 [600/1863 (32%)]\tLoss: 7.862035\n",
            "Train Epoch: 18 [720/1863 (39%)]\tLoss: 7.078401\n",
            "Train Epoch: 18 [840/1863 (45%)]\tLoss: 13.323649\n",
            "Train Epoch: 18 [960/1863 (51%)]\tLoss: 7.596419\n",
            "Train Epoch: 18 [1080/1863 (58%)]\tLoss: 13.143423\n",
            "Train Epoch: 18 [1200/1863 (64%)]\tLoss: 8.290815\n",
            "Train Epoch: 18 [1320/1863 (71%)]\tLoss: 4.488399\n",
            "Train Epoch: 18 [1440/1863 (77%)]\tLoss: 4.916799\n",
            "Train Epoch: 18 [1560/1863 (83%)]\tLoss: 9.803202\n",
            "Train Epoch: 18 [1680/1863 (90%)]\tLoss: 12.043019\n",
            "Train Epoch: 18 [1800/1863 (96%)]\tLoss: 24.037647\n",
            "Training Loss: 11.1643 Acc: 50.5099\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6050, Accuracy: 706/1406 (50.213%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 19/200\n",
            "----------\n",
            "Train Epoch: 19 [0/1863 (0%)]\tLoss: 5.091425\n",
            "Train Epoch: 19 [120/1863 (6%)]\tLoss: 1.768962\n",
            "Train Epoch: 19 [240/1863 (13%)]\tLoss: 7.739929\n",
            "Train Epoch: 19 [360/1863 (19%)]\tLoss: 17.139389\n",
            "Train Epoch: 19 [480/1863 (26%)]\tLoss: 4.083301\n",
            "Train Epoch: 19 [600/1863 (32%)]\tLoss: 3.715405\n",
            "Train Epoch: 19 [720/1863 (39%)]\tLoss: 14.570368\n",
            "Train Epoch: 19 [840/1863 (45%)]\tLoss: 14.010396\n",
            "Train Epoch: 19 [960/1863 (51%)]\tLoss: 27.554462\n",
            "Train Epoch: 19 [1080/1863 (58%)]\tLoss: 11.303200\n",
            "Train Epoch: 19 [1200/1863 (64%)]\tLoss: 14.914744\n",
            "Train Epoch: 19 [1320/1863 (71%)]\tLoss: 17.212631\n",
            "Train Epoch: 19 [1440/1863 (77%)]\tLoss: 4.106133\n",
            "Train Epoch: 19 [1560/1863 (83%)]\tLoss: 5.152583\n",
            "Train Epoch: 19 [1680/1863 (90%)]\tLoss: 5.400832\n",
            "Train Epoch: 19 [1800/1863 (96%)]\tLoss: 8.892724\n",
            "Training Loss: 11.4040 Acc: 51.1004\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6336, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 20/200\n",
            "----------\n",
            "Train Epoch: 20 [0/1863 (0%)]\tLoss: 6.877420\n",
            "Train Epoch: 20 [120/1863 (6%)]\tLoss: 11.777228\n",
            "Train Epoch: 20 [240/1863 (13%)]\tLoss: 27.661739\n",
            "Train Epoch: 20 [360/1863 (19%)]\tLoss: 6.122175\n",
            "Train Epoch: 20 [480/1863 (26%)]\tLoss: 10.422174\n",
            "Train Epoch: 20 [600/1863 (32%)]\tLoss: 7.941026\n",
            "Train Epoch: 20 [720/1863 (39%)]\tLoss: 17.106714\n",
            "Train Epoch: 20 [840/1863 (45%)]\tLoss: 8.260087\n",
            "Train Epoch: 20 [960/1863 (51%)]\tLoss: 9.709940\n",
            "Train Epoch: 20 [1080/1863 (58%)]\tLoss: 1.816536\n",
            "Train Epoch: 20 [1200/1863 (64%)]\tLoss: 8.862357\n",
            "Train Epoch: 20 [1320/1863 (71%)]\tLoss: 9.051851\n",
            "Train Epoch: 20 [1440/1863 (77%)]\tLoss: 11.729824\n",
            "Train Epoch: 20 [1560/1863 (83%)]\tLoss: 7.588000\n",
            "Train Epoch: 20 [1680/1863 (90%)]\tLoss: 8.182764\n",
            "Train Epoch: 20 [1800/1863 (96%)]\tLoss: 18.486685\n",
            "Training Loss: 11.5848 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4392, Accuracy: 743/1406 (52.845%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 21/200\n",
            "----------\n",
            "Train Epoch: 21 [0/1863 (0%)]\tLoss: 20.617352\n",
            "Train Epoch: 21 [120/1863 (6%)]\tLoss: 17.522511\n",
            "Train Epoch: 21 [240/1863 (13%)]\tLoss: 6.314279\n",
            "Train Epoch: 21 [360/1863 (19%)]\tLoss: 9.891092\n",
            "Train Epoch: 21 [480/1863 (26%)]\tLoss: 10.597109\n",
            "Train Epoch: 21 [600/1863 (32%)]\tLoss: 25.551035\n",
            "Train Epoch: 21 [720/1863 (39%)]\tLoss: 13.459333\n",
            "Train Epoch: 21 [840/1863 (45%)]\tLoss: 12.724731\n",
            "Train Epoch: 21 [960/1863 (51%)]\tLoss: 12.434763\n",
            "Train Epoch: 21 [1080/1863 (58%)]\tLoss: 2.629537\n",
            "Train Epoch: 21 [1200/1863 (64%)]\tLoss: 17.569757\n",
            "Train Epoch: 21 [1320/1863 (71%)]\tLoss: 14.222445\n",
            "Train Epoch: 21 [1440/1863 (77%)]\tLoss: 4.824800\n",
            "Train Epoch: 21 [1560/1863 (83%)]\tLoss: 17.827868\n",
            "Train Epoch: 21 [1680/1863 (90%)]\tLoss: 13.427172\n",
            "Train Epoch: 21 [1800/1863 (96%)]\tLoss: 7.964823\n",
            "Training Loss: 11.6103 Acc: 51.3151\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5523, Accuracy: 722/1406 (51.351%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 22/200\n",
            "----------\n",
            "Train Epoch: 22 [0/1863 (0%)]\tLoss: 6.347546\n",
            "Train Epoch: 22 [120/1863 (6%)]\tLoss: 16.309856\n",
            "Train Epoch: 22 [240/1863 (13%)]\tLoss: 6.062853\n",
            "Train Epoch: 22 [360/1863 (19%)]\tLoss: 4.191242\n",
            "Train Epoch: 22 [480/1863 (26%)]\tLoss: 10.307654\n",
            "Train Epoch: 22 [600/1863 (32%)]\tLoss: 13.166104\n",
            "Train Epoch: 22 [720/1863 (39%)]\tLoss: 8.449286\n",
            "Train Epoch: 22 [840/1863 (45%)]\tLoss: 9.470504\n",
            "Train Epoch: 22 [960/1863 (51%)]\tLoss: 9.229869\n",
            "Train Epoch: 22 [1080/1863 (58%)]\tLoss: 8.517943\n",
            "Train Epoch: 22 [1200/1863 (64%)]\tLoss: 16.050051\n",
            "Train Epoch: 22 [1320/1863 (71%)]\tLoss: 13.351819\n",
            "Train Epoch: 22 [1440/1863 (77%)]\tLoss: 9.058930\n",
            "Train Epoch: 22 [1560/1863 (83%)]\tLoss: 3.078280\n",
            "Train Epoch: 22 [1680/1863 (90%)]\tLoss: 11.263009\n",
            "Train Epoch: 22 [1800/1863 (96%)]\tLoss: 6.707368\n",
            "Training Loss: 10.9971 Acc: 50.2952\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5128, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 23/200\n",
            "----------\n",
            "Train Epoch: 23 [0/1863 (0%)]\tLoss: 24.769695\n",
            "Train Epoch: 23 [120/1863 (6%)]\tLoss: 2.165142\n",
            "Train Epoch: 23 [240/1863 (13%)]\tLoss: 8.499142\n",
            "Train Epoch: 23 [360/1863 (19%)]\tLoss: 16.510826\n",
            "Train Epoch: 23 [480/1863 (26%)]\tLoss: 6.603381\n",
            "Train Epoch: 23 [600/1863 (32%)]\tLoss: 19.628063\n",
            "Train Epoch: 23 [720/1863 (39%)]\tLoss: 10.881677\n",
            "Train Epoch: 23 [840/1863 (45%)]\tLoss: 8.742409\n",
            "Train Epoch: 23 [960/1863 (51%)]\tLoss: 14.665982\n",
            "Train Epoch: 23 [1080/1863 (58%)]\tLoss: 6.283924\n",
            "Train Epoch: 23 [1200/1863 (64%)]\tLoss: 20.016277\n",
            "Train Epoch: 23 [1320/1863 (71%)]\tLoss: 13.139209\n",
            "Train Epoch: 23 [1440/1863 (77%)]\tLoss: 11.876217\n",
            "Train Epoch: 23 [1560/1863 (83%)]\tLoss: 22.035458\n",
            "Train Epoch: 23 [1680/1863 (90%)]\tLoss: 3.403598\n",
            "Train Epoch: 23 [1800/1863 (96%)]\tLoss: 7.190716\n",
            "Training Loss: 11.6544 Acc: 50.3489\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3177, Accuracy: 882/1406 (62.731%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 24/200\n",
            "----------\n",
            "Train Epoch: 24 [0/1863 (0%)]\tLoss: 3.018750\n",
            "Train Epoch: 24 [120/1863 (6%)]\tLoss: 11.436055\n",
            "Train Epoch: 24 [240/1863 (13%)]\tLoss: 11.006028\n",
            "Train Epoch: 24 [360/1863 (19%)]\tLoss: 7.101228\n",
            "Train Epoch: 24 [480/1863 (26%)]\tLoss: 6.370585\n",
            "Train Epoch: 24 [600/1863 (32%)]\tLoss: 6.188006\n",
            "Train Epoch: 24 [720/1863 (39%)]\tLoss: 9.534166\n",
            "Train Epoch: 24 [840/1863 (45%)]\tLoss: 8.205957\n",
            "Train Epoch: 24 [960/1863 (51%)]\tLoss: 3.011812\n",
            "Train Epoch: 24 [1080/1863 (58%)]\tLoss: 2.888978\n",
            "Train Epoch: 24 [1200/1863 (64%)]\tLoss: 4.479105\n",
            "Train Epoch: 24 [1320/1863 (71%)]\tLoss: 6.878694\n",
            "Train Epoch: 24 [1440/1863 (77%)]\tLoss: 5.153625\n",
            "Train Epoch: 24 [1560/1863 (83%)]\tLoss: 17.619816\n",
            "Train Epoch: 24 [1680/1863 (90%)]\tLoss: 5.613765\n",
            "Train Epoch: 24 [1800/1863 (96%)]\tLoss: 17.738268\n",
            "Training Loss: 11.3737 Acc: 49.7585\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6030, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 25/200\n",
            "----------\n",
            "Train Epoch: 25 [0/1863 (0%)]\tLoss: 3.834787\n",
            "Train Epoch: 25 [120/1863 (6%)]\tLoss: 13.548123\n",
            "Train Epoch: 25 [240/1863 (13%)]\tLoss: 7.219621\n",
            "Train Epoch: 25 [360/1863 (19%)]\tLoss: 18.451792\n",
            "Train Epoch: 25 [480/1863 (26%)]\tLoss: 15.891294\n",
            "Train Epoch: 25 [600/1863 (32%)]\tLoss: 11.800179\n",
            "Train Epoch: 25 [720/1863 (39%)]\tLoss: 29.466141\n",
            "Train Epoch: 25 [840/1863 (45%)]\tLoss: 14.722585\n",
            "Train Epoch: 25 [960/1863 (51%)]\tLoss: 4.470256\n",
            "Train Epoch: 25 [1080/1863 (58%)]\tLoss: 18.418446\n",
            "Train Epoch: 25 [1200/1863 (64%)]\tLoss: 9.726460\n",
            "Train Epoch: 25 [1320/1863 (71%)]\tLoss: 28.368473\n",
            "Train Epoch: 25 [1440/1863 (77%)]\tLoss: 4.207054\n",
            "Train Epoch: 25 [1560/1863 (83%)]\tLoss: 15.353826\n",
            "Train Epoch: 25 [1680/1863 (90%)]\tLoss: 8.714146\n",
            "Train Epoch: 25 [1800/1863 (96%)]\tLoss: 14.795024\n",
            "Training Loss: 11.4235 Acc: 50.7783\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6607, Accuracy: 715/1406 (50.853%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 26/200\n",
            "----------\n",
            "Train Epoch: 26 [0/1863 (0%)]\tLoss: 13.820529\n",
            "Train Epoch: 26 [120/1863 (6%)]\tLoss: 17.165005\n",
            "Train Epoch: 26 [240/1863 (13%)]\tLoss: 12.036190\n",
            "Train Epoch: 26 [360/1863 (19%)]\tLoss: 8.379375\n",
            "Train Epoch: 26 [480/1863 (26%)]\tLoss: 13.204494\n",
            "Train Epoch: 26 [600/1863 (32%)]\tLoss: 9.599689\n",
            "Train Epoch: 26 [720/1863 (39%)]\tLoss: 10.053788\n",
            "Train Epoch: 26 [840/1863 (45%)]\tLoss: 4.847781\n",
            "Train Epoch: 26 [960/1863 (51%)]\tLoss: 13.947824\n",
            "Train Epoch: 26 [1080/1863 (58%)]\tLoss: 7.559706\n",
            "Train Epoch: 26 [1200/1863 (64%)]\tLoss: 13.710060\n",
            "Train Epoch: 26 [1320/1863 (71%)]\tLoss: 3.605883\n",
            "Train Epoch: 26 [1440/1863 (77%)]\tLoss: 23.325428\n",
            "Train Epoch: 26 [1560/1863 (83%)]\tLoss: 10.231087\n",
            "Train Epoch: 26 [1680/1863 (90%)]\tLoss: 22.047680\n",
            "Train Epoch: 26 [1800/1863 (96%)]\tLoss: 5.455798\n",
            "Training Loss: 11.1180 Acc: 51.1004\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5049, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 27/200\n",
            "----------\n",
            "Train Epoch: 27 [0/1863 (0%)]\tLoss: 3.121981\n",
            "Train Epoch: 27 [120/1863 (6%)]\tLoss: 7.148547\n",
            "Train Epoch: 27 [240/1863 (13%)]\tLoss: 10.237298\n",
            "Train Epoch: 27 [360/1863 (19%)]\tLoss: 21.993441\n",
            "Train Epoch: 27 [480/1863 (26%)]\tLoss: 14.181460\n",
            "Train Epoch: 27 [600/1863 (32%)]\tLoss: 8.002916\n",
            "Train Epoch: 27 [720/1863 (39%)]\tLoss: 16.744541\n",
            "Train Epoch: 27 [840/1863 (45%)]\tLoss: 6.920503\n",
            "Train Epoch: 27 [960/1863 (51%)]\tLoss: 7.174294\n",
            "Train Epoch: 27 [1080/1863 (58%)]\tLoss: 10.465234\n",
            "Train Epoch: 27 [1200/1863 (64%)]\tLoss: 13.666681\n",
            "Train Epoch: 27 [1320/1863 (71%)]\tLoss: 11.702286\n",
            "Train Epoch: 27 [1440/1863 (77%)]\tLoss: 10.400843\n",
            "Train Epoch: 27 [1560/1863 (83%)]\tLoss: 15.450846\n",
            "Train Epoch: 27 [1680/1863 (90%)]\tLoss: 21.449934\n",
            "Train Epoch: 27 [1800/1863 (96%)]\tLoss: 22.648567\n",
            "Training Loss: 11.3076 Acc: 51.6908\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4670, Accuracy: 753/1406 (53.556%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 28/200\n",
            "----------\n",
            "Train Epoch: 28 [0/1863 (0%)]\tLoss: 13.958811\n",
            "Train Epoch: 28 [120/1863 (6%)]\tLoss: 5.240015\n",
            "Train Epoch: 28 [240/1863 (13%)]\tLoss: 3.943872\n",
            "Train Epoch: 28 [360/1863 (19%)]\tLoss: 11.741230\n",
            "Train Epoch: 28 [480/1863 (26%)]\tLoss: 8.886758\n",
            "Train Epoch: 28 [600/1863 (32%)]\tLoss: 19.037334\n",
            "Train Epoch: 28 [720/1863 (39%)]\tLoss: 7.426047\n",
            "Train Epoch: 28 [840/1863 (45%)]\tLoss: 11.316943\n",
            "Train Epoch: 28 [960/1863 (51%)]\tLoss: 10.604086\n",
            "Train Epoch: 28 [1080/1863 (58%)]\tLoss: 3.922729\n",
            "Train Epoch: 28 [1200/1863 (64%)]\tLoss: 34.429268\n",
            "Train Epoch: 28 [1320/1863 (71%)]\tLoss: 14.962585\n",
            "Train Epoch: 28 [1440/1863 (77%)]\tLoss: 5.438068\n",
            "Train Epoch: 28 [1560/1863 (83%)]\tLoss: 8.776029\n",
            "Train Epoch: 28 [1680/1863 (90%)]\tLoss: 6.624994\n",
            "Train Epoch: 28 [1800/1863 (96%)]\tLoss: 11.804496\n",
            "Training Loss: 11.4258 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3711, Accuracy: 757/1406 (53.841%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 29/200\n",
            "----------\n",
            "Train Epoch: 29 [0/1863 (0%)]\tLoss: 15.178825\n",
            "Train Epoch: 29 [120/1863 (6%)]\tLoss: 4.037875\n",
            "Train Epoch: 29 [240/1863 (13%)]\tLoss: 8.278589\n",
            "Train Epoch: 29 [360/1863 (19%)]\tLoss: 23.027149\n",
            "Train Epoch: 29 [480/1863 (26%)]\tLoss: 15.280339\n",
            "Train Epoch: 29 [600/1863 (32%)]\tLoss: 6.601691\n",
            "Train Epoch: 29 [720/1863 (39%)]\tLoss: 17.257046\n",
            "Train Epoch: 29 [840/1863 (45%)]\tLoss: 4.767932\n",
            "Train Epoch: 29 [960/1863 (51%)]\tLoss: 6.999613\n",
            "Train Epoch: 29 [1080/1863 (58%)]\tLoss: 6.961718\n",
            "Train Epoch: 29 [1200/1863 (64%)]\tLoss: 12.420683\n",
            "Train Epoch: 29 [1320/1863 (71%)]\tLoss: 7.801965\n",
            "Train Epoch: 29 [1440/1863 (77%)]\tLoss: 22.571758\n",
            "Train Epoch: 29 [1560/1863 (83%)]\tLoss: 22.168467\n",
            "Train Epoch: 29 [1680/1863 (90%)]\tLoss: 3.760617\n",
            "Train Epoch: 29 [1800/1863 (96%)]\tLoss: 17.235119\n",
            "Training Loss: 11.3729 Acc: 51.3151\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5312, Accuracy: 722/1406 (51.351%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 30/200\n",
            "----------\n",
            "Train Epoch: 30 [0/1863 (0%)]\tLoss: 4.767394\n",
            "Train Epoch: 30 [120/1863 (6%)]\tLoss: 13.587146\n",
            "Train Epoch: 30 [240/1863 (13%)]\tLoss: 1.711060\n",
            "Train Epoch: 30 [360/1863 (19%)]\tLoss: 3.839128\n",
            "Train Epoch: 30 [480/1863 (26%)]\tLoss: 10.181850\n",
            "Train Epoch: 30 [600/1863 (32%)]\tLoss: 8.928565\n",
            "Train Epoch: 30 [720/1863 (39%)]\tLoss: 7.889405\n",
            "Train Epoch: 30 [840/1863 (45%)]\tLoss: 11.308699\n",
            "Train Epoch: 30 [960/1863 (51%)]\tLoss: 8.978278\n",
            "Train Epoch: 30 [1080/1863 (58%)]\tLoss: 18.394499\n",
            "Train Epoch: 30 [1200/1863 (64%)]\tLoss: 19.572361\n",
            "Train Epoch: 30 [1320/1863 (71%)]\tLoss: 4.153946\n",
            "Train Epoch: 30 [1440/1863 (77%)]\tLoss: 4.041503\n",
            "Train Epoch: 30 [1560/1863 (83%)]\tLoss: 11.585963\n",
            "Train Epoch: 30 [1680/1863 (90%)]\tLoss: 5.715292\n",
            "Train Epoch: 30 [1800/1863 (96%)]\tLoss: 4.248589\n",
            "Training Loss: 11.1142 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6216, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 31/200\n",
            "----------\n",
            "Train Epoch: 31 [0/1863 (0%)]\tLoss: 15.482854\n",
            "Train Epoch: 31 [120/1863 (6%)]\tLoss: 6.850519\n",
            "Train Epoch: 31 [240/1863 (13%)]\tLoss: 6.451819\n",
            "Train Epoch: 31 [360/1863 (19%)]\tLoss: 11.416873\n",
            "Train Epoch: 31 [480/1863 (26%)]\tLoss: 8.128517\n",
            "Train Epoch: 31 [600/1863 (32%)]\tLoss: 3.526041\n",
            "Train Epoch: 31 [720/1863 (39%)]\tLoss: 5.831098\n",
            "Train Epoch: 31 [840/1863 (45%)]\tLoss: 7.886445\n",
            "Train Epoch: 31 [960/1863 (51%)]\tLoss: 10.966642\n",
            "Train Epoch: 31 [1080/1863 (58%)]\tLoss: 18.762062\n",
            "Train Epoch: 31 [1200/1863 (64%)]\tLoss: 9.152468\n",
            "Train Epoch: 31 [1320/1863 (71%)]\tLoss: 5.379952\n",
            "Train Epoch: 31 [1440/1863 (77%)]\tLoss: 2.351886\n",
            "Train Epoch: 31 [1560/1863 (83%)]\tLoss: 20.953798\n",
            "Train Epoch: 31 [1680/1863 (90%)]\tLoss: 12.374957\n",
            "Train Epoch: 31 [1800/1863 (96%)]\tLoss: 10.845176\n",
            "Training Loss: 10.9397 Acc: 50.3489\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2751, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 32/200\n",
            "----------\n",
            "Train Epoch: 32 [0/1863 (0%)]\tLoss: 12.392659\n",
            "Train Epoch: 32 [120/1863 (6%)]\tLoss: 15.593002\n",
            "Train Epoch: 32 [240/1863 (13%)]\tLoss: 16.202370\n",
            "Train Epoch: 32 [360/1863 (19%)]\tLoss: 7.756994\n",
            "Train Epoch: 32 [480/1863 (26%)]\tLoss: 6.692017\n",
            "Train Epoch: 32 [600/1863 (32%)]\tLoss: 1.134002\n",
            "Train Epoch: 32 [720/1863 (39%)]\tLoss: 10.078818\n",
            "Train Epoch: 32 [840/1863 (45%)]\tLoss: 7.602586\n",
            "Train Epoch: 32 [960/1863 (51%)]\tLoss: 10.269286\n",
            "Train Epoch: 32 [1080/1863 (58%)]\tLoss: 24.119873\n",
            "Train Epoch: 32 [1200/1863 (64%)]\tLoss: 7.716273\n",
            "Train Epoch: 32 [1320/1863 (71%)]\tLoss: 9.994081\n",
            "Train Epoch: 32 [1440/1863 (77%)]\tLoss: 14.103403\n",
            "Train Epoch: 32 [1560/1863 (83%)]\tLoss: 10.477555\n",
            "Train Epoch: 32 [1680/1863 (90%)]\tLoss: 23.497633\n",
            "Train Epoch: 32 [1800/1863 (96%)]\tLoss: 6.333337\n",
            "Training Loss: 11.1335 Acc: 50.8320\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2657, Accuracy: 896/1406 (63.727%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 33/200\n",
            "----------\n",
            "Train Epoch: 33 [0/1863 (0%)]\tLoss: 12.553528\n",
            "Train Epoch: 33 [120/1863 (6%)]\tLoss: 15.778529\n",
            "Train Epoch: 33 [240/1863 (13%)]\tLoss: 5.047410\n",
            "Train Epoch: 33 [360/1863 (19%)]\tLoss: 15.100342\n",
            "Train Epoch: 33 [480/1863 (26%)]\tLoss: 7.647306\n",
            "Train Epoch: 33 [600/1863 (32%)]\tLoss: 6.129754\n",
            "Train Epoch: 33 [720/1863 (39%)]\tLoss: 15.935946\n",
            "Train Epoch: 33 [840/1863 (45%)]\tLoss: 19.169437\n",
            "Train Epoch: 33 [960/1863 (51%)]\tLoss: 11.767002\n",
            "Train Epoch: 33 [1080/1863 (58%)]\tLoss: 11.067852\n",
            "Train Epoch: 33 [1200/1863 (64%)]\tLoss: 7.616067\n",
            "Train Epoch: 33 [1320/1863 (71%)]\tLoss: 21.307053\n",
            "Train Epoch: 33 [1440/1863 (77%)]\tLoss: 2.618052\n",
            "Train Epoch: 33 [1560/1863 (83%)]\tLoss: 11.914808\n",
            "Train Epoch: 33 [1680/1863 (90%)]\tLoss: 12.873837\n",
            "Train Epoch: 33 [1800/1863 (96%)]\tLoss: 20.267965\n",
            "Training Loss: 11.3900 Acc: 50.4563\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3067, Accuracy: 969/1406 (68.919%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 34/200\n",
            "----------\n",
            "Train Epoch: 34 [0/1863 (0%)]\tLoss: 7.389333\n",
            "Train Epoch: 34 [120/1863 (6%)]\tLoss: 1.176595\n",
            "Train Epoch: 34 [240/1863 (13%)]\tLoss: 16.301075\n",
            "Train Epoch: 34 [360/1863 (19%)]\tLoss: 3.553634\n",
            "Train Epoch: 34 [480/1863 (26%)]\tLoss: 9.392197\n",
            "Train Epoch: 34 [600/1863 (32%)]\tLoss: 2.998567\n",
            "Train Epoch: 34 [720/1863 (39%)]\tLoss: 14.044490\n",
            "Train Epoch: 34 [840/1863 (45%)]\tLoss: 17.099613\n",
            "Train Epoch: 34 [960/1863 (51%)]\tLoss: 12.296185\n",
            "Train Epoch: 34 [1080/1863 (58%)]\tLoss: 9.925328\n",
            "Train Epoch: 34 [1200/1863 (64%)]\tLoss: 20.120693\n",
            "Train Epoch: 34 [1320/1863 (71%)]\tLoss: 9.185205\n",
            "Train Epoch: 34 [1440/1863 (77%)]\tLoss: 13.997549\n",
            "Train Epoch: 34 [1560/1863 (83%)]\tLoss: 12.259615\n",
            "Train Epoch: 34 [1680/1863 (90%)]\tLoss: 16.348007\n",
            "Train Epoch: 34 [1800/1863 (96%)]\tLoss: 12.980655\n",
            "Training Loss: 10.9339 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5492, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 35/200\n",
            "----------\n",
            "Train Epoch: 35 [0/1863 (0%)]\tLoss: 6.369211\n",
            "Train Epoch: 35 [120/1863 (6%)]\tLoss: 11.772640\n",
            "Train Epoch: 35 [240/1863 (13%)]\tLoss: 16.306513\n",
            "Train Epoch: 35 [360/1863 (19%)]\tLoss: 7.708211\n",
            "Train Epoch: 35 [480/1863 (26%)]\tLoss: 3.519904\n",
            "Train Epoch: 35 [600/1863 (32%)]\tLoss: 2.617558\n",
            "Train Epoch: 35 [720/1863 (39%)]\tLoss: 18.464495\n",
            "Train Epoch: 35 [840/1863 (45%)]\tLoss: 10.077467\n",
            "Train Epoch: 35 [960/1863 (51%)]\tLoss: 13.714244\n",
            "Train Epoch: 35 [1080/1863 (58%)]\tLoss: 7.224576\n",
            "Train Epoch: 35 [1200/1863 (64%)]\tLoss: 13.145328\n",
            "Train Epoch: 35 [1320/1863 (71%)]\tLoss: 9.308443\n",
            "Train Epoch: 35 [1440/1863 (77%)]\tLoss: 19.102514\n",
            "Train Epoch: 35 [1560/1863 (83%)]\tLoss: 19.530197\n",
            "Train Epoch: 35 [1680/1863 (90%)]\tLoss: 12.492823\n",
            "Train Epoch: 35 [1800/1863 (96%)]\tLoss: 18.339184\n",
            "Training Loss: 11.1595 Acc: 49.5437\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5459, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 36/200\n",
            "----------\n",
            "Train Epoch: 36 [0/1863 (0%)]\tLoss: 15.358618\n",
            "Train Epoch: 36 [120/1863 (6%)]\tLoss: 8.336020\n",
            "Train Epoch: 36 [240/1863 (13%)]\tLoss: 17.794498\n",
            "Train Epoch: 36 [360/1863 (19%)]\tLoss: 13.113736\n",
            "Train Epoch: 36 [480/1863 (26%)]\tLoss: 3.213773\n",
            "Train Epoch: 36 [600/1863 (32%)]\tLoss: 4.769968\n",
            "Train Epoch: 36 [720/1863 (39%)]\tLoss: 7.768693\n",
            "Train Epoch: 36 [840/1863 (45%)]\tLoss: 3.669945\n",
            "Train Epoch: 36 [960/1863 (51%)]\tLoss: 17.655371\n",
            "Train Epoch: 36 [1080/1863 (58%)]\tLoss: 5.287616\n",
            "Train Epoch: 36 [1200/1863 (64%)]\tLoss: 19.097582\n",
            "Train Epoch: 36 [1320/1863 (71%)]\tLoss: 12.909460\n",
            "Train Epoch: 36 [1440/1863 (77%)]\tLoss: 10.120126\n",
            "Train Epoch: 36 [1560/1863 (83%)]\tLoss: 3.996020\n",
            "Train Epoch: 36 [1680/1863 (90%)]\tLoss: 11.675092\n",
            "Train Epoch: 36 [1800/1863 (96%)]\tLoss: 16.550499\n",
            "Training Loss: 11.0752 Acc: 50.4026\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4668, Accuracy: 713/1406 (50.711%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 37/200\n",
            "----------\n",
            "Train Epoch: 37 [0/1863 (0%)]\tLoss: 19.931789\n",
            "Train Epoch: 37 [120/1863 (6%)]\tLoss: 19.067909\n",
            "Train Epoch: 37 [240/1863 (13%)]\tLoss: 20.467588\n",
            "Train Epoch: 37 [360/1863 (19%)]\tLoss: 12.845899\n",
            "Train Epoch: 37 [480/1863 (26%)]\tLoss: 5.955377\n",
            "Train Epoch: 37 [600/1863 (32%)]\tLoss: 11.027622\n",
            "Train Epoch: 37 [720/1863 (39%)]\tLoss: 11.535350\n",
            "Train Epoch: 37 [840/1863 (45%)]\tLoss: 11.747291\n",
            "Train Epoch: 37 [960/1863 (51%)]\tLoss: 6.743840\n",
            "Train Epoch: 37 [1080/1863 (58%)]\tLoss: 12.156309\n",
            "Train Epoch: 37 [1200/1863 (64%)]\tLoss: 15.766409\n",
            "Train Epoch: 37 [1320/1863 (71%)]\tLoss: 11.378595\n",
            "Train Epoch: 37 [1440/1863 (77%)]\tLoss: 2.359352\n",
            "Train Epoch: 37 [1560/1863 (83%)]\tLoss: 7.678582\n",
            "Train Epoch: 37 [1680/1863 (90%)]\tLoss: 3.462056\n",
            "Train Epoch: 37 [1800/1863 (96%)]\tLoss: 11.953821\n",
            "Training Loss: 10.7516 Acc: 51.0467\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5149, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 38/200\n",
            "----------\n",
            "Train Epoch: 38 [0/1863 (0%)]\tLoss: 21.780340\n",
            "Train Epoch: 38 [120/1863 (6%)]\tLoss: 14.254997\n",
            "Train Epoch: 38 [240/1863 (13%)]\tLoss: 16.326431\n",
            "Train Epoch: 38 [360/1863 (19%)]\tLoss: 12.317606\n",
            "Train Epoch: 38 [480/1863 (26%)]\tLoss: 6.703215\n",
            "Train Epoch: 38 [600/1863 (32%)]\tLoss: 16.518417\n",
            "Train Epoch: 38 [720/1863 (39%)]\tLoss: 19.266949\n",
            "Train Epoch: 38 [840/1863 (45%)]\tLoss: 9.990521\n",
            "Train Epoch: 38 [960/1863 (51%)]\tLoss: 9.562178\n",
            "Train Epoch: 38 [1080/1863 (58%)]\tLoss: 12.621061\n",
            "Train Epoch: 38 [1200/1863 (64%)]\tLoss: 14.198153\n",
            "Train Epoch: 38 [1320/1863 (71%)]\tLoss: 13.637663\n",
            "Train Epoch: 38 [1440/1863 (77%)]\tLoss: 13.620245\n",
            "Train Epoch: 38 [1560/1863 (83%)]\tLoss: 5.566213\n",
            "Train Epoch: 38 [1680/1863 (90%)]\tLoss: 8.206588\n",
            "Train Epoch: 38 [1800/1863 (96%)]\tLoss: 16.484409\n",
            "Training Loss: 11.3118 Acc: 50.7783\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3811, Accuracy: 798/1406 (56.757%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 39/200\n",
            "----------\n",
            "Train Epoch: 39 [0/1863 (0%)]\tLoss: 1.281473\n",
            "Train Epoch: 39 [120/1863 (6%)]\tLoss: 5.183018\n",
            "Train Epoch: 39 [240/1863 (13%)]\tLoss: 9.537282\n",
            "Train Epoch: 39 [360/1863 (19%)]\tLoss: 16.905743\n",
            "Train Epoch: 39 [480/1863 (26%)]\tLoss: 19.406340\n",
            "Train Epoch: 39 [600/1863 (32%)]\tLoss: 6.224496\n",
            "Train Epoch: 39 [720/1863 (39%)]\tLoss: 18.476894\n",
            "Train Epoch: 39 [840/1863 (45%)]\tLoss: 6.321038\n",
            "Train Epoch: 39 [960/1863 (51%)]\tLoss: 4.749592\n",
            "Train Epoch: 39 [1080/1863 (58%)]\tLoss: 4.763156\n",
            "Train Epoch: 39 [1200/1863 (64%)]\tLoss: 3.318232\n",
            "Train Epoch: 39 [1320/1863 (71%)]\tLoss: 5.704646\n",
            "Train Epoch: 39 [1440/1863 (77%)]\tLoss: 17.503754\n",
            "Train Epoch: 39 [1560/1863 (83%)]\tLoss: 17.163685\n",
            "Train Epoch: 39 [1680/1863 (90%)]\tLoss: 21.318581\n",
            "Train Epoch: 39 [1800/1863 (96%)]\tLoss: 7.539445\n",
            "Training Loss: 11.1451 Acc: 50.4026\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5074, Accuracy: 729/1406 (51.849%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 40/200\n",
            "----------\n",
            "Train Epoch: 40 [0/1863 (0%)]\tLoss: 10.811645\n",
            "Train Epoch: 40 [120/1863 (6%)]\tLoss: 16.563787\n",
            "Train Epoch: 40 [240/1863 (13%)]\tLoss: 22.576839\n",
            "Train Epoch: 40 [360/1863 (19%)]\tLoss: 9.855680\n",
            "Train Epoch: 40 [480/1863 (26%)]\tLoss: 6.682851\n",
            "Train Epoch: 40 [600/1863 (32%)]\tLoss: 7.093540\n",
            "Train Epoch: 40 [720/1863 (39%)]\tLoss: 3.462476\n",
            "Train Epoch: 40 [840/1863 (45%)]\tLoss: 12.717532\n",
            "Train Epoch: 40 [960/1863 (51%)]\tLoss: 7.272147\n",
            "Train Epoch: 40 [1080/1863 (58%)]\tLoss: 4.303178\n",
            "Train Epoch: 40 [1200/1863 (64%)]\tLoss: 20.338722\n",
            "Train Epoch: 40 [1320/1863 (71%)]\tLoss: 9.758214\n",
            "Train Epoch: 40 [1440/1863 (77%)]\tLoss: 9.106189\n",
            "Train Epoch: 40 [1560/1863 (83%)]\tLoss: 14.644031\n",
            "Train Epoch: 40 [1680/1863 (90%)]\tLoss: 13.596704\n",
            "Train Epoch: 40 [1800/1863 (96%)]\tLoss: 3.197127\n",
            "Training Loss: 10.8989 Acc: 51.3688\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4560, Accuracy: 757/1406 (53.841%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 41/200\n",
            "----------\n",
            "Train Epoch: 41 [0/1863 (0%)]\tLoss: 23.146637\n",
            "Train Epoch: 41 [120/1863 (6%)]\tLoss: 7.011101\n",
            "Train Epoch: 41 [240/1863 (13%)]\tLoss: 5.193894\n",
            "Train Epoch: 41 [360/1863 (19%)]\tLoss: 4.103769\n",
            "Train Epoch: 41 [480/1863 (26%)]\tLoss: 7.314318\n",
            "Train Epoch: 41 [600/1863 (32%)]\tLoss: 13.036104\n",
            "Train Epoch: 41 [720/1863 (39%)]\tLoss: 3.223325\n",
            "Train Epoch: 41 [840/1863 (45%)]\tLoss: 6.665049\n",
            "Train Epoch: 41 [960/1863 (51%)]\tLoss: 11.762508\n",
            "Train Epoch: 41 [1080/1863 (58%)]\tLoss: 22.096943\n",
            "Train Epoch: 41 [1200/1863 (64%)]\tLoss: 5.767771\n",
            "Train Epoch: 41 [1320/1863 (71%)]\tLoss: 14.537396\n",
            "Train Epoch: 41 [1440/1863 (77%)]\tLoss: 17.723879\n",
            "Train Epoch: 41 [1560/1863 (83%)]\tLoss: 24.784611\n",
            "Train Epoch: 41 [1680/1863 (90%)]\tLoss: 26.950794\n",
            "Train Epoch: 41 [1800/1863 (96%)]\tLoss: 7.723502\n",
            "Training Loss: 11.6364 Acc: 50.5636\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5298, Accuracy: 775/1406 (55.121%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 42/200\n",
            "----------\n",
            "Train Epoch: 42 [0/1863 (0%)]\tLoss: 9.051672\n",
            "Train Epoch: 42 [120/1863 (6%)]\tLoss: 11.917727\n",
            "Train Epoch: 42 [240/1863 (13%)]\tLoss: 3.225452\n",
            "Train Epoch: 42 [360/1863 (19%)]\tLoss: 14.948265\n",
            "Train Epoch: 42 [480/1863 (26%)]\tLoss: 8.237119\n",
            "Train Epoch: 42 [600/1863 (32%)]\tLoss: 21.626343\n",
            "Train Epoch: 42 [720/1863 (39%)]\tLoss: 12.028748\n",
            "Train Epoch: 42 [840/1863 (45%)]\tLoss: 17.125414\n",
            "Train Epoch: 42 [960/1863 (51%)]\tLoss: 10.076906\n",
            "Train Epoch: 42 [1080/1863 (58%)]\tLoss: 11.775781\n",
            "Train Epoch: 42 [1200/1863 (64%)]\tLoss: 2.980467\n",
            "Train Epoch: 42 [1320/1863 (71%)]\tLoss: 7.803153\n",
            "Train Epoch: 42 [1440/1863 (77%)]\tLoss: 10.886915\n",
            "Train Epoch: 42 [1560/1863 (83%)]\tLoss: 19.507355\n",
            "Train Epoch: 42 [1680/1863 (90%)]\tLoss: 6.285213\n",
            "Train Epoch: 42 [1800/1863 (96%)]\tLoss: 18.715326\n",
            "Training Loss: 11.2951 Acc: 51.4224\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4430, Accuracy: 716/1406 (50.925%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 43/200\n",
            "----------\n",
            "Train Epoch: 43 [0/1863 (0%)]\tLoss: 4.477283\n",
            "Train Epoch: 43 [120/1863 (6%)]\tLoss: 3.034963\n",
            "Train Epoch: 43 [240/1863 (13%)]\tLoss: 21.533667\n",
            "Train Epoch: 43 [360/1863 (19%)]\tLoss: 13.799420\n",
            "Train Epoch: 43 [480/1863 (26%)]\tLoss: 10.284841\n",
            "Train Epoch: 43 [600/1863 (32%)]\tLoss: 10.510714\n",
            "Train Epoch: 43 [720/1863 (39%)]\tLoss: 10.970060\n",
            "Train Epoch: 43 [840/1863 (45%)]\tLoss: 13.526367\n",
            "Train Epoch: 43 [960/1863 (51%)]\tLoss: 7.999307\n",
            "Train Epoch: 43 [1080/1863 (58%)]\tLoss: 6.194173\n",
            "Train Epoch: 43 [1200/1863 (64%)]\tLoss: 12.686262\n",
            "Train Epoch: 43 [1320/1863 (71%)]\tLoss: 10.037569\n",
            "Train Epoch: 43 [1440/1863 (77%)]\tLoss: 7.580945\n",
            "Train Epoch: 43 [1560/1863 (83%)]\tLoss: 16.200825\n",
            "Train Epoch: 43 [1680/1863 (90%)]\tLoss: 9.154486\n",
            "Train Epoch: 43 [1800/1863 (96%)]\tLoss: 9.361724\n",
            "Training Loss: 11.1935 Acc: 50.7246\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6404, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 44/200\n",
            "----------\n",
            "Train Epoch: 44 [0/1863 (0%)]\tLoss: 8.708025\n",
            "Train Epoch: 44 [120/1863 (6%)]\tLoss: 6.027581\n",
            "Train Epoch: 44 [240/1863 (13%)]\tLoss: 22.012146\n",
            "Train Epoch: 44 [360/1863 (19%)]\tLoss: 21.755795\n",
            "Train Epoch: 44 [480/1863 (26%)]\tLoss: 13.795209\n",
            "Train Epoch: 44 [600/1863 (32%)]\tLoss: 14.537395\n",
            "Train Epoch: 44 [720/1863 (39%)]\tLoss: 7.409343\n",
            "Train Epoch: 44 [840/1863 (45%)]\tLoss: 2.644730\n",
            "Train Epoch: 44 [960/1863 (51%)]\tLoss: 7.460098\n",
            "Train Epoch: 44 [1080/1863 (58%)]\tLoss: 13.645536\n",
            "Train Epoch: 44 [1200/1863 (64%)]\tLoss: 10.279220\n",
            "Train Epoch: 44 [1320/1863 (71%)]\tLoss: 7.032617\n",
            "Train Epoch: 44 [1440/1863 (77%)]\tLoss: 16.506273\n",
            "Train Epoch: 44 [1560/1863 (83%)]\tLoss: 9.069592\n",
            "Train Epoch: 44 [1680/1863 (90%)]\tLoss: 34.866188\n",
            "Train Epoch: 44 [1800/1863 (96%)]\tLoss: 10.448978\n",
            "Training Loss: 11.2609 Acc: 50.5099\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4912, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 45/200\n",
            "----------\n",
            "Train Epoch: 45 [0/1863 (0%)]\tLoss: 12.428929\n",
            "Train Epoch: 45 [120/1863 (6%)]\tLoss: 10.247257\n",
            "Train Epoch: 45 [240/1863 (13%)]\tLoss: 3.209592\n",
            "Train Epoch: 45 [360/1863 (19%)]\tLoss: 8.036940\n",
            "Train Epoch: 45 [480/1863 (26%)]\tLoss: 14.136414\n",
            "Train Epoch: 45 [600/1863 (32%)]\tLoss: 9.300920\n",
            "Train Epoch: 45 [720/1863 (39%)]\tLoss: 22.253136\n",
            "Train Epoch: 45 [840/1863 (45%)]\tLoss: 9.884043\n",
            "Train Epoch: 45 [960/1863 (51%)]\tLoss: 6.223890\n",
            "Train Epoch: 45 [1080/1863 (58%)]\tLoss: 9.063951\n",
            "Train Epoch: 45 [1200/1863 (64%)]\tLoss: 18.295355\n",
            "Train Epoch: 45 [1320/1863 (71%)]\tLoss: 4.994741\n",
            "Train Epoch: 45 [1440/1863 (77%)]\tLoss: 9.736002\n",
            "Train Epoch: 45 [1560/1863 (83%)]\tLoss: 10.642036\n",
            "Train Epoch: 45 [1680/1863 (90%)]\tLoss: 11.714903\n",
            "Train Epoch: 45 [1800/1863 (96%)]\tLoss: 8.802274\n",
            "Training Loss: 11.4036 Acc: 50.7783\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4872, Accuracy: 714/1406 (50.782%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 46/200\n",
            "----------\n",
            "Train Epoch: 46 [0/1863 (0%)]\tLoss: 7.914411\n",
            "Train Epoch: 46 [120/1863 (6%)]\tLoss: 13.565618\n",
            "Train Epoch: 46 [240/1863 (13%)]\tLoss: 3.742572\n",
            "Train Epoch: 46 [360/1863 (19%)]\tLoss: 12.871486\n",
            "Train Epoch: 46 [480/1863 (26%)]\tLoss: 22.008255\n",
            "Train Epoch: 46 [600/1863 (32%)]\tLoss: 16.457762\n",
            "Train Epoch: 46 [720/1863 (39%)]\tLoss: 5.876344\n",
            "Train Epoch: 46 [840/1863 (45%)]\tLoss: 6.455728\n",
            "Train Epoch: 46 [960/1863 (51%)]\tLoss: 12.489145\n",
            "Train Epoch: 46 [1080/1863 (58%)]\tLoss: 6.610188\n",
            "Train Epoch: 46 [1200/1863 (64%)]\tLoss: 9.683354\n",
            "Train Epoch: 46 [1320/1863 (71%)]\tLoss: 2.919085\n",
            "Train Epoch: 46 [1440/1863 (77%)]\tLoss: 14.259198\n",
            "Train Epoch: 46 [1560/1863 (83%)]\tLoss: 8.123955\n",
            "Train Epoch: 46 [1680/1863 (90%)]\tLoss: 9.656469\n",
            "Train Epoch: 46 [1800/1863 (96%)]\tLoss: 11.907639\n",
            "Training Loss: 10.8663 Acc: 50.1879\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.7412, Accuracy: 721/1406 (51.280%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 47/200\n",
            "----------\n",
            "Train Epoch: 47 [0/1863 (0%)]\tLoss: 3.195114\n",
            "Train Epoch: 47 [120/1863 (6%)]\tLoss: 17.752888\n",
            "Train Epoch: 47 [240/1863 (13%)]\tLoss: 3.240749\n",
            "Train Epoch: 47 [360/1863 (19%)]\tLoss: 4.336659\n",
            "Train Epoch: 47 [480/1863 (26%)]\tLoss: 10.225199\n",
            "Train Epoch: 47 [600/1863 (32%)]\tLoss: 7.826527\n",
            "Train Epoch: 47 [720/1863 (39%)]\tLoss: 13.349307\n",
            "Train Epoch: 47 [840/1863 (45%)]\tLoss: 7.091580\n",
            "Train Epoch: 47 [960/1863 (51%)]\tLoss: 16.007328\n",
            "Train Epoch: 47 [1080/1863 (58%)]\tLoss: 6.290150\n",
            "Train Epoch: 47 [1200/1863 (64%)]\tLoss: 5.487842\n",
            "Train Epoch: 47 [1320/1863 (71%)]\tLoss: 35.055443\n",
            "Train Epoch: 47 [1440/1863 (77%)]\tLoss: 12.826795\n",
            "Train Epoch: 47 [1560/1863 (83%)]\tLoss: 15.909152\n",
            "Train Epoch: 47 [1680/1863 (90%)]\tLoss: 14.407579\n",
            "Train Epoch: 47 [1800/1863 (96%)]\tLoss: 11.769518\n",
            "Training Loss: 10.7987 Acc: 50.9930\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4289, Accuracy: 731/1406 (51.991%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 48/200\n",
            "----------\n",
            "Train Epoch: 48 [0/1863 (0%)]\tLoss: 14.794540\n",
            "Train Epoch: 48 [120/1863 (6%)]\tLoss: 22.102983\n",
            "Train Epoch: 48 [240/1863 (13%)]\tLoss: 9.339699\n",
            "Train Epoch: 48 [360/1863 (19%)]\tLoss: 3.067652\n",
            "Train Epoch: 48 [480/1863 (26%)]\tLoss: 7.907656\n",
            "Train Epoch: 48 [600/1863 (32%)]\tLoss: 6.865180\n",
            "Train Epoch: 48 [720/1863 (39%)]\tLoss: 10.744159\n",
            "Train Epoch: 48 [840/1863 (45%)]\tLoss: 21.891644\n",
            "Train Epoch: 48 [960/1863 (51%)]\tLoss: 3.156094\n",
            "Train Epoch: 48 [1080/1863 (58%)]\tLoss: 7.563126\n",
            "Train Epoch: 48 [1200/1863 (64%)]\tLoss: 9.583813\n",
            "Train Epoch: 48 [1320/1863 (71%)]\tLoss: 26.605276\n",
            "Train Epoch: 48 [1440/1863 (77%)]\tLoss: 17.779024\n",
            "Train Epoch: 48 [1560/1863 (83%)]\tLoss: 11.757193\n",
            "Train Epoch: 48 [1680/1863 (90%)]\tLoss: 7.174907\n",
            "Train Epoch: 48 [1800/1863 (96%)]\tLoss: 5.396521\n",
            "Training Loss: 10.9482 Acc: 50.5636\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5928, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 49/200\n",
            "----------\n",
            "Train Epoch: 49 [0/1863 (0%)]\tLoss: 10.140280\n",
            "Train Epoch: 49 [120/1863 (6%)]\tLoss: 0.647958\n",
            "Train Epoch: 49 [240/1863 (13%)]\tLoss: 6.079967\n",
            "Train Epoch: 49 [360/1863 (19%)]\tLoss: 20.345463\n",
            "Train Epoch: 49 [480/1863 (26%)]\tLoss: 8.152471\n",
            "Train Epoch: 49 [600/1863 (32%)]\tLoss: 17.488085\n",
            "Train Epoch: 49 [720/1863 (39%)]\tLoss: 4.519542\n",
            "Train Epoch: 49 [840/1863 (45%)]\tLoss: 2.209061\n",
            "Train Epoch: 49 [960/1863 (51%)]\tLoss: 27.937037\n",
            "Train Epoch: 49 [1080/1863 (58%)]\tLoss: 8.584508\n",
            "Train Epoch: 49 [1200/1863 (64%)]\tLoss: 4.505858\n",
            "Train Epoch: 49 [1320/1863 (71%)]\tLoss: 6.252291\n",
            "Train Epoch: 49 [1440/1863 (77%)]\tLoss: 9.988554\n",
            "Train Epoch: 49 [1560/1863 (83%)]\tLoss: 4.319264\n",
            "Train Epoch: 49 [1680/1863 (90%)]\tLoss: 9.459492\n",
            "Train Epoch: 49 [1800/1863 (96%)]\tLoss: 13.277132\n",
            "Training Loss: 10.9898 Acc: 51.2614\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4503, Accuracy: 704/1406 (50.071%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 50/200\n",
            "----------\n",
            "Train Epoch: 50 [0/1863 (0%)]\tLoss: 8.822228\n",
            "Train Epoch: 50 [120/1863 (6%)]\tLoss: 11.486242\n",
            "Train Epoch: 50 [240/1863 (13%)]\tLoss: 17.868244\n",
            "Train Epoch: 50 [360/1863 (19%)]\tLoss: 8.050694\n",
            "Train Epoch: 50 [480/1863 (26%)]\tLoss: 11.672626\n",
            "Train Epoch: 50 [600/1863 (32%)]\tLoss: 25.188688\n",
            "Train Epoch: 50 [720/1863 (39%)]\tLoss: 4.779231\n",
            "Train Epoch: 50 [840/1863 (45%)]\tLoss: 4.631520\n",
            "Train Epoch: 50 [960/1863 (51%)]\tLoss: 8.269932\n",
            "Train Epoch: 50 [1080/1863 (58%)]\tLoss: 20.965158\n",
            "Train Epoch: 50 [1200/1863 (64%)]\tLoss: 37.493763\n",
            "Train Epoch: 50 [1320/1863 (71%)]\tLoss: 13.646948\n",
            "Train Epoch: 50 [1440/1863 (77%)]\tLoss: 18.564360\n",
            "Train Epoch: 50 [1560/1863 (83%)]\tLoss: 10.005017\n",
            "Train Epoch: 50 [1680/1863 (90%)]\tLoss: 15.979658\n",
            "Train Epoch: 50 [1800/1863 (96%)]\tLoss: 7.917493\n",
            "Training Loss: 10.8818 Acc: 50.8320\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5806, Accuracy: 713/1406 (50.711%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 51/200\n",
            "----------\n",
            "Train Epoch: 51 [0/1863 (0%)]\tLoss: 19.691942\n",
            "Train Epoch: 51 [120/1863 (6%)]\tLoss: 8.122503\n",
            "Train Epoch: 51 [240/1863 (13%)]\tLoss: 31.899836\n",
            "Train Epoch: 51 [360/1863 (19%)]\tLoss: 16.425924\n",
            "Train Epoch: 51 [480/1863 (26%)]\tLoss: 3.568280\n",
            "Train Epoch: 51 [600/1863 (32%)]\tLoss: 13.064076\n",
            "Train Epoch: 51 [720/1863 (39%)]\tLoss: 4.704973\n",
            "Train Epoch: 51 [840/1863 (45%)]\tLoss: 4.887977\n",
            "Train Epoch: 51 [960/1863 (51%)]\tLoss: 11.346584\n",
            "Train Epoch: 51 [1080/1863 (58%)]\tLoss: 7.574057\n",
            "Train Epoch: 51 [1200/1863 (64%)]\tLoss: 2.943562\n",
            "Train Epoch: 51 [1320/1863 (71%)]\tLoss: 7.745888\n",
            "Train Epoch: 51 [1440/1863 (77%)]\tLoss: 19.613377\n",
            "Train Epoch: 51 [1560/1863 (83%)]\tLoss: 8.056383\n",
            "Train Epoch: 51 [1680/1863 (90%)]\tLoss: 8.483354\n",
            "Train Epoch: 51 [1800/1863 (96%)]\tLoss: 1.464651\n",
            "Training Loss: 10.7353 Acc: 51.3688\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4021, Accuracy: 786/1406 (55.903%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 52/200\n",
            "----------\n",
            "Train Epoch: 52 [0/1863 (0%)]\tLoss: 4.710374\n",
            "Train Epoch: 52 [120/1863 (6%)]\tLoss: 11.699534\n",
            "Train Epoch: 52 [240/1863 (13%)]\tLoss: 18.933903\n",
            "Train Epoch: 52 [360/1863 (19%)]\tLoss: 8.150985\n",
            "Train Epoch: 52 [480/1863 (26%)]\tLoss: 13.933603\n",
            "Train Epoch: 52 [600/1863 (32%)]\tLoss: 4.686106\n",
            "Train Epoch: 52 [720/1863 (39%)]\tLoss: 6.386096\n",
            "Train Epoch: 52 [840/1863 (45%)]\tLoss: 14.661252\n",
            "Train Epoch: 52 [960/1863 (51%)]\tLoss: 15.078650\n",
            "Train Epoch: 52 [1080/1863 (58%)]\tLoss: 14.805624\n",
            "Train Epoch: 52 [1200/1863 (64%)]\tLoss: 5.785396\n",
            "Train Epoch: 52 [1320/1863 (71%)]\tLoss: 7.836233\n",
            "Train Epoch: 52 [1440/1863 (77%)]\tLoss: 8.391411\n",
            "Train Epoch: 52 [1560/1863 (83%)]\tLoss: 12.819699\n",
            "Train Epoch: 52 [1680/1863 (90%)]\tLoss: 12.119092\n",
            "Train Epoch: 52 [1800/1863 (96%)]\tLoss: 7.670317\n",
            "Training Loss: 10.9882 Acc: 50.4026\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3250, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 53/200\n",
            "----------\n",
            "Train Epoch: 53 [0/1863 (0%)]\tLoss: 1.560872\n",
            "Train Epoch: 53 [120/1863 (6%)]\tLoss: 13.243639\n",
            "Train Epoch: 53 [240/1863 (13%)]\tLoss: 9.091579\n",
            "Train Epoch: 53 [360/1863 (19%)]\tLoss: 17.817062\n",
            "Train Epoch: 53 [480/1863 (26%)]\tLoss: 20.359432\n",
            "Train Epoch: 53 [600/1863 (32%)]\tLoss: 3.284223\n",
            "Train Epoch: 53 [720/1863 (39%)]\tLoss: 18.041124\n",
            "Train Epoch: 53 [840/1863 (45%)]\tLoss: 11.405211\n",
            "Train Epoch: 53 [960/1863 (51%)]\tLoss: 17.933437\n",
            "Train Epoch: 53 [1080/1863 (58%)]\tLoss: 21.401119\n",
            "Train Epoch: 53 [1200/1863 (64%)]\tLoss: 13.488123\n",
            "Train Epoch: 53 [1320/1863 (71%)]\tLoss: 21.634373\n",
            "Train Epoch: 53 [1440/1863 (77%)]\tLoss: 8.515811\n",
            "Train Epoch: 53 [1560/1863 (83%)]\tLoss: 2.070600\n",
            "Train Epoch: 53 [1680/1863 (90%)]\tLoss: 6.582166\n",
            "Train Epoch: 53 [1800/1863 (96%)]\tLoss: 13.401608\n",
            "Training Loss: 11.3045 Acc: 50.0805\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.2918, Accuracy: 865/1406 (61.522%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 54/200\n",
            "----------\n",
            "Train Epoch: 54 [0/1863 (0%)]\tLoss: 10.997148\n",
            "Train Epoch: 54 [120/1863 (6%)]\tLoss: 10.062429\n",
            "Train Epoch: 54 [240/1863 (13%)]\tLoss: 18.486319\n",
            "Train Epoch: 54 [360/1863 (19%)]\tLoss: 6.499061\n",
            "Train Epoch: 54 [480/1863 (26%)]\tLoss: 5.380029\n",
            "Train Epoch: 54 [600/1863 (32%)]\tLoss: 13.653776\n",
            "Train Epoch: 54 [720/1863 (39%)]\tLoss: 14.879158\n",
            "Train Epoch: 54 [840/1863 (45%)]\tLoss: 19.479258\n",
            "Train Epoch: 54 [960/1863 (51%)]\tLoss: 10.965878\n",
            "Train Epoch: 54 [1080/1863 (58%)]\tLoss: 6.375309\n",
            "Train Epoch: 54 [1200/1863 (64%)]\tLoss: 17.111692\n",
            "Train Epoch: 54 [1320/1863 (71%)]\tLoss: 20.710365\n",
            "Train Epoch: 54 [1440/1863 (77%)]\tLoss: 7.395411\n",
            "Train Epoch: 54 [1560/1863 (83%)]\tLoss: 6.515971\n",
            "Train Epoch: 54 [1680/1863 (90%)]\tLoss: 10.635965\n",
            "Train Epoch: 54 [1800/1863 (96%)]\tLoss: 19.070818\n",
            "Training Loss: 11.4814 Acc: 51.1004\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5648, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 55/200\n",
            "----------\n",
            "Train Epoch: 55 [0/1863 (0%)]\tLoss: 6.618598\n",
            "Train Epoch: 55 [120/1863 (6%)]\tLoss: 7.847180\n",
            "Train Epoch: 55 [240/1863 (13%)]\tLoss: 10.648824\n",
            "Train Epoch: 55 [360/1863 (19%)]\tLoss: 12.222105\n",
            "Train Epoch: 55 [480/1863 (26%)]\tLoss: 18.004913\n",
            "Train Epoch: 55 [600/1863 (32%)]\tLoss: 22.793507\n",
            "Train Epoch: 55 [720/1863 (39%)]\tLoss: 3.507624\n",
            "Train Epoch: 55 [840/1863 (45%)]\tLoss: 23.709141\n",
            "Train Epoch: 55 [960/1863 (51%)]\tLoss: 7.315564\n",
            "Train Epoch: 55 [1080/1863 (58%)]\tLoss: 14.800850\n",
            "Train Epoch: 55 [1200/1863 (64%)]\tLoss: 6.040148\n",
            "Train Epoch: 55 [1320/1863 (71%)]\tLoss: 11.513845\n",
            "Train Epoch: 55 [1440/1863 (77%)]\tLoss: 7.912734\n",
            "Train Epoch: 55 [1560/1863 (83%)]\tLoss: 1.123314\n",
            "Train Epoch: 55 [1680/1863 (90%)]\tLoss: 12.709416\n",
            "Train Epoch: 55 [1800/1863 (96%)]\tLoss: 1.206865\n",
            "Training Loss: 11.6237 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4867, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 56/200\n",
            "----------\n",
            "Train Epoch: 56 [0/1863 (0%)]\tLoss: 12.033373\n",
            "Train Epoch: 56 [120/1863 (6%)]\tLoss: 4.797743\n",
            "Train Epoch: 56 [240/1863 (13%)]\tLoss: 21.914440\n",
            "Train Epoch: 56 [360/1863 (19%)]\tLoss: 10.568041\n",
            "Train Epoch: 56 [480/1863 (26%)]\tLoss: 10.285458\n",
            "Train Epoch: 56 [600/1863 (32%)]\tLoss: 13.671206\n",
            "Train Epoch: 56 [720/1863 (39%)]\tLoss: 10.759043\n",
            "Train Epoch: 56 [840/1863 (45%)]\tLoss: 2.330625\n",
            "Train Epoch: 56 [960/1863 (51%)]\tLoss: 30.242771\n",
            "Train Epoch: 56 [1080/1863 (58%)]\tLoss: 10.450539\n",
            "Train Epoch: 56 [1200/1863 (64%)]\tLoss: 6.307055\n",
            "Train Epoch: 56 [1320/1863 (71%)]\tLoss: 8.639177\n",
            "Train Epoch: 56 [1440/1863 (77%)]\tLoss: 9.961198\n",
            "Train Epoch: 56 [1560/1863 (83%)]\tLoss: 16.416945\n",
            "Train Epoch: 56 [1680/1863 (90%)]\tLoss: 5.367942\n",
            "Train Epoch: 56 [1800/1863 (96%)]\tLoss: 21.188074\n",
            "Training Loss: 11.4816 Acc: 50.9930\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4825, Accuracy: 728/1406 (51.778%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 57/200\n",
            "----------\n",
            "Train Epoch: 57 [0/1863 (0%)]\tLoss: 6.811103\n",
            "Train Epoch: 57 [120/1863 (6%)]\tLoss: 8.870977\n",
            "Train Epoch: 57 [240/1863 (13%)]\tLoss: 18.146109\n",
            "Train Epoch: 57 [360/1863 (19%)]\tLoss: 4.182622\n",
            "Train Epoch: 57 [480/1863 (26%)]\tLoss: 13.119951\n",
            "Train Epoch: 57 [600/1863 (32%)]\tLoss: 8.922545\n",
            "Train Epoch: 57 [720/1863 (39%)]\tLoss: 12.359331\n",
            "Train Epoch: 57 [840/1863 (45%)]\tLoss: 14.110054\n",
            "Train Epoch: 57 [960/1863 (51%)]\tLoss: 11.838877\n",
            "Train Epoch: 57 [1080/1863 (58%)]\tLoss: 2.065287\n",
            "Train Epoch: 57 [1200/1863 (64%)]\tLoss: 1.770033\n",
            "Train Epoch: 57 [1320/1863 (71%)]\tLoss: 2.618323\n",
            "Train Epoch: 57 [1440/1863 (77%)]\tLoss: 8.160636\n",
            "Train Epoch: 57 [1560/1863 (83%)]\tLoss: 29.663706\n",
            "Train Epoch: 57 [1680/1863 (90%)]\tLoss: 12.768933\n",
            "Train Epoch: 57 [1800/1863 (96%)]\tLoss: 18.012398\n",
            "Training Loss: 10.9604 Acc: 51.1004\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4550, Accuracy: 749/1406 (53.272%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 58/200\n",
            "----------\n",
            "Train Epoch: 58 [0/1863 (0%)]\tLoss: 16.926868\n",
            "Train Epoch: 58 [120/1863 (6%)]\tLoss: 12.210350\n",
            "Train Epoch: 58 [240/1863 (13%)]\tLoss: 12.242601\n",
            "Train Epoch: 58 [360/1863 (19%)]\tLoss: 5.214926\n",
            "Train Epoch: 58 [480/1863 (26%)]\tLoss: 10.924446\n",
            "Train Epoch: 58 [600/1863 (32%)]\tLoss: 6.051863\n",
            "Train Epoch: 58 [720/1863 (39%)]\tLoss: 11.065610\n",
            "Train Epoch: 58 [840/1863 (45%)]\tLoss: 10.546510\n",
            "Train Epoch: 58 [960/1863 (51%)]\tLoss: 1.950392\n",
            "Train Epoch: 58 [1080/1863 (58%)]\tLoss: 11.224345\n",
            "Train Epoch: 58 [1200/1863 (64%)]\tLoss: 11.915397\n",
            "Train Epoch: 58 [1320/1863 (71%)]\tLoss: 6.950325\n",
            "Train Epoch: 58 [1440/1863 (77%)]\tLoss: 10.667717\n",
            "Train Epoch: 58 [1560/1863 (83%)]\tLoss: 17.859238\n",
            "Train Epoch: 58 [1680/1863 (90%)]\tLoss: 10.846273\n",
            "Train Epoch: 58 [1800/1863 (96%)]\tLoss: 4.606537\n",
            "Training Loss: 11.1964 Acc: 51.1004\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4923, Accuracy: 753/1406 (53.556%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 59/200\n",
            "----------\n",
            "Train Epoch: 59 [0/1863 (0%)]\tLoss: 11.456671\n",
            "Train Epoch: 59 [120/1863 (6%)]\tLoss: 20.236002\n",
            "Train Epoch: 59 [240/1863 (13%)]\tLoss: 25.394806\n",
            "Train Epoch: 59 [360/1863 (19%)]\tLoss: 9.636627\n",
            "Train Epoch: 59 [480/1863 (26%)]\tLoss: 2.624986\n",
            "Train Epoch: 59 [600/1863 (32%)]\tLoss: 19.825647\n",
            "Train Epoch: 59 [720/1863 (39%)]\tLoss: 17.029003\n",
            "Train Epoch: 59 [840/1863 (45%)]\tLoss: 5.575828\n",
            "Train Epoch: 59 [960/1863 (51%)]\tLoss: 17.777668\n",
            "Train Epoch: 59 [1080/1863 (58%)]\tLoss: 6.168139\n",
            "Train Epoch: 59 [1200/1863 (64%)]\tLoss: 9.328249\n",
            "Train Epoch: 59 [1320/1863 (71%)]\tLoss: 13.951009\n",
            "Train Epoch: 59 [1440/1863 (77%)]\tLoss: 12.477048\n",
            "Train Epoch: 59 [1560/1863 (83%)]\tLoss: 6.864422\n",
            "Train Epoch: 59 [1680/1863 (90%)]\tLoss: 3.249427\n",
            "Train Epoch: 59 [1800/1863 (96%)]\tLoss: 14.038356\n",
            "Training Loss: 10.8080 Acc: 51.6371\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4375, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 60/200\n",
            "----------\n",
            "Train Epoch: 60 [0/1863 (0%)]\tLoss: 10.920740\n",
            "Train Epoch: 60 [120/1863 (6%)]\tLoss: 2.964035\n",
            "Train Epoch: 60 [240/1863 (13%)]\tLoss: 17.976570\n",
            "Train Epoch: 60 [360/1863 (19%)]\tLoss: 4.494491\n",
            "Train Epoch: 60 [480/1863 (26%)]\tLoss: 12.965570\n",
            "Train Epoch: 60 [600/1863 (32%)]\tLoss: 14.549129\n",
            "Train Epoch: 60 [720/1863 (39%)]\tLoss: 4.070773\n",
            "Train Epoch: 60 [840/1863 (45%)]\tLoss: 23.490976\n",
            "Train Epoch: 60 [960/1863 (51%)]\tLoss: 0.148967\n",
            "Train Epoch: 60 [1080/1863 (58%)]\tLoss: 3.886279\n",
            "Train Epoch: 60 [1200/1863 (64%)]\tLoss: 18.087242\n",
            "Train Epoch: 60 [1320/1863 (71%)]\tLoss: 9.956033\n",
            "Train Epoch: 60 [1440/1863 (77%)]\tLoss: 6.630386\n",
            "Train Epoch: 60 [1560/1863 (83%)]\tLoss: 17.688524\n",
            "Train Epoch: 60 [1680/1863 (90%)]\tLoss: 10.051657\n",
            "Train Epoch: 60 [1800/1863 (96%)]\tLoss: 12.471338\n",
            "Training Loss: 11.0364 Acc: 51.1004\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.8476, Accuracy: 713/1406 (50.711%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 61/200\n",
            "----------\n",
            "Train Epoch: 61 [0/1863 (0%)]\tLoss: 7.089093\n",
            "Train Epoch: 61 [120/1863 (6%)]\tLoss: 19.817467\n",
            "Train Epoch: 61 [240/1863 (13%)]\tLoss: 4.078949\n",
            "Train Epoch: 61 [360/1863 (19%)]\tLoss: 13.997088\n",
            "Train Epoch: 61 [480/1863 (26%)]\tLoss: 18.260916\n",
            "Train Epoch: 61 [600/1863 (32%)]\tLoss: 2.943614\n",
            "Train Epoch: 61 [720/1863 (39%)]\tLoss: 4.534828\n",
            "Train Epoch: 61 [840/1863 (45%)]\tLoss: 13.902331\n",
            "Train Epoch: 61 [960/1863 (51%)]\tLoss: 7.116606\n",
            "Train Epoch: 61 [1080/1863 (58%)]\tLoss: 4.854353\n",
            "Train Epoch: 61 [1200/1863 (64%)]\tLoss: 28.171942\n",
            "Train Epoch: 61 [1320/1863 (71%)]\tLoss: 8.600278\n",
            "Train Epoch: 61 [1440/1863 (77%)]\tLoss: 10.788177\n",
            "Train Epoch: 61 [1560/1863 (83%)]\tLoss: 6.566659\n",
            "Train Epoch: 61 [1680/1863 (90%)]\tLoss: 14.304029\n",
            "Train Epoch: 61 [1800/1863 (96%)]\tLoss: 19.767193\n",
            "Training Loss: 11.1099 Acc: 49.9732\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4844, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 62/200\n",
            "----------\n",
            "Train Epoch: 62 [0/1863 (0%)]\tLoss: 19.490671\n",
            "Train Epoch: 62 [120/1863 (6%)]\tLoss: 19.043049\n",
            "Train Epoch: 62 [240/1863 (13%)]\tLoss: 17.562798\n",
            "Train Epoch: 62 [360/1863 (19%)]\tLoss: 12.535205\n",
            "Train Epoch: 62 [480/1863 (26%)]\tLoss: 10.612981\n",
            "Train Epoch: 62 [600/1863 (32%)]\tLoss: 7.035681\n",
            "Train Epoch: 62 [720/1863 (39%)]\tLoss: 21.201004\n",
            "Train Epoch: 62 [840/1863 (45%)]\tLoss: 11.880714\n",
            "Train Epoch: 62 [960/1863 (51%)]\tLoss: 22.836540\n",
            "Train Epoch: 62 [1080/1863 (58%)]\tLoss: 8.755112\n",
            "Train Epoch: 62 [1200/1863 (64%)]\tLoss: 3.054866\n",
            "Train Epoch: 62 [1320/1863 (71%)]\tLoss: 17.397646\n",
            "Train Epoch: 62 [1440/1863 (77%)]\tLoss: 4.318559\n",
            "Train Epoch: 62 [1560/1863 (83%)]\tLoss: 14.503352\n",
            "Train Epoch: 62 [1680/1863 (90%)]\tLoss: 9.518720\n",
            "Train Epoch: 62 [1800/1863 (96%)]\tLoss: 12.456198\n",
            "Training Loss: 11.1074 Acc: 50.9393\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5736, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 63/200\n",
            "----------\n",
            "Train Epoch: 63 [0/1863 (0%)]\tLoss: 12.817777\n",
            "Train Epoch: 63 [120/1863 (6%)]\tLoss: 6.226311\n",
            "Train Epoch: 63 [240/1863 (13%)]\tLoss: 4.924123\n",
            "Train Epoch: 63 [360/1863 (19%)]\tLoss: 8.104360\n",
            "Train Epoch: 63 [480/1863 (26%)]\tLoss: 9.253209\n",
            "Train Epoch: 63 [600/1863 (32%)]\tLoss: 21.424530\n",
            "Train Epoch: 63 [720/1863 (39%)]\tLoss: 21.891872\n",
            "Train Epoch: 63 [840/1863 (45%)]\tLoss: 9.167482\n",
            "Train Epoch: 63 [960/1863 (51%)]\tLoss: 10.783252\n",
            "Train Epoch: 63 [1080/1863 (58%)]\tLoss: 8.717688\n",
            "Train Epoch: 63 [1200/1863 (64%)]\tLoss: 14.862055\n",
            "Train Epoch: 63 [1320/1863 (71%)]\tLoss: 13.608937\n",
            "Train Epoch: 63 [1440/1863 (77%)]\tLoss: 12.495317\n",
            "Train Epoch: 63 [1560/1863 (83%)]\tLoss: 8.371013\n",
            "Train Epoch: 63 [1680/1863 (90%)]\tLoss: 15.662352\n",
            "Train Epoch: 63 [1800/1863 (96%)]\tLoss: 19.109440\n",
            "Training Loss: 11.1073 Acc: 51.3151\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4180, Accuracy: 780/1406 (55.477%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 64/200\n",
            "----------\n",
            "Train Epoch: 64 [0/1863 (0%)]\tLoss: 5.932763\n",
            "Train Epoch: 64 [120/1863 (6%)]\tLoss: 5.297298\n",
            "Train Epoch: 64 [240/1863 (13%)]\tLoss: 15.439776\n",
            "Train Epoch: 64 [360/1863 (19%)]\tLoss: 14.315648\n",
            "Train Epoch: 64 [480/1863 (26%)]\tLoss: 23.057301\n",
            "Train Epoch: 64 [600/1863 (32%)]\tLoss: 6.830386\n",
            "Train Epoch: 64 [720/1863 (39%)]\tLoss: 1.571399\n",
            "Train Epoch: 64 [840/1863 (45%)]\tLoss: 9.285128\n",
            "Train Epoch: 64 [960/1863 (51%)]\tLoss: 4.054351\n",
            "Train Epoch: 64 [1080/1863 (58%)]\tLoss: 18.012274\n",
            "Train Epoch: 64 [1200/1863 (64%)]\tLoss: 16.360312\n",
            "Train Epoch: 64 [1320/1863 (71%)]\tLoss: 2.778635\n",
            "Train Epoch: 64 [1440/1863 (77%)]\tLoss: 20.400150\n",
            "Train Epoch: 64 [1560/1863 (83%)]\tLoss: 6.361372\n",
            "Train Epoch: 64 [1680/1863 (90%)]\tLoss: 27.707455\n",
            "Train Epoch: 64 [1800/1863 (96%)]\tLoss: 5.086736\n",
            "Training Loss: 11.0187 Acc: 51.2614\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4662, Accuracy: 723/1406 (51.422%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 65/200\n",
            "----------\n",
            "Train Epoch: 65 [0/1863 (0%)]\tLoss: 12.629692\n",
            "Train Epoch: 65 [120/1863 (6%)]\tLoss: 4.745584\n",
            "Train Epoch: 65 [240/1863 (13%)]\tLoss: 13.999829\n",
            "Train Epoch: 65 [360/1863 (19%)]\tLoss: 6.170800\n",
            "Train Epoch: 65 [480/1863 (26%)]\tLoss: 17.049881\n",
            "Train Epoch: 65 [600/1863 (32%)]\tLoss: 15.802139\n",
            "Train Epoch: 65 [720/1863 (39%)]\tLoss: 6.767210\n",
            "Train Epoch: 65 [840/1863 (45%)]\tLoss: 12.978129\n",
            "Train Epoch: 65 [960/1863 (51%)]\tLoss: 11.595917\n",
            "Train Epoch: 65 [1080/1863 (58%)]\tLoss: 9.404699\n",
            "Train Epoch: 65 [1200/1863 (64%)]\tLoss: 10.057512\n",
            "Train Epoch: 65 [1320/1863 (71%)]\tLoss: 5.332814\n",
            "Train Epoch: 65 [1440/1863 (77%)]\tLoss: 14.485365\n",
            "Train Epoch: 65 [1560/1863 (83%)]\tLoss: 8.074280\n",
            "Train Epoch: 65 [1680/1863 (90%)]\tLoss: 1.323085\n",
            "Train Epoch: 65 [1800/1863 (96%)]\tLoss: 7.742255\n",
            "Training Loss: 11.1128 Acc: 49.9195\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4716, Accuracy: 719/1406 (51.138%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 66/200\n",
            "----------\n",
            "Train Epoch: 66 [0/1863 (0%)]\tLoss: 1.651819\n",
            "Train Epoch: 66 [120/1863 (6%)]\tLoss: 9.645069\n",
            "Train Epoch: 66 [240/1863 (13%)]\tLoss: 5.462036\n",
            "Train Epoch: 66 [360/1863 (19%)]\tLoss: 7.328868\n",
            "Train Epoch: 66 [480/1863 (26%)]\tLoss: 19.571707\n",
            "Train Epoch: 66 [600/1863 (32%)]\tLoss: 2.805518\n",
            "Train Epoch: 66 [720/1863 (39%)]\tLoss: 0.898174\n",
            "Train Epoch: 66 [840/1863 (45%)]\tLoss: 19.284197\n",
            "Train Epoch: 66 [960/1863 (51%)]\tLoss: 9.952099\n",
            "Train Epoch: 66 [1080/1863 (58%)]\tLoss: 6.511157\n",
            "Train Epoch: 66 [1200/1863 (64%)]\tLoss: 13.335340\n",
            "Train Epoch: 66 [1320/1863 (71%)]\tLoss: 13.128183\n",
            "Train Epoch: 66 [1440/1863 (77%)]\tLoss: 11.607018\n",
            "Train Epoch: 66 [1560/1863 (83%)]\tLoss: 11.224013\n",
            "Train Epoch: 66 [1680/1863 (90%)]\tLoss: 5.121935\n",
            "Train Epoch: 66 [1800/1863 (96%)]\tLoss: 14.963356\n",
            "Training Loss: 11.1216 Acc: 50.7783\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5450, Accuracy: 714/1406 (50.782%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 67/200\n",
            "----------\n",
            "Train Epoch: 67 [0/1863 (0%)]\tLoss: 14.674647\n",
            "Train Epoch: 67 [120/1863 (6%)]\tLoss: 16.014454\n",
            "Train Epoch: 67 [240/1863 (13%)]\tLoss: 3.998309\n",
            "Train Epoch: 67 [360/1863 (19%)]\tLoss: 9.825496\n",
            "Train Epoch: 67 [480/1863 (26%)]\tLoss: 13.251871\n",
            "Train Epoch: 67 [600/1863 (32%)]\tLoss: 14.325722\n",
            "Train Epoch: 67 [720/1863 (39%)]\tLoss: 4.880901\n",
            "Train Epoch: 67 [840/1863 (45%)]\tLoss: 17.863422\n",
            "Train Epoch: 67 [960/1863 (51%)]\tLoss: 11.834303\n",
            "Train Epoch: 67 [1080/1863 (58%)]\tLoss: 16.199650\n",
            "Train Epoch: 67 [1200/1863 (64%)]\tLoss: 4.980691\n",
            "Train Epoch: 67 [1320/1863 (71%)]\tLoss: 12.643385\n",
            "Train Epoch: 67 [1440/1863 (77%)]\tLoss: 10.659276\n",
            "Train Epoch: 67 [1560/1863 (83%)]\tLoss: 2.276975\n",
            "Train Epoch: 67 [1680/1863 (90%)]\tLoss: 3.648679\n",
            "Train Epoch: 67 [1800/1863 (96%)]\tLoss: 15.054710\n",
            "Training Loss: 11.3733 Acc: 50.9930\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6703, Accuracy: 720/1406 (51.209%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 68/200\n",
            "----------\n",
            "Train Epoch: 68 [0/1863 (0%)]\tLoss: 11.911901\n",
            "Train Epoch: 68 [120/1863 (6%)]\tLoss: 4.298426\n",
            "Train Epoch: 68 [240/1863 (13%)]\tLoss: 5.604993\n",
            "Train Epoch: 68 [360/1863 (19%)]\tLoss: 15.978681\n",
            "Train Epoch: 68 [480/1863 (26%)]\tLoss: 13.661392\n",
            "Train Epoch: 68 [600/1863 (32%)]\tLoss: 2.413455\n",
            "Train Epoch: 68 [720/1863 (39%)]\tLoss: 16.069515\n",
            "Train Epoch: 68 [840/1863 (45%)]\tLoss: 1.493739\n",
            "Train Epoch: 68 [960/1863 (51%)]\tLoss: 5.891956\n",
            "Train Epoch: 68 [1080/1863 (58%)]\tLoss: 5.189132\n",
            "Train Epoch: 68 [1200/1863 (64%)]\tLoss: 9.006907\n",
            "Train Epoch: 68 [1320/1863 (71%)]\tLoss: 0.965220\n",
            "Train Epoch: 68 [1440/1863 (77%)]\tLoss: 18.650965\n",
            "Train Epoch: 68 [1560/1863 (83%)]\tLoss: 17.784290\n",
            "Train Epoch: 68 [1680/1863 (90%)]\tLoss: 10.642084\n",
            "Train Epoch: 68 [1800/1863 (96%)]\tLoss: 4.635359\n",
            "Training Loss: 11.0056 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4640, Accuracy: 726/1406 (51.636%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 69/200\n",
            "----------\n",
            "Train Epoch: 69 [0/1863 (0%)]\tLoss: 20.714956\n",
            "Train Epoch: 69 [120/1863 (6%)]\tLoss: 9.560132\n",
            "Train Epoch: 69 [240/1863 (13%)]\tLoss: 4.652541\n",
            "Train Epoch: 69 [360/1863 (19%)]\tLoss: 6.259835\n",
            "Train Epoch: 69 [480/1863 (26%)]\tLoss: 13.186931\n",
            "Train Epoch: 69 [600/1863 (32%)]\tLoss: 7.284709\n",
            "Train Epoch: 69 [720/1863 (39%)]\tLoss: 2.982478\n",
            "Train Epoch: 69 [840/1863 (45%)]\tLoss: 5.483861\n",
            "Train Epoch: 69 [960/1863 (51%)]\tLoss: 3.676125\n",
            "Train Epoch: 69 [1080/1863 (58%)]\tLoss: 8.765787\n",
            "Train Epoch: 69 [1200/1863 (64%)]\tLoss: 21.309948\n",
            "Train Epoch: 69 [1320/1863 (71%)]\tLoss: 9.306276\n",
            "Train Epoch: 69 [1440/1863 (77%)]\tLoss: 16.329943\n",
            "Train Epoch: 69 [1560/1863 (83%)]\tLoss: 4.648895\n",
            "Train Epoch: 69 [1680/1863 (90%)]\tLoss: 6.958675\n",
            "Train Epoch: 69 [1800/1863 (96%)]\tLoss: 13.479803\n",
            "Training Loss: 11.0279 Acc: 50.1342\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5898, Accuracy: 715/1406 (50.853%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 70/200\n",
            "----------\n",
            "Train Epoch: 70 [0/1863 (0%)]\tLoss: 17.050091\n",
            "Train Epoch: 70 [120/1863 (6%)]\tLoss: 13.332225\n",
            "Train Epoch: 70 [240/1863 (13%)]\tLoss: 11.533510\n",
            "Train Epoch: 70 [360/1863 (19%)]\tLoss: 7.863431\n",
            "Train Epoch: 70 [480/1863 (26%)]\tLoss: 5.763544\n",
            "Train Epoch: 70 [600/1863 (32%)]\tLoss: 4.813256\n",
            "Train Epoch: 70 [720/1863 (39%)]\tLoss: 5.004842\n",
            "Train Epoch: 70 [840/1863 (45%)]\tLoss: 16.750278\n",
            "Train Epoch: 70 [960/1863 (51%)]\tLoss: 12.718867\n",
            "Train Epoch: 70 [1080/1863 (58%)]\tLoss: 4.238446\n",
            "Train Epoch: 70 [1200/1863 (64%)]\tLoss: 9.276029\n",
            "Train Epoch: 70 [1320/1863 (71%)]\tLoss: 4.831885\n",
            "Train Epoch: 70 [1440/1863 (77%)]\tLoss: 6.924129\n",
            "Train Epoch: 70 [1560/1863 (83%)]\tLoss: 14.375903\n",
            "Train Epoch: 70 [1680/1863 (90%)]\tLoss: 8.876116\n",
            "Train Epoch: 70 [1800/1863 (96%)]\tLoss: 6.760843\n",
            "Training Loss: 11.1036 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4378, Accuracy: 712/1406 (50.640%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 71/200\n",
            "----------\n",
            "Train Epoch: 71 [0/1863 (0%)]\tLoss: 5.309978\n",
            "Train Epoch: 71 [120/1863 (6%)]\tLoss: 14.917944\n",
            "Train Epoch: 71 [240/1863 (13%)]\tLoss: 16.559280\n",
            "Train Epoch: 71 [360/1863 (19%)]\tLoss: 6.989501\n",
            "Train Epoch: 71 [480/1863 (26%)]\tLoss: 1.338437\n",
            "Train Epoch: 71 [600/1863 (32%)]\tLoss: 10.063535\n",
            "Train Epoch: 71 [720/1863 (39%)]\tLoss: 8.852089\n",
            "Train Epoch: 71 [840/1863 (45%)]\tLoss: 11.951288\n",
            "Train Epoch: 71 [960/1863 (51%)]\tLoss: 24.405310\n",
            "Train Epoch: 71 [1080/1863 (58%)]\tLoss: 13.021083\n",
            "Train Epoch: 71 [1200/1863 (64%)]\tLoss: 12.773916\n",
            "Train Epoch: 71 [1320/1863 (71%)]\tLoss: 2.915121\n",
            "Train Epoch: 71 [1440/1863 (77%)]\tLoss: 1.507075\n",
            "Train Epoch: 71 [1560/1863 (83%)]\tLoss: 2.724329\n",
            "Train Epoch: 71 [1680/1863 (90%)]\tLoss: 6.866202\n",
            "Train Epoch: 71 [1800/1863 (96%)]\tLoss: 1.358891\n",
            "Training Loss: 11.1087 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4933, Accuracy: 712/1406 (50.640%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 72/200\n",
            "----------\n",
            "Train Epoch: 72 [0/1863 (0%)]\tLoss: 13.509326\n",
            "Train Epoch: 72 [120/1863 (6%)]\tLoss: 8.330103\n",
            "Train Epoch: 72 [240/1863 (13%)]\tLoss: 19.839382\n",
            "Train Epoch: 72 [360/1863 (19%)]\tLoss: 10.688213\n",
            "Train Epoch: 72 [480/1863 (26%)]\tLoss: 8.054251\n",
            "Train Epoch: 72 [600/1863 (32%)]\tLoss: 4.887555\n",
            "Train Epoch: 72 [720/1863 (39%)]\tLoss: 3.993059\n",
            "Train Epoch: 72 [840/1863 (45%)]\tLoss: 6.139719\n",
            "Train Epoch: 72 [960/1863 (51%)]\tLoss: 10.700876\n",
            "Train Epoch: 72 [1080/1863 (58%)]\tLoss: 6.703175\n",
            "Train Epoch: 72 [1200/1863 (64%)]\tLoss: 15.458508\n",
            "Train Epoch: 72 [1320/1863 (71%)]\tLoss: 9.236649\n",
            "Train Epoch: 72 [1440/1863 (77%)]\tLoss: 16.990404\n",
            "Train Epoch: 72 [1560/1863 (83%)]\tLoss: 8.820908\n",
            "Train Epoch: 72 [1680/1863 (90%)]\tLoss: 16.053707\n",
            "Train Epoch: 72 [1800/1863 (96%)]\tLoss: 7.384252\n",
            "Training Loss: 10.9018 Acc: 51.3688\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4150, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 73/200\n",
            "----------\n",
            "Train Epoch: 73 [0/1863 (0%)]\tLoss: 8.991631\n",
            "Train Epoch: 73 [120/1863 (6%)]\tLoss: 14.920283\n",
            "Train Epoch: 73 [240/1863 (13%)]\tLoss: 5.519954\n",
            "Train Epoch: 73 [360/1863 (19%)]\tLoss: 8.435915\n",
            "Train Epoch: 73 [480/1863 (26%)]\tLoss: 4.203092\n",
            "Train Epoch: 73 [600/1863 (32%)]\tLoss: 2.923496\n",
            "Train Epoch: 73 [720/1863 (39%)]\tLoss: 7.480077\n",
            "Train Epoch: 73 [840/1863 (45%)]\tLoss: 11.295839\n",
            "Train Epoch: 73 [960/1863 (51%)]\tLoss: 9.650810\n",
            "Train Epoch: 73 [1080/1863 (58%)]\tLoss: 3.291584\n",
            "Train Epoch: 73 [1200/1863 (64%)]\tLoss: 11.692963\n",
            "Train Epoch: 73 [1320/1863 (71%)]\tLoss: 8.101417\n",
            "Train Epoch: 73 [1440/1863 (77%)]\tLoss: 10.146286\n",
            "Train Epoch: 73 [1560/1863 (83%)]\tLoss: 5.421538\n",
            "Train Epoch: 73 [1680/1863 (90%)]\tLoss: 14.017225\n",
            "Train Epoch: 73 [1800/1863 (96%)]\tLoss: 4.998893\n",
            "Training Loss: 11.0070 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6587, Accuracy: 715/1406 (50.853%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 74/200\n",
            "----------\n",
            "Train Epoch: 74 [0/1863 (0%)]\tLoss: 18.649757\n",
            "Train Epoch: 74 [120/1863 (6%)]\tLoss: 10.156125\n",
            "Train Epoch: 74 [240/1863 (13%)]\tLoss: 7.817294\n",
            "Train Epoch: 74 [360/1863 (19%)]\tLoss: 10.145767\n",
            "Train Epoch: 74 [480/1863 (26%)]\tLoss: 16.460817\n",
            "Train Epoch: 74 [600/1863 (32%)]\tLoss: 3.488972\n",
            "Train Epoch: 74 [720/1863 (39%)]\tLoss: 11.873691\n",
            "Train Epoch: 74 [840/1863 (45%)]\tLoss: 19.181385\n",
            "Train Epoch: 74 [960/1863 (51%)]\tLoss: 3.266872\n",
            "Train Epoch: 74 [1080/1863 (58%)]\tLoss: 3.431096\n",
            "Train Epoch: 74 [1200/1863 (64%)]\tLoss: 5.490880\n",
            "Train Epoch: 74 [1320/1863 (71%)]\tLoss: 2.675349\n",
            "Train Epoch: 74 [1440/1863 (77%)]\tLoss: 27.899124\n",
            "Train Epoch: 74 [1560/1863 (83%)]\tLoss: 13.304410\n",
            "Train Epoch: 74 [1680/1863 (90%)]\tLoss: 10.651030\n",
            "Train Epoch: 74 [1800/1863 (96%)]\tLoss: 4.460917\n",
            "Training Loss: 11.1931 Acc: 50.8320\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3103, Accuracy: 864/1406 (61.451%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 75/200\n",
            "----------\n",
            "Train Epoch: 75 [0/1863 (0%)]\tLoss: 13.031964\n",
            "Train Epoch: 75 [120/1863 (6%)]\tLoss: 11.972822\n",
            "Train Epoch: 75 [240/1863 (13%)]\tLoss: 1.818684\n",
            "Train Epoch: 75 [360/1863 (19%)]\tLoss: 5.321052\n",
            "Train Epoch: 75 [480/1863 (26%)]\tLoss: 4.546420\n",
            "Train Epoch: 75 [600/1863 (32%)]\tLoss: 3.101048\n",
            "Train Epoch: 75 [720/1863 (39%)]\tLoss: 2.427106\n",
            "Train Epoch: 75 [840/1863 (45%)]\tLoss: 4.287676\n",
            "Train Epoch: 75 [960/1863 (51%)]\tLoss: 12.069478\n",
            "Train Epoch: 75 [1080/1863 (58%)]\tLoss: 5.828573\n",
            "Train Epoch: 75 [1200/1863 (64%)]\tLoss: 13.592664\n",
            "Train Epoch: 75 [1320/1863 (71%)]\tLoss: 4.974507\n",
            "Train Epoch: 75 [1440/1863 (77%)]\tLoss: 14.584702\n",
            "Train Epoch: 75 [1560/1863 (83%)]\tLoss: 6.092754\n",
            "Train Epoch: 75 [1680/1863 (90%)]\tLoss: 17.929119\n",
            "Train Epoch: 75 [1800/1863 (96%)]\tLoss: 8.379295\n",
            "Training Loss: 11.3895 Acc: 50.7246\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.7138, Accuracy: 713/1406 (50.711%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 76/200\n",
            "----------\n",
            "Train Epoch: 76 [0/1863 (0%)]\tLoss: 5.292262\n",
            "Train Epoch: 76 [120/1863 (6%)]\tLoss: 11.888556\n",
            "Train Epoch: 76 [240/1863 (13%)]\tLoss: 7.691100\n",
            "Train Epoch: 76 [360/1863 (19%)]\tLoss: 13.626411\n",
            "Train Epoch: 76 [480/1863 (26%)]\tLoss: 0.790774\n",
            "Train Epoch: 76 [600/1863 (32%)]\tLoss: 5.506307\n",
            "Train Epoch: 76 [720/1863 (39%)]\tLoss: 30.926325\n",
            "Train Epoch: 76 [840/1863 (45%)]\tLoss: 9.737380\n",
            "Train Epoch: 76 [960/1863 (51%)]\tLoss: 2.430884\n",
            "Train Epoch: 76 [1080/1863 (58%)]\tLoss: 14.931337\n",
            "Train Epoch: 76 [1200/1863 (64%)]\tLoss: 11.766607\n",
            "Train Epoch: 76 [1320/1863 (71%)]\tLoss: 7.475155\n",
            "Train Epoch: 76 [1440/1863 (77%)]\tLoss: 1.970074\n",
            "Train Epoch: 76 [1560/1863 (83%)]\tLoss: 8.121915\n",
            "Train Epoch: 76 [1680/1863 (90%)]\tLoss: 16.342920\n",
            "Train Epoch: 76 [1800/1863 (96%)]\tLoss: 7.323148\n",
            "Training Loss: 11.2955 Acc: 51.6908\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5066, Accuracy: 750/1406 (53.343%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 77/200\n",
            "----------\n",
            "Train Epoch: 77 [0/1863 (0%)]\tLoss: 5.744408\n",
            "Train Epoch: 77 [120/1863 (6%)]\tLoss: 11.961103\n",
            "Train Epoch: 77 [240/1863 (13%)]\tLoss: 2.223128\n",
            "Train Epoch: 77 [360/1863 (19%)]\tLoss: 6.971976\n",
            "Train Epoch: 77 [480/1863 (26%)]\tLoss: 12.560770\n",
            "Train Epoch: 77 [600/1863 (32%)]\tLoss: 1.798282\n",
            "Train Epoch: 77 [720/1863 (39%)]\tLoss: 14.732058\n",
            "Train Epoch: 77 [840/1863 (45%)]\tLoss: 5.413136\n",
            "Train Epoch: 77 [960/1863 (51%)]\tLoss: 14.220072\n",
            "Train Epoch: 77 [1080/1863 (58%)]\tLoss: 6.543412\n",
            "Train Epoch: 77 [1200/1863 (64%)]\tLoss: 20.859770\n",
            "Train Epoch: 77 [1320/1863 (71%)]\tLoss: 26.392269\n",
            "Train Epoch: 77 [1440/1863 (77%)]\tLoss: 15.299006\n",
            "Train Epoch: 77 [1560/1863 (83%)]\tLoss: 8.840302\n",
            "Train Epoch: 77 [1680/1863 (90%)]\tLoss: 9.144482\n",
            "Train Epoch: 77 [1800/1863 (96%)]\tLoss: 11.541923\n",
            "Training Loss: 11.4456 Acc: 50.5099\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.7197, Accuracy: 722/1406 (51.351%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 78/200\n",
            "----------\n",
            "Train Epoch: 78 [0/1863 (0%)]\tLoss: 14.404993\n",
            "Train Epoch: 78 [120/1863 (6%)]\tLoss: 9.096437\n",
            "Train Epoch: 78 [240/1863 (13%)]\tLoss: 22.986841\n",
            "Train Epoch: 78 [360/1863 (19%)]\tLoss: 11.869816\n",
            "Train Epoch: 78 [480/1863 (26%)]\tLoss: 7.461664\n",
            "Train Epoch: 78 [600/1863 (32%)]\tLoss: 13.550305\n",
            "Train Epoch: 78 [720/1863 (39%)]\tLoss: 1.177075\n",
            "Train Epoch: 78 [840/1863 (45%)]\tLoss: 9.431381\n",
            "Train Epoch: 78 [960/1863 (51%)]\tLoss: 10.288932\n",
            "Train Epoch: 78 [1080/1863 (58%)]\tLoss: 19.938829\n",
            "Train Epoch: 78 [1200/1863 (64%)]\tLoss: 8.315838\n",
            "Train Epoch: 78 [1320/1863 (71%)]\tLoss: 0.815163\n",
            "Train Epoch: 78 [1440/1863 (77%)]\tLoss: 6.825920\n",
            "Train Epoch: 78 [1560/1863 (83%)]\tLoss: 4.909416\n",
            "Train Epoch: 78 [1680/1863 (90%)]\tLoss: 15.739879\n",
            "Train Epoch: 78 [1800/1863 (96%)]\tLoss: 10.328929\n",
            "Training Loss: 10.8996 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5680, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 79/200\n",
            "----------\n",
            "Train Epoch: 79 [0/1863 (0%)]\tLoss: 3.243114\n",
            "Train Epoch: 79 [120/1863 (6%)]\tLoss: 5.416224\n",
            "Train Epoch: 79 [240/1863 (13%)]\tLoss: 4.868945\n",
            "Train Epoch: 79 [360/1863 (19%)]\tLoss: 19.021463\n",
            "Train Epoch: 79 [480/1863 (26%)]\tLoss: 19.900206\n",
            "Train Epoch: 79 [600/1863 (32%)]\tLoss: 16.750002\n",
            "Train Epoch: 79 [720/1863 (39%)]\tLoss: 10.214604\n",
            "Train Epoch: 79 [840/1863 (45%)]\tLoss: 9.981233\n",
            "Train Epoch: 79 [960/1863 (51%)]\tLoss: 13.598532\n",
            "Train Epoch: 79 [1080/1863 (58%)]\tLoss: 2.237928\n",
            "Train Epoch: 79 [1200/1863 (64%)]\tLoss: 13.509584\n",
            "Train Epoch: 79 [1320/1863 (71%)]\tLoss: 25.818241\n",
            "Train Epoch: 79 [1440/1863 (77%)]\tLoss: 4.022824\n",
            "Train Epoch: 79 [1560/1863 (83%)]\tLoss: 17.490038\n",
            "Train Epoch: 79 [1680/1863 (90%)]\tLoss: 10.481192\n",
            "Train Epoch: 79 [1800/1863 (96%)]\tLoss: 0.255041\n",
            "Training Loss: 11.0399 Acc: 50.8320\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4215, Accuracy: 757/1406 (53.841%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 80/200\n",
            "----------\n",
            "Train Epoch: 80 [0/1863 (0%)]\tLoss: 10.375399\n",
            "Train Epoch: 80 [120/1863 (6%)]\tLoss: 9.925541\n",
            "Train Epoch: 80 [240/1863 (13%)]\tLoss: 8.985103\n",
            "Train Epoch: 80 [360/1863 (19%)]\tLoss: 1.403493\n",
            "Train Epoch: 80 [480/1863 (26%)]\tLoss: 19.324329\n",
            "Train Epoch: 80 [600/1863 (32%)]\tLoss: 15.154630\n",
            "Train Epoch: 80 [720/1863 (39%)]\tLoss: 38.568306\n",
            "Train Epoch: 80 [840/1863 (45%)]\tLoss: 16.547478\n",
            "Train Epoch: 80 [960/1863 (51%)]\tLoss: 5.767507\n",
            "Train Epoch: 80 [1080/1863 (58%)]\tLoss: 6.686971\n",
            "Train Epoch: 80 [1200/1863 (64%)]\tLoss: 14.601848\n",
            "Train Epoch: 80 [1320/1863 (71%)]\tLoss: 9.837221\n",
            "Train Epoch: 80 [1440/1863 (77%)]\tLoss: 11.299333\n",
            "Train Epoch: 80 [1560/1863 (83%)]\tLoss: 18.093157\n",
            "Train Epoch: 80 [1680/1863 (90%)]\tLoss: 29.974085\n",
            "Train Epoch: 80 [1800/1863 (96%)]\tLoss: 9.331938\n",
            "Training Loss: 11.4046 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4985, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 81/200\n",
            "----------\n",
            "Train Epoch: 81 [0/1863 (0%)]\tLoss: 5.099422\n",
            "Train Epoch: 81 [120/1863 (6%)]\tLoss: 7.131452\n",
            "Train Epoch: 81 [240/1863 (13%)]\tLoss: 10.303076\n",
            "Train Epoch: 81 [360/1863 (19%)]\tLoss: 5.063809\n",
            "Train Epoch: 81 [480/1863 (26%)]\tLoss: 7.531677\n",
            "Train Epoch: 81 [600/1863 (32%)]\tLoss: 10.173600\n",
            "Train Epoch: 81 [720/1863 (39%)]\tLoss: 18.188068\n",
            "Train Epoch: 81 [840/1863 (45%)]\tLoss: 9.797141\n",
            "Train Epoch: 81 [960/1863 (51%)]\tLoss: 14.850737\n",
            "Train Epoch: 81 [1080/1863 (58%)]\tLoss: 11.577957\n",
            "Train Epoch: 81 [1200/1863 (64%)]\tLoss: 11.881987\n",
            "Train Epoch: 81 [1320/1863 (71%)]\tLoss: 9.878852\n",
            "Train Epoch: 81 [1440/1863 (77%)]\tLoss: 11.043408\n",
            "Train Epoch: 81 [1560/1863 (83%)]\tLoss: 8.723211\n",
            "Train Epoch: 81 [1680/1863 (90%)]\tLoss: 0.902693\n",
            "Train Epoch: 81 [1800/1863 (96%)]\tLoss: 9.620768\n",
            "Training Loss: 10.9112 Acc: 51.4224\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3815, Accuracy: 888/1406 (63.158%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 82/200\n",
            "----------\n",
            "Train Epoch: 82 [0/1863 (0%)]\tLoss: 20.831587\n",
            "Train Epoch: 82 [120/1863 (6%)]\tLoss: 5.966283\n",
            "Train Epoch: 82 [240/1863 (13%)]\tLoss: 13.172826\n",
            "Train Epoch: 82 [360/1863 (19%)]\tLoss: 5.098346\n",
            "Train Epoch: 82 [480/1863 (26%)]\tLoss: 7.617260\n",
            "Train Epoch: 82 [600/1863 (32%)]\tLoss: 6.629127\n",
            "Train Epoch: 82 [720/1863 (39%)]\tLoss: 14.298307\n",
            "Train Epoch: 82 [840/1863 (45%)]\tLoss: 9.203682\n",
            "Train Epoch: 82 [960/1863 (51%)]\tLoss: 22.721186\n",
            "Train Epoch: 82 [1080/1863 (58%)]\tLoss: 11.132560\n",
            "Train Epoch: 82 [1200/1863 (64%)]\tLoss: 2.439597\n",
            "Train Epoch: 82 [1320/1863 (71%)]\tLoss: 8.708755\n",
            "Train Epoch: 82 [1440/1863 (77%)]\tLoss: 19.428040\n",
            "Train Epoch: 82 [1560/1863 (83%)]\tLoss: 10.929561\n",
            "Train Epoch: 82 [1680/1863 (90%)]\tLoss: 6.567164\n",
            "Train Epoch: 82 [1800/1863 (96%)]\tLoss: 2.489854\n",
            "Training Loss: 11.3975 Acc: 49.6511\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4911, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 83/200\n",
            "----------\n",
            "Train Epoch: 83 [0/1863 (0%)]\tLoss: 20.087360\n",
            "Train Epoch: 83 [120/1863 (6%)]\tLoss: 13.624741\n",
            "Train Epoch: 83 [240/1863 (13%)]\tLoss: 13.859204\n",
            "Train Epoch: 83 [360/1863 (19%)]\tLoss: 9.217529\n",
            "Train Epoch: 83 [480/1863 (26%)]\tLoss: 7.151562\n",
            "Train Epoch: 83 [600/1863 (32%)]\tLoss: 11.520227\n",
            "Train Epoch: 83 [720/1863 (39%)]\tLoss: 14.103746\n",
            "Train Epoch: 83 [840/1863 (45%)]\tLoss: 19.477839\n",
            "Train Epoch: 83 [960/1863 (51%)]\tLoss: 7.034727\n",
            "Train Epoch: 83 [1080/1863 (58%)]\tLoss: 4.999355\n",
            "Train Epoch: 83 [1200/1863 (64%)]\tLoss: 29.595886\n",
            "Train Epoch: 83 [1320/1863 (71%)]\tLoss: 6.255533\n",
            "Train Epoch: 83 [1440/1863 (77%)]\tLoss: 11.439065\n",
            "Train Epoch: 83 [1560/1863 (83%)]\tLoss: 3.136202\n",
            "Train Epoch: 83 [1680/1863 (90%)]\tLoss: 10.854359\n",
            "Train Epoch: 83 [1800/1863 (96%)]\tLoss: 14.835701\n",
            "Training Loss: 11.2700 Acc: 50.7783\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3574, Accuracy: 842/1406 (59.886%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 84/200\n",
            "----------\n",
            "Train Epoch: 84 [0/1863 (0%)]\tLoss: 8.955759\n",
            "Train Epoch: 84 [120/1863 (6%)]\tLoss: 9.419988\n",
            "Train Epoch: 84 [240/1863 (13%)]\tLoss: 11.812184\n",
            "Train Epoch: 84 [360/1863 (19%)]\tLoss: 16.837549\n",
            "Train Epoch: 84 [480/1863 (26%)]\tLoss: 7.722329\n",
            "Train Epoch: 84 [600/1863 (32%)]\tLoss: 4.134489\n",
            "Train Epoch: 84 [720/1863 (39%)]\tLoss: 8.032320\n",
            "Train Epoch: 84 [840/1863 (45%)]\tLoss: 14.123642\n",
            "Train Epoch: 84 [960/1863 (51%)]\tLoss: 14.949303\n",
            "Train Epoch: 84 [1080/1863 (58%)]\tLoss: 10.181089\n",
            "Train Epoch: 84 [1200/1863 (64%)]\tLoss: 12.436588\n",
            "Train Epoch: 84 [1320/1863 (71%)]\tLoss: 11.148433\n",
            "Train Epoch: 84 [1440/1863 (77%)]\tLoss: 9.203172\n",
            "Train Epoch: 84 [1560/1863 (83%)]\tLoss: 9.983450\n",
            "Train Epoch: 84 [1680/1863 (90%)]\tLoss: 19.377253\n",
            "Train Epoch: 84 [1800/1863 (96%)]\tLoss: 6.296663\n",
            "Training Loss: 11.3324 Acc: 50.0268\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5469, Accuracy: 706/1406 (50.213%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 85/200\n",
            "----------\n",
            "Train Epoch: 85 [0/1863 (0%)]\tLoss: 8.609243\n",
            "Train Epoch: 85 [120/1863 (6%)]\tLoss: 21.856342\n",
            "Train Epoch: 85 [240/1863 (13%)]\tLoss: 13.435926\n",
            "Train Epoch: 85 [360/1863 (19%)]\tLoss: 1.486713\n",
            "Train Epoch: 85 [480/1863 (26%)]\tLoss: 20.510979\n",
            "Train Epoch: 85 [600/1863 (32%)]\tLoss: 15.325389\n",
            "Train Epoch: 85 [720/1863 (39%)]\tLoss: 10.252887\n",
            "Train Epoch: 85 [840/1863 (45%)]\tLoss: 9.599253\n",
            "Train Epoch: 85 [960/1863 (51%)]\tLoss: 24.302773\n",
            "Train Epoch: 85 [1080/1863 (58%)]\tLoss: 17.934944\n",
            "Train Epoch: 85 [1200/1863 (64%)]\tLoss: 10.045835\n",
            "Train Epoch: 85 [1320/1863 (71%)]\tLoss: 20.170984\n",
            "Train Epoch: 85 [1440/1863 (77%)]\tLoss: 16.145672\n",
            "Train Epoch: 85 [1560/1863 (83%)]\tLoss: 6.364826\n",
            "Train Epoch: 85 [1680/1863 (90%)]\tLoss: 3.810091\n",
            "Train Epoch: 85 [1800/1863 (96%)]\tLoss: 3.756896\n",
            "Training Loss: 11.3554 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5981, Accuracy: 706/1406 (50.213%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 86/200\n",
            "----------\n",
            "Train Epoch: 86 [0/1863 (0%)]\tLoss: 7.131518\n",
            "Train Epoch: 86 [120/1863 (6%)]\tLoss: 22.243816\n",
            "Train Epoch: 86 [240/1863 (13%)]\tLoss: 26.353786\n",
            "Train Epoch: 86 [360/1863 (19%)]\tLoss: 16.958096\n",
            "Train Epoch: 86 [480/1863 (26%)]\tLoss: 25.347033\n",
            "Train Epoch: 86 [600/1863 (32%)]\tLoss: 0.448479\n",
            "Train Epoch: 86 [720/1863 (39%)]\tLoss: 3.444976\n",
            "Train Epoch: 86 [840/1863 (45%)]\tLoss: 9.842218\n",
            "Train Epoch: 86 [960/1863 (51%)]\tLoss: 23.871929\n",
            "Train Epoch: 86 [1080/1863 (58%)]\tLoss: 6.779452\n",
            "Train Epoch: 86 [1200/1863 (64%)]\tLoss: 8.903173\n",
            "Train Epoch: 86 [1320/1863 (71%)]\tLoss: 10.346714\n",
            "Train Epoch: 86 [1440/1863 (77%)]\tLoss: 8.500690\n",
            "Train Epoch: 86 [1560/1863 (83%)]\tLoss: 25.135548\n",
            "Train Epoch: 86 [1680/1863 (90%)]\tLoss: 16.265141\n",
            "Train Epoch: 86 [1800/1863 (96%)]\tLoss: 15.140312\n",
            "Training Loss: 11.1636 Acc: 50.4563\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5743, Accuracy: 740/1406 (52.632%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 87/200\n",
            "----------\n",
            "Train Epoch: 87 [0/1863 (0%)]\tLoss: 12.835851\n",
            "Train Epoch: 87 [120/1863 (6%)]\tLoss: 10.052208\n",
            "Train Epoch: 87 [240/1863 (13%)]\tLoss: 3.420879\n",
            "Train Epoch: 87 [360/1863 (19%)]\tLoss: 5.125163\n",
            "Train Epoch: 87 [480/1863 (26%)]\tLoss: 24.380980\n",
            "Train Epoch: 87 [600/1863 (32%)]\tLoss: 7.573279\n",
            "Train Epoch: 87 [720/1863 (39%)]\tLoss: 11.542908\n",
            "Train Epoch: 87 [840/1863 (45%)]\tLoss: 20.827866\n",
            "Train Epoch: 87 [960/1863 (51%)]\tLoss: 1.978034\n",
            "Train Epoch: 87 [1080/1863 (58%)]\tLoss: 15.258795\n",
            "Train Epoch: 87 [1200/1863 (64%)]\tLoss: 14.970363\n",
            "Train Epoch: 87 [1320/1863 (71%)]\tLoss: 6.978402\n",
            "Train Epoch: 87 [1440/1863 (77%)]\tLoss: 16.532894\n",
            "Train Epoch: 87 [1560/1863 (83%)]\tLoss: 4.423357\n",
            "Train Epoch: 87 [1680/1863 (90%)]\tLoss: 6.478970\n",
            "Train Epoch: 87 [1800/1863 (96%)]\tLoss: 13.397588\n",
            "Training Loss: 11.3486 Acc: 50.1879\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5967, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 88/200\n",
            "----------\n",
            "Train Epoch: 88 [0/1863 (0%)]\tLoss: 6.322161\n",
            "Train Epoch: 88 [120/1863 (6%)]\tLoss: 18.064280\n",
            "Train Epoch: 88 [240/1863 (13%)]\tLoss: 6.003726\n",
            "Train Epoch: 88 [360/1863 (19%)]\tLoss: 11.465059\n",
            "Train Epoch: 88 [480/1863 (26%)]\tLoss: 2.213944\n",
            "Train Epoch: 88 [600/1863 (32%)]\tLoss: 20.707310\n",
            "Train Epoch: 88 [720/1863 (39%)]\tLoss: 7.849314\n",
            "Train Epoch: 88 [840/1863 (45%)]\tLoss: 8.974403\n",
            "Train Epoch: 88 [960/1863 (51%)]\tLoss: 8.711248\n",
            "Train Epoch: 88 [1080/1863 (58%)]\tLoss: 10.160120\n",
            "Train Epoch: 88 [1200/1863 (64%)]\tLoss: 1.815796\n",
            "Train Epoch: 88 [1320/1863 (71%)]\tLoss: 23.467468\n",
            "Train Epoch: 88 [1440/1863 (77%)]\tLoss: 14.004552\n",
            "Train Epoch: 88 [1560/1863 (83%)]\tLoss: 15.679552\n",
            "Train Epoch: 88 [1680/1863 (90%)]\tLoss: 23.253611\n",
            "Train Epoch: 88 [1800/1863 (96%)]\tLoss: 5.292872\n",
            "Training Loss: 10.8573 Acc: 50.1879\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6448, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 89/200\n",
            "----------\n",
            "Train Epoch: 89 [0/1863 (0%)]\tLoss: 18.787420\n",
            "Train Epoch: 89 [120/1863 (6%)]\tLoss: 12.999193\n",
            "Train Epoch: 89 [240/1863 (13%)]\tLoss: 2.558754\n",
            "Train Epoch: 89 [360/1863 (19%)]\tLoss: 8.186483\n",
            "Train Epoch: 89 [480/1863 (26%)]\tLoss: 15.038320\n",
            "Train Epoch: 89 [600/1863 (32%)]\tLoss: 7.811893\n",
            "Train Epoch: 89 [720/1863 (39%)]\tLoss: 12.261643\n",
            "Train Epoch: 89 [840/1863 (45%)]\tLoss: 10.362138\n",
            "Train Epoch: 89 [960/1863 (51%)]\tLoss: 9.864589\n",
            "Train Epoch: 89 [1080/1863 (58%)]\tLoss: 19.571140\n",
            "Train Epoch: 89 [1200/1863 (64%)]\tLoss: 9.551103\n",
            "Train Epoch: 89 [1320/1863 (71%)]\tLoss: 7.683773\n",
            "Train Epoch: 89 [1440/1863 (77%)]\tLoss: 16.399279\n",
            "Train Epoch: 89 [1560/1863 (83%)]\tLoss: 13.168627\n",
            "Train Epoch: 89 [1680/1863 (90%)]\tLoss: 6.724738\n",
            "Train Epoch: 89 [1800/1863 (96%)]\tLoss: 11.320351\n",
            "Training Loss: 11.0592 Acc: 51.4224\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5764, Accuracy: 738/1406 (52.489%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 90/200\n",
            "----------\n",
            "Train Epoch: 90 [0/1863 (0%)]\tLoss: 22.174599\n",
            "Train Epoch: 90 [120/1863 (6%)]\tLoss: 6.527276\n",
            "Train Epoch: 90 [240/1863 (13%)]\tLoss: 14.636663\n",
            "Train Epoch: 90 [360/1863 (19%)]\tLoss: 22.429846\n",
            "Train Epoch: 90 [480/1863 (26%)]\tLoss: 15.463997\n",
            "Train Epoch: 90 [600/1863 (32%)]\tLoss: 3.488265\n",
            "Train Epoch: 90 [720/1863 (39%)]\tLoss: 12.666362\n",
            "Train Epoch: 90 [840/1863 (45%)]\tLoss: 14.941170\n",
            "Train Epoch: 90 [960/1863 (51%)]\tLoss: 7.839165\n",
            "Train Epoch: 90 [1080/1863 (58%)]\tLoss: 11.703505\n",
            "Train Epoch: 90 [1200/1863 (64%)]\tLoss: 10.216508\n",
            "Train Epoch: 90 [1320/1863 (71%)]\tLoss: 8.757990\n",
            "Train Epoch: 90 [1440/1863 (77%)]\tLoss: 6.718909\n",
            "Train Epoch: 90 [1560/1863 (83%)]\tLoss: 9.912471\n",
            "Train Epoch: 90 [1680/1863 (90%)]\tLoss: 12.394481\n",
            "Train Epoch: 90 [1800/1863 (96%)]\tLoss: 2.870852\n",
            "Training Loss: 11.5323 Acc: 50.2952\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3467, Accuracy: 718/1406 (51.067%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 91/200\n",
            "----------\n",
            "Train Epoch: 91 [0/1863 (0%)]\tLoss: 11.130166\n",
            "Train Epoch: 91 [120/1863 (6%)]\tLoss: 4.908770\n",
            "Train Epoch: 91 [240/1863 (13%)]\tLoss: 7.008561\n",
            "Train Epoch: 91 [360/1863 (19%)]\tLoss: 22.330851\n",
            "Train Epoch: 91 [480/1863 (26%)]\tLoss: 4.964579\n",
            "Train Epoch: 91 [600/1863 (32%)]\tLoss: 6.279633\n",
            "Train Epoch: 91 [720/1863 (39%)]\tLoss: 21.047123\n",
            "Train Epoch: 91 [840/1863 (45%)]\tLoss: 6.719636\n",
            "Train Epoch: 91 [960/1863 (51%)]\tLoss: 5.293248\n",
            "Train Epoch: 91 [1080/1863 (58%)]\tLoss: 21.119753\n",
            "Train Epoch: 91 [1200/1863 (64%)]\tLoss: 5.864224\n",
            "Train Epoch: 91 [1320/1863 (71%)]\tLoss: 10.703387\n",
            "Train Epoch: 91 [1440/1863 (77%)]\tLoss: 17.049103\n",
            "Train Epoch: 91 [1560/1863 (83%)]\tLoss: 15.587260\n",
            "Train Epoch: 91 [1680/1863 (90%)]\tLoss: 15.876012\n",
            "Train Epoch: 91 [1800/1863 (96%)]\tLoss: 6.307653\n",
            "Training Loss: 10.7320 Acc: 51.0467\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4582, Accuracy: 729/1406 (51.849%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 92/200\n",
            "----------\n",
            "Train Epoch: 92 [0/1863 (0%)]\tLoss: 19.845379\n",
            "Train Epoch: 92 [120/1863 (6%)]\tLoss: 7.636699\n",
            "Train Epoch: 92 [240/1863 (13%)]\tLoss: 19.453360\n",
            "Train Epoch: 92 [360/1863 (19%)]\tLoss: 8.782358\n",
            "Train Epoch: 92 [480/1863 (26%)]\tLoss: 6.089912\n",
            "Train Epoch: 92 [600/1863 (32%)]\tLoss: 24.057932\n",
            "Train Epoch: 92 [720/1863 (39%)]\tLoss: 13.261251\n",
            "Train Epoch: 92 [840/1863 (45%)]\tLoss: 15.760462\n",
            "Train Epoch: 92 [960/1863 (51%)]\tLoss: 3.692953\n",
            "Train Epoch: 92 [1080/1863 (58%)]\tLoss: 7.194327\n",
            "Train Epoch: 92 [1200/1863 (64%)]\tLoss: 9.755355\n",
            "Train Epoch: 92 [1320/1863 (71%)]\tLoss: 6.098608\n",
            "Train Epoch: 92 [1440/1863 (77%)]\tLoss: 6.151099\n",
            "Train Epoch: 92 [1560/1863 (83%)]\tLoss: 9.205882\n",
            "Train Epoch: 92 [1680/1863 (90%)]\tLoss: 12.820704\n",
            "Train Epoch: 92 [1800/1863 (96%)]\tLoss: 10.067435\n",
            "Training Loss: 11.3887 Acc: 50.5636\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5315, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 93/200\n",
            "----------\n",
            "Train Epoch: 93 [0/1863 (0%)]\tLoss: 6.516485\n",
            "Train Epoch: 93 [120/1863 (6%)]\tLoss: 17.598391\n",
            "Train Epoch: 93 [240/1863 (13%)]\tLoss: 10.941699\n",
            "Train Epoch: 93 [360/1863 (19%)]\tLoss: 20.637640\n",
            "Train Epoch: 93 [480/1863 (26%)]\tLoss: 6.801198\n",
            "Train Epoch: 93 [600/1863 (32%)]\tLoss: 11.997465\n",
            "Train Epoch: 93 [720/1863 (39%)]\tLoss: 7.243536\n",
            "Train Epoch: 93 [840/1863 (45%)]\tLoss: 15.101801\n",
            "Train Epoch: 93 [960/1863 (51%)]\tLoss: 14.925570\n",
            "Train Epoch: 93 [1080/1863 (58%)]\tLoss: 11.915358\n",
            "Train Epoch: 93 [1200/1863 (64%)]\tLoss: 8.913165\n",
            "Train Epoch: 93 [1320/1863 (71%)]\tLoss: 22.489517\n",
            "Train Epoch: 93 [1440/1863 (77%)]\tLoss: 6.241735\n",
            "Train Epoch: 93 [1560/1863 (83%)]\tLoss: 10.090443\n",
            "Train Epoch: 93 [1680/1863 (90%)]\tLoss: 8.596265\n",
            "Train Epoch: 93 [1800/1863 (96%)]\tLoss: 7.244408\n",
            "Training Loss: 11.1373 Acc: 49.9732\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4638, Accuracy: 726/1406 (51.636%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 94/200\n",
            "----------\n",
            "Train Epoch: 94 [0/1863 (0%)]\tLoss: 5.852290\n",
            "Train Epoch: 94 [120/1863 (6%)]\tLoss: 8.436209\n",
            "Train Epoch: 94 [240/1863 (13%)]\tLoss: 15.389674\n",
            "Train Epoch: 94 [360/1863 (19%)]\tLoss: 12.965854\n",
            "Train Epoch: 94 [480/1863 (26%)]\tLoss: 10.022497\n",
            "Train Epoch: 94 [600/1863 (32%)]\tLoss: 10.080104\n",
            "Train Epoch: 94 [720/1863 (39%)]\tLoss: 4.023216\n",
            "Train Epoch: 94 [840/1863 (45%)]\tLoss: 12.706030\n",
            "Train Epoch: 94 [960/1863 (51%)]\tLoss: 3.001320\n",
            "Train Epoch: 94 [1080/1863 (58%)]\tLoss: 6.957428\n",
            "Train Epoch: 94 [1200/1863 (64%)]\tLoss: 8.771815\n",
            "Train Epoch: 94 [1320/1863 (71%)]\tLoss: 14.611526\n",
            "Train Epoch: 94 [1440/1863 (77%)]\tLoss: 21.892376\n",
            "Train Epoch: 94 [1560/1863 (83%)]\tLoss: 11.503365\n",
            "Train Epoch: 94 [1680/1863 (90%)]\tLoss: 16.491112\n",
            "Train Epoch: 94 [1800/1863 (96%)]\tLoss: 13.191057\n",
            "Training Loss: 11.0301 Acc: 50.7783\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3972, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 95/200\n",
            "----------\n",
            "Train Epoch: 95 [0/1863 (0%)]\tLoss: 16.044102\n",
            "Train Epoch: 95 [120/1863 (6%)]\tLoss: 24.169643\n",
            "Train Epoch: 95 [240/1863 (13%)]\tLoss: 19.248676\n",
            "Train Epoch: 95 [360/1863 (19%)]\tLoss: 8.816875\n",
            "Train Epoch: 95 [480/1863 (26%)]\tLoss: 17.392879\n",
            "Train Epoch: 95 [600/1863 (32%)]\tLoss: 1.330634\n",
            "Train Epoch: 95 [720/1863 (39%)]\tLoss: 9.907398\n",
            "Train Epoch: 95 [840/1863 (45%)]\tLoss: 13.457730\n",
            "Train Epoch: 95 [960/1863 (51%)]\tLoss: 5.823003\n",
            "Train Epoch: 95 [1080/1863 (58%)]\tLoss: 12.674219\n",
            "Train Epoch: 95 [1200/1863 (64%)]\tLoss: 15.392896\n",
            "Train Epoch: 95 [1320/1863 (71%)]\tLoss: 3.700080\n",
            "Train Epoch: 95 [1440/1863 (77%)]\tLoss: 12.759236\n",
            "Train Epoch: 95 [1560/1863 (83%)]\tLoss: 2.710247\n",
            "Train Epoch: 95 [1680/1863 (90%)]\tLoss: 24.879442\n",
            "Train Epoch: 95 [1800/1863 (96%)]\tLoss: 9.982725\n",
            "Training Loss: 11.1800 Acc: 50.2415\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6482, Accuracy: 720/1406 (51.209%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 96/200\n",
            "----------\n",
            "Train Epoch: 96 [0/1863 (0%)]\tLoss: 14.148547\n",
            "Train Epoch: 96 [120/1863 (6%)]\tLoss: 9.609972\n",
            "Train Epoch: 96 [240/1863 (13%)]\tLoss: 6.847201\n",
            "Train Epoch: 96 [360/1863 (19%)]\tLoss: 12.315896\n",
            "Train Epoch: 96 [480/1863 (26%)]\tLoss: 10.379514\n",
            "Train Epoch: 96 [600/1863 (32%)]\tLoss: 8.016016\n",
            "Train Epoch: 96 [720/1863 (39%)]\tLoss: 12.819664\n",
            "Train Epoch: 96 [840/1863 (45%)]\tLoss: 7.020066\n",
            "Train Epoch: 96 [960/1863 (51%)]\tLoss: 19.790054\n",
            "Train Epoch: 96 [1080/1863 (58%)]\tLoss: 9.031916\n",
            "Train Epoch: 96 [1200/1863 (64%)]\tLoss: 4.200572\n",
            "Train Epoch: 96 [1320/1863 (71%)]\tLoss: 19.706797\n",
            "Train Epoch: 96 [1440/1863 (77%)]\tLoss: 16.089411\n",
            "Train Epoch: 96 [1560/1863 (83%)]\tLoss: 2.499047\n",
            "Train Epoch: 96 [1680/1863 (90%)]\tLoss: 21.460966\n",
            "Train Epoch: 96 [1800/1863 (96%)]\tLoss: 9.853670\n",
            "Training Loss: 11.2462 Acc: 51.1541\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4573, Accuracy: 731/1406 (51.991%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 97/200\n",
            "----------\n",
            "Train Epoch: 97 [0/1863 (0%)]\tLoss: 12.817244\n",
            "Train Epoch: 97 [120/1863 (6%)]\tLoss: 13.237549\n",
            "Train Epoch: 97 [240/1863 (13%)]\tLoss: 15.322884\n",
            "Train Epoch: 97 [360/1863 (19%)]\tLoss: 8.196295\n",
            "Train Epoch: 97 [480/1863 (26%)]\tLoss: 1.094340\n",
            "Train Epoch: 97 [600/1863 (32%)]\tLoss: 5.553899\n",
            "Train Epoch: 97 [720/1863 (39%)]\tLoss: 19.283947\n",
            "Train Epoch: 97 [840/1863 (45%)]\tLoss: 7.836787\n",
            "Train Epoch: 97 [960/1863 (51%)]\tLoss: 9.968907\n",
            "Train Epoch: 97 [1080/1863 (58%)]\tLoss: 4.107347\n",
            "Train Epoch: 97 [1200/1863 (64%)]\tLoss: 13.202272\n",
            "Train Epoch: 97 [1320/1863 (71%)]\tLoss: 6.453417\n",
            "Train Epoch: 97 [1440/1863 (77%)]\tLoss: 6.407380\n",
            "Train Epoch: 97 [1560/1863 (83%)]\tLoss: 8.142183\n",
            "Train Epoch: 97 [1680/1863 (90%)]\tLoss: 12.604672\n",
            "Train Epoch: 97 [1800/1863 (96%)]\tLoss: 13.998587\n",
            "Training Loss: 10.9662 Acc: 51.3151\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5157, Accuracy: 714/1406 (50.782%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 98/200\n",
            "----------\n",
            "Train Epoch: 98 [0/1863 (0%)]\tLoss: 7.296594\n",
            "Train Epoch: 98 [120/1863 (6%)]\tLoss: 5.814596\n",
            "Train Epoch: 98 [240/1863 (13%)]\tLoss: 10.965820\n",
            "Train Epoch: 98 [360/1863 (19%)]\tLoss: 9.980498\n",
            "Train Epoch: 98 [480/1863 (26%)]\tLoss: 14.219708\n",
            "Train Epoch: 98 [600/1863 (32%)]\tLoss: 7.430340\n",
            "Train Epoch: 98 [720/1863 (39%)]\tLoss: 11.873265\n",
            "Train Epoch: 98 [840/1863 (45%)]\tLoss: 5.456940\n",
            "Train Epoch: 98 [960/1863 (51%)]\tLoss: 3.538221\n",
            "Train Epoch: 98 [1080/1863 (58%)]\tLoss: 8.945848\n",
            "Train Epoch: 98 [1200/1863 (64%)]\tLoss: 20.993876\n",
            "Train Epoch: 98 [1320/1863 (71%)]\tLoss: 22.164700\n",
            "Train Epoch: 98 [1440/1863 (77%)]\tLoss: 12.435352\n",
            "Train Epoch: 98 [1560/1863 (83%)]\tLoss: 3.978721\n",
            "Train Epoch: 98 [1680/1863 (90%)]\tLoss: 17.384247\n",
            "Train Epoch: 98 [1800/1863 (96%)]\tLoss: 15.586264\n",
            "Training Loss: 11.2754 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5814, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 99/200\n",
            "----------\n",
            "Train Epoch: 99 [0/1863 (0%)]\tLoss: 15.068561\n",
            "Train Epoch: 99 [120/1863 (6%)]\tLoss: 7.076137\n",
            "Train Epoch: 99 [240/1863 (13%)]\tLoss: 7.918809\n",
            "Train Epoch: 99 [360/1863 (19%)]\tLoss: 6.250103\n",
            "Train Epoch: 99 [480/1863 (26%)]\tLoss: 4.265858\n",
            "Train Epoch: 99 [600/1863 (32%)]\tLoss: 11.888244\n",
            "Train Epoch: 99 [720/1863 (39%)]\tLoss: 13.144383\n",
            "Train Epoch: 99 [840/1863 (45%)]\tLoss: 15.268396\n",
            "Train Epoch: 99 [960/1863 (51%)]\tLoss: 18.056215\n",
            "Train Epoch: 99 [1080/1863 (58%)]\tLoss: 21.097460\n",
            "Train Epoch: 99 [1200/1863 (64%)]\tLoss: 13.618876\n",
            "Train Epoch: 99 [1320/1863 (71%)]\tLoss: 14.076436\n",
            "Train Epoch: 99 [1440/1863 (77%)]\tLoss: 15.012522\n",
            "Train Epoch: 99 [1560/1863 (83%)]\tLoss: 5.531066\n",
            "Train Epoch: 99 [1680/1863 (90%)]\tLoss: 4.731791\n",
            "Train Epoch: 99 [1800/1863 (96%)]\tLoss: 5.346021\n",
            "Training Loss: 11.4010 Acc: 50.4026\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5058, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 100/200\n",
            "----------\n",
            "Train Epoch: 100 [0/1863 (0%)]\tLoss: 18.804672\n",
            "Train Epoch: 100 [120/1863 (6%)]\tLoss: 12.637156\n",
            "Train Epoch: 100 [240/1863 (13%)]\tLoss: 6.765434\n",
            "Train Epoch: 100 [360/1863 (19%)]\tLoss: 9.795236\n",
            "Train Epoch: 100 [480/1863 (26%)]\tLoss: 5.804283\n",
            "Train Epoch: 100 [600/1863 (32%)]\tLoss: 4.412355\n",
            "Train Epoch: 100 [720/1863 (39%)]\tLoss: 5.556782\n",
            "Train Epoch: 100 [840/1863 (45%)]\tLoss: 20.286871\n",
            "Train Epoch: 100 [960/1863 (51%)]\tLoss: 7.629776\n",
            "Train Epoch: 100 [1080/1863 (58%)]\tLoss: 29.172525\n",
            "Train Epoch: 100 [1200/1863 (64%)]\tLoss: 23.270243\n",
            "Train Epoch: 100 [1320/1863 (71%)]\tLoss: 14.102224\n",
            "Train Epoch: 100 [1440/1863 (77%)]\tLoss: 6.395028\n",
            "Train Epoch: 100 [1560/1863 (83%)]\tLoss: 14.173758\n",
            "Train Epoch: 100 [1680/1863 (90%)]\tLoss: 3.957397\n",
            "Train Epoch: 100 [1800/1863 (96%)]\tLoss: 16.294096\n",
            "Training Loss: 11.1235 Acc: 51.0467\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3897, Accuracy: 704/1406 (50.071%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 101/200\n",
            "----------\n",
            "Train Epoch: 101 [0/1863 (0%)]\tLoss: 7.959099\n",
            "Train Epoch: 101 [120/1863 (6%)]\tLoss: 3.958636\n",
            "Train Epoch: 101 [240/1863 (13%)]\tLoss: 7.302197\n",
            "Train Epoch: 101 [360/1863 (19%)]\tLoss: 18.510538\n",
            "Train Epoch: 101 [480/1863 (26%)]\tLoss: 13.410748\n",
            "Train Epoch: 101 [600/1863 (32%)]\tLoss: 11.400259\n",
            "Train Epoch: 101 [720/1863 (39%)]\tLoss: 17.194038\n",
            "Train Epoch: 101 [840/1863 (45%)]\tLoss: 20.560118\n",
            "Train Epoch: 101 [960/1863 (51%)]\tLoss: 12.582655\n",
            "Train Epoch: 101 [1080/1863 (58%)]\tLoss: 6.817253\n",
            "Train Epoch: 101 [1200/1863 (64%)]\tLoss: 13.789808\n",
            "Train Epoch: 101 [1320/1863 (71%)]\tLoss: 21.970507\n",
            "Train Epoch: 101 [1440/1863 (77%)]\tLoss: 6.197512\n",
            "Train Epoch: 101 [1560/1863 (83%)]\tLoss: 5.095339\n",
            "Train Epoch: 101 [1680/1863 (90%)]\tLoss: 8.822320\n",
            "Train Epoch: 101 [1800/1863 (96%)]\tLoss: 17.509176\n",
            "Training Loss: 11.0722 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4860, Accuracy: 720/1406 (51.209%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 102/200\n",
            "----------\n",
            "Train Epoch: 102 [0/1863 (0%)]\tLoss: 4.561312\n",
            "Train Epoch: 102 [120/1863 (6%)]\tLoss: 13.836598\n",
            "Train Epoch: 102 [240/1863 (13%)]\tLoss: 3.232268\n",
            "Train Epoch: 102 [360/1863 (19%)]\tLoss: 21.225830\n",
            "Train Epoch: 102 [480/1863 (26%)]\tLoss: 7.973066\n",
            "Train Epoch: 102 [600/1863 (32%)]\tLoss: 5.952755\n",
            "Train Epoch: 102 [720/1863 (39%)]\tLoss: 28.261501\n",
            "Train Epoch: 102 [840/1863 (45%)]\tLoss: 4.785834\n",
            "Train Epoch: 102 [960/1863 (51%)]\tLoss: 15.878740\n",
            "Train Epoch: 102 [1080/1863 (58%)]\tLoss: 4.993611\n",
            "Train Epoch: 102 [1200/1863 (64%)]\tLoss: 11.032512\n",
            "Train Epoch: 102 [1320/1863 (71%)]\tLoss: 15.008402\n",
            "Train Epoch: 102 [1440/1863 (77%)]\tLoss: 5.659453\n",
            "Train Epoch: 102 [1560/1863 (83%)]\tLoss: 10.741749\n",
            "Train Epoch: 102 [1680/1863 (90%)]\tLoss: 9.284447\n",
            "Train Epoch: 102 [1800/1863 (96%)]\tLoss: 10.749249\n",
            "Training Loss: 11.5097 Acc: 50.9393\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4385, Accuracy: 728/1406 (51.778%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 103/200\n",
            "----------\n",
            "Train Epoch: 103 [0/1863 (0%)]\tLoss: 3.664188\n",
            "Train Epoch: 103 [120/1863 (6%)]\tLoss: 10.011592\n",
            "Train Epoch: 103 [240/1863 (13%)]\tLoss: 9.732004\n",
            "Train Epoch: 103 [360/1863 (19%)]\tLoss: 12.693647\n",
            "Train Epoch: 103 [480/1863 (26%)]\tLoss: 7.054967\n",
            "Train Epoch: 103 [600/1863 (32%)]\tLoss: 14.303415\n",
            "Train Epoch: 103 [720/1863 (39%)]\tLoss: 22.537851\n",
            "Train Epoch: 103 [840/1863 (45%)]\tLoss: 17.521648\n",
            "Train Epoch: 103 [960/1863 (51%)]\tLoss: 8.757810\n",
            "Train Epoch: 103 [1080/1863 (58%)]\tLoss: 6.768982\n",
            "Train Epoch: 103 [1200/1863 (64%)]\tLoss: 13.037872\n",
            "Train Epoch: 103 [1320/1863 (71%)]\tLoss: 20.065639\n",
            "Train Epoch: 103 [1440/1863 (77%)]\tLoss: 4.923409\n",
            "Train Epoch: 103 [1560/1863 (83%)]\tLoss: 3.588521\n",
            "Train Epoch: 103 [1680/1863 (90%)]\tLoss: 7.267213\n",
            "Train Epoch: 103 [1800/1863 (96%)]\tLoss: 18.632010\n",
            "Training Loss: 11.0571 Acc: 50.0268\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4596, Accuracy: 726/1406 (51.636%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 104/200\n",
            "----------\n",
            "Train Epoch: 104 [0/1863 (0%)]\tLoss: 22.058035\n",
            "Train Epoch: 104 [120/1863 (6%)]\tLoss: 4.439047\n",
            "Train Epoch: 104 [240/1863 (13%)]\tLoss: 11.063006\n",
            "Train Epoch: 104 [360/1863 (19%)]\tLoss: 12.914778\n",
            "Train Epoch: 104 [480/1863 (26%)]\tLoss: 10.627301\n",
            "Train Epoch: 104 [600/1863 (32%)]\tLoss: 21.481810\n",
            "Train Epoch: 104 [720/1863 (39%)]\tLoss: 6.201169\n",
            "Train Epoch: 104 [840/1863 (45%)]\tLoss: 14.870989\n",
            "Train Epoch: 104 [960/1863 (51%)]\tLoss: 9.467093\n",
            "Train Epoch: 104 [1080/1863 (58%)]\tLoss: 1.995595\n",
            "Train Epoch: 104 [1200/1863 (64%)]\tLoss: 13.907329\n",
            "Train Epoch: 104 [1320/1863 (71%)]\tLoss: 15.263133\n",
            "Train Epoch: 104 [1440/1863 (77%)]\tLoss: 16.366447\n",
            "Train Epoch: 104 [1560/1863 (83%)]\tLoss: 1.962415\n",
            "Train Epoch: 104 [1680/1863 (90%)]\tLoss: 10.572382\n",
            "Train Epoch: 104 [1800/1863 (96%)]\tLoss: 11.326877\n",
            "Training Loss: 11.1356 Acc: 51.1004\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4716, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 105/200\n",
            "----------\n",
            "Train Epoch: 105 [0/1863 (0%)]\tLoss: 13.757301\n",
            "Train Epoch: 105 [120/1863 (6%)]\tLoss: 6.721796\n",
            "Train Epoch: 105 [240/1863 (13%)]\tLoss: 11.369131\n",
            "Train Epoch: 105 [360/1863 (19%)]\tLoss: 21.754990\n",
            "Train Epoch: 105 [480/1863 (26%)]\tLoss: 8.390051\n",
            "Train Epoch: 105 [600/1863 (32%)]\tLoss: 7.213853\n",
            "Train Epoch: 105 [720/1863 (39%)]\tLoss: 2.929467\n",
            "Train Epoch: 105 [840/1863 (45%)]\tLoss: 18.070597\n",
            "Train Epoch: 105 [960/1863 (51%)]\tLoss: 23.782333\n",
            "Train Epoch: 105 [1080/1863 (58%)]\tLoss: 11.147943\n",
            "Train Epoch: 105 [1200/1863 (64%)]\tLoss: 3.532888\n",
            "Train Epoch: 105 [1320/1863 (71%)]\tLoss: 14.057101\n",
            "Train Epoch: 105 [1440/1863 (77%)]\tLoss: 9.110445\n",
            "Train Epoch: 105 [1560/1863 (83%)]\tLoss: 7.657343\n",
            "Train Epoch: 105 [1680/1863 (90%)]\tLoss: 19.753506\n",
            "Train Epoch: 105 [1800/1863 (96%)]\tLoss: 3.701542\n",
            "Training Loss: 11.1016 Acc: 51.2614\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3867, Accuracy: 715/1406 (50.853%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 106/200\n",
            "----------\n",
            "Train Epoch: 106 [0/1863 (0%)]\tLoss: 21.066381\n",
            "Train Epoch: 106 [120/1863 (6%)]\tLoss: 5.908721\n",
            "Train Epoch: 106 [240/1863 (13%)]\tLoss: 10.052291\n",
            "Train Epoch: 106 [360/1863 (19%)]\tLoss: 9.981062\n",
            "Train Epoch: 106 [480/1863 (26%)]\tLoss: 6.261421\n",
            "Train Epoch: 106 [600/1863 (32%)]\tLoss: 7.322142\n",
            "Train Epoch: 106 [720/1863 (39%)]\tLoss: 7.706607\n",
            "Train Epoch: 106 [840/1863 (45%)]\tLoss: 3.427809\n",
            "Train Epoch: 106 [960/1863 (51%)]\tLoss: 10.545328\n",
            "Train Epoch: 106 [1080/1863 (58%)]\tLoss: 8.097533\n",
            "Train Epoch: 106 [1200/1863 (64%)]\tLoss: 7.177613\n",
            "Train Epoch: 106 [1320/1863 (71%)]\tLoss: 8.267597\n",
            "Train Epoch: 106 [1440/1863 (77%)]\tLoss: 15.483419\n",
            "Train Epoch: 106 [1560/1863 (83%)]\tLoss: 11.477968\n",
            "Train Epoch: 106 [1680/1863 (90%)]\tLoss: 5.660501\n",
            "Train Epoch: 106 [1800/1863 (96%)]\tLoss: 4.815967\n",
            "Training Loss: 11.2122 Acc: 49.9732\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4099, Accuracy: 764/1406 (54.339%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 107/200\n",
            "----------\n",
            "Train Epoch: 107 [0/1863 (0%)]\tLoss: 12.827789\n",
            "Train Epoch: 107 [120/1863 (6%)]\tLoss: 1.670792\n",
            "Train Epoch: 107 [240/1863 (13%)]\tLoss: 12.976858\n",
            "Train Epoch: 107 [360/1863 (19%)]\tLoss: 12.526482\n",
            "Train Epoch: 107 [480/1863 (26%)]\tLoss: 15.434047\n",
            "Train Epoch: 107 [600/1863 (32%)]\tLoss: 3.072514\n",
            "Train Epoch: 107 [720/1863 (39%)]\tLoss: 5.106214\n",
            "Train Epoch: 107 [840/1863 (45%)]\tLoss: 3.472762\n",
            "Train Epoch: 107 [960/1863 (51%)]\tLoss: 10.285968\n",
            "Train Epoch: 107 [1080/1863 (58%)]\tLoss: 17.902246\n",
            "Train Epoch: 107 [1200/1863 (64%)]\tLoss: 9.285154\n",
            "Train Epoch: 107 [1320/1863 (71%)]\tLoss: 13.532407\n",
            "Train Epoch: 107 [1440/1863 (77%)]\tLoss: 22.616104\n",
            "Train Epoch: 107 [1560/1863 (83%)]\tLoss: 9.351308\n",
            "Train Epoch: 107 [1680/1863 (90%)]\tLoss: 11.886626\n",
            "Train Epoch: 107 [1800/1863 (96%)]\tLoss: 12.454111\n",
            "Training Loss: 11.3891 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5072, Accuracy: 706/1406 (50.213%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 108/200\n",
            "----------\n",
            "Train Epoch: 108 [0/1863 (0%)]\tLoss: 8.726108\n",
            "Train Epoch: 108 [120/1863 (6%)]\tLoss: 14.362615\n",
            "Train Epoch: 108 [240/1863 (13%)]\tLoss: 9.900779\n",
            "Train Epoch: 108 [360/1863 (19%)]\tLoss: 11.978258\n",
            "Train Epoch: 108 [480/1863 (26%)]\tLoss: 16.918911\n",
            "Train Epoch: 108 [600/1863 (32%)]\tLoss: 14.732641\n",
            "Train Epoch: 108 [720/1863 (39%)]\tLoss: 9.153247\n",
            "Train Epoch: 108 [840/1863 (45%)]\tLoss: 4.996290\n",
            "Train Epoch: 108 [960/1863 (51%)]\tLoss: 1.387313\n",
            "Train Epoch: 108 [1080/1863 (58%)]\tLoss: 4.781638\n",
            "Train Epoch: 108 [1200/1863 (64%)]\tLoss: 9.196884\n",
            "Train Epoch: 108 [1320/1863 (71%)]\tLoss: 22.713255\n",
            "Train Epoch: 108 [1440/1863 (77%)]\tLoss: 18.838284\n",
            "Train Epoch: 108 [1560/1863 (83%)]\tLoss: 3.232697\n",
            "Train Epoch: 108 [1680/1863 (90%)]\tLoss: 21.730927\n",
            "Train Epoch: 108 [1800/1863 (96%)]\tLoss: 6.123743\n",
            "Training Loss: 10.9871 Acc: 50.7783\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5009, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 109/200\n",
            "----------\n",
            "Train Epoch: 109 [0/1863 (0%)]\tLoss: 7.705138\n",
            "Train Epoch: 109 [120/1863 (6%)]\tLoss: 20.092644\n",
            "Train Epoch: 109 [240/1863 (13%)]\tLoss: 15.103220\n",
            "Train Epoch: 109 [360/1863 (19%)]\tLoss: 12.820803\n",
            "Train Epoch: 109 [480/1863 (26%)]\tLoss: 11.798841\n",
            "Train Epoch: 109 [600/1863 (32%)]\tLoss: 10.215528\n",
            "Train Epoch: 109 [720/1863 (39%)]\tLoss: 11.205475\n",
            "Train Epoch: 109 [840/1863 (45%)]\tLoss: 11.965510\n",
            "Train Epoch: 109 [960/1863 (51%)]\tLoss: 0.780995\n",
            "Train Epoch: 109 [1080/1863 (58%)]\tLoss: 10.754662\n",
            "Train Epoch: 109 [1200/1863 (64%)]\tLoss: 15.419194\n",
            "Train Epoch: 109 [1320/1863 (71%)]\tLoss: 12.294870\n",
            "Train Epoch: 109 [1440/1863 (77%)]\tLoss: 5.717339\n",
            "Train Epoch: 109 [1560/1863 (83%)]\tLoss: 16.146961\n",
            "Train Epoch: 109 [1680/1863 (90%)]\tLoss: 5.969908\n",
            "Train Epoch: 109 [1800/1863 (96%)]\tLoss: 17.150631\n",
            "Training Loss: 10.9181 Acc: 51.0467\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4382, Accuracy: 729/1406 (51.849%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 110/200\n",
            "----------\n",
            "Train Epoch: 110 [0/1863 (0%)]\tLoss: 21.464405\n",
            "Train Epoch: 110 [120/1863 (6%)]\tLoss: 7.390543\n",
            "Train Epoch: 110 [240/1863 (13%)]\tLoss: 12.215403\n",
            "Train Epoch: 110 [360/1863 (19%)]\tLoss: 20.485083\n",
            "Train Epoch: 110 [480/1863 (26%)]\tLoss: 12.915576\n",
            "Train Epoch: 110 [600/1863 (32%)]\tLoss: 16.012928\n",
            "Train Epoch: 110 [720/1863 (39%)]\tLoss: 12.290373\n",
            "Train Epoch: 110 [840/1863 (45%)]\tLoss: 25.507618\n",
            "Train Epoch: 110 [960/1863 (51%)]\tLoss: 16.979954\n",
            "Train Epoch: 110 [1080/1863 (58%)]\tLoss: 17.819633\n",
            "Train Epoch: 110 [1200/1863 (64%)]\tLoss: 5.206648\n",
            "Train Epoch: 110 [1320/1863 (71%)]\tLoss: 6.684682\n",
            "Train Epoch: 110 [1440/1863 (77%)]\tLoss: 0.261002\n",
            "Train Epoch: 110 [1560/1863 (83%)]\tLoss: 16.122080\n",
            "Train Epoch: 110 [1680/1863 (90%)]\tLoss: 7.449969\n",
            "Train Epoch: 110 [1800/1863 (96%)]\tLoss: 23.177902\n",
            "Training Loss: 11.5015 Acc: 50.3489\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6232, Accuracy: 736/1406 (52.347%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 111/200\n",
            "----------\n",
            "Train Epoch: 111 [0/1863 (0%)]\tLoss: 23.741520\n",
            "Train Epoch: 111 [120/1863 (6%)]\tLoss: 7.308638\n",
            "Train Epoch: 111 [240/1863 (13%)]\tLoss: 28.954370\n",
            "Train Epoch: 111 [360/1863 (19%)]\tLoss: 14.293017\n",
            "Train Epoch: 111 [480/1863 (26%)]\tLoss: 17.959673\n",
            "Train Epoch: 111 [600/1863 (32%)]\tLoss: 13.820065\n",
            "Train Epoch: 111 [720/1863 (39%)]\tLoss: 5.931556\n",
            "Train Epoch: 111 [840/1863 (45%)]\tLoss: 8.437620\n",
            "Train Epoch: 111 [960/1863 (51%)]\tLoss: 14.037073\n",
            "Train Epoch: 111 [1080/1863 (58%)]\tLoss: 4.789785\n",
            "Train Epoch: 111 [1200/1863 (64%)]\tLoss: 15.903643\n",
            "Train Epoch: 111 [1320/1863 (71%)]\tLoss: 7.574088\n",
            "Train Epoch: 111 [1440/1863 (77%)]\tLoss: 11.626684\n",
            "Train Epoch: 111 [1560/1863 (83%)]\tLoss: 22.589100\n",
            "Train Epoch: 111 [1680/1863 (90%)]\tLoss: 19.234741\n",
            "Train Epoch: 111 [1800/1863 (96%)]\tLoss: 5.579349\n",
            "Training Loss: 11.3640 Acc: 49.9195\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4020, Accuracy: 761/1406 (54.125%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 112/200\n",
            "----------\n",
            "Train Epoch: 112 [0/1863 (0%)]\tLoss: 26.428577\n",
            "Train Epoch: 112 [120/1863 (6%)]\tLoss: 7.774261\n",
            "Train Epoch: 112 [240/1863 (13%)]\tLoss: 3.240777\n",
            "Train Epoch: 112 [360/1863 (19%)]\tLoss: 19.489193\n",
            "Train Epoch: 112 [480/1863 (26%)]\tLoss: 13.066545\n",
            "Train Epoch: 112 [600/1863 (32%)]\tLoss: 15.654045\n",
            "Train Epoch: 112 [720/1863 (39%)]\tLoss: 6.707128\n",
            "Train Epoch: 112 [840/1863 (45%)]\tLoss: 5.862281\n",
            "Train Epoch: 112 [960/1863 (51%)]\tLoss: 6.841034\n",
            "Train Epoch: 112 [1080/1863 (58%)]\tLoss: 9.161988\n",
            "Train Epoch: 112 [1200/1863 (64%)]\tLoss: 9.470496\n",
            "Train Epoch: 112 [1320/1863 (71%)]\tLoss: 10.480719\n",
            "Train Epoch: 112 [1440/1863 (77%)]\tLoss: 17.418694\n",
            "Train Epoch: 112 [1560/1863 (83%)]\tLoss: 14.780850\n",
            "Train Epoch: 112 [1680/1863 (90%)]\tLoss: 2.621178\n",
            "Train Epoch: 112 [1800/1863 (96%)]\tLoss: 1.146132\n",
            "Training Loss: 11.1517 Acc: 50.5099\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5461, Accuracy: 731/1406 (51.991%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 113/200\n",
            "----------\n",
            "Train Epoch: 113 [0/1863 (0%)]\tLoss: 5.595571\n",
            "Train Epoch: 113 [120/1863 (6%)]\tLoss: 17.235144\n",
            "Train Epoch: 113 [240/1863 (13%)]\tLoss: 11.000660\n",
            "Train Epoch: 113 [360/1863 (19%)]\tLoss: 17.823118\n",
            "Train Epoch: 113 [480/1863 (26%)]\tLoss: 3.548477\n",
            "Train Epoch: 113 [600/1863 (32%)]\tLoss: 16.791239\n",
            "Train Epoch: 113 [720/1863 (39%)]\tLoss: 11.204496\n",
            "Train Epoch: 113 [840/1863 (45%)]\tLoss: 17.278046\n",
            "Train Epoch: 113 [960/1863 (51%)]\tLoss: 3.599926\n",
            "Train Epoch: 113 [1080/1863 (58%)]\tLoss: 8.060557\n",
            "Train Epoch: 113 [1200/1863 (64%)]\tLoss: 27.019718\n",
            "Train Epoch: 113 [1320/1863 (71%)]\tLoss: 7.339738\n",
            "Train Epoch: 113 [1440/1863 (77%)]\tLoss: 2.062963\n",
            "Train Epoch: 113 [1560/1863 (83%)]\tLoss: 15.447937\n",
            "Train Epoch: 113 [1680/1863 (90%)]\tLoss: 16.276728\n",
            "Train Epoch: 113 [1800/1863 (96%)]\tLoss: 2.999932\n",
            "Training Loss: 11.3244 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5838, Accuracy: 707/1406 (50.284%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 114/200\n",
            "----------\n",
            "Train Epoch: 114 [0/1863 (0%)]\tLoss: 0.999874\n",
            "Train Epoch: 114 [120/1863 (6%)]\tLoss: 9.291807\n",
            "Train Epoch: 114 [240/1863 (13%)]\tLoss: 20.538769\n",
            "Train Epoch: 114 [360/1863 (19%)]\tLoss: 12.470843\n",
            "Train Epoch: 114 [480/1863 (26%)]\tLoss: 13.148509\n",
            "Train Epoch: 114 [600/1863 (32%)]\tLoss: 17.772078\n",
            "Train Epoch: 114 [720/1863 (39%)]\tLoss: 5.737305\n",
            "Train Epoch: 114 [840/1863 (45%)]\tLoss: 4.278893\n",
            "Train Epoch: 114 [960/1863 (51%)]\tLoss: 15.160364\n",
            "Train Epoch: 114 [1080/1863 (58%)]\tLoss: 18.863096\n",
            "Train Epoch: 114 [1200/1863 (64%)]\tLoss: 15.518147\n",
            "Train Epoch: 114 [1320/1863 (71%)]\tLoss: 7.691923\n",
            "Train Epoch: 114 [1440/1863 (77%)]\tLoss: 8.761810\n",
            "Train Epoch: 114 [1560/1863 (83%)]\tLoss: 20.444111\n",
            "Train Epoch: 114 [1680/1863 (90%)]\tLoss: 13.883165\n",
            "Train Epoch: 114 [1800/1863 (96%)]\tLoss: 13.354833\n",
            "Training Loss: 10.9591 Acc: 50.2415\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6000, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 115/200\n",
            "----------\n",
            "Train Epoch: 115 [0/1863 (0%)]\tLoss: 19.091646\n",
            "Train Epoch: 115 [120/1863 (6%)]\tLoss: 3.695557\n",
            "Train Epoch: 115 [240/1863 (13%)]\tLoss: 10.545462\n",
            "Train Epoch: 115 [360/1863 (19%)]\tLoss: 10.186811\n",
            "Train Epoch: 115 [480/1863 (26%)]\tLoss: 5.468560\n",
            "Train Epoch: 115 [600/1863 (32%)]\tLoss: 9.480958\n",
            "Train Epoch: 115 [720/1863 (39%)]\tLoss: 10.406771\n",
            "Train Epoch: 115 [840/1863 (45%)]\tLoss: 8.030082\n",
            "Train Epoch: 115 [960/1863 (51%)]\tLoss: 10.312883\n",
            "Train Epoch: 115 [1080/1863 (58%)]\tLoss: 12.619089\n",
            "Train Epoch: 115 [1200/1863 (64%)]\tLoss: 12.922434\n",
            "Train Epoch: 115 [1320/1863 (71%)]\tLoss: 5.597951\n",
            "Train Epoch: 115 [1440/1863 (77%)]\tLoss: 11.146423\n",
            "Train Epoch: 115 [1560/1863 (83%)]\tLoss: 13.100881\n",
            "Train Epoch: 115 [1680/1863 (90%)]\tLoss: 4.999357\n",
            "Train Epoch: 115 [1800/1863 (96%)]\tLoss: 10.949757\n",
            "Training Loss: 11.1483 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4091, Accuracy: 716/1406 (50.925%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 116/200\n",
            "----------\n",
            "Train Epoch: 116 [0/1863 (0%)]\tLoss: 24.631134\n",
            "Train Epoch: 116 [120/1863 (6%)]\tLoss: 11.886972\n",
            "Train Epoch: 116 [240/1863 (13%)]\tLoss: 8.551822\n",
            "Train Epoch: 116 [360/1863 (19%)]\tLoss: 10.721663\n",
            "Train Epoch: 116 [480/1863 (26%)]\tLoss: 8.602217\n",
            "Train Epoch: 116 [600/1863 (32%)]\tLoss: 4.534892\n",
            "Train Epoch: 116 [720/1863 (39%)]\tLoss: 17.342709\n",
            "Train Epoch: 116 [840/1863 (45%)]\tLoss: 10.857762\n",
            "Train Epoch: 116 [960/1863 (51%)]\tLoss: 16.094244\n",
            "Train Epoch: 116 [1080/1863 (58%)]\tLoss: 30.909901\n",
            "Train Epoch: 116 [1200/1863 (64%)]\tLoss: 18.835260\n",
            "Train Epoch: 116 [1320/1863 (71%)]\tLoss: 4.697670\n",
            "Train Epoch: 116 [1440/1863 (77%)]\tLoss: 10.916825\n",
            "Train Epoch: 116 [1560/1863 (83%)]\tLoss: 11.669243\n",
            "Train Epoch: 116 [1680/1863 (90%)]\tLoss: 11.899473\n",
            "Train Epoch: 116 [1800/1863 (96%)]\tLoss: 10.265434\n",
            "Training Loss: 11.1059 Acc: 51.1004\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4184, Accuracy: 799/1406 (56.828%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 117/200\n",
            "----------\n",
            "Train Epoch: 117 [0/1863 (0%)]\tLoss: 7.844275\n",
            "Train Epoch: 117 [120/1863 (6%)]\tLoss: 18.462337\n",
            "Train Epoch: 117 [240/1863 (13%)]\tLoss: 15.071393\n",
            "Train Epoch: 117 [360/1863 (19%)]\tLoss: 4.069663\n",
            "Train Epoch: 117 [480/1863 (26%)]\tLoss: 11.406969\n",
            "Train Epoch: 117 [600/1863 (32%)]\tLoss: 19.757925\n",
            "Train Epoch: 117 [720/1863 (39%)]\tLoss: 28.348089\n",
            "Train Epoch: 117 [840/1863 (45%)]\tLoss: 11.161918\n",
            "Train Epoch: 117 [960/1863 (51%)]\tLoss: 13.213289\n",
            "Train Epoch: 117 [1080/1863 (58%)]\tLoss: 8.652731\n",
            "Train Epoch: 117 [1200/1863 (64%)]\tLoss: 15.980501\n",
            "Train Epoch: 117 [1320/1863 (71%)]\tLoss: 7.494269\n",
            "Train Epoch: 117 [1440/1863 (77%)]\tLoss: 15.524872\n",
            "Train Epoch: 117 [1560/1863 (83%)]\tLoss: 18.000860\n",
            "Train Epoch: 117 [1680/1863 (90%)]\tLoss: 4.447318\n",
            "Train Epoch: 117 [1800/1863 (96%)]\tLoss: 28.470621\n",
            "Training Loss: 11.2450 Acc: 50.8320\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3892, Accuracy: 725/1406 (51.565%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 118/200\n",
            "----------\n",
            "Train Epoch: 118 [0/1863 (0%)]\tLoss: 14.640117\n",
            "Train Epoch: 118 [120/1863 (6%)]\tLoss: 4.411383\n",
            "Train Epoch: 118 [240/1863 (13%)]\tLoss: 2.707684\n",
            "Train Epoch: 118 [360/1863 (19%)]\tLoss: 11.724930\n",
            "Train Epoch: 118 [480/1863 (26%)]\tLoss: 20.676081\n",
            "Train Epoch: 118 [600/1863 (32%)]\tLoss: 8.963255\n",
            "Train Epoch: 118 [720/1863 (39%)]\tLoss: 10.689372\n",
            "Train Epoch: 118 [840/1863 (45%)]\tLoss: 5.799268\n",
            "Train Epoch: 118 [960/1863 (51%)]\tLoss: 11.614265\n",
            "Train Epoch: 118 [1080/1863 (58%)]\tLoss: 5.000182\n",
            "Train Epoch: 118 [1200/1863 (64%)]\tLoss: 11.048656\n",
            "Train Epoch: 118 [1320/1863 (71%)]\tLoss: 9.550734\n",
            "Train Epoch: 118 [1440/1863 (77%)]\tLoss: 18.694201\n",
            "Train Epoch: 118 [1560/1863 (83%)]\tLoss: 7.819505\n",
            "Train Epoch: 118 [1680/1863 (90%)]\tLoss: 7.552063\n",
            "Train Epoch: 118 [1800/1863 (96%)]\tLoss: 4.787538\n",
            "Training Loss: 11.1832 Acc: 49.9195\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5336, Accuracy: 721/1406 (51.280%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 119/200\n",
            "----------\n",
            "Train Epoch: 119 [0/1863 (0%)]\tLoss: 9.544252\n",
            "Train Epoch: 119 [120/1863 (6%)]\tLoss: 20.469784\n",
            "Train Epoch: 119 [240/1863 (13%)]\tLoss: 5.226048\n",
            "Train Epoch: 119 [360/1863 (19%)]\tLoss: 10.504520\n",
            "Train Epoch: 119 [480/1863 (26%)]\tLoss: 15.998227\n",
            "Train Epoch: 119 [600/1863 (32%)]\tLoss: 6.747282\n",
            "Train Epoch: 119 [720/1863 (39%)]\tLoss: 17.466892\n",
            "Train Epoch: 119 [840/1863 (45%)]\tLoss: 15.165878\n",
            "Train Epoch: 119 [960/1863 (51%)]\tLoss: 13.802637\n",
            "Train Epoch: 119 [1080/1863 (58%)]\tLoss: 24.917997\n",
            "Train Epoch: 119 [1200/1863 (64%)]\tLoss: 18.471401\n",
            "Train Epoch: 119 [1320/1863 (71%)]\tLoss: 7.754606\n",
            "Train Epoch: 119 [1440/1863 (77%)]\tLoss: 8.581097\n",
            "Train Epoch: 119 [1560/1863 (83%)]\tLoss: 2.425032\n",
            "Train Epoch: 119 [1680/1863 (90%)]\tLoss: 14.857180\n",
            "Train Epoch: 119 [1800/1863 (96%)]\tLoss: 17.076683\n",
            "Training Loss: 11.1312 Acc: 50.2952\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6961, Accuracy: 707/1406 (50.284%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 120/200\n",
            "----------\n",
            "Train Epoch: 120 [0/1863 (0%)]\tLoss: 18.236050\n",
            "Train Epoch: 120 [120/1863 (6%)]\tLoss: 8.614948\n",
            "Train Epoch: 120 [240/1863 (13%)]\tLoss: 11.914148\n",
            "Train Epoch: 120 [360/1863 (19%)]\tLoss: 19.861185\n",
            "Train Epoch: 120 [480/1863 (26%)]\tLoss: 13.122310\n",
            "Train Epoch: 120 [600/1863 (32%)]\tLoss: 20.721029\n",
            "Train Epoch: 120 [720/1863 (39%)]\tLoss: 16.059875\n",
            "Train Epoch: 120 [840/1863 (45%)]\tLoss: 15.308627\n",
            "Train Epoch: 120 [960/1863 (51%)]\tLoss: 14.647936\n",
            "Train Epoch: 120 [1080/1863 (58%)]\tLoss: 16.503252\n",
            "Train Epoch: 120 [1200/1863 (64%)]\tLoss: 2.905305\n",
            "Train Epoch: 120 [1320/1863 (71%)]\tLoss: 15.019850\n",
            "Train Epoch: 120 [1440/1863 (77%)]\tLoss: 4.757309\n",
            "Train Epoch: 120 [1560/1863 (83%)]\tLoss: 18.679733\n",
            "Train Epoch: 120 [1680/1863 (90%)]\tLoss: 3.402119\n",
            "Train Epoch: 120 [1800/1863 (96%)]\tLoss: 10.529009\n",
            "Training Loss: 10.8082 Acc: 51.1541\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3293, Accuracy: 703/1406 (50.000%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 121/200\n",
            "----------\n",
            "Train Epoch: 121 [0/1863 (0%)]\tLoss: 6.013146\n",
            "Train Epoch: 121 [120/1863 (6%)]\tLoss: 8.152236\n",
            "Train Epoch: 121 [240/1863 (13%)]\tLoss: 12.169122\n",
            "Train Epoch: 121 [360/1863 (19%)]\tLoss: 6.354712\n",
            "Train Epoch: 121 [480/1863 (26%)]\tLoss: 18.533817\n",
            "Train Epoch: 121 [600/1863 (32%)]\tLoss: 5.581741\n",
            "Train Epoch: 121 [720/1863 (39%)]\tLoss: 7.931443\n",
            "Train Epoch: 121 [840/1863 (45%)]\tLoss: 16.408619\n",
            "Train Epoch: 121 [960/1863 (51%)]\tLoss: 4.154465\n",
            "Train Epoch: 121 [1080/1863 (58%)]\tLoss: 3.604501\n",
            "Train Epoch: 121 [1200/1863 (64%)]\tLoss: 5.363182\n",
            "Train Epoch: 121 [1320/1863 (71%)]\tLoss: 4.705075\n",
            "Train Epoch: 121 [1440/1863 (77%)]\tLoss: 25.152277\n",
            "Train Epoch: 121 [1560/1863 (83%)]\tLoss: 6.989829\n",
            "Train Epoch: 121 [1680/1863 (90%)]\tLoss: 3.091868\n",
            "Train Epoch: 121 [1800/1863 (96%)]\tLoss: 3.668851\n",
            "Training Loss: 11.4236 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4738, Accuracy: 761/1406 (54.125%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 122/200\n",
            "----------\n",
            "Train Epoch: 122 [0/1863 (0%)]\tLoss: 3.028784\n",
            "Train Epoch: 122 [120/1863 (6%)]\tLoss: 20.387901\n",
            "Train Epoch: 122 [240/1863 (13%)]\tLoss: 11.314566\n",
            "Train Epoch: 122 [360/1863 (19%)]\tLoss: 17.218567\n",
            "Train Epoch: 122 [480/1863 (26%)]\tLoss: 12.528304\n",
            "Train Epoch: 122 [600/1863 (32%)]\tLoss: 16.948782\n",
            "Train Epoch: 122 [720/1863 (39%)]\tLoss: 11.747559\n",
            "Train Epoch: 122 [840/1863 (45%)]\tLoss: 11.990937\n",
            "Train Epoch: 122 [960/1863 (51%)]\tLoss: 10.683502\n",
            "Train Epoch: 122 [1080/1863 (58%)]\tLoss: 3.894936\n",
            "Train Epoch: 122 [1200/1863 (64%)]\tLoss: 13.177981\n",
            "Train Epoch: 122 [1320/1863 (71%)]\tLoss: 6.233768\n",
            "Train Epoch: 122 [1440/1863 (77%)]\tLoss: 6.165328\n",
            "Train Epoch: 122 [1560/1863 (83%)]\tLoss: 14.313930\n",
            "Train Epoch: 122 [1680/1863 (90%)]\tLoss: 8.691275\n",
            "Train Epoch: 122 [1800/1863 (96%)]\tLoss: 8.880167\n",
            "Training Loss: 11.0240 Acc: 50.4563\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4796, Accuracy: 752/1406 (53.485%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 123/200\n",
            "----------\n",
            "Train Epoch: 123 [0/1863 (0%)]\tLoss: 4.252691\n",
            "Train Epoch: 123 [120/1863 (6%)]\tLoss: 7.482184\n",
            "Train Epoch: 123 [240/1863 (13%)]\tLoss: 4.807055\n",
            "Train Epoch: 123 [360/1863 (19%)]\tLoss: 13.528160\n",
            "Train Epoch: 123 [480/1863 (26%)]\tLoss: 13.616043\n",
            "Train Epoch: 123 [600/1863 (32%)]\tLoss: 8.361853\n",
            "Train Epoch: 123 [720/1863 (39%)]\tLoss: 14.223677\n",
            "Train Epoch: 123 [840/1863 (45%)]\tLoss: 6.706508\n",
            "Train Epoch: 123 [960/1863 (51%)]\tLoss: 8.298772\n",
            "Train Epoch: 123 [1080/1863 (58%)]\tLoss: 17.044521\n",
            "Train Epoch: 123 [1200/1863 (64%)]\tLoss: 8.869160\n",
            "Train Epoch: 123 [1320/1863 (71%)]\tLoss: 5.344304\n",
            "Train Epoch: 123 [1440/1863 (77%)]\tLoss: 10.626235\n",
            "Train Epoch: 123 [1560/1863 (83%)]\tLoss: 11.909421\n",
            "Train Epoch: 123 [1680/1863 (90%)]\tLoss: 5.741940\n",
            "Train Epoch: 123 [1800/1863 (96%)]\tLoss: 28.008320\n",
            "Training Loss: 10.9666 Acc: 50.7246\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5582, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 124/200\n",
            "----------\n",
            "Train Epoch: 124 [0/1863 (0%)]\tLoss: 6.720223\n",
            "Train Epoch: 124 [120/1863 (6%)]\tLoss: 13.339262\n",
            "Train Epoch: 124 [240/1863 (13%)]\tLoss: 6.520535\n",
            "Train Epoch: 124 [360/1863 (19%)]\tLoss: 9.731178\n",
            "Train Epoch: 124 [480/1863 (26%)]\tLoss: 4.286910\n",
            "Train Epoch: 124 [600/1863 (32%)]\tLoss: 18.767756\n",
            "Train Epoch: 124 [720/1863 (39%)]\tLoss: 6.584772\n",
            "Train Epoch: 124 [840/1863 (45%)]\tLoss: 9.009439\n",
            "Train Epoch: 124 [960/1863 (51%)]\tLoss: 2.931926\n",
            "Train Epoch: 124 [1080/1863 (58%)]\tLoss: 11.888638\n",
            "Train Epoch: 124 [1200/1863 (64%)]\tLoss: 10.851492\n",
            "Train Epoch: 124 [1320/1863 (71%)]\tLoss: 9.733122\n",
            "Train Epoch: 124 [1440/1863 (77%)]\tLoss: 27.663382\n",
            "Train Epoch: 124 [1560/1863 (83%)]\tLoss: 18.969568\n",
            "Train Epoch: 124 [1680/1863 (90%)]\tLoss: 10.620724\n",
            "Train Epoch: 124 [1800/1863 (96%)]\tLoss: 6.590777\n",
            "Training Loss: 10.9436 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4983, Accuracy: 741/1406 (52.703%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 125/200\n",
            "----------\n",
            "Train Epoch: 125 [0/1863 (0%)]\tLoss: 7.689903\n",
            "Train Epoch: 125 [120/1863 (6%)]\tLoss: 7.260291\n",
            "Train Epoch: 125 [240/1863 (13%)]\tLoss: 5.148738\n",
            "Train Epoch: 125 [360/1863 (19%)]\tLoss: 5.063052\n",
            "Train Epoch: 125 [480/1863 (26%)]\tLoss: 8.422278\n",
            "Train Epoch: 125 [600/1863 (32%)]\tLoss: 16.519526\n",
            "Train Epoch: 125 [720/1863 (39%)]\tLoss: 12.386533\n",
            "Train Epoch: 125 [840/1863 (45%)]\tLoss: 7.567456\n",
            "Train Epoch: 125 [960/1863 (51%)]\tLoss: 7.587890\n",
            "Train Epoch: 125 [1080/1863 (58%)]\tLoss: 4.286314\n",
            "Train Epoch: 125 [1200/1863 (64%)]\tLoss: 4.614776\n",
            "Train Epoch: 125 [1320/1863 (71%)]\tLoss: 6.504247\n",
            "Train Epoch: 125 [1440/1863 (77%)]\tLoss: 11.695999\n",
            "Train Epoch: 125 [1560/1863 (83%)]\tLoss: 34.535316\n",
            "Train Epoch: 125 [1680/1863 (90%)]\tLoss: 6.697582\n",
            "Train Epoch: 125 [1800/1863 (96%)]\tLoss: 11.204931\n",
            "Training Loss: 11.2770 Acc: 51.2614\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5504, Accuracy: 732/1406 (52.063%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 126/200\n",
            "----------\n",
            "Train Epoch: 126 [0/1863 (0%)]\tLoss: 6.641849\n",
            "Train Epoch: 126 [120/1863 (6%)]\tLoss: 7.813263\n",
            "Train Epoch: 126 [240/1863 (13%)]\tLoss: 22.955120\n",
            "Train Epoch: 126 [360/1863 (19%)]\tLoss: 4.822646\n",
            "Train Epoch: 126 [480/1863 (26%)]\tLoss: 7.858892\n",
            "Train Epoch: 126 [600/1863 (32%)]\tLoss: 10.502064\n",
            "Train Epoch: 126 [720/1863 (39%)]\tLoss: 7.310254\n",
            "Train Epoch: 126 [840/1863 (45%)]\tLoss: 9.805256\n",
            "Train Epoch: 126 [960/1863 (51%)]\tLoss: 11.193260\n",
            "Train Epoch: 126 [1080/1863 (58%)]\tLoss: 20.284988\n",
            "Train Epoch: 126 [1200/1863 (64%)]\tLoss: 24.259235\n",
            "Train Epoch: 126 [1320/1863 (71%)]\tLoss: 5.259439\n",
            "Train Epoch: 126 [1440/1863 (77%)]\tLoss: 22.103884\n",
            "Train Epoch: 126 [1560/1863 (83%)]\tLoss: 8.880726\n",
            "Train Epoch: 126 [1680/1863 (90%)]\tLoss: 5.547965\n",
            "Train Epoch: 126 [1800/1863 (96%)]\tLoss: 14.701979\n",
            "Training Loss: 11.5015 Acc: 50.7246\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5051, Accuracy: 707/1406 (50.284%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 127/200\n",
            "----------\n",
            "Train Epoch: 127 [0/1863 (0%)]\tLoss: 16.554653\n",
            "Train Epoch: 127 [120/1863 (6%)]\tLoss: 5.034774\n",
            "Train Epoch: 127 [240/1863 (13%)]\tLoss: 8.508846\n",
            "Train Epoch: 127 [360/1863 (19%)]\tLoss: 6.149455\n",
            "Train Epoch: 127 [480/1863 (26%)]\tLoss: 5.309986\n",
            "Train Epoch: 127 [600/1863 (32%)]\tLoss: 12.393085\n",
            "Train Epoch: 127 [720/1863 (39%)]\tLoss: 19.258097\n",
            "Train Epoch: 127 [840/1863 (45%)]\tLoss: 9.510426\n",
            "Train Epoch: 127 [960/1863 (51%)]\tLoss: 21.525585\n",
            "Train Epoch: 127 [1080/1863 (58%)]\tLoss: 13.489588\n",
            "Train Epoch: 127 [1200/1863 (64%)]\tLoss: 6.215072\n",
            "Train Epoch: 127 [1320/1863 (71%)]\tLoss: 2.805636\n",
            "Train Epoch: 127 [1440/1863 (77%)]\tLoss: 20.014830\n",
            "Train Epoch: 127 [1560/1863 (83%)]\tLoss: 7.153223\n",
            "Train Epoch: 127 [1680/1863 (90%)]\tLoss: 18.080027\n",
            "Train Epoch: 127 [1800/1863 (96%)]\tLoss: 14.141909\n",
            "Training Loss: 10.6887 Acc: 49.9732\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5523, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 128/200\n",
            "----------\n",
            "Train Epoch: 128 [0/1863 (0%)]\tLoss: 19.746735\n",
            "Train Epoch: 128 [120/1863 (6%)]\tLoss: 9.271566\n",
            "Train Epoch: 128 [240/1863 (13%)]\tLoss: 5.974161\n",
            "Train Epoch: 128 [360/1863 (19%)]\tLoss: 13.610014\n",
            "Train Epoch: 128 [480/1863 (26%)]\tLoss: 24.341785\n",
            "Train Epoch: 128 [600/1863 (32%)]\tLoss: 16.944456\n",
            "Train Epoch: 128 [720/1863 (39%)]\tLoss: 7.938827\n",
            "Train Epoch: 128 [840/1863 (45%)]\tLoss: 9.954474\n",
            "Train Epoch: 128 [960/1863 (51%)]\tLoss: 20.734341\n",
            "Train Epoch: 128 [1080/1863 (58%)]\tLoss: 6.005517\n",
            "Train Epoch: 128 [1200/1863 (64%)]\tLoss: 14.870776\n",
            "Train Epoch: 128 [1320/1863 (71%)]\tLoss: 4.613190\n",
            "Train Epoch: 128 [1440/1863 (77%)]\tLoss: 7.027759\n",
            "Train Epoch: 128 [1560/1863 (83%)]\tLoss: 0.000012\n",
            "Train Epoch: 128 [1680/1863 (90%)]\tLoss: 7.068419\n",
            "Train Epoch: 128 [1800/1863 (96%)]\tLoss: 13.473269\n",
            "Training Loss: 10.8902 Acc: 50.3489\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5109, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 129/200\n",
            "----------\n",
            "Train Epoch: 129 [0/1863 (0%)]\tLoss: 12.323805\n",
            "Train Epoch: 129 [120/1863 (6%)]\tLoss: 17.419273\n",
            "Train Epoch: 129 [240/1863 (13%)]\tLoss: 17.631866\n",
            "Train Epoch: 129 [360/1863 (19%)]\tLoss: 26.254490\n",
            "Train Epoch: 129 [480/1863 (26%)]\tLoss: 19.748646\n",
            "Train Epoch: 129 [600/1863 (32%)]\tLoss: 4.573249\n",
            "Train Epoch: 129 [720/1863 (39%)]\tLoss: 10.579414\n",
            "Train Epoch: 129 [840/1863 (45%)]\tLoss: 15.312078\n",
            "Train Epoch: 129 [960/1863 (51%)]\tLoss: 12.819040\n",
            "Train Epoch: 129 [1080/1863 (58%)]\tLoss: 0.403023\n",
            "Train Epoch: 129 [1200/1863 (64%)]\tLoss: 11.648257\n",
            "Train Epoch: 129 [1320/1863 (71%)]\tLoss: 11.559605\n",
            "Train Epoch: 129 [1440/1863 (77%)]\tLoss: 20.355045\n",
            "Train Epoch: 129 [1560/1863 (83%)]\tLoss: 14.435948\n",
            "Train Epoch: 129 [1680/1863 (90%)]\tLoss: 13.431964\n",
            "Train Epoch: 129 [1800/1863 (96%)]\tLoss: 13.285914\n",
            "Training Loss: 11.2417 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4741, Accuracy: 744/1406 (52.916%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 130/200\n",
            "----------\n",
            "Train Epoch: 130 [0/1863 (0%)]\tLoss: 14.671303\n",
            "Train Epoch: 130 [120/1863 (6%)]\tLoss: 14.707634\n",
            "Train Epoch: 130 [240/1863 (13%)]\tLoss: 6.530909\n",
            "Train Epoch: 130 [360/1863 (19%)]\tLoss: 7.962129\n",
            "Train Epoch: 130 [480/1863 (26%)]\tLoss: 3.599663\n",
            "Train Epoch: 130 [600/1863 (32%)]\tLoss: 14.284857\n",
            "Train Epoch: 130 [720/1863 (39%)]\tLoss: 13.829303\n",
            "Train Epoch: 130 [840/1863 (45%)]\tLoss: 5.554349\n",
            "Train Epoch: 130 [960/1863 (51%)]\tLoss: 11.922270\n",
            "Train Epoch: 130 [1080/1863 (58%)]\tLoss: 4.464499\n",
            "Train Epoch: 130 [1200/1863 (64%)]\tLoss: 11.169941\n",
            "Train Epoch: 130 [1320/1863 (71%)]\tLoss: 18.902994\n",
            "Train Epoch: 130 [1440/1863 (77%)]\tLoss: 18.614439\n",
            "Train Epoch: 130 [1560/1863 (83%)]\tLoss: 4.345809\n",
            "Train Epoch: 130 [1680/1863 (90%)]\tLoss: 7.664369\n",
            "Train Epoch: 130 [1800/1863 (96%)]\tLoss: 7.734177\n",
            "Training Loss: 11.5787 Acc: 50.3489\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5567, Accuracy: 714/1406 (50.782%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 131/200\n",
            "----------\n",
            "Train Epoch: 131 [0/1863 (0%)]\tLoss: 2.870509\n",
            "Train Epoch: 131 [120/1863 (6%)]\tLoss: 13.186811\n",
            "Train Epoch: 131 [240/1863 (13%)]\tLoss: 4.008291\n",
            "Train Epoch: 131 [360/1863 (19%)]\tLoss: 9.955655\n",
            "Train Epoch: 131 [480/1863 (26%)]\tLoss: 9.417257\n",
            "Train Epoch: 131 [600/1863 (32%)]\tLoss: 17.169985\n",
            "Train Epoch: 131 [720/1863 (39%)]\tLoss: 27.090342\n",
            "Train Epoch: 131 [840/1863 (45%)]\tLoss: 17.406202\n",
            "Train Epoch: 131 [960/1863 (51%)]\tLoss: 5.223550\n",
            "Train Epoch: 131 [1080/1863 (58%)]\tLoss: 7.446597\n",
            "Train Epoch: 131 [1200/1863 (64%)]\tLoss: 7.236799\n",
            "Train Epoch: 131 [1320/1863 (71%)]\tLoss: 8.081627\n",
            "Train Epoch: 131 [1440/1863 (77%)]\tLoss: 12.541795\n",
            "Train Epoch: 131 [1560/1863 (83%)]\tLoss: 31.707294\n",
            "Train Epoch: 131 [1680/1863 (90%)]\tLoss: 3.153888\n",
            "Train Epoch: 131 [1800/1863 (96%)]\tLoss: 7.054596\n",
            "Training Loss: 11.2416 Acc: 51.1541\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5243, Accuracy: 712/1406 (50.640%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 132/200\n",
            "----------\n",
            "Train Epoch: 132 [0/1863 (0%)]\tLoss: 17.308834\n",
            "Train Epoch: 132 [120/1863 (6%)]\tLoss: 16.915417\n",
            "Train Epoch: 132 [240/1863 (13%)]\tLoss: 1.985299\n",
            "Train Epoch: 132 [360/1863 (19%)]\tLoss: 21.785347\n",
            "Train Epoch: 132 [480/1863 (26%)]\tLoss: 4.651572\n",
            "Train Epoch: 132 [600/1863 (32%)]\tLoss: 9.694868\n",
            "Train Epoch: 132 [720/1863 (39%)]\tLoss: 18.321590\n",
            "Train Epoch: 132 [840/1863 (45%)]\tLoss: 13.272379\n",
            "Train Epoch: 132 [960/1863 (51%)]\tLoss: 11.208171\n",
            "Train Epoch: 132 [1080/1863 (58%)]\tLoss: 5.161860\n",
            "Train Epoch: 132 [1200/1863 (64%)]\tLoss: 18.465536\n",
            "Train Epoch: 132 [1320/1863 (71%)]\tLoss: 6.131868\n",
            "Train Epoch: 132 [1440/1863 (77%)]\tLoss: 9.643270\n",
            "Train Epoch: 132 [1560/1863 (83%)]\tLoss: 3.252797\n",
            "Train Epoch: 132 [1680/1863 (90%)]\tLoss: 7.472351\n",
            "Train Epoch: 132 [1800/1863 (96%)]\tLoss: 11.010027\n",
            "Training Loss: 11.3185 Acc: 51.3688\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3620, Accuracy: 844/1406 (60.028%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 133/200\n",
            "----------\n",
            "Train Epoch: 133 [0/1863 (0%)]\tLoss: 13.336062\n",
            "Train Epoch: 133 [120/1863 (6%)]\tLoss: 17.798609\n",
            "Train Epoch: 133 [240/1863 (13%)]\tLoss: 23.177357\n",
            "Train Epoch: 133 [360/1863 (19%)]\tLoss: 9.772825\n",
            "Train Epoch: 133 [480/1863 (26%)]\tLoss: 5.862582\n",
            "Train Epoch: 133 [600/1863 (32%)]\tLoss: 12.111237\n",
            "Train Epoch: 133 [720/1863 (39%)]\tLoss: 6.078570\n",
            "Train Epoch: 133 [840/1863 (45%)]\tLoss: 6.558948\n",
            "Train Epoch: 133 [960/1863 (51%)]\tLoss: 7.331856\n",
            "Train Epoch: 133 [1080/1863 (58%)]\tLoss: 7.272434\n",
            "Train Epoch: 133 [1200/1863 (64%)]\tLoss: 7.065598\n",
            "Train Epoch: 133 [1320/1863 (71%)]\tLoss: 13.937680\n",
            "Train Epoch: 133 [1440/1863 (77%)]\tLoss: 4.786768\n",
            "Train Epoch: 133 [1560/1863 (83%)]\tLoss: 6.669524\n",
            "Train Epoch: 133 [1680/1863 (90%)]\tLoss: 10.415403\n",
            "Train Epoch: 133 [1800/1863 (96%)]\tLoss: 2.061210\n",
            "Training Loss: 10.9799 Acc: 51.2077\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4540, Accuracy: 714/1406 (50.782%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 134/200\n",
            "----------\n",
            "Train Epoch: 134 [0/1863 (0%)]\tLoss: 4.655254\n",
            "Train Epoch: 134 [120/1863 (6%)]\tLoss: 16.475368\n",
            "Train Epoch: 134 [240/1863 (13%)]\tLoss: 17.669624\n",
            "Train Epoch: 134 [360/1863 (19%)]\tLoss: 10.417653\n",
            "Train Epoch: 134 [480/1863 (26%)]\tLoss: 5.690057\n",
            "Train Epoch: 134 [600/1863 (32%)]\tLoss: 4.936311\n",
            "Train Epoch: 134 [720/1863 (39%)]\tLoss: 2.585892\n",
            "Train Epoch: 134 [840/1863 (45%)]\tLoss: 16.213835\n",
            "Train Epoch: 134 [960/1863 (51%)]\tLoss: 8.398329\n",
            "Train Epoch: 134 [1080/1863 (58%)]\tLoss: 4.963894\n",
            "Train Epoch: 134 [1200/1863 (64%)]\tLoss: 6.796369\n",
            "Train Epoch: 134 [1320/1863 (71%)]\tLoss: 3.290450\n",
            "Train Epoch: 134 [1440/1863 (77%)]\tLoss: 7.240911\n",
            "Train Epoch: 134 [1560/1863 (83%)]\tLoss: 16.243689\n",
            "Train Epoch: 134 [1680/1863 (90%)]\tLoss: 15.909742\n",
            "Train Epoch: 134 [1800/1863 (96%)]\tLoss: 2.399933\n",
            "Training Loss: 11.4123 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4902, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 135/200\n",
            "----------\n",
            "Train Epoch: 135 [0/1863 (0%)]\tLoss: 3.480185\n",
            "Train Epoch: 135 [120/1863 (6%)]\tLoss: 11.243968\n",
            "Train Epoch: 135 [240/1863 (13%)]\tLoss: 11.508497\n",
            "Train Epoch: 135 [360/1863 (19%)]\tLoss: 20.428749\n",
            "Train Epoch: 135 [480/1863 (26%)]\tLoss: 6.400891\n",
            "Train Epoch: 135 [600/1863 (32%)]\tLoss: 6.495077\n",
            "Train Epoch: 135 [720/1863 (39%)]\tLoss: 11.790008\n",
            "Train Epoch: 135 [840/1863 (45%)]\tLoss: 23.073206\n",
            "Train Epoch: 135 [960/1863 (51%)]\tLoss: 24.089066\n",
            "Train Epoch: 135 [1080/1863 (58%)]\tLoss: 7.310094\n",
            "Train Epoch: 135 [1200/1863 (64%)]\tLoss: 17.704281\n",
            "Train Epoch: 135 [1320/1863 (71%)]\tLoss: 14.862535\n",
            "Train Epoch: 135 [1440/1863 (77%)]\tLoss: 4.945298\n",
            "Train Epoch: 135 [1560/1863 (83%)]\tLoss: 14.122622\n",
            "Train Epoch: 135 [1680/1863 (90%)]\tLoss: 16.091413\n",
            "Train Epoch: 135 [1800/1863 (96%)]\tLoss: 3.640734\n",
            "Training Loss: 11.0108 Acc: 50.2415\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6904, Accuracy: 707/1406 (50.284%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 136/200\n",
            "----------\n",
            "Train Epoch: 136 [0/1863 (0%)]\tLoss: 10.086011\n",
            "Train Epoch: 136 [120/1863 (6%)]\tLoss: 16.354397\n",
            "Train Epoch: 136 [240/1863 (13%)]\tLoss: 8.809158\n",
            "Train Epoch: 136 [360/1863 (19%)]\tLoss: 12.226619\n",
            "Train Epoch: 136 [480/1863 (26%)]\tLoss: 25.512453\n",
            "Train Epoch: 136 [600/1863 (32%)]\tLoss: 10.268076\n",
            "Train Epoch: 136 [720/1863 (39%)]\tLoss: 4.030385\n",
            "Train Epoch: 136 [840/1863 (45%)]\tLoss: 1.043382\n",
            "Train Epoch: 136 [960/1863 (51%)]\tLoss: 9.561309\n",
            "Train Epoch: 136 [1080/1863 (58%)]\tLoss: 15.810925\n",
            "Train Epoch: 136 [1200/1863 (64%)]\tLoss: 22.013309\n",
            "Train Epoch: 136 [1320/1863 (71%)]\tLoss: 5.386368\n",
            "Train Epoch: 136 [1440/1863 (77%)]\tLoss: 10.996019\n",
            "Train Epoch: 136 [1560/1863 (83%)]\tLoss: 6.328870\n",
            "Train Epoch: 136 [1680/1863 (90%)]\tLoss: 11.383752\n",
            "Train Epoch: 136 [1800/1863 (96%)]\tLoss: 4.014644\n",
            "Training Loss: 11.1126 Acc: 51.8519\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5688, Accuracy: 720/1406 (51.209%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 137/200\n",
            "----------\n",
            "Train Epoch: 137 [0/1863 (0%)]\tLoss: 7.723544\n",
            "Train Epoch: 137 [120/1863 (6%)]\tLoss: 5.842264\n",
            "Train Epoch: 137 [240/1863 (13%)]\tLoss: 11.309845\n",
            "Train Epoch: 137 [360/1863 (19%)]\tLoss: 12.732350\n",
            "Train Epoch: 137 [480/1863 (26%)]\tLoss: 13.817014\n",
            "Train Epoch: 137 [600/1863 (32%)]\tLoss: 17.640882\n",
            "Train Epoch: 137 [720/1863 (39%)]\tLoss: 15.721906\n",
            "Train Epoch: 137 [840/1863 (45%)]\tLoss: 20.072617\n",
            "Train Epoch: 137 [960/1863 (51%)]\tLoss: 9.767007\n",
            "Train Epoch: 137 [1080/1863 (58%)]\tLoss: 12.585809\n",
            "Train Epoch: 137 [1200/1863 (64%)]\tLoss: 10.256647\n",
            "Train Epoch: 137 [1320/1863 (71%)]\tLoss: 17.146446\n",
            "Train Epoch: 137 [1440/1863 (77%)]\tLoss: 13.874704\n",
            "Train Epoch: 137 [1560/1863 (83%)]\tLoss: 12.169698\n",
            "Train Epoch: 137 [1680/1863 (90%)]\tLoss: 3.353109\n",
            "Train Epoch: 137 [1800/1863 (96%)]\tLoss: 7.175973\n",
            "Training Loss: 11.0391 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3445, Accuracy: 720/1406 (51.209%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 138/200\n",
            "----------\n",
            "Train Epoch: 138 [0/1863 (0%)]\tLoss: 8.723548\n",
            "Train Epoch: 138 [120/1863 (6%)]\tLoss: 9.324789\n",
            "Train Epoch: 138 [240/1863 (13%)]\tLoss: 20.159140\n",
            "Train Epoch: 138 [360/1863 (19%)]\tLoss: 13.435956\n",
            "Train Epoch: 138 [480/1863 (26%)]\tLoss: 16.719105\n",
            "Train Epoch: 138 [600/1863 (32%)]\tLoss: 2.853118\n",
            "Train Epoch: 138 [720/1863 (39%)]\tLoss: 4.401232\n",
            "Train Epoch: 138 [840/1863 (45%)]\tLoss: 6.388504\n",
            "Train Epoch: 138 [960/1863 (51%)]\tLoss: 7.006269\n",
            "Train Epoch: 138 [1080/1863 (58%)]\tLoss: 14.794357\n",
            "Train Epoch: 138 [1200/1863 (64%)]\tLoss: 11.947261\n",
            "Train Epoch: 138 [1320/1863 (71%)]\tLoss: 16.361446\n",
            "Train Epoch: 138 [1440/1863 (77%)]\tLoss: 7.714826\n",
            "Train Epoch: 138 [1560/1863 (83%)]\tLoss: 8.240366\n",
            "Train Epoch: 138 [1680/1863 (90%)]\tLoss: 2.724736\n",
            "Train Epoch: 138 [1800/1863 (96%)]\tLoss: 11.253017\n",
            "Training Loss: 11.2394 Acc: 50.7783\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4153, Accuracy: 746/1406 (53.058%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 139/200\n",
            "----------\n",
            "Train Epoch: 139 [0/1863 (0%)]\tLoss: 9.368677\n",
            "Train Epoch: 139 [120/1863 (6%)]\tLoss: 14.242952\n",
            "Train Epoch: 139 [240/1863 (13%)]\tLoss: 11.909719\n",
            "Train Epoch: 139 [360/1863 (19%)]\tLoss: 10.683712\n",
            "Train Epoch: 139 [480/1863 (26%)]\tLoss: 14.584417\n",
            "Train Epoch: 139 [600/1863 (32%)]\tLoss: 5.266459\n",
            "Train Epoch: 139 [720/1863 (39%)]\tLoss: 6.687175\n",
            "Train Epoch: 139 [840/1863 (45%)]\tLoss: 18.755512\n",
            "Train Epoch: 139 [960/1863 (51%)]\tLoss: 8.237085\n",
            "Train Epoch: 139 [1080/1863 (58%)]\tLoss: 14.778900\n",
            "Train Epoch: 139 [1200/1863 (64%)]\tLoss: 8.540898\n",
            "Train Epoch: 139 [1320/1863 (71%)]\tLoss: 25.486631\n",
            "Train Epoch: 139 [1440/1863 (77%)]\tLoss: 12.805669\n",
            "Train Epoch: 139 [1560/1863 (83%)]\tLoss: 21.007803\n",
            "Train Epoch: 139 [1680/1863 (90%)]\tLoss: 9.421768\n",
            "Train Epoch: 139 [1800/1863 (96%)]\tLoss: 13.903847\n",
            "Training Loss: 11.2019 Acc: 50.5099\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3989, Accuracy: 770/1406 (54.765%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 140/200\n",
            "----------\n",
            "Train Epoch: 140 [0/1863 (0%)]\tLoss: 9.676073\n",
            "Train Epoch: 140 [120/1863 (6%)]\tLoss: 14.850520\n",
            "Train Epoch: 140 [240/1863 (13%)]\tLoss: 30.757645\n",
            "Train Epoch: 140 [360/1863 (19%)]\tLoss: 4.826427\n",
            "Train Epoch: 140 [480/1863 (26%)]\tLoss: 13.573936\n",
            "Train Epoch: 140 [600/1863 (32%)]\tLoss: 15.092456\n",
            "Train Epoch: 140 [720/1863 (39%)]\tLoss: 7.818660\n",
            "Train Epoch: 140 [840/1863 (45%)]\tLoss: 5.415359\n",
            "Train Epoch: 140 [960/1863 (51%)]\tLoss: 4.344651\n",
            "Train Epoch: 140 [1080/1863 (58%)]\tLoss: 9.370064\n",
            "Train Epoch: 140 [1200/1863 (64%)]\tLoss: 18.161427\n",
            "Train Epoch: 140 [1320/1863 (71%)]\tLoss: 14.734222\n",
            "Train Epoch: 140 [1440/1863 (77%)]\tLoss: 3.368959\n",
            "Train Epoch: 140 [1560/1863 (83%)]\tLoss: 11.281649\n",
            "Train Epoch: 140 [1680/1863 (90%)]\tLoss: 5.268949\n",
            "Train Epoch: 140 [1800/1863 (96%)]\tLoss: 6.445234\n",
            "Training Loss: 11.1616 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5366, Accuracy: 715/1406 (50.853%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 141/200\n",
            "----------\n",
            "Train Epoch: 141 [0/1863 (0%)]\tLoss: 7.888172\n",
            "Train Epoch: 141 [120/1863 (6%)]\tLoss: 12.021646\n",
            "Train Epoch: 141 [240/1863 (13%)]\tLoss: 2.682661\n",
            "Train Epoch: 141 [360/1863 (19%)]\tLoss: 19.093517\n",
            "Train Epoch: 141 [480/1863 (26%)]\tLoss: 2.354046\n",
            "Train Epoch: 141 [600/1863 (32%)]\tLoss: 14.486567\n",
            "Train Epoch: 141 [720/1863 (39%)]\tLoss: 11.761444\n",
            "Train Epoch: 141 [840/1863 (45%)]\tLoss: 8.807515\n",
            "Train Epoch: 141 [960/1863 (51%)]\tLoss: 5.517818\n",
            "Train Epoch: 141 [1080/1863 (58%)]\tLoss: 1.801056\n",
            "Train Epoch: 141 [1200/1863 (64%)]\tLoss: 10.999563\n",
            "Train Epoch: 141 [1320/1863 (71%)]\tLoss: 17.677700\n",
            "Train Epoch: 141 [1440/1863 (77%)]\tLoss: 7.801372\n",
            "Train Epoch: 141 [1560/1863 (83%)]\tLoss: 8.446669\n",
            "Train Epoch: 141 [1680/1863 (90%)]\tLoss: 3.048805\n",
            "Train Epoch: 141 [1800/1863 (96%)]\tLoss: 11.505586\n",
            "Training Loss: 10.9223 Acc: 50.9930\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5470, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 142/200\n",
            "----------\n",
            "Train Epoch: 142 [0/1863 (0%)]\tLoss: 2.737590\n",
            "Train Epoch: 142 [120/1863 (6%)]\tLoss: 16.194181\n",
            "Train Epoch: 142 [240/1863 (13%)]\tLoss: 6.149806\n",
            "Train Epoch: 142 [360/1863 (19%)]\tLoss: 22.144066\n",
            "Train Epoch: 142 [480/1863 (26%)]\tLoss: 1.802841\n",
            "Train Epoch: 142 [600/1863 (32%)]\tLoss: 30.015320\n",
            "Train Epoch: 142 [720/1863 (39%)]\tLoss: 12.281217\n",
            "Train Epoch: 142 [840/1863 (45%)]\tLoss: 16.564159\n",
            "Train Epoch: 142 [960/1863 (51%)]\tLoss: 16.023388\n",
            "Train Epoch: 142 [1080/1863 (58%)]\tLoss: 3.684263\n",
            "Train Epoch: 142 [1200/1863 (64%)]\tLoss: 8.196009\n",
            "Train Epoch: 142 [1320/1863 (71%)]\tLoss: 6.459579\n",
            "Train Epoch: 142 [1440/1863 (77%)]\tLoss: 11.173011\n",
            "Train Epoch: 142 [1560/1863 (83%)]\tLoss: 6.006237\n",
            "Train Epoch: 142 [1680/1863 (90%)]\tLoss: 2.885904\n",
            "Train Epoch: 142 [1800/1863 (96%)]\tLoss: 16.953159\n",
            "Training Loss: 10.8593 Acc: 51.2077\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4581, Accuracy: 771/1406 (54.836%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 143/200\n",
            "----------\n",
            "Train Epoch: 143 [0/1863 (0%)]\tLoss: 13.156888\n",
            "Train Epoch: 143 [120/1863 (6%)]\tLoss: 10.297906\n",
            "Train Epoch: 143 [240/1863 (13%)]\tLoss: 12.992897\n",
            "Train Epoch: 143 [360/1863 (19%)]\tLoss: 10.910497\n",
            "Train Epoch: 143 [480/1863 (26%)]\tLoss: 9.658612\n",
            "Train Epoch: 143 [600/1863 (32%)]\tLoss: 5.372792\n",
            "Train Epoch: 143 [720/1863 (39%)]\tLoss: 12.470759\n",
            "Train Epoch: 143 [840/1863 (45%)]\tLoss: 13.248996\n",
            "Train Epoch: 143 [960/1863 (51%)]\tLoss: 16.538294\n",
            "Train Epoch: 143 [1080/1863 (58%)]\tLoss: 5.290812\n",
            "Train Epoch: 143 [1200/1863 (64%)]\tLoss: 13.904979\n",
            "Train Epoch: 143 [1320/1863 (71%)]\tLoss: 15.685140\n",
            "Train Epoch: 143 [1440/1863 (77%)]\tLoss: 3.359174\n",
            "Train Epoch: 143 [1560/1863 (83%)]\tLoss: 13.864642\n",
            "Train Epoch: 143 [1680/1863 (90%)]\tLoss: 2.439190\n",
            "Train Epoch: 143 [1800/1863 (96%)]\tLoss: 10.815668\n",
            "Training Loss: 11.1031 Acc: 51.5298\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5373, Accuracy: 713/1406 (50.711%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 144/200\n",
            "----------\n",
            "Train Epoch: 144 [0/1863 (0%)]\tLoss: 14.097488\n",
            "Train Epoch: 144 [120/1863 (6%)]\tLoss: 11.042532\n",
            "Train Epoch: 144 [240/1863 (13%)]\tLoss: 9.826887\n",
            "Train Epoch: 144 [360/1863 (19%)]\tLoss: 8.521297\n",
            "Train Epoch: 144 [480/1863 (26%)]\tLoss: 3.557195\n",
            "Train Epoch: 144 [600/1863 (32%)]\tLoss: 11.492217\n",
            "Train Epoch: 144 [720/1863 (39%)]\tLoss: 3.079035\n",
            "Train Epoch: 144 [840/1863 (45%)]\tLoss: 0.003837\n",
            "Train Epoch: 144 [960/1863 (51%)]\tLoss: 1.361318\n",
            "Train Epoch: 144 [1080/1863 (58%)]\tLoss: 10.037519\n",
            "Train Epoch: 144 [1200/1863 (64%)]\tLoss: 5.689846\n",
            "Train Epoch: 144 [1320/1863 (71%)]\tLoss: 3.196003\n",
            "Train Epoch: 144 [1440/1863 (77%)]\tLoss: 10.799491\n",
            "Train Epoch: 144 [1560/1863 (83%)]\tLoss: 3.185663\n",
            "Train Epoch: 144 [1680/1863 (90%)]\tLoss: 4.072307\n",
            "Train Epoch: 144 [1800/1863 (96%)]\tLoss: 5.057406\n",
            "Training Loss: 11.1816 Acc: 50.9393\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4597, Accuracy: 707/1406 (50.284%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 145/200\n",
            "----------\n",
            "Train Epoch: 145 [0/1863 (0%)]\tLoss: 14.355675\n",
            "Train Epoch: 145 [120/1863 (6%)]\tLoss: 9.435021\n",
            "Train Epoch: 145 [240/1863 (13%)]\tLoss: 5.767345\n",
            "Train Epoch: 145 [360/1863 (19%)]\tLoss: 12.389482\n",
            "Train Epoch: 145 [480/1863 (26%)]\tLoss: 8.500559\n",
            "Train Epoch: 145 [600/1863 (32%)]\tLoss: 22.517490\n",
            "Train Epoch: 145 [720/1863 (39%)]\tLoss: 8.807375\n",
            "Train Epoch: 145 [840/1863 (45%)]\tLoss: 16.444717\n",
            "Train Epoch: 145 [960/1863 (51%)]\tLoss: 14.812235\n",
            "Train Epoch: 145 [1080/1863 (58%)]\tLoss: 29.838322\n",
            "Train Epoch: 145 [1200/1863 (64%)]\tLoss: 19.170782\n",
            "Train Epoch: 145 [1320/1863 (71%)]\tLoss: 32.878639\n",
            "Train Epoch: 145 [1440/1863 (77%)]\tLoss: 1.650563\n",
            "Train Epoch: 145 [1560/1863 (83%)]\tLoss: 7.912184\n",
            "Train Epoch: 145 [1680/1863 (90%)]\tLoss: 15.278200\n",
            "Train Epoch: 145 [1800/1863 (96%)]\tLoss: 9.080623\n",
            "Training Loss: 11.1427 Acc: 50.5099\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4867, Accuracy: 721/1406 (51.280%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 146/200\n",
            "----------\n",
            "Train Epoch: 146 [0/1863 (0%)]\tLoss: 4.719450\n",
            "Train Epoch: 146 [120/1863 (6%)]\tLoss: 12.365433\n",
            "Train Epoch: 146 [240/1863 (13%)]\tLoss: 27.630747\n",
            "Train Epoch: 146 [360/1863 (19%)]\tLoss: 14.649707\n",
            "Train Epoch: 146 [480/1863 (26%)]\tLoss: 7.481727\n",
            "Train Epoch: 146 [600/1863 (32%)]\tLoss: 19.336815\n",
            "Train Epoch: 146 [720/1863 (39%)]\tLoss: 3.647046\n",
            "Train Epoch: 146 [840/1863 (45%)]\tLoss: 14.421980\n",
            "Train Epoch: 146 [960/1863 (51%)]\tLoss: 14.939878\n",
            "Train Epoch: 146 [1080/1863 (58%)]\tLoss: 7.668757\n",
            "Train Epoch: 146 [1200/1863 (64%)]\tLoss: 28.029846\n",
            "Train Epoch: 146 [1320/1863 (71%)]\tLoss: 8.416181\n",
            "Train Epoch: 146 [1440/1863 (77%)]\tLoss: 9.206706\n",
            "Train Epoch: 146 [1560/1863 (83%)]\tLoss: 21.723766\n",
            "Train Epoch: 146 [1680/1863 (90%)]\tLoss: 9.445281\n",
            "Train Epoch: 146 [1800/1863 (96%)]\tLoss: 9.637117\n",
            "Training Loss: 11.0892 Acc: 51.6371\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5262, Accuracy: 726/1406 (51.636%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 147/200\n",
            "----------\n",
            "Train Epoch: 147 [0/1863 (0%)]\tLoss: 19.814375\n",
            "Train Epoch: 147 [120/1863 (6%)]\tLoss: 6.187067\n",
            "Train Epoch: 147 [240/1863 (13%)]\tLoss: 14.541270\n",
            "Train Epoch: 147 [360/1863 (19%)]\tLoss: 13.016174\n",
            "Train Epoch: 147 [480/1863 (26%)]\tLoss: 13.046282\n",
            "Train Epoch: 147 [600/1863 (32%)]\tLoss: 17.001436\n",
            "Train Epoch: 147 [720/1863 (39%)]\tLoss: 11.502031\n",
            "Train Epoch: 147 [840/1863 (45%)]\tLoss: 19.751110\n",
            "Train Epoch: 147 [960/1863 (51%)]\tLoss: 1.348940\n",
            "Train Epoch: 147 [1080/1863 (58%)]\tLoss: 9.068182\n",
            "Train Epoch: 147 [1200/1863 (64%)]\tLoss: 8.334002\n",
            "Train Epoch: 147 [1320/1863 (71%)]\tLoss: 7.625172\n",
            "Train Epoch: 147 [1440/1863 (77%)]\tLoss: 4.952499\n",
            "Train Epoch: 147 [1560/1863 (83%)]\tLoss: 10.198534\n",
            "Train Epoch: 147 [1680/1863 (90%)]\tLoss: 6.250150\n",
            "Train Epoch: 147 [1800/1863 (96%)]\tLoss: 2.692466\n",
            "Training Loss: 11.3929 Acc: 50.0268\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4934, Accuracy: 715/1406 (50.853%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 148/200\n",
            "----------\n",
            "Train Epoch: 148 [0/1863 (0%)]\tLoss: 7.758423\n",
            "Train Epoch: 148 [120/1863 (6%)]\tLoss: 6.485208\n",
            "Train Epoch: 148 [240/1863 (13%)]\tLoss: 29.596252\n",
            "Train Epoch: 148 [360/1863 (19%)]\tLoss: 6.051341\n",
            "Train Epoch: 148 [480/1863 (26%)]\tLoss: 7.228978\n",
            "Train Epoch: 148 [600/1863 (32%)]\tLoss: 9.367665\n",
            "Train Epoch: 148 [720/1863 (39%)]\tLoss: 0.146173\n",
            "Train Epoch: 148 [840/1863 (45%)]\tLoss: 11.495607\n",
            "Train Epoch: 148 [960/1863 (51%)]\tLoss: 9.248931\n",
            "Train Epoch: 148 [1080/1863 (58%)]\tLoss: 11.691720\n",
            "Train Epoch: 148 [1200/1863 (64%)]\tLoss: 21.635828\n",
            "Train Epoch: 148 [1320/1863 (71%)]\tLoss: 21.887344\n",
            "Train Epoch: 148 [1440/1863 (77%)]\tLoss: 7.515609\n",
            "Train Epoch: 148 [1560/1863 (83%)]\tLoss: 8.157686\n",
            "Train Epoch: 148 [1680/1863 (90%)]\tLoss: 11.225092\n",
            "Train Epoch: 148 [1800/1863 (96%)]\tLoss: 3.457723\n",
            "Training Loss: 11.2729 Acc: 50.7246\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4249, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 149/200\n",
            "----------\n",
            "Train Epoch: 149 [0/1863 (0%)]\tLoss: 26.901733\n",
            "Train Epoch: 149 [120/1863 (6%)]\tLoss: 5.248790\n",
            "Train Epoch: 149 [240/1863 (13%)]\tLoss: 11.592226\n",
            "Train Epoch: 149 [360/1863 (19%)]\tLoss: 14.551344\n",
            "Train Epoch: 149 [480/1863 (26%)]\tLoss: 10.206388\n",
            "Train Epoch: 149 [600/1863 (32%)]\tLoss: 10.974272\n",
            "Train Epoch: 149 [720/1863 (39%)]\tLoss: 3.268665\n",
            "Train Epoch: 149 [840/1863 (45%)]\tLoss: 8.888499\n",
            "Train Epoch: 149 [960/1863 (51%)]\tLoss: 11.993723\n",
            "Train Epoch: 149 [1080/1863 (58%)]\tLoss: 5.721438\n",
            "Train Epoch: 149 [1200/1863 (64%)]\tLoss: 15.762586\n",
            "Train Epoch: 149 [1320/1863 (71%)]\tLoss: 6.816473\n",
            "Train Epoch: 149 [1440/1863 (77%)]\tLoss: 7.351081\n",
            "Train Epoch: 149 [1560/1863 (83%)]\tLoss: 14.226999\n",
            "Train Epoch: 149 [1680/1863 (90%)]\tLoss: 6.641976\n",
            "Train Epoch: 149 [1800/1863 (96%)]\tLoss: 5.512604\n",
            "Training Loss: 11.1659 Acc: 50.5636\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5941, Accuracy: 726/1406 (51.636%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 150/200\n",
            "----------\n",
            "Train Epoch: 150 [0/1863 (0%)]\tLoss: 28.526560\n",
            "Train Epoch: 150 [120/1863 (6%)]\tLoss: 8.019751\n",
            "Train Epoch: 150 [240/1863 (13%)]\tLoss: 11.464171\n",
            "Train Epoch: 150 [360/1863 (19%)]\tLoss: 10.783270\n",
            "Train Epoch: 150 [480/1863 (26%)]\tLoss: 5.253249\n",
            "Train Epoch: 150 [600/1863 (32%)]\tLoss: 10.097039\n",
            "Train Epoch: 150 [720/1863 (39%)]\tLoss: 16.002136\n",
            "Train Epoch: 150 [840/1863 (45%)]\tLoss: 11.918977\n",
            "Train Epoch: 150 [960/1863 (51%)]\tLoss: 16.750198\n",
            "Train Epoch: 150 [1080/1863 (58%)]\tLoss: 9.035250\n",
            "Train Epoch: 150 [1200/1863 (64%)]\tLoss: 11.927942\n",
            "Train Epoch: 150 [1320/1863 (71%)]\tLoss: 9.610735\n",
            "Train Epoch: 150 [1440/1863 (77%)]\tLoss: 17.259453\n",
            "Train Epoch: 150 [1560/1863 (83%)]\tLoss: 11.679594\n",
            "Train Epoch: 150 [1680/1863 (90%)]\tLoss: 11.402437\n",
            "Train Epoch: 150 [1800/1863 (96%)]\tLoss: 34.094734\n",
            "Training Loss: 11.1933 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4206, Accuracy: 758/1406 (53.912%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 151/200\n",
            "----------\n",
            "Train Epoch: 151 [0/1863 (0%)]\tLoss: 5.932251\n",
            "Train Epoch: 151 [120/1863 (6%)]\tLoss: 5.113723\n",
            "Train Epoch: 151 [240/1863 (13%)]\tLoss: 18.182768\n",
            "Train Epoch: 151 [360/1863 (19%)]\tLoss: 25.424648\n",
            "Train Epoch: 151 [480/1863 (26%)]\tLoss: 16.226858\n",
            "Train Epoch: 151 [600/1863 (32%)]\tLoss: 1.902951\n",
            "Train Epoch: 151 [720/1863 (39%)]\tLoss: 10.360739\n",
            "Train Epoch: 151 [840/1863 (45%)]\tLoss: 8.880224\n",
            "Train Epoch: 151 [960/1863 (51%)]\tLoss: 6.136819\n",
            "Train Epoch: 151 [1080/1863 (58%)]\tLoss: 5.962492\n",
            "Train Epoch: 151 [1200/1863 (64%)]\tLoss: 12.965198\n",
            "Train Epoch: 151 [1320/1863 (71%)]\tLoss: 11.976474\n",
            "Train Epoch: 151 [1440/1863 (77%)]\tLoss: 10.311026\n",
            "Train Epoch: 151 [1560/1863 (83%)]\tLoss: 3.696814\n",
            "Train Epoch: 151 [1680/1863 (90%)]\tLoss: 8.837209\n",
            "Train Epoch: 151 [1800/1863 (96%)]\tLoss: 19.326260\n",
            "Training Loss: 11.0813 Acc: 50.4563\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5271, Accuracy: 715/1406 (50.853%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 152/200\n",
            "----------\n",
            "Train Epoch: 152 [0/1863 (0%)]\tLoss: 12.640562\n",
            "Train Epoch: 152 [120/1863 (6%)]\tLoss: 3.973307\n",
            "Train Epoch: 152 [240/1863 (13%)]\tLoss: 11.589468\n",
            "Train Epoch: 152 [360/1863 (19%)]\tLoss: 6.971520\n",
            "Train Epoch: 152 [480/1863 (26%)]\tLoss: 1.417985\n",
            "Train Epoch: 152 [600/1863 (32%)]\tLoss: 6.179046\n",
            "Train Epoch: 152 [720/1863 (39%)]\tLoss: 4.737580\n",
            "Train Epoch: 152 [840/1863 (45%)]\tLoss: 5.826756\n",
            "Train Epoch: 152 [960/1863 (51%)]\tLoss: 6.451861\n",
            "Train Epoch: 152 [1080/1863 (58%)]\tLoss: 13.899553\n",
            "Train Epoch: 152 [1200/1863 (64%)]\tLoss: 9.640989\n",
            "Train Epoch: 152 [1320/1863 (71%)]\tLoss: 14.035463\n",
            "Train Epoch: 152 [1440/1863 (77%)]\tLoss: 5.018672\n",
            "Train Epoch: 152 [1560/1863 (83%)]\tLoss: 6.716400\n",
            "Train Epoch: 152 [1680/1863 (90%)]\tLoss: 21.806120\n",
            "Train Epoch: 152 [1800/1863 (96%)]\tLoss: 12.075703\n",
            "Training Loss: 11.0988 Acc: 50.9393\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4312, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 153/200\n",
            "----------\n",
            "Train Epoch: 153 [0/1863 (0%)]\tLoss: 7.249014\n",
            "Train Epoch: 153 [120/1863 (6%)]\tLoss: 34.685608\n",
            "Train Epoch: 153 [240/1863 (13%)]\tLoss: 8.647174\n",
            "Train Epoch: 153 [360/1863 (19%)]\tLoss: 1.114006\n",
            "Train Epoch: 153 [480/1863 (26%)]\tLoss: 24.261648\n",
            "Train Epoch: 153 [600/1863 (32%)]\tLoss: 28.929302\n",
            "Train Epoch: 153 [720/1863 (39%)]\tLoss: 8.959205\n",
            "Train Epoch: 153 [840/1863 (45%)]\tLoss: 8.578049\n",
            "Train Epoch: 153 [960/1863 (51%)]\tLoss: 4.511395\n",
            "Train Epoch: 153 [1080/1863 (58%)]\tLoss: 12.039808\n",
            "Train Epoch: 153 [1200/1863 (64%)]\tLoss: 3.109087\n",
            "Train Epoch: 153 [1320/1863 (71%)]\tLoss: 16.174467\n",
            "Train Epoch: 153 [1440/1863 (77%)]\tLoss: 8.668173\n",
            "Train Epoch: 153 [1560/1863 (83%)]\tLoss: 10.395778\n",
            "Train Epoch: 153 [1680/1863 (90%)]\tLoss: 4.975904\n",
            "Train Epoch: 153 [1800/1863 (96%)]\tLoss: 27.866749\n",
            "Training Loss: 11.1409 Acc: 51.6908\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4507, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 154/200\n",
            "----------\n",
            "Train Epoch: 154 [0/1863 (0%)]\tLoss: 9.382541\n",
            "Train Epoch: 154 [120/1863 (6%)]\tLoss: 16.488354\n",
            "Train Epoch: 154 [240/1863 (13%)]\tLoss: 2.773574\n",
            "Train Epoch: 154 [360/1863 (19%)]\tLoss: 13.553375\n",
            "Train Epoch: 154 [480/1863 (26%)]\tLoss: 3.875137\n",
            "Train Epoch: 154 [600/1863 (32%)]\tLoss: 9.604565\n",
            "Train Epoch: 154 [720/1863 (39%)]\tLoss: 1.364587\n",
            "Train Epoch: 154 [840/1863 (45%)]\tLoss: 2.937302\n",
            "Train Epoch: 154 [960/1863 (51%)]\tLoss: 19.167530\n",
            "Train Epoch: 154 [1080/1863 (58%)]\tLoss: 5.448256\n",
            "Train Epoch: 154 [1200/1863 (64%)]\tLoss: 4.877563\n",
            "Train Epoch: 154 [1320/1863 (71%)]\tLoss: 8.050852\n",
            "Train Epoch: 154 [1440/1863 (77%)]\tLoss: 3.943082\n",
            "Train Epoch: 154 [1560/1863 (83%)]\tLoss: 8.905813\n",
            "Train Epoch: 154 [1680/1863 (90%)]\tLoss: 20.758320\n",
            "Train Epoch: 154 [1800/1863 (96%)]\tLoss: 10.388398\n",
            "Training Loss: 10.7970 Acc: 50.5636\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4136, Accuracy: 842/1406 (59.886%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 155/200\n",
            "----------\n",
            "Train Epoch: 155 [0/1863 (0%)]\tLoss: 14.284607\n",
            "Train Epoch: 155 [120/1863 (6%)]\tLoss: 3.990377\n",
            "Train Epoch: 155 [240/1863 (13%)]\tLoss: 27.331060\n",
            "Train Epoch: 155 [360/1863 (19%)]\tLoss: 33.635460\n",
            "Train Epoch: 155 [480/1863 (26%)]\tLoss: 12.230260\n",
            "Train Epoch: 155 [600/1863 (32%)]\tLoss: 21.301977\n",
            "Train Epoch: 155 [720/1863 (39%)]\tLoss: 13.648247\n",
            "Train Epoch: 155 [840/1863 (45%)]\tLoss: 17.351751\n",
            "Train Epoch: 155 [960/1863 (51%)]\tLoss: 1.907569\n",
            "Train Epoch: 155 [1080/1863 (58%)]\tLoss: 18.369627\n",
            "Train Epoch: 155 [1200/1863 (64%)]\tLoss: 2.153475\n",
            "Train Epoch: 155 [1320/1863 (71%)]\tLoss: 15.840083\n",
            "Train Epoch: 155 [1440/1863 (77%)]\tLoss: 13.606535\n",
            "Train Epoch: 155 [1560/1863 (83%)]\tLoss: 2.666579\n",
            "Train Epoch: 155 [1680/1863 (90%)]\tLoss: 5.902354\n",
            "Train Epoch: 155 [1800/1863 (96%)]\tLoss: 15.369057\n",
            "Training Loss: 11.1358 Acc: 50.9930\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6186, Accuracy: 739/1406 (52.560%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 156/200\n",
            "----------\n",
            "Train Epoch: 156 [0/1863 (0%)]\tLoss: 13.485044\n",
            "Train Epoch: 156 [120/1863 (6%)]\tLoss: 15.155975\n",
            "Train Epoch: 156 [240/1863 (13%)]\tLoss: 21.453190\n",
            "Train Epoch: 156 [360/1863 (19%)]\tLoss: 6.219322\n",
            "Train Epoch: 156 [480/1863 (26%)]\tLoss: 9.134604\n",
            "Train Epoch: 156 [600/1863 (32%)]\tLoss: 8.209951\n",
            "Train Epoch: 156 [720/1863 (39%)]\tLoss: 13.741762\n",
            "Train Epoch: 156 [840/1863 (45%)]\tLoss: 19.307892\n",
            "Train Epoch: 156 [960/1863 (51%)]\tLoss: 6.420753\n",
            "Train Epoch: 156 [1080/1863 (58%)]\tLoss: 15.160357\n",
            "Train Epoch: 156 [1200/1863 (64%)]\tLoss: 15.414444\n",
            "Train Epoch: 156 [1320/1863 (71%)]\tLoss: 12.940724\n",
            "Train Epoch: 156 [1440/1863 (77%)]\tLoss: 8.680124\n",
            "Train Epoch: 156 [1560/1863 (83%)]\tLoss: 3.406032\n",
            "Train Epoch: 156 [1680/1863 (90%)]\tLoss: 21.373941\n",
            "Train Epoch: 156 [1800/1863 (96%)]\tLoss: 12.267111\n",
            "Training Loss: 11.3099 Acc: 50.7246\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5491, Accuracy: 713/1406 (50.711%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 157/200\n",
            "----------\n",
            "Train Epoch: 157 [0/1863 (0%)]\tLoss: 3.889798\n",
            "Train Epoch: 157 [120/1863 (6%)]\tLoss: 9.163239\n",
            "Train Epoch: 157 [240/1863 (13%)]\tLoss: 9.274463\n",
            "Train Epoch: 157 [360/1863 (19%)]\tLoss: 23.185898\n",
            "Train Epoch: 157 [480/1863 (26%)]\tLoss: 12.808683\n",
            "Train Epoch: 157 [600/1863 (32%)]\tLoss: 9.249140\n",
            "Train Epoch: 157 [720/1863 (39%)]\tLoss: 12.939955\n",
            "Train Epoch: 157 [840/1863 (45%)]\tLoss: 5.736489\n",
            "Train Epoch: 157 [960/1863 (51%)]\tLoss: 18.632030\n",
            "Train Epoch: 157 [1080/1863 (58%)]\tLoss: 0.902577\n",
            "Train Epoch: 157 [1200/1863 (64%)]\tLoss: 3.772036\n",
            "Train Epoch: 157 [1320/1863 (71%)]\tLoss: 2.416119\n",
            "Train Epoch: 157 [1440/1863 (77%)]\tLoss: 17.238058\n",
            "Train Epoch: 157 [1560/1863 (83%)]\tLoss: 17.853785\n",
            "Train Epoch: 157 [1680/1863 (90%)]\tLoss: 15.255821\n",
            "Train Epoch: 157 [1800/1863 (96%)]\tLoss: 6.958444\n",
            "Training Loss: 11.0973 Acc: 51.3688\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5506, Accuracy: 721/1406 (51.280%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 158/200\n",
            "----------\n",
            "Train Epoch: 158 [0/1863 (0%)]\tLoss: 10.086752\n",
            "Train Epoch: 158 [120/1863 (6%)]\tLoss: 19.181988\n",
            "Train Epoch: 158 [240/1863 (13%)]\tLoss: 17.811230\n",
            "Train Epoch: 158 [360/1863 (19%)]\tLoss: 12.174383\n",
            "Train Epoch: 158 [480/1863 (26%)]\tLoss: 12.953577\n",
            "Train Epoch: 158 [600/1863 (32%)]\tLoss: 8.122887\n",
            "Train Epoch: 158 [720/1863 (39%)]\tLoss: 15.005396\n",
            "Train Epoch: 158 [840/1863 (45%)]\tLoss: 15.943056\n",
            "Train Epoch: 158 [960/1863 (51%)]\tLoss: 14.696398\n",
            "Train Epoch: 158 [1080/1863 (58%)]\tLoss: 5.242538\n",
            "Train Epoch: 158 [1200/1863 (64%)]\tLoss: 1.999452\n",
            "Train Epoch: 158 [1320/1863 (71%)]\tLoss: 5.931354\n",
            "Train Epoch: 158 [1440/1863 (77%)]\tLoss: 6.531396\n",
            "Train Epoch: 158 [1560/1863 (83%)]\tLoss: 9.462561\n",
            "Train Epoch: 158 [1680/1863 (90%)]\tLoss: 5.746318\n",
            "Train Epoch: 158 [1800/1863 (96%)]\tLoss: 6.316988\n",
            "Training Loss: 11.1416 Acc: 49.9732\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5864, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 159/200\n",
            "----------\n",
            "Train Epoch: 159 [0/1863 (0%)]\tLoss: 5.981055\n",
            "Train Epoch: 159 [120/1863 (6%)]\tLoss: 19.314554\n",
            "Train Epoch: 159 [240/1863 (13%)]\tLoss: 13.454994\n",
            "Train Epoch: 159 [360/1863 (19%)]\tLoss: 4.424666\n",
            "Train Epoch: 159 [480/1863 (26%)]\tLoss: 20.108616\n",
            "Train Epoch: 159 [600/1863 (32%)]\tLoss: 13.857058\n",
            "Train Epoch: 159 [720/1863 (39%)]\tLoss: 4.929032\n",
            "Train Epoch: 159 [840/1863 (45%)]\tLoss: 20.542513\n",
            "Train Epoch: 159 [960/1863 (51%)]\tLoss: 20.893408\n",
            "Train Epoch: 159 [1080/1863 (58%)]\tLoss: 8.365004\n",
            "Train Epoch: 159 [1200/1863 (64%)]\tLoss: 9.035353\n",
            "Train Epoch: 159 [1320/1863 (71%)]\tLoss: 5.592368\n",
            "Train Epoch: 159 [1440/1863 (77%)]\tLoss: 16.807087\n",
            "Train Epoch: 159 [1560/1863 (83%)]\tLoss: 19.037386\n",
            "Train Epoch: 159 [1680/1863 (90%)]\tLoss: 2.941976\n",
            "Train Epoch: 159 [1800/1863 (96%)]\tLoss: 15.095972\n",
            "Training Loss: 10.9659 Acc: 51.2614\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5532, Accuracy: 729/1406 (51.849%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 160/200\n",
            "----------\n",
            "Train Epoch: 160 [0/1863 (0%)]\tLoss: 6.859857\n",
            "Train Epoch: 160 [120/1863 (6%)]\tLoss: 9.790759\n",
            "Train Epoch: 160 [240/1863 (13%)]\tLoss: 11.026883\n",
            "Train Epoch: 160 [360/1863 (19%)]\tLoss: 15.572920\n",
            "Train Epoch: 160 [480/1863 (26%)]\tLoss: 24.214758\n",
            "Train Epoch: 160 [600/1863 (32%)]\tLoss: 16.419003\n",
            "Train Epoch: 160 [720/1863 (39%)]\tLoss: 3.205627\n",
            "Train Epoch: 160 [840/1863 (45%)]\tLoss: 1.125172\n",
            "Train Epoch: 160 [960/1863 (51%)]\tLoss: 12.780424\n",
            "Train Epoch: 160 [1080/1863 (58%)]\tLoss: 8.031837\n",
            "Train Epoch: 160 [1200/1863 (64%)]\tLoss: 7.906421\n",
            "Train Epoch: 160 [1320/1863 (71%)]\tLoss: 5.730289\n",
            "Train Epoch: 160 [1440/1863 (77%)]\tLoss: 18.860472\n",
            "Train Epoch: 160 [1560/1863 (83%)]\tLoss: 6.111287\n",
            "Train Epoch: 160 [1680/1863 (90%)]\tLoss: 3.573494\n",
            "Train Epoch: 160 [1800/1863 (96%)]\tLoss: 6.793429\n",
            "Training Loss: 11.1164 Acc: 51.1541\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4500, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 161/200\n",
            "----------\n",
            "Train Epoch: 161 [0/1863 (0%)]\tLoss: 3.504108\n",
            "Train Epoch: 161 [120/1863 (6%)]\tLoss: 15.158252\n",
            "Train Epoch: 161 [240/1863 (13%)]\tLoss: 10.380371\n",
            "Train Epoch: 161 [360/1863 (19%)]\tLoss: 5.400861\n",
            "Train Epoch: 161 [480/1863 (26%)]\tLoss: 21.244293\n",
            "Train Epoch: 161 [600/1863 (32%)]\tLoss: 10.045695\n",
            "Train Epoch: 161 [720/1863 (39%)]\tLoss: 13.508530\n",
            "Train Epoch: 161 [840/1863 (45%)]\tLoss: 5.513292\n",
            "Train Epoch: 161 [960/1863 (51%)]\tLoss: 10.582357\n",
            "Train Epoch: 161 [1080/1863 (58%)]\tLoss: 19.420765\n",
            "Train Epoch: 161 [1200/1863 (64%)]\tLoss: 5.595855\n",
            "Train Epoch: 161 [1320/1863 (71%)]\tLoss: 15.616414\n",
            "Train Epoch: 161 [1440/1863 (77%)]\tLoss: 4.937801\n",
            "Train Epoch: 161 [1560/1863 (83%)]\tLoss: 8.103184\n",
            "Train Epoch: 161 [1680/1863 (90%)]\tLoss: 0.069125\n",
            "Train Epoch: 161 [1800/1863 (96%)]\tLoss: 10.744192\n",
            "Training Loss: 10.9606 Acc: 51.3151\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4962, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 162/200\n",
            "----------\n",
            "Train Epoch: 162 [0/1863 (0%)]\tLoss: 10.675737\n",
            "Train Epoch: 162 [120/1863 (6%)]\tLoss: 21.589010\n",
            "Train Epoch: 162 [240/1863 (13%)]\tLoss: 8.416312\n",
            "Train Epoch: 162 [360/1863 (19%)]\tLoss: 1.906349\n",
            "Train Epoch: 162 [480/1863 (26%)]\tLoss: 5.715326\n",
            "Train Epoch: 162 [600/1863 (32%)]\tLoss: 3.887762\n",
            "Train Epoch: 162 [720/1863 (39%)]\tLoss: 5.600978\n",
            "Train Epoch: 162 [840/1863 (45%)]\tLoss: 8.831500\n",
            "Train Epoch: 162 [960/1863 (51%)]\tLoss: 3.646101\n",
            "Train Epoch: 162 [1080/1863 (58%)]\tLoss: 20.827877\n",
            "Train Epoch: 162 [1200/1863 (64%)]\tLoss: 4.402566\n",
            "Train Epoch: 162 [1320/1863 (71%)]\tLoss: 4.263309\n",
            "Train Epoch: 162 [1440/1863 (77%)]\tLoss: 5.423921\n",
            "Train Epoch: 162 [1560/1863 (83%)]\tLoss: 1.013330\n",
            "Train Epoch: 162 [1680/1863 (90%)]\tLoss: 11.391335\n",
            "Train Epoch: 162 [1800/1863 (96%)]\tLoss: 23.118885\n",
            "Training Loss: 11.1171 Acc: 50.2415\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5388, Accuracy: 740/1406 (52.632%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 163/200\n",
            "----------\n",
            "Train Epoch: 163 [0/1863 (0%)]\tLoss: 3.470948\n",
            "Train Epoch: 163 [120/1863 (6%)]\tLoss: 5.774780\n",
            "Train Epoch: 163 [240/1863 (13%)]\tLoss: 26.669592\n",
            "Train Epoch: 163 [360/1863 (19%)]\tLoss: 2.838942\n",
            "Train Epoch: 163 [480/1863 (26%)]\tLoss: 9.264881\n",
            "Train Epoch: 163 [600/1863 (32%)]\tLoss: 7.791373\n",
            "Train Epoch: 163 [720/1863 (39%)]\tLoss: 11.363055\n",
            "Train Epoch: 163 [840/1863 (45%)]\tLoss: 16.240763\n",
            "Train Epoch: 163 [960/1863 (51%)]\tLoss: 20.681976\n",
            "Train Epoch: 163 [1080/1863 (58%)]\tLoss: 33.323498\n",
            "Train Epoch: 163 [1200/1863 (64%)]\tLoss: 3.416177\n",
            "Train Epoch: 163 [1320/1863 (71%)]\tLoss: 2.424185\n",
            "Train Epoch: 163 [1440/1863 (77%)]\tLoss: 7.191621\n",
            "Train Epoch: 163 [1560/1863 (83%)]\tLoss: 18.588816\n",
            "Train Epoch: 163 [1680/1863 (90%)]\tLoss: 11.087063\n",
            "Train Epoch: 163 [1800/1863 (96%)]\tLoss: 16.743713\n",
            "Training Loss: 11.6661 Acc: 50.3489\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4824, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 164/200\n",
            "----------\n",
            "Train Epoch: 164 [0/1863 (0%)]\tLoss: 14.879745\n",
            "Train Epoch: 164 [120/1863 (6%)]\tLoss: 8.948707\n",
            "Train Epoch: 164 [240/1863 (13%)]\tLoss: 10.666687\n",
            "Train Epoch: 164 [360/1863 (19%)]\tLoss: 13.247678\n",
            "Train Epoch: 164 [480/1863 (26%)]\tLoss: 12.865492\n",
            "Train Epoch: 164 [600/1863 (32%)]\tLoss: 7.799838\n",
            "Train Epoch: 164 [720/1863 (39%)]\tLoss: 9.081814\n",
            "Train Epoch: 164 [840/1863 (45%)]\tLoss: 3.619667\n",
            "Train Epoch: 164 [960/1863 (51%)]\tLoss: 12.280042\n",
            "Train Epoch: 164 [1080/1863 (58%)]\tLoss: 15.561991\n",
            "Train Epoch: 164 [1200/1863 (64%)]\tLoss: 24.655962\n",
            "Train Epoch: 164 [1320/1863 (71%)]\tLoss: 13.649984\n",
            "Train Epoch: 164 [1440/1863 (77%)]\tLoss: 22.806562\n",
            "Train Epoch: 164 [1560/1863 (83%)]\tLoss: 3.672818\n",
            "Train Epoch: 164 [1680/1863 (90%)]\tLoss: 8.323043\n",
            "Train Epoch: 164 [1800/1863 (96%)]\tLoss: 11.846751\n",
            "Training Loss: 11.1481 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5713, Accuracy: 715/1406 (50.853%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 165/200\n",
            "----------\n",
            "Train Epoch: 165 [0/1863 (0%)]\tLoss: 5.846012\n",
            "Train Epoch: 165 [120/1863 (6%)]\tLoss: 4.514898\n",
            "Train Epoch: 165 [240/1863 (13%)]\tLoss: 11.386675\n",
            "Train Epoch: 165 [360/1863 (19%)]\tLoss: 6.001343\n",
            "Train Epoch: 165 [480/1863 (26%)]\tLoss: 9.451246\n",
            "Train Epoch: 165 [600/1863 (32%)]\tLoss: 8.494554\n",
            "Train Epoch: 165 [720/1863 (39%)]\tLoss: 9.296697\n",
            "Train Epoch: 165 [840/1863 (45%)]\tLoss: 11.155157\n",
            "Train Epoch: 165 [960/1863 (51%)]\tLoss: 21.081928\n",
            "Train Epoch: 165 [1080/1863 (58%)]\tLoss: 12.843259\n",
            "Train Epoch: 165 [1200/1863 (64%)]\tLoss: 18.285267\n",
            "Train Epoch: 165 [1320/1863 (71%)]\tLoss: 12.612234\n",
            "Train Epoch: 165 [1440/1863 (77%)]\tLoss: 3.401462\n",
            "Train Epoch: 165 [1560/1863 (83%)]\tLoss: 17.505030\n",
            "Train Epoch: 165 [1680/1863 (90%)]\tLoss: 23.075710\n",
            "Train Epoch: 165 [1800/1863 (96%)]\tLoss: 5.791189\n",
            "Training Loss: 10.9645 Acc: 51.3688\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5523, Accuracy: 721/1406 (51.280%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 166/200\n",
            "----------\n",
            "Train Epoch: 166 [0/1863 (0%)]\tLoss: 13.564775\n",
            "Train Epoch: 166 [120/1863 (6%)]\tLoss: 14.034851\n",
            "Train Epoch: 166 [240/1863 (13%)]\tLoss: 28.488165\n",
            "Train Epoch: 166 [360/1863 (19%)]\tLoss: 10.929420\n",
            "Train Epoch: 166 [480/1863 (26%)]\tLoss: 5.222515\n",
            "Train Epoch: 166 [600/1863 (32%)]\tLoss: 12.036030\n",
            "Train Epoch: 166 [720/1863 (39%)]\tLoss: 22.296274\n",
            "Train Epoch: 166 [840/1863 (45%)]\tLoss: 3.186162\n",
            "Train Epoch: 166 [960/1863 (51%)]\tLoss: 12.948706\n",
            "Train Epoch: 166 [1080/1863 (58%)]\tLoss: 2.721723\n",
            "Train Epoch: 166 [1200/1863 (64%)]\tLoss: 17.581160\n",
            "Train Epoch: 166 [1320/1863 (71%)]\tLoss: 16.156221\n",
            "Train Epoch: 166 [1440/1863 (77%)]\tLoss: 15.427351\n",
            "Train Epoch: 166 [1560/1863 (83%)]\tLoss: 24.255882\n",
            "Train Epoch: 166 [1680/1863 (90%)]\tLoss: 2.514043\n",
            "Train Epoch: 166 [1800/1863 (96%)]\tLoss: 13.185918\n",
            "Training Loss: 11.6374 Acc: 50.1342\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4095, Accuracy: 704/1406 (50.071%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 167/200\n",
            "----------\n",
            "Train Epoch: 167 [0/1863 (0%)]\tLoss: 15.637881\n",
            "Train Epoch: 167 [120/1863 (6%)]\tLoss: 29.464060\n",
            "Train Epoch: 167 [240/1863 (13%)]\tLoss: 0.877620\n",
            "Train Epoch: 167 [360/1863 (19%)]\tLoss: 9.424444\n",
            "Train Epoch: 167 [480/1863 (26%)]\tLoss: 1.429364\n",
            "Train Epoch: 167 [600/1863 (32%)]\tLoss: 3.818776\n",
            "Train Epoch: 167 [720/1863 (39%)]\tLoss: 9.889384\n",
            "Train Epoch: 167 [840/1863 (45%)]\tLoss: 5.786667\n",
            "Train Epoch: 167 [960/1863 (51%)]\tLoss: 2.193782\n",
            "Train Epoch: 167 [1080/1863 (58%)]\tLoss: 9.559621\n",
            "Train Epoch: 167 [1200/1863 (64%)]\tLoss: 6.751817\n",
            "Train Epoch: 167 [1320/1863 (71%)]\tLoss: 6.535522\n",
            "Train Epoch: 167 [1440/1863 (77%)]\tLoss: 7.014509\n",
            "Train Epoch: 167 [1560/1863 (83%)]\tLoss: 14.407219\n",
            "Train Epoch: 167 [1680/1863 (90%)]\tLoss: 9.369495\n",
            "Train Epoch: 167 [1800/1863 (96%)]\tLoss: 8.902041\n",
            "Training Loss: 11.4457 Acc: 50.8320\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4812, Accuracy: 761/1406 (54.125%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 168/200\n",
            "----------\n",
            "Train Epoch: 168 [0/1863 (0%)]\tLoss: 11.392384\n",
            "Train Epoch: 168 [120/1863 (6%)]\tLoss: 30.349804\n",
            "Train Epoch: 168 [240/1863 (13%)]\tLoss: 11.095236\n",
            "Train Epoch: 168 [360/1863 (19%)]\tLoss: 3.636025\n",
            "Train Epoch: 168 [480/1863 (26%)]\tLoss: 5.022793\n",
            "Train Epoch: 168 [600/1863 (32%)]\tLoss: 5.219049\n",
            "Train Epoch: 168 [720/1863 (39%)]\tLoss: 20.747553\n",
            "Train Epoch: 168 [840/1863 (45%)]\tLoss: 24.778200\n",
            "Train Epoch: 168 [960/1863 (51%)]\tLoss: 8.876165\n",
            "Train Epoch: 168 [1080/1863 (58%)]\tLoss: 18.600178\n",
            "Train Epoch: 168 [1200/1863 (64%)]\tLoss: 16.799585\n",
            "Train Epoch: 168 [1320/1863 (71%)]\tLoss: 15.392835\n",
            "Train Epoch: 168 [1440/1863 (77%)]\tLoss: 15.126053\n",
            "Train Epoch: 168 [1560/1863 (83%)]\tLoss: 16.583370\n",
            "Train Epoch: 168 [1680/1863 (90%)]\tLoss: 12.132461\n",
            "Train Epoch: 168 [1800/1863 (96%)]\tLoss: 12.981323\n",
            "Training Loss: 11.1927 Acc: 49.3827\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5167, Accuracy: 717/1406 (50.996%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 169/200\n",
            "----------\n",
            "Train Epoch: 169 [0/1863 (0%)]\tLoss: 2.751631\n",
            "Train Epoch: 169 [120/1863 (6%)]\tLoss: 9.488913\n",
            "Train Epoch: 169 [240/1863 (13%)]\tLoss: 11.456602\n",
            "Train Epoch: 169 [360/1863 (19%)]\tLoss: 8.301161\n",
            "Train Epoch: 169 [480/1863 (26%)]\tLoss: 6.041541\n",
            "Train Epoch: 169 [600/1863 (32%)]\tLoss: 5.854736\n",
            "Train Epoch: 169 [720/1863 (39%)]\tLoss: 16.806684\n",
            "Train Epoch: 169 [840/1863 (45%)]\tLoss: 21.509823\n",
            "Train Epoch: 169 [960/1863 (51%)]\tLoss: 11.996965\n",
            "Train Epoch: 169 [1080/1863 (58%)]\tLoss: 4.637403\n",
            "Train Epoch: 169 [1200/1863 (64%)]\tLoss: 7.463988\n",
            "Train Epoch: 169 [1320/1863 (71%)]\tLoss: 7.330207\n",
            "Train Epoch: 169 [1440/1863 (77%)]\tLoss: 6.520901\n",
            "Train Epoch: 169 [1560/1863 (83%)]\tLoss: 24.448980\n",
            "Train Epoch: 169 [1680/1863 (90%)]\tLoss: 11.328787\n",
            "Train Epoch: 169 [1800/1863 (96%)]\tLoss: 6.000588\n",
            "Training Loss: 11.5108 Acc: 50.0268\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6780, Accuracy: 721/1406 (51.280%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 170/200\n",
            "----------\n",
            "Train Epoch: 170 [0/1863 (0%)]\tLoss: 7.004053\n",
            "Train Epoch: 170 [120/1863 (6%)]\tLoss: 12.642654\n",
            "Train Epoch: 170 [240/1863 (13%)]\tLoss: 3.079819\n",
            "Train Epoch: 170 [360/1863 (19%)]\tLoss: 12.586336\n",
            "Train Epoch: 170 [480/1863 (26%)]\tLoss: 3.399135\n",
            "Train Epoch: 170 [600/1863 (32%)]\tLoss: 16.113644\n",
            "Train Epoch: 170 [720/1863 (39%)]\tLoss: 19.469046\n",
            "Train Epoch: 170 [840/1863 (45%)]\tLoss: 20.862125\n",
            "Train Epoch: 170 [960/1863 (51%)]\tLoss: 21.260250\n",
            "Train Epoch: 170 [1080/1863 (58%)]\tLoss: 9.505984\n",
            "Train Epoch: 170 [1200/1863 (64%)]\tLoss: 19.102551\n",
            "Train Epoch: 170 [1320/1863 (71%)]\tLoss: 20.133764\n",
            "Train Epoch: 170 [1440/1863 (77%)]\tLoss: 3.144389\n",
            "Train Epoch: 170 [1560/1863 (83%)]\tLoss: 15.887075\n",
            "Train Epoch: 170 [1680/1863 (90%)]\tLoss: 6.938778\n",
            "Train Epoch: 170 [1800/1863 (96%)]\tLoss: 5.796343\n",
            "Training Loss: 11.0274 Acc: 50.6173\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4637, Accuracy: 704/1406 (50.071%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 171/200\n",
            "----------\n",
            "Train Epoch: 171 [0/1863 (0%)]\tLoss: 27.392752\n",
            "Train Epoch: 171 [120/1863 (6%)]\tLoss: 10.250514\n",
            "Train Epoch: 171 [240/1863 (13%)]\tLoss: 4.305472\n",
            "Train Epoch: 171 [360/1863 (19%)]\tLoss: 13.623209\n",
            "Train Epoch: 171 [480/1863 (26%)]\tLoss: 12.927800\n",
            "Train Epoch: 171 [600/1863 (32%)]\tLoss: 1.691339\n",
            "Train Epoch: 171 [720/1863 (39%)]\tLoss: 10.565674\n",
            "Train Epoch: 171 [840/1863 (45%)]\tLoss: 7.144532\n",
            "Train Epoch: 171 [960/1863 (51%)]\tLoss: 9.262471\n",
            "Train Epoch: 171 [1080/1863 (58%)]\tLoss: 4.279096\n",
            "Train Epoch: 171 [1200/1863 (64%)]\tLoss: 26.178345\n",
            "Train Epoch: 171 [1320/1863 (71%)]\tLoss: 11.975114\n",
            "Train Epoch: 171 [1440/1863 (77%)]\tLoss: 4.868014\n",
            "Train Epoch: 171 [1560/1863 (83%)]\tLoss: 10.505013\n",
            "Train Epoch: 171 [1680/1863 (90%)]\tLoss: 4.342382\n",
            "Train Epoch: 171 [1800/1863 (96%)]\tLoss: 0.047481\n",
            "Training Loss: 10.8853 Acc: 51.2077\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4993, Accuracy: 717/1406 (50.996%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 172/200\n",
            "----------\n",
            "Train Epoch: 172 [0/1863 (0%)]\tLoss: 40.177055\n",
            "Train Epoch: 172 [120/1863 (6%)]\tLoss: 4.703300\n",
            "Train Epoch: 172 [240/1863 (13%)]\tLoss: 15.930695\n",
            "Train Epoch: 172 [360/1863 (19%)]\tLoss: 15.608218\n",
            "Train Epoch: 172 [480/1863 (26%)]\tLoss: 10.683154\n",
            "Train Epoch: 172 [600/1863 (32%)]\tLoss: 13.895319\n",
            "Train Epoch: 172 [720/1863 (39%)]\tLoss: 17.479570\n",
            "Train Epoch: 172 [840/1863 (45%)]\tLoss: 15.085032\n",
            "Train Epoch: 172 [960/1863 (51%)]\tLoss: 1.833276\n",
            "Train Epoch: 172 [1080/1863 (58%)]\tLoss: 19.145945\n",
            "Train Epoch: 172 [1200/1863 (64%)]\tLoss: 6.178566\n",
            "Train Epoch: 172 [1320/1863 (71%)]\tLoss: 18.917166\n",
            "Train Epoch: 172 [1440/1863 (77%)]\tLoss: 17.049683\n",
            "Train Epoch: 172 [1560/1863 (83%)]\tLoss: 8.775327\n",
            "Train Epoch: 172 [1680/1863 (90%)]\tLoss: 15.623621\n",
            "Train Epoch: 172 [1800/1863 (96%)]\tLoss: 9.049743\n",
            "Training Loss: 10.9976 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5422, Accuracy: 714/1406 (50.782%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 173/200\n",
            "----------\n",
            "Train Epoch: 173 [0/1863 (0%)]\tLoss: 4.740433\n",
            "Train Epoch: 173 [120/1863 (6%)]\tLoss: 3.780464\n",
            "Train Epoch: 173 [240/1863 (13%)]\tLoss: 4.967937\n",
            "Train Epoch: 173 [360/1863 (19%)]\tLoss: 17.978153\n",
            "Train Epoch: 173 [480/1863 (26%)]\tLoss: 5.600768\n",
            "Train Epoch: 173 [600/1863 (32%)]\tLoss: 2.904661\n",
            "Train Epoch: 173 [720/1863 (39%)]\tLoss: 9.239862\n",
            "Train Epoch: 173 [840/1863 (45%)]\tLoss: 8.108190\n",
            "Train Epoch: 173 [960/1863 (51%)]\tLoss: 3.223933\n",
            "Train Epoch: 173 [1080/1863 (58%)]\tLoss: 15.498095\n",
            "Train Epoch: 173 [1200/1863 (64%)]\tLoss: 5.760539\n",
            "Train Epoch: 173 [1320/1863 (71%)]\tLoss: 6.959523\n",
            "Train Epoch: 173 [1440/1863 (77%)]\tLoss: 13.419586\n",
            "Train Epoch: 173 [1560/1863 (83%)]\tLoss: 15.638501\n",
            "Train Epoch: 173 [1680/1863 (90%)]\tLoss: 4.671591\n",
            "Train Epoch: 173 [1800/1863 (96%)]\tLoss: 10.621380\n",
            "Training Loss: 11.1015 Acc: 50.4026\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6137, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 174/200\n",
            "----------\n",
            "Train Epoch: 174 [0/1863 (0%)]\tLoss: 6.276853\n",
            "Train Epoch: 174 [120/1863 (6%)]\tLoss: 25.089235\n",
            "Train Epoch: 174 [240/1863 (13%)]\tLoss: 14.140249\n",
            "Train Epoch: 174 [360/1863 (19%)]\tLoss: 7.915671\n",
            "Train Epoch: 174 [480/1863 (26%)]\tLoss: 6.208417\n",
            "Train Epoch: 174 [600/1863 (32%)]\tLoss: 18.275305\n",
            "Train Epoch: 174 [720/1863 (39%)]\tLoss: 1.409917\n",
            "Train Epoch: 174 [840/1863 (45%)]\tLoss: 4.972484\n",
            "Train Epoch: 174 [960/1863 (51%)]\tLoss: 6.460416\n",
            "Train Epoch: 174 [1080/1863 (58%)]\tLoss: 15.907248\n",
            "Train Epoch: 174 [1200/1863 (64%)]\tLoss: 18.261410\n",
            "Train Epoch: 174 [1320/1863 (71%)]\tLoss: 14.132932\n",
            "Train Epoch: 174 [1440/1863 (77%)]\tLoss: 16.942226\n",
            "Train Epoch: 174 [1560/1863 (83%)]\tLoss: 5.054596\n",
            "Train Epoch: 174 [1680/1863 (90%)]\tLoss: 6.102410\n",
            "Train Epoch: 174 [1800/1863 (96%)]\tLoss: 5.076000\n",
            "Training Loss: 11.0009 Acc: 50.3489\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6945, Accuracy: 708/1406 (50.356%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 175/200\n",
            "----------\n",
            "Train Epoch: 175 [0/1863 (0%)]\tLoss: 35.124233\n",
            "Train Epoch: 175 [120/1863 (6%)]\tLoss: 13.397731\n",
            "Train Epoch: 175 [240/1863 (13%)]\tLoss: 13.694013\n",
            "Train Epoch: 175 [360/1863 (19%)]\tLoss: 24.598057\n",
            "Train Epoch: 175 [480/1863 (26%)]\tLoss: 26.382328\n",
            "Train Epoch: 175 [600/1863 (32%)]\tLoss: 11.081973\n",
            "Train Epoch: 175 [720/1863 (39%)]\tLoss: 7.776011\n",
            "Train Epoch: 175 [840/1863 (45%)]\tLoss: 7.045000\n",
            "Train Epoch: 175 [960/1863 (51%)]\tLoss: 8.282705\n",
            "Train Epoch: 175 [1080/1863 (58%)]\tLoss: 18.705259\n",
            "Train Epoch: 175 [1200/1863 (64%)]\tLoss: 10.280462\n",
            "Train Epoch: 175 [1320/1863 (71%)]\tLoss: 2.621420\n",
            "Train Epoch: 175 [1440/1863 (77%)]\tLoss: 10.664679\n",
            "Train Epoch: 175 [1560/1863 (83%)]\tLoss: 9.551558\n",
            "Train Epoch: 175 [1680/1863 (90%)]\tLoss: 3.475903\n",
            "Train Epoch: 175 [1800/1863 (96%)]\tLoss: 7.293604\n",
            "Training Loss: 11.0010 Acc: 50.1342\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3587, Accuracy: 713/1406 (50.711%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 176/200\n",
            "----------\n",
            "Train Epoch: 176 [0/1863 (0%)]\tLoss: 6.500014\n",
            "Train Epoch: 176 [120/1863 (6%)]\tLoss: 9.763064\n",
            "Train Epoch: 176 [240/1863 (13%)]\tLoss: 1.066015\n",
            "Train Epoch: 176 [360/1863 (19%)]\tLoss: 9.149224\n",
            "Train Epoch: 176 [480/1863 (26%)]\tLoss: 12.787418\n",
            "Train Epoch: 176 [600/1863 (32%)]\tLoss: 7.036346\n",
            "Train Epoch: 176 [720/1863 (39%)]\tLoss: 13.684776\n",
            "Train Epoch: 176 [840/1863 (45%)]\tLoss: 16.320265\n",
            "Train Epoch: 176 [960/1863 (51%)]\tLoss: 23.378057\n",
            "Train Epoch: 176 [1080/1863 (58%)]\tLoss: 5.198087\n",
            "Train Epoch: 176 [1200/1863 (64%)]\tLoss: 18.422054\n",
            "Train Epoch: 176 [1320/1863 (71%)]\tLoss: 10.402263\n",
            "Train Epoch: 176 [1440/1863 (77%)]\tLoss: 13.674217\n",
            "Train Epoch: 176 [1560/1863 (83%)]\tLoss: 16.235828\n",
            "Train Epoch: 176 [1680/1863 (90%)]\tLoss: 9.373077\n",
            "Train Epoch: 176 [1800/1863 (96%)]\tLoss: 11.803510\n",
            "Training Loss: 11.5444 Acc: 50.2952\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4281, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 177/200\n",
            "----------\n",
            "Train Epoch: 177 [0/1863 (0%)]\tLoss: 10.963730\n",
            "Train Epoch: 177 [120/1863 (6%)]\tLoss: 8.347740\n",
            "Train Epoch: 177 [240/1863 (13%)]\tLoss: 19.240387\n",
            "Train Epoch: 177 [360/1863 (19%)]\tLoss: 14.751686\n",
            "Train Epoch: 177 [480/1863 (26%)]\tLoss: 6.361812\n",
            "Train Epoch: 177 [600/1863 (32%)]\tLoss: 9.240319\n",
            "Train Epoch: 177 [720/1863 (39%)]\tLoss: 20.315758\n",
            "Train Epoch: 177 [840/1863 (45%)]\tLoss: 4.014000\n",
            "Train Epoch: 177 [960/1863 (51%)]\tLoss: 6.436848\n",
            "Train Epoch: 177 [1080/1863 (58%)]\tLoss: 7.802254\n",
            "Train Epoch: 177 [1200/1863 (64%)]\tLoss: 11.917234\n",
            "Train Epoch: 177 [1320/1863 (71%)]\tLoss: 4.157772\n",
            "Train Epoch: 177 [1440/1863 (77%)]\tLoss: 4.180683\n",
            "Train Epoch: 177 [1560/1863 (83%)]\tLoss: 16.405491\n",
            "Train Epoch: 177 [1680/1863 (90%)]\tLoss: 2.194454\n",
            "Train Epoch: 177 [1800/1863 (96%)]\tLoss: 10.561880\n",
            "Training Loss: 11.7027 Acc: 50.2952\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5090, Accuracy: 745/1406 (52.987%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 178/200\n",
            "----------\n",
            "Train Epoch: 178 [0/1863 (0%)]\tLoss: 8.102566\n",
            "Train Epoch: 178 [120/1863 (6%)]\tLoss: 5.444661\n",
            "Train Epoch: 178 [240/1863 (13%)]\tLoss: 1.341569\n",
            "Train Epoch: 178 [360/1863 (19%)]\tLoss: 13.506697\n",
            "Train Epoch: 178 [480/1863 (26%)]\tLoss: 13.117238\n",
            "Train Epoch: 178 [600/1863 (32%)]\tLoss: 11.024988\n",
            "Train Epoch: 178 [720/1863 (39%)]\tLoss: 15.401052\n",
            "Train Epoch: 178 [840/1863 (45%)]\tLoss: 10.447272\n",
            "Train Epoch: 178 [960/1863 (51%)]\tLoss: 11.239804\n",
            "Train Epoch: 178 [1080/1863 (58%)]\tLoss: 17.354219\n",
            "Train Epoch: 178 [1200/1863 (64%)]\tLoss: 18.684700\n",
            "Train Epoch: 178 [1320/1863 (71%)]\tLoss: 7.409141\n",
            "Train Epoch: 178 [1440/1863 (77%)]\tLoss: 14.905690\n",
            "Train Epoch: 178 [1560/1863 (83%)]\tLoss: 2.709060\n",
            "Train Epoch: 178 [1680/1863 (90%)]\tLoss: 16.112234\n",
            "Train Epoch: 178 [1800/1863 (96%)]\tLoss: 16.993111\n",
            "Training Loss: 11.0644 Acc: 51.3151\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4433, Accuracy: 749/1406 (53.272%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 179/200\n",
            "----------\n",
            "Train Epoch: 179 [0/1863 (0%)]\tLoss: 9.562340\n",
            "Train Epoch: 179 [120/1863 (6%)]\tLoss: 6.046741\n",
            "Train Epoch: 179 [240/1863 (13%)]\tLoss: 5.586210\n",
            "Train Epoch: 179 [360/1863 (19%)]\tLoss: 8.498938\n",
            "Train Epoch: 179 [480/1863 (26%)]\tLoss: 14.873240\n",
            "Train Epoch: 179 [600/1863 (32%)]\tLoss: 9.349296\n",
            "Train Epoch: 179 [720/1863 (39%)]\tLoss: 12.619618\n",
            "Train Epoch: 179 [840/1863 (45%)]\tLoss: 16.253107\n",
            "Train Epoch: 179 [960/1863 (51%)]\tLoss: 13.631697\n",
            "Train Epoch: 179 [1080/1863 (58%)]\tLoss: 12.578766\n",
            "Train Epoch: 179 [1200/1863 (64%)]\tLoss: 16.551775\n",
            "Train Epoch: 179 [1320/1863 (71%)]\tLoss: 11.891764\n",
            "Train Epoch: 179 [1440/1863 (77%)]\tLoss: 11.779197\n",
            "Train Epoch: 179 [1560/1863 (83%)]\tLoss: 6.158917\n",
            "Train Epoch: 179 [1680/1863 (90%)]\tLoss: 3.352276\n",
            "Train Epoch: 179 [1800/1863 (96%)]\tLoss: 9.920876\n",
            "Training Loss: 11.1786 Acc: 51.6371\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4885, Accuracy: 749/1406 (53.272%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 180/200\n",
            "----------\n",
            "Train Epoch: 180 [0/1863 (0%)]\tLoss: 17.195169\n",
            "Train Epoch: 180 [120/1863 (6%)]\tLoss: 10.778845\n",
            "Train Epoch: 180 [240/1863 (13%)]\tLoss: 8.914009\n",
            "Train Epoch: 180 [360/1863 (19%)]\tLoss: 4.499249\n",
            "Train Epoch: 180 [480/1863 (26%)]\tLoss: 6.369442\n",
            "Train Epoch: 180 [600/1863 (32%)]\tLoss: 4.512094\n",
            "Train Epoch: 180 [720/1863 (39%)]\tLoss: 4.920776\n",
            "Train Epoch: 180 [840/1863 (45%)]\tLoss: 17.209871\n",
            "Train Epoch: 180 [960/1863 (51%)]\tLoss: 11.306937\n",
            "Train Epoch: 180 [1080/1863 (58%)]\tLoss: 11.554472\n",
            "Train Epoch: 180 [1200/1863 (64%)]\tLoss: 5.844863\n",
            "Train Epoch: 180 [1320/1863 (71%)]\tLoss: 13.279181\n",
            "Train Epoch: 180 [1440/1863 (77%)]\tLoss: 16.074045\n",
            "Train Epoch: 180 [1560/1863 (83%)]\tLoss: 15.040007\n",
            "Train Epoch: 180 [1680/1863 (90%)]\tLoss: 7.517515\n",
            "Train Epoch: 180 [1800/1863 (96%)]\tLoss: 11.054077\n",
            "Training Loss: 10.9067 Acc: 51.1004\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5615, Accuracy: 724/1406 (51.494%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 181/200\n",
            "----------\n",
            "Train Epoch: 181 [0/1863 (0%)]\tLoss: 9.364408\n",
            "Train Epoch: 181 [120/1863 (6%)]\tLoss: 11.730836\n",
            "Train Epoch: 181 [240/1863 (13%)]\tLoss: 15.291003\n",
            "Train Epoch: 181 [360/1863 (19%)]\tLoss: 9.716238\n",
            "Train Epoch: 181 [480/1863 (26%)]\tLoss: 7.186213\n",
            "Train Epoch: 181 [600/1863 (32%)]\tLoss: 7.732300\n",
            "Train Epoch: 181 [720/1863 (39%)]\tLoss: 10.766800\n",
            "Train Epoch: 181 [840/1863 (45%)]\tLoss: 8.462433\n",
            "Train Epoch: 181 [960/1863 (51%)]\tLoss: 3.695483\n",
            "Train Epoch: 181 [1080/1863 (58%)]\tLoss: 9.501259\n",
            "Train Epoch: 181 [1200/1863 (64%)]\tLoss: 29.527292\n",
            "Train Epoch: 181 [1320/1863 (71%)]\tLoss: 2.722123\n",
            "Train Epoch: 181 [1440/1863 (77%)]\tLoss: 14.699224\n",
            "Train Epoch: 181 [1560/1863 (83%)]\tLoss: 5.686235\n",
            "Train Epoch: 181 [1680/1863 (90%)]\tLoss: 2.866001\n",
            "Train Epoch: 181 [1800/1863 (96%)]\tLoss: 9.114871\n",
            "Training Loss: 11.5659 Acc: 50.7246\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5320, Accuracy: 741/1406 (52.703%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 182/200\n",
            "----------\n",
            "Train Epoch: 182 [0/1863 (0%)]\tLoss: 16.927729\n",
            "Train Epoch: 182 [120/1863 (6%)]\tLoss: 4.800940\n",
            "Train Epoch: 182 [240/1863 (13%)]\tLoss: 7.506213\n",
            "Train Epoch: 182 [360/1863 (19%)]\tLoss: 19.841305\n",
            "Train Epoch: 182 [480/1863 (26%)]\tLoss: 8.524908\n",
            "Train Epoch: 182 [600/1863 (32%)]\tLoss: 10.008452\n",
            "Train Epoch: 182 [720/1863 (39%)]\tLoss: 8.594847\n",
            "Train Epoch: 182 [840/1863 (45%)]\tLoss: 9.980680\n",
            "Train Epoch: 182 [960/1863 (51%)]\tLoss: 14.224459\n",
            "Train Epoch: 182 [1080/1863 (58%)]\tLoss: 8.225744\n",
            "Train Epoch: 182 [1200/1863 (64%)]\tLoss: 6.033830\n",
            "Train Epoch: 182 [1320/1863 (71%)]\tLoss: 13.864693\n",
            "Train Epoch: 182 [1440/1863 (77%)]\tLoss: 16.080803\n",
            "Train Epoch: 182 [1560/1863 (83%)]\tLoss: 7.231717\n",
            "Train Epoch: 182 [1680/1863 (90%)]\tLoss: 4.990673\n",
            "Train Epoch: 182 [1800/1863 (96%)]\tLoss: 28.726192\n",
            "Training Loss: 11.0115 Acc: 50.9393\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5151, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 183/200\n",
            "----------\n",
            "Train Epoch: 183 [0/1863 (0%)]\tLoss: 17.307972\n",
            "Train Epoch: 183 [120/1863 (6%)]\tLoss: 4.885840\n",
            "Train Epoch: 183 [240/1863 (13%)]\tLoss: 19.159081\n",
            "Train Epoch: 183 [360/1863 (19%)]\tLoss: 6.460895\n",
            "Train Epoch: 183 [480/1863 (26%)]\tLoss: 2.832822\n",
            "Train Epoch: 183 [600/1863 (32%)]\tLoss: 13.364996\n",
            "Train Epoch: 183 [720/1863 (39%)]\tLoss: 21.518734\n",
            "Train Epoch: 183 [840/1863 (45%)]\tLoss: 3.999823\n",
            "Train Epoch: 183 [960/1863 (51%)]\tLoss: 10.224401\n",
            "Train Epoch: 183 [1080/1863 (58%)]\tLoss: 7.780178\n",
            "Train Epoch: 183 [1200/1863 (64%)]\tLoss: 16.059971\n",
            "Train Epoch: 183 [1320/1863 (71%)]\tLoss: 6.537555\n",
            "Train Epoch: 183 [1440/1863 (77%)]\tLoss: 10.925285\n",
            "Train Epoch: 183 [1560/1863 (83%)]\tLoss: 1.591130\n",
            "Train Epoch: 183 [1680/1863 (90%)]\tLoss: 18.003572\n",
            "Train Epoch: 183 [1800/1863 (96%)]\tLoss: 13.094629\n",
            "Training Loss: 11.4274 Acc: 50.1342\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3354, Accuracy: 716/1406 (50.925%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 184/200\n",
            "----------\n",
            "Train Epoch: 184 [0/1863 (0%)]\tLoss: 9.851580\n",
            "Train Epoch: 184 [120/1863 (6%)]\tLoss: 12.657655\n",
            "Train Epoch: 184 [240/1863 (13%)]\tLoss: 8.477454\n",
            "Train Epoch: 184 [360/1863 (19%)]\tLoss: 18.742367\n",
            "Train Epoch: 184 [480/1863 (26%)]\tLoss: 5.444146\n",
            "Train Epoch: 184 [600/1863 (32%)]\tLoss: 14.990527\n",
            "Train Epoch: 184 [720/1863 (39%)]\tLoss: 7.211752\n",
            "Train Epoch: 184 [840/1863 (45%)]\tLoss: 2.958199\n",
            "Train Epoch: 184 [960/1863 (51%)]\tLoss: 7.580121\n",
            "Train Epoch: 184 [1080/1863 (58%)]\tLoss: 1.402591\n",
            "Train Epoch: 184 [1200/1863 (64%)]\tLoss: 5.693297\n",
            "Train Epoch: 184 [1320/1863 (71%)]\tLoss: 8.869413\n",
            "Train Epoch: 184 [1440/1863 (77%)]\tLoss: 9.149309\n",
            "Train Epoch: 184 [1560/1863 (83%)]\tLoss: 5.218866\n",
            "Train Epoch: 184 [1680/1863 (90%)]\tLoss: 5.384693\n",
            "Train Epoch: 184 [1800/1863 (96%)]\tLoss: 28.754461\n",
            "Training Loss: 10.9736 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5407, Accuracy: 719/1406 (51.138%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 185/200\n",
            "----------\n",
            "Train Epoch: 185 [0/1863 (0%)]\tLoss: 8.760942\n",
            "Train Epoch: 185 [120/1863 (6%)]\tLoss: 10.151480\n",
            "Train Epoch: 185 [240/1863 (13%)]\tLoss: 5.096027\n",
            "Train Epoch: 185 [360/1863 (19%)]\tLoss: 19.866570\n",
            "Train Epoch: 185 [480/1863 (26%)]\tLoss: 27.383102\n",
            "Train Epoch: 185 [600/1863 (32%)]\tLoss: 14.698410\n",
            "Train Epoch: 185 [720/1863 (39%)]\tLoss: 15.464017\n",
            "Train Epoch: 185 [840/1863 (45%)]\tLoss: 15.844229\n",
            "Train Epoch: 185 [960/1863 (51%)]\tLoss: 7.756538\n",
            "Train Epoch: 185 [1080/1863 (58%)]\tLoss: 2.438713\n",
            "Train Epoch: 185 [1200/1863 (64%)]\tLoss: 15.239797\n",
            "Train Epoch: 185 [1320/1863 (71%)]\tLoss: 6.451349\n",
            "Train Epoch: 185 [1440/1863 (77%)]\tLoss: 13.999692\n",
            "Train Epoch: 185 [1560/1863 (83%)]\tLoss: 6.540198\n",
            "Train Epoch: 185 [1680/1863 (90%)]\tLoss: 4.163626\n",
            "Train Epoch: 185 [1800/1863 (96%)]\tLoss: 9.590663\n",
            "Training Loss: 10.7027 Acc: 51.2077\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4885, Accuracy: 710/1406 (50.498%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 186/200\n",
            "----------\n",
            "Train Epoch: 186 [0/1863 (0%)]\tLoss: 6.685198\n",
            "Train Epoch: 186 [120/1863 (6%)]\tLoss: 14.026059\n",
            "Train Epoch: 186 [240/1863 (13%)]\tLoss: 13.232149\n",
            "Train Epoch: 186 [360/1863 (19%)]\tLoss: 14.297754\n",
            "Train Epoch: 186 [480/1863 (26%)]\tLoss: 13.897995\n",
            "Train Epoch: 186 [600/1863 (32%)]\tLoss: 22.449636\n",
            "Train Epoch: 186 [720/1863 (39%)]\tLoss: 26.974941\n",
            "Train Epoch: 186 [840/1863 (45%)]\tLoss: 13.017011\n",
            "Train Epoch: 186 [960/1863 (51%)]\tLoss: 7.909191\n",
            "Train Epoch: 186 [1080/1863 (58%)]\tLoss: 8.816216\n",
            "Train Epoch: 186 [1200/1863 (64%)]\tLoss: 15.515081\n",
            "Train Epoch: 186 [1320/1863 (71%)]\tLoss: 12.458529\n",
            "Train Epoch: 186 [1440/1863 (77%)]\tLoss: 3.881649\n",
            "Train Epoch: 186 [1560/1863 (83%)]\tLoss: 19.637529\n",
            "Train Epoch: 186 [1680/1863 (90%)]\tLoss: 13.400167\n",
            "Train Epoch: 186 [1800/1863 (96%)]\tLoss: 11.125371\n",
            "Training Loss: 11.4643 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5593, Accuracy: 706/1406 (50.213%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 187/200\n",
            "----------\n",
            "Train Epoch: 187 [0/1863 (0%)]\tLoss: 7.521605\n",
            "Train Epoch: 187 [120/1863 (6%)]\tLoss: 13.225965\n",
            "Train Epoch: 187 [240/1863 (13%)]\tLoss: 15.447443\n",
            "Train Epoch: 187 [360/1863 (19%)]\tLoss: 4.409365\n",
            "Train Epoch: 187 [480/1863 (26%)]\tLoss: 8.353500\n",
            "Train Epoch: 187 [600/1863 (32%)]\tLoss: 3.745291\n",
            "Train Epoch: 187 [720/1863 (39%)]\tLoss: 5.564710\n",
            "Train Epoch: 187 [840/1863 (45%)]\tLoss: 14.493517\n",
            "Train Epoch: 187 [960/1863 (51%)]\tLoss: 18.514059\n",
            "Train Epoch: 187 [1080/1863 (58%)]\tLoss: 0.640259\n",
            "Train Epoch: 187 [1200/1863 (64%)]\tLoss: 10.588118\n",
            "Train Epoch: 187 [1320/1863 (71%)]\tLoss: 4.171553\n",
            "Train Epoch: 187 [1440/1863 (77%)]\tLoss: 5.861771\n",
            "Train Epoch: 187 [1560/1863 (83%)]\tLoss: 17.429008\n",
            "Train Epoch: 187 [1680/1863 (90%)]\tLoss: 1.783877\n",
            "Train Epoch: 187 [1800/1863 (96%)]\tLoss: 19.131516\n",
            "Training Loss: 11.5467 Acc: 50.3489\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5154, Accuracy: 704/1406 (50.071%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 188/200\n",
            "----------\n",
            "Train Epoch: 188 [0/1863 (0%)]\tLoss: 14.491196\n",
            "Train Epoch: 188 [120/1863 (6%)]\tLoss: 11.862798\n",
            "Train Epoch: 188 [240/1863 (13%)]\tLoss: 6.296715\n",
            "Train Epoch: 188 [360/1863 (19%)]\tLoss: 7.143911\n",
            "Train Epoch: 188 [480/1863 (26%)]\tLoss: 7.977937\n",
            "Train Epoch: 188 [600/1863 (32%)]\tLoss: 8.778183\n",
            "Train Epoch: 188 [720/1863 (39%)]\tLoss: 24.578894\n",
            "Train Epoch: 188 [840/1863 (45%)]\tLoss: 8.210447\n",
            "Train Epoch: 188 [960/1863 (51%)]\tLoss: 12.559399\n",
            "Train Epoch: 188 [1080/1863 (58%)]\tLoss: 4.894258\n",
            "Train Epoch: 188 [1200/1863 (64%)]\tLoss: 6.581736\n",
            "Train Epoch: 188 [1320/1863 (71%)]\tLoss: 11.613719\n",
            "Train Epoch: 188 [1440/1863 (77%)]\tLoss: 23.048141\n",
            "Train Epoch: 188 [1560/1863 (83%)]\tLoss: 4.482041\n",
            "Train Epoch: 188 [1680/1863 (90%)]\tLoss: 6.700667\n",
            "Train Epoch: 188 [1800/1863 (96%)]\tLoss: 6.508646\n",
            "Training Loss: 11.0177 Acc: 50.2952\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4972, Accuracy: 707/1406 (50.284%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 189/200\n",
            "----------\n",
            "Train Epoch: 189 [0/1863 (0%)]\tLoss: 15.879648\n",
            "Train Epoch: 189 [120/1863 (6%)]\tLoss: 15.813103\n",
            "Train Epoch: 189 [240/1863 (13%)]\tLoss: 9.748888\n",
            "Train Epoch: 189 [360/1863 (19%)]\tLoss: 2.484567\n",
            "Train Epoch: 189 [480/1863 (26%)]\tLoss: 9.318604\n",
            "Train Epoch: 189 [600/1863 (32%)]\tLoss: 9.144242\n",
            "Train Epoch: 189 [720/1863 (39%)]\tLoss: 6.501493\n",
            "Train Epoch: 189 [840/1863 (45%)]\tLoss: 7.351523\n",
            "Train Epoch: 189 [960/1863 (51%)]\tLoss: 7.367040\n",
            "Train Epoch: 189 [1080/1863 (58%)]\tLoss: 10.757627\n",
            "Train Epoch: 189 [1200/1863 (64%)]\tLoss: 10.545878\n",
            "Train Epoch: 189 [1320/1863 (71%)]\tLoss: 5.109328\n",
            "Train Epoch: 189 [1440/1863 (77%)]\tLoss: 11.504779\n",
            "Train Epoch: 189 [1560/1863 (83%)]\tLoss: 13.837059\n",
            "Train Epoch: 189 [1680/1863 (90%)]\tLoss: 18.047663\n",
            "Train Epoch: 189 [1800/1863 (96%)]\tLoss: 15.274908\n",
            "Training Loss: 10.8799 Acc: 50.6710\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6095, Accuracy: 714/1406 (50.782%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 190/200\n",
            "----------\n",
            "Train Epoch: 190 [0/1863 (0%)]\tLoss: 8.411812\n",
            "Train Epoch: 190 [120/1863 (6%)]\tLoss: 6.515727\n",
            "Train Epoch: 190 [240/1863 (13%)]\tLoss: 10.324057\n",
            "Train Epoch: 190 [360/1863 (19%)]\tLoss: 19.769604\n",
            "Train Epoch: 190 [480/1863 (26%)]\tLoss: 17.921017\n",
            "Train Epoch: 190 [600/1863 (32%)]\tLoss: 15.776423\n",
            "Train Epoch: 190 [720/1863 (39%)]\tLoss: 17.037373\n",
            "Train Epoch: 190 [840/1863 (45%)]\tLoss: 8.303311\n",
            "Train Epoch: 190 [960/1863 (51%)]\tLoss: 18.805962\n",
            "Train Epoch: 190 [1080/1863 (58%)]\tLoss: 6.463316\n",
            "Train Epoch: 190 [1200/1863 (64%)]\tLoss: 7.986301\n",
            "Train Epoch: 190 [1320/1863 (71%)]\tLoss: 7.986138\n",
            "Train Epoch: 190 [1440/1863 (77%)]\tLoss: 6.584965\n",
            "Train Epoch: 190 [1560/1863 (83%)]\tLoss: 16.328575\n",
            "Train Epoch: 190 [1680/1863 (90%)]\tLoss: 11.199771\n",
            "Train Epoch: 190 [1800/1863 (96%)]\tLoss: 8.559550\n",
            "Training Loss: 11.0270 Acc: 51.0467\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4090, Accuracy: 771/1406 (54.836%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 191/200\n",
            "----------\n",
            "Train Epoch: 191 [0/1863 (0%)]\tLoss: 5.912982\n",
            "Train Epoch: 191 [120/1863 (6%)]\tLoss: 20.012722\n",
            "Train Epoch: 191 [240/1863 (13%)]\tLoss: 8.489862\n",
            "Train Epoch: 191 [360/1863 (19%)]\tLoss: 4.649512\n",
            "Train Epoch: 191 [480/1863 (26%)]\tLoss: 16.241360\n",
            "Train Epoch: 191 [600/1863 (32%)]\tLoss: 22.089993\n",
            "Train Epoch: 191 [720/1863 (39%)]\tLoss: 16.720165\n",
            "Train Epoch: 191 [840/1863 (45%)]\tLoss: 17.363577\n",
            "Train Epoch: 191 [960/1863 (51%)]\tLoss: 6.980315\n",
            "Train Epoch: 191 [1080/1863 (58%)]\tLoss: 17.185970\n",
            "Train Epoch: 191 [1200/1863 (64%)]\tLoss: 10.934715\n",
            "Train Epoch: 191 [1320/1863 (71%)]\tLoss: 4.668319\n",
            "Train Epoch: 191 [1440/1863 (77%)]\tLoss: 15.043477\n",
            "Train Epoch: 191 [1560/1863 (83%)]\tLoss: 14.632632\n",
            "Train Epoch: 191 [1680/1863 (90%)]\tLoss: 16.319399\n",
            "Train Epoch: 191 [1800/1863 (96%)]\tLoss: 14.955538\n",
            "Training Loss: 11.0892 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4986, Accuracy: 709/1406 (50.427%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 192/200\n",
            "----------\n",
            "Train Epoch: 192 [0/1863 (0%)]\tLoss: 1.159670\n",
            "Train Epoch: 192 [120/1863 (6%)]\tLoss: 23.088367\n",
            "Train Epoch: 192 [240/1863 (13%)]\tLoss: 5.281035\n",
            "Train Epoch: 192 [360/1863 (19%)]\tLoss: 5.704232\n",
            "Train Epoch: 192 [480/1863 (26%)]\tLoss: 22.582157\n",
            "Train Epoch: 192 [600/1863 (32%)]\tLoss: 9.166335\n",
            "Train Epoch: 192 [720/1863 (39%)]\tLoss: 5.692409\n",
            "Train Epoch: 192 [840/1863 (45%)]\tLoss: 11.950342\n",
            "Train Epoch: 192 [960/1863 (51%)]\tLoss: 6.333108\n",
            "Train Epoch: 192 [1080/1863 (58%)]\tLoss: 2.497419\n",
            "Train Epoch: 192 [1200/1863 (64%)]\tLoss: 5.891799\n",
            "Train Epoch: 192 [1320/1863 (71%)]\tLoss: 12.019852\n",
            "Train Epoch: 192 [1440/1863 (77%)]\tLoss: 4.791196\n",
            "Train Epoch: 192 [1560/1863 (83%)]\tLoss: 17.252886\n",
            "Train Epoch: 192 [1680/1863 (90%)]\tLoss: 10.720900\n",
            "Train Epoch: 192 [1800/1863 (96%)]\tLoss: 6.284278\n",
            "Training Loss: 11.1924 Acc: 50.2952\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3930, Accuracy: 771/1406 (54.836%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 193/200\n",
            "----------\n",
            "Train Epoch: 193 [0/1863 (0%)]\tLoss: 14.677980\n",
            "Train Epoch: 193 [120/1863 (6%)]\tLoss: 3.412670\n",
            "Train Epoch: 193 [240/1863 (13%)]\tLoss: 15.715940\n",
            "Train Epoch: 193 [360/1863 (19%)]\tLoss: 5.414744\n",
            "Train Epoch: 193 [480/1863 (26%)]\tLoss: 17.228603\n",
            "Train Epoch: 193 [600/1863 (32%)]\tLoss: 19.949177\n",
            "Train Epoch: 193 [720/1863 (39%)]\tLoss: 7.801914\n",
            "Train Epoch: 193 [840/1863 (45%)]\tLoss: 1.430924\n",
            "Train Epoch: 193 [960/1863 (51%)]\tLoss: 13.152054\n",
            "Train Epoch: 193 [1080/1863 (58%)]\tLoss: 9.718668\n",
            "Train Epoch: 193 [1200/1863 (64%)]\tLoss: 4.872009\n",
            "Train Epoch: 193 [1320/1863 (71%)]\tLoss: 11.715828\n",
            "Train Epoch: 193 [1440/1863 (77%)]\tLoss: 16.088560\n",
            "Train Epoch: 193 [1560/1863 (83%)]\tLoss: 11.190888\n",
            "Train Epoch: 193 [1680/1863 (90%)]\tLoss: 12.417389\n",
            "Train Epoch: 193 [1800/1863 (96%)]\tLoss: 23.955654\n",
            "Training Loss: 11.0268 Acc: 50.3489\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.3577, Accuracy: 713/1406 (50.711%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 194/200\n",
            "----------\n",
            "Train Epoch: 194 [0/1863 (0%)]\tLoss: 10.465799\n",
            "Train Epoch: 194 [120/1863 (6%)]\tLoss: 22.462353\n",
            "Train Epoch: 194 [240/1863 (13%)]\tLoss: 7.114745\n",
            "Train Epoch: 194 [360/1863 (19%)]\tLoss: 9.713134\n",
            "Train Epoch: 194 [480/1863 (26%)]\tLoss: 7.092336\n",
            "Train Epoch: 194 [600/1863 (32%)]\tLoss: 3.805653\n",
            "Train Epoch: 194 [720/1863 (39%)]\tLoss: 21.026760\n",
            "Train Epoch: 194 [840/1863 (45%)]\tLoss: 9.068070\n",
            "Train Epoch: 194 [960/1863 (51%)]\tLoss: 5.832713\n",
            "Train Epoch: 194 [1080/1863 (58%)]\tLoss: 15.133496\n",
            "Train Epoch: 194 [1200/1863 (64%)]\tLoss: 5.054016\n",
            "Train Epoch: 194 [1320/1863 (71%)]\tLoss: 12.459604\n",
            "Train Epoch: 194 [1440/1863 (77%)]\tLoss: 8.385818\n",
            "Train Epoch: 194 [1560/1863 (83%)]\tLoss: 6.070808\n",
            "Train Epoch: 194 [1680/1863 (90%)]\tLoss: 26.837795\n",
            "Train Epoch: 194 [1800/1863 (96%)]\tLoss: 8.617444\n",
            "Training Loss: 11.2086 Acc: 50.1342\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4660, Accuracy: 714/1406 (50.782%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 195/200\n",
            "----------\n",
            "Train Epoch: 195 [0/1863 (0%)]\tLoss: 7.972034\n",
            "Train Epoch: 195 [120/1863 (6%)]\tLoss: 10.483801\n",
            "Train Epoch: 195 [240/1863 (13%)]\tLoss: 14.242868\n",
            "Train Epoch: 195 [360/1863 (19%)]\tLoss: 16.254040\n",
            "Train Epoch: 195 [480/1863 (26%)]\tLoss: 6.101704\n",
            "Train Epoch: 195 [600/1863 (32%)]\tLoss: 0.585189\n",
            "Train Epoch: 195 [720/1863 (39%)]\tLoss: 17.156046\n",
            "Train Epoch: 195 [840/1863 (45%)]\tLoss: 6.046432\n",
            "Train Epoch: 195 [960/1863 (51%)]\tLoss: 13.921806\n",
            "Train Epoch: 195 [1080/1863 (58%)]\tLoss: 5.290378\n",
            "Train Epoch: 195 [1200/1863 (64%)]\tLoss: 20.360426\n",
            "Train Epoch: 195 [1320/1863 (71%)]\tLoss: 3.949177\n",
            "Train Epoch: 195 [1440/1863 (77%)]\tLoss: 4.249505\n",
            "Train Epoch: 195 [1560/1863 (83%)]\tLoss: 3.019625\n",
            "Train Epoch: 195 [1680/1863 (90%)]\tLoss: 32.305538\n",
            "Train Epoch: 195 [1800/1863 (96%)]\tLoss: 5.847196\n",
            "Training Loss: 11.2629 Acc: 50.1879\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6827, Accuracy: 706/1406 (50.213%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 196/200\n",
            "----------\n",
            "Train Epoch: 196 [0/1863 (0%)]\tLoss: 18.688103\n",
            "Train Epoch: 196 [120/1863 (6%)]\tLoss: 3.595515\n",
            "Train Epoch: 196 [240/1863 (13%)]\tLoss: 17.922943\n",
            "Train Epoch: 196 [360/1863 (19%)]\tLoss: 14.762217\n",
            "Train Epoch: 196 [480/1863 (26%)]\tLoss: 17.779062\n",
            "Train Epoch: 196 [600/1863 (32%)]\tLoss: 9.573682\n",
            "Train Epoch: 196 [720/1863 (39%)]\tLoss: 11.060411\n",
            "Train Epoch: 196 [840/1863 (45%)]\tLoss: 14.474321\n",
            "Train Epoch: 196 [960/1863 (51%)]\tLoss: 7.103068\n",
            "Train Epoch: 196 [1080/1863 (58%)]\tLoss: 11.786356\n",
            "Train Epoch: 196 [1200/1863 (64%)]\tLoss: 11.915257\n",
            "Train Epoch: 196 [1320/1863 (71%)]\tLoss: 7.715117\n",
            "Train Epoch: 196 [1440/1863 (77%)]\tLoss: 6.075698\n",
            "Train Epoch: 196 [1560/1863 (83%)]\tLoss: 9.109182\n",
            "Train Epoch: 196 [1680/1863 (90%)]\tLoss: 6.950624\n",
            "Train Epoch: 196 [1800/1863 (96%)]\tLoss: 11.211073\n",
            "Training Loss: 11.1725 Acc: 51.2614\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.4242, Accuracy: 704/1406 (50.071%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 197/200\n",
            "----------\n",
            "Train Epoch: 197 [0/1863 (0%)]\tLoss: 6.558461\n",
            "Train Epoch: 197 [120/1863 (6%)]\tLoss: 9.779343\n",
            "Train Epoch: 197 [240/1863 (13%)]\tLoss: 4.431950\n",
            "Train Epoch: 197 [360/1863 (19%)]\tLoss: 4.495247\n",
            "Train Epoch: 197 [480/1863 (26%)]\tLoss: 14.681307\n",
            "Train Epoch: 197 [600/1863 (32%)]\tLoss: 13.628166\n",
            "Train Epoch: 197 [720/1863 (39%)]\tLoss: 17.739653\n",
            "Train Epoch: 197 [840/1863 (45%)]\tLoss: 3.698301\n",
            "Train Epoch: 197 [960/1863 (51%)]\tLoss: 2.034749\n",
            "Train Epoch: 197 [1080/1863 (58%)]\tLoss: 4.333024\n",
            "Train Epoch: 197 [1200/1863 (64%)]\tLoss: 10.388694\n",
            "Train Epoch: 197 [1320/1863 (71%)]\tLoss: 6.083812\n",
            "Train Epoch: 197 [1440/1863 (77%)]\tLoss: 15.308023\n",
            "Train Epoch: 197 [1560/1863 (83%)]\tLoss: 25.587206\n",
            "Train Epoch: 197 [1680/1863 (90%)]\tLoss: 20.077003\n",
            "Train Epoch: 197 [1800/1863 (96%)]\tLoss: 10.549604\n",
            "Training Loss: 10.9042 Acc: 50.5099\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.6044, Accuracy: 711/1406 (50.569%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 198/200\n",
            "----------\n",
            "Train Epoch: 198 [0/1863 (0%)]\tLoss: 25.332560\n",
            "Train Epoch: 198 [120/1863 (6%)]\tLoss: 16.631584\n",
            "Train Epoch: 198 [240/1863 (13%)]\tLoss: 12.530921\n",
            "Train Epoch: 198 [360/1863 (19%)]\tLoss: 8.582079\n",
            "Train Epoch: 198 [480/1863 (26%)]\tLoss: 11.781735\n",
            "Train Epoch: 198 [600/1863 (32%)]\tLoss: 8.428732\n",
            "Train Epoch: 198 [720/1863 (39%)]\tLoss: 1.278356\n",
            "Train Epoch: 198 [840/1863 (45%)]\tLoss: 8.292169\n",
            "Train Epoch: 198 [960/1863 (51%)]\tLoss: 7.887478\n",
            "Train Epoch: 198 [1080/1863 (58%)]\tLoss: 8.185644\n",
            "Train Epoch: 198 [1200/1863 (64%)]\tLoss: 13.456839\n",
            "Train Epoch: 198 [1320/1863 (71%)]\tLoss: 9.411736\n",
            "Train Epoch: 198 [1440/1863 (77%)]\tLoss: 11.014637\n",
            "Train Epoch: 198 [1560/1863 (83%)]\tLoss: 14.784839\n",
            "Train Epoch: 198 [1680/1863 (90%)]\tLoss: 8.212975\n",
            "Train Epoch: 198 [1800/1863 (96%)]\tLoss: 11.321564\n",
            "Training Loss: 11.0225 Acc: 50.8320\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5321, Accuracy: 767/1406 (54.552%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 199/200\n",
            "----------\n",
            "Train Epoch: 199 [0/1863 (0%)]\tLoss: 10.551931\n",
            "Train Epoch: 199 [120/1863 (6%)]\tLoss: 4.953728\n",
            "Train Epoch: 199 [240/1863 (13%)]\tLoss: 8.472047\n",
            "Train Epoch: 199 [360/1863 (19%)]\tLoss: 7.419432\n",
            "Train Epoch: 199 [480/1863 (26%)]\tLoss: 20.263525\n",
            "Train Epoch: 199 [600/1863 (32%)]\tLoss: 13.591242\n",
            "Train Epoch: 199 [720/1863 (39%)]\tLoss: 6.258709\n",
            "Train Epoch: 199 [840/1863 (45%)]\tLoss: 18.429632\n",
            "Train Epoch: 199 [960/1863 (51%)]\tLoss: 5.296187\n",
            "Train Epoch: 199 [1080/1863 (58%)]\tLoss: 21.818665\n",
            "Train Epoch: 199 [1200/1863 (64%)]\tLoss: 21.616934\n",
            "Train Epoch: 199 [1320/1863 (71%)]\tLoss: 13.621058\n",
            "Train Epoch: 199 [1440/1863 (77%)]\tLoss: 14.412333\n",
            "Train Epoch: 199 [1560/1863 (83%)]\tLoss: 13.548032\n",
            "Train Epoch: 199 [1680/1863 (90%)]\tLoss: 7.718301\n",
            "Train Epoch: 199 [1800/1863 (96%)]\tLoss: 7.036568\n",
            "Training Loss: 11.1382 Acc: 50.8857\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5198, Accuracy: 714/1406 (50.782%)\n",
            "\n",
            "Mode: fine tuning cycle   Epoch 200/200\n",
            "----------\n",
            "Train Epoch: 200 [0/1863 (0%)]\tLoss: 1.871264\n",
            "Train Epoch: 200 [120/1863 (6%)]\tLoss: 4.164380\n",
            "Train Epoch: 200 [240/1863 (13%)]\tLoss: 10.297070\n",
            "Train Epoch: 200 [360/1863 (19%)]\tLoss: 15.227730\n",
            "Train Epoch: 200 [480/1863 (26%)]\tLoss: 18.460245\n",
            "Train Epoch: 200 [600/1863 (32%)]\tLoss: 0.001003\n",
            "Train Epoch: 200 [720/1863 (39%)]\tLoss: 11.668753\n",
            "Train Epoch: 200 [840/1863 (45%)]\tLoss: 7.147799\n",
            "Train Epoch: 200 [960/1863 (51%)]\tLoss: 13.524530\n",
            "Train Epoch: 200 [1080/1863 (58%)]\tLoss: 6.265432\n",
            "Train Epoch: 200 [1200/1863 (64%)]\tLoss: 8.399825\n",
            "Train Epoch: 200 [1320/1863 (71%)]\tLoss: 7.954685\n",
            "Train Epoch: 200 [1440/1863 (77%)]\tLoss: 14.985514\n",
            "Train Epoch: 200 [1560/1863 (83%)]\tLoss: 17.797457\n",
            "Train Epoch: 200 [1680/1863 (90%)]\tLoss: 4.151919\n",
            "Train Epoch: 200 [1800/1863 (96%)]\tLoss: 14.578583\n",
            "Training Loss: 11.2871 Acc: 50.9930\n",
            "length of validation loader:  141\n",
            "\n",
            "Validation set: Average loss: 0.5805, Accuracy: 705/1406 (50.142%)\n",
            "\n",
            "Training complete in 41m 14s\n",
            "\n",
            "Best validation accuracy=68.9189%\n",
            "length of test loader:  141\n",
            "\n",
            "Test set: Average loss: 0.3306, Accuracy: 958/1406 (68.137%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoMKNVuu5QAH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "# modified from main.py https://github.com/zhangrong1722/CheXNet-Pytorch\n",
        "\n",
        "def plt_roc(test_y, probas_y, plot_micro=False, plot_macro=False):\n",
        "    assert isinstance(test_y, list) and isinstance(probas_y, list), 'the type of input must be list'\n",
        "    skplt.metrics.plot_roc(test_y, probas_y, plot_micro=plot_micro, plot_macro=plot_macro)\n",
        "    plt.savefig('roc_auc_curve.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "###########################################\n",
        "# Define confusion matrix and ROC visualization functions\n",
        "# from https://colab.research.google.com/drive/1ISfhxFDntfOos7cOeT7swduSqzLEqyFn#scrollTo=UiKRYOWPfhJs\n",
        "\n",
        "def plot_confusion_matrix(cm, classes=None,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues,\n",
        "                          cv=10):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "   \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"\\nNormalized confusion matrix\")\n",
        "    else:\n",
        "        print('\\nConfusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    if classes:\n",
        "        tick_marks = np.arange(len(classes))\n",
        "        plt.xticks(tick_marks, classes, rotation=45)\n",
        "        plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 1.5\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.locator_params(nbins=2)\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOd0ZL829ce1"
      },
      "source": [
        "best_model_preds = pd.read_csv('best_val_model_predictions.csv')\n",
        "pred_y = best_model_preds['pred_y'].values\n",
        "test_y = best_model_preds['test_y'].values\n",
        "probas_y = [s.replace('[', '').replace(']', '').split(', ') for s in best_model_preds['probas_y'].values]\n",
        "probas_y = [[float(t[0]), float(t[1])] for t in probas_y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXCwPEYx9ZeC",
        "outputId": "b63d4dee-c67e-4c4f-c471-08eed3b1ba75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion = confusion_matrix(pred_y, test_y)\n",
        "plot_confusion_matrix(confusion,\n",
        "                      classes=['hc', 'sz'],\n",
        "                      title='Confusion matrix')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion matrix, without normalization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgit09GQHyJ4",
        "outputId": "d237f437-6cd0-4cf3-facd-795f44888c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "!pip install scikit_plot\n",
        "import scikitplot as skplt\n",
        "plt_roc(list(test_y), list(probas_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit_plot in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit_plot) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit_plot) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit_plot) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit_plot) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->scikit_plot) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit_plot) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit_plot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit_plot) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit_plot) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit_plot) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ive-YKE_7E0k",
        "outputId": "60ccad4d-dec0-4e63-85c1-c7d8483254ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "metrics = pd.read_csv('metrics_by_epoch.csv')\n",
        "metrics.head()\n",
        "#TODO chart these values\n",
        "\n",
        "metrics[['train_loss', 'val_loss']].plot(figsize=(10,5), title='Train and Validation Loss over Epochs')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f257a4a4be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYjx8J6sPJT4",
        "outputId": "c8ac643d-ab62-46f2-f0b5-c4bf0697a9a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "metrics[['train_acc', 'val_acc']].plot(figsize=(10,5), title='Train and Validation Accuracy over Epochs')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f257a45c2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAE/CAYAAACEto0QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZxcZZ3v8c+vqvfupNNb9pAEEsISIEgAURAFFXEc0JkBXIYBr3MZx13Hq4x6R2f0zugM6uiM4qAIBMEFBEEEkS0oWyCBkH1POt1JutP73lVdVc/94zmn6lSlurt6q+qu83u/Xnl1dW3nqepOnW//nt95jhhjUEoppZRSExfI9QCUUkoppfKFBiullFJKqUmiwUoppZRSapJosFJKKaWUmiQarJRSSimlJokGK6WUUkqpSaLBSqkMichjInLDNBjH10TkZ1PwvDeKyHOe73tF5ORM7juObU2L91LNDFP1O6/UVNBgpfKaEw7cfzERGfB8/6GxPJcx5kpjzF1TNdaJEpFFIhIRkVPS3PagiNwyluczxlQYYw5MwrhO2ClO9XvpbNOIyIVTtQ2/ckJ1NOX/Vq+ILMz12JSaDjRYqbzmhIMKY0wFcBj4c89197j3E5GC3I1ychhjjgBPAdd7rxeRauDdwLQNhZNJRAT4G6Dd+ZrNbc/43yOvEV7Pi97/W86/o1kdnFLTlAYr5Usi8lYRaRSRL4pIE3CHiFSJyCMi0iIiHc7lxZ7HrBeRv3Uu3ygiz4nILc59D4rIlSNs72YR2S8iPSKyQ0Te57ltxOcSkeUi8qzz2CeA2hFe2l2kBCvg/cAOY8zWkcaRZsxGRFY4l2tE5GER6RaRl4FTUu77PRFpcG7fJCKXONe/C/gScJ1T1Xg9zXsZEJGviEi9iBwXkXUiUunctswZxw0iclhEWkXkyyO8foBLgAXAp4D3i0iRZ5ylIvJtZ1tdzvte6tx2sYi8ICKdzmu5MXWszvepU6ZGRD4uInuBvSO9H85tQRH5kufnsElElojID0Tk2ynv68Mi8tlhfj5vEpFXnNfxioi8ybn+OhHZmHLfz4rIw87lYud37bCINIvIjzzvwQn/L0Z5r9ON65CI/KPz+9UhIneISInn9v8tIvtEpN15fQs9t50pIk84tzWLyJc8T13k/G70iMh2EVnredwXReSIc9tuEbl8rONWarJosFJ+Nh+oBpYCN2H/P9zhfH8SMAD89wiPvxDYjQ06/w7cLiIyzH33Y3f4lcA/Az8TkQUZPte9wCbntq8DI/UmPQjUisjFnuuuJ1GtGm0cw/kBMIgNLP/L+ef1CrAG+37eC9wnIiXGmN8D/wr80qlqnJPmuW90/r0NOBmo4MT3/WJgFXA58E8icvoIY70B+C3wK+f7P/fcdgtwHvAmZ6xfAGIishR4DPgvoM55LZtH2Eaq92J/hmc436d9P5zbPgd8AFtFnI19L/uxP6MPiEgAQERqgbc7j08itgr5O+D7QA3wHeB3IlLjvPZVIrLS85APep7nm8CpzvhWAIuAf/LcN/X/xXh8CLgCG8BPBb7ijPsy4N+Aa7G/S/XAL5zbZgFPAr8HFjpje8rznFc5950DPIzzOyIiq4BPAOcbY2Y52z00znErNXHGGP2n/3zxD/th+3bn8luBMFAywv3XAB2e79cDf+tcvhHY57mtDDDA/AzHshm4erTnwga8CFDuuf1e4GcjPPdPgNucyyud1zk3w3E857nNYHduQWAIOM1z279675vmeTuAc5zLX0sdb8p7+RTwMc9tq5ztFQDLnHEs9tz+MvD+YbZbBnQD73W+/x/gIedyABuWz0nzuH8EHhzmOeNjHeF9umyUn7f3/djtvudp7rcTeIdz+RPAo8Pc73rg5ZTrXgRudC7/DPgnz+9Aj/PeCNAHnOJ53EXAwTH8v7jR+Z3s9Pzbn/L/7KOe79/t3g7cDvy757YK52e9DBs2Xxtmm18DnvR8fwYw4FxeARzHhtDCTP7/6T/9N5X/tGKl/KzFGDPofiMiZSLyP840UTfwR2COiASHeXyTe8EY0+9crEh3RxH5GxHZ7EwzdQKrSZ7SG+65FmLDXZ/nvvWjvK67gGucCsn1wOPGmOMZjiOdOmzIaRhuDCLyeRHZ6UxLdWIrYqM9r2thyvPVO9ub57muyXO5n2HeZ+B92J3+o8739wBXikidM54SbNUu1ZJhrs+U970Z7f0YaVt3AX/tXP5r4O5h7pf6nuF8v8i5fC82qICtVv3G+b2qwwasTZ7fgd8717uS/l8M4yVjzBzPv9QDJlJ/V9zpvqRxG2N6gTZn3KP9DFJ/B0pEpMAYsw/4DDZ8HReRX4g20qsc0mCl/MykfP8P2GrJhcaY2cBbnOuHm97LiDPN9GNsBaLGGDMH2Jbh8x4DqkSk3HPdSaM85jls4/bV2J3zXRMcRws2rCxJNwanf+gL2OmdKud5uzzPm/o+pzqKnXbyPncEaB7lcencgA1dh50eofuAQmy4aMVOZ55w1CQ2CKS7HmyFp8zz/fw094m/xgzej5G29TPgahE5Bzgd+M0w90t9z8C+b0ecy08AdSKyBhuw3GnAVmzV7kxPKKo09uCOE17LBKT+rriN7Unjdn6va5xxN2CngsfMGHOvMeZi57kN8K3xPI9Sk0GDlVIJs7A7nU6nh+Wrk/S85dgP+xYAEfkwtlI0KmNMPbAR+GcRKXJ6p/58lMcYYB125zIH23Mz7nEYY6LAA8DXnKreGST3ec3CBqEWoEBE/gnbO+RqBpa5vUNp/Bz4rNgm/QoSPVmR0cbmJSKLsD1Y78FO464BzsG+D39jjIkBPwW+IyILnSbyi0SkGFvZeruIXCsiBWKb9dc4T70Z+Avnta8APjLKUEZ7P34CfF1EVop1ttMbhTGmEdufdTfwa2PMwDDbeBQ4VUQ+6Iz3Ouz02CPO8wxhQ+V/YPulnnCuj2HD9XdFZK77vonIFaO8prH6uIgsdv4ffRn4pXP9z4EPi8ga533/V2CDMeaQM/YFIvIZsQ32sySD5TJEZJWIXOY83yD2/3Bskl+PUhnTYKVUwn8Cpdi/6l/CTpFMmDFmB/BtbA9MM3AW8PwYnuKD2MbodmzYW5fBY9ZhKwW/NMaEJmEcn8BWgpqAO0k+Wuxx7Hu1BzvNM0jyVNB9ztc2EXk1zXP/FBsk/ggcdB7/yQzH5XU9sNkY8wdjTJP7D9vgfbaIrAY+D2zFhpd2bOgKGGMOY3uB/sG5fjM2lAF8F9t31Iyt/t3DyEZ7P76Dbaz/A7Yf7Hbs753rLuzPZrhpQIwxbdgA+Q/YqbQvAO8xxrR67nYvtu/ovpSQ+kVgH/CSM+X9JLZSOxYXyYnrWJ2fsu0/AAew03vfcMb9JPB/gV9jq7GnYI9axRjTA7wD+4dDE/YIy7dlMJZibEN+q/O4udieOaVyQuwft0oppaYDEXkLdkpwqZmBH9Aicgjb7P9krseiVC5oxUoppaYJESkEPg38ZCaGKqWUBiullJoWnLW5OrHrO/1njoejlBonnQpUSimllJokWrFSSimllJokGqyUUkoppSbJtDgTe21trVm2bFmuh6GUUkopNapNmza1GmPq0t02LYLVsmXL2Lhx4+h3VEoppZTKMREZ9tRiOhWolFJKKTVJNFgppZRSSk0SDVZKKaWUUpNkWvRYKaWUUmryDQ0N0djYyODgYK6HMiOVlJSwePFiCgsLM36MBiullFIqTzU2NjJr1iyWLVuGiOR6ODOKMYa2tjYaGxtZvnx5xo/TqUCllFIqTw0ODlJTU6OhahxEhJqamjFX+zRYKaWUUnlMQ9X4jee9GzVYichPReS4iGzzXFctIk+IyF7na5VzvYjI90Vkn4hsEZE3jHlESimllFIzVCYVqzuBd6VcdzPwlDFmJfCU8z3AlcBK599NwK2TM0yllFJKzTSdnZ388Ic/HPPj3v3ud9PZ2TkFI5p6ozavG2P+KCLLUq6+Gnirc/kuYD3wRef6dcYYA7wkInNEZIEx5thkDdjP7NsKxsCf9rVywbJqSouCAMRiBgMEA+nLlk1dg2w/2sXbVs1FBGImcdvgUJQX97fR0huiqqyQ1Ysq2dLYxUnVZZy5cHa8FGqMiT9OgEBA0l7nino2EgwIrb0hnt55HBF4xxnzmFNWxP6WXjbVd8Tvu6SqjEVVpWyq72AoGuO0+bNYvaiSoAgi8OL+Nurb+xPPK8LbTpvL4FCU/S29vGVlHc/ta6WytJCCoFDf1s9ZiyrZcayb9r4wACWFAdYurWbv8R6au0MAFAYDXLi8moVzSgkIhCIxHt/eRH84Gt/W7JJC3nnmPF473EllaSGr5s+ioy/Mc/ta6Q1Fhv25lRUFecNJVew93kNZUQG1FcW8ergDYwxvXTWXmDFsaezizIWz2drYRefAUPxxF51Sw5zSIl5v7KSzf4jT5s/itYZO+kIRFleVcv6yagqDgfjPZ09zL8e6BnjrqrlsONjG3FklrJhbEf/9MMaw7Wg3O491UxgMcN7SKo52DjAUjXFybQUb69sJRWIA1JQXcfqC2bx6uCPpfUgnGBDOW1rFsppyDrT0squphwuWV1NdXsSWxi72NPfEf0fOXFiJCBxu7+fsxZVsO9JNR384/lwBgTVLqugNRZIet3pRJcbA9qNdBALCBcuqWVZbDsDx7kFePtTOqfNm0TM4RFtvmItOqWFWSeZH8iilJp8brD72sY8lXR+JRCgoGD6CPProo1M9tCkz3qMC53nCUhMwz7m8CGjw3K/Rue6EYCUiN2GrWpx00knjHEZ+OdY1wH0bG7npLSdTUhhMum0oGuPvf7aJwaEYF6+s5ZuP7eINJ83h81es4qHXjnL/q41EY4ZzFldyytwKGtsH2N3cw4cutO/tXS8coi8cZcXcCo53D9I9OHwQ8Jo/u4QLllcTikR5YX8bPc7jigsCvOGkKnY398QDS2lhkL+9ZDnGwJM7m9nV1BN/npVzK2jqHow/vrq8iMrSQg629mU0jtLCIMtry9lxrPuE22YVFxCOxghFYtTNKqalJ5TRcw5n7qxiigoCNHYMnHCb+/wBsQFh+9GupJA6VuVFQWIGBoZGDi5j5Y6zICCcvmA22452YSYwzunqlLpyyosL2NLYdcJtZUVBnvn8W5k3uyQHI1NKAdx8883s37+fNWvWUFhYSElJCVVVVezatYs9e/bw3ve+l4aGBgYHB/n0pz/NTTfdBCROddfb28uVV17JxRdfzAsvvMCiRYt46KGHKC0tTbu9H//4x9x2222Ew2FWrFjB3XffTVlZGc3NzXz0ox/lwIEDANx666286U1vYt26ddxyyy2ICGeffTZ33333hF+zmAw+bZ2K1SPGmNXO953GmDme2zuMMVUi8gjwTWPMc871TwFfNMaMeCLAtWvXGr+fKzAWM3zgxy+x4WA7f/eWk/nEZSv43pN7OdTWx/fefy7/+uhO7tlwOH7/MxbMZt/xXsLRGAUB4drzlzCntJCXDrTR3B2iqryQebNKeGrXcQICl58+j7esrOX+TY2snDeLk6rL4s8VEDj3pCpOriunoX2AbUe6OGdJJQdb+3lyRzPbjnZREBDOX1bNEudxrb0hXjnUwap5FZxcVwHAzmPdPLatiWBAOH9ZFRcsq6YgGCASM7xa30FpUZBPX76ScDTG95/aS8zAO06fy5tX1FJWVIDBsP1IN8e6BnjjyTWUFAbZVN/B4fZ+jvcM8npDF1eds5D3nLMAQeLj+O4TeygvLuDck+bw61cb+eAFSykrChKJGZbXlvF6g60GLa2x1Y32vjAvH2zjlLkVrJhbgSB0Dw7x/L5Wugci7G7upqUnxMfetoLT58+Ov0+bGzq5df0+Lj99Hm29IbYc6eKSFbVcdvo85o+w87bvlaea0hfmjSfXEI7E+M8n9xAMCB+44CT2Nvdy9uJKFlcl3uMX97cxMBTl5LpyasqL2Xmsm/OWVjF3djE7jnaz42g33v/B82eXUFgg/PS5Q1x51nwa2gfY09zD+cuqKXOqm0uqS1m7tJrBoSgvHWhjQWUphQUBDrX2ccHyaqrKigA42NrHrqZu1i6tpm5W8Yi/v33hCC/ub6O9L0zdrGJWzZ/Fq/W20rW0pozzllZREAgwFI3xyqF2jIFlzs9m9aLKpN/HwaEoGw62UVpUwBtOmhN/3MsH2wGcoB/jub0tPLXrOAPhKG87bS4XnVLD3mZbFWzqGuT/PbqTRz55MasXVY44dqXy2c6dOzn99NMB+OffbmfH0RP/OJ2IMxbO5qt/fuawtx86dIj3vOc9bNu2jfXr1/Nnf/ZnbNu2Lb58QXt7O9XV1QwMDHD++efz7LPPUlNTkxSsVqxYwcaNG1mzZg3XXnstV111FX/913+ddnttbW3U1NQA8JWvfIV58+bxyU9+kuuuu46LLrqIz3zmM0SjUXp7e2lsbOR973sfL7zwArW1tfGxpPK+hy4R2WSMWZtuDOOtWDW7U3wisgA47lx/BFjiud9i5zo1ip9tqGfDwXZWzZvFj/90gLtePEQoEkOAt3/nWY51DfJ3l55MZWkh9244zE9vPJ+haIyG9n6WVJfFA0+qg619zCktpKrc7iyvv2jZiONYUFnKBcvtL9Z5S6v5q/MWj+l1HGjppbq8iDnOznk4d374gmG37zXc63LNryzh9hvPj3//4TefuNbIeUuT/6PMryzhjIWzT7ju1HmzRtzWuyrn867V80e8z3BjHG7n/j/XJ/5fXrIy+UTp6R530Sk18csLKku5/PR5pPO+czP7ua30vOZLTz1x+97tjeYUJ2C73nBSVdr7eX+mqT8blzvFN9zjAFbMreDGlJ+3u80ndjSPPmClVNZdcMEFSWtCff/73+fBBx8EoKGhgb1798aDkWv58uWsWbMGgPPOO49Dhw4N+/zbtm3jK1/5Cp2dnfT29nLFFVcA8PTTT7Nu3ToAgsEglZWVrFu3jmuuuYba2lqAtKFqPMYbrB4GbgC+6Xx9yHP9J0TkF8CFQJf2V42srTdEbyjCNx/bxVtOreO/P3gu//Cr11lYWcJfnbeEVw618y+P7OATb1vBP7zzVESEv7/0lHjf02jBY3maHdRUOjll56pULridfrF8nP9UapxGqixlS3l5Yp+0fv16nnzySV588UXKysp461vfmnbNqOLiRMU8GAwyMHBim4brxhtv5De/+Q3nnHMOd955J+vXr5/U8Wdi1GAlIj/HNqrXikgj8FVsoPqViHwEqAeude7+KPBuYB/QD3x4CsY8o9y6fj/V5YVcd/6JfWT1bX1c9u1nAdtD9G9/cRazSwr58d8kqhhnLa7kvecuoro8UQHSNUmUGlnAOd5Zc5VSuTVr1ix6enrS3tbV1UVVVRVlZWXs2rWLl156acLb6+npYcGCBQwNDXHPPfewaNEiAC6//HJuvfXWpKnAyy67jPe973187nOfo6amZtipwLHK5KjADwxz0+Vp7muAj090UPmiZ3CI7z65h5Nry9MGq9cOdxKNGd55xjz+4g2LWTQnfTOeN1QppUbn9uBpxUqp3KqpqeHNb34zq1evprS0lHnzEu0L73rXu/jRj37E6aefzqpVq3jjG9844e19/etf58ILL6Suro4LL7wwHuq+973vcdNNN3H77bcTDAa59dZbueiii/jyl7/MpZdeSjAY5Nxzz+XOO++c8Bgyal6favnavP7Q5iN8+hebCQaE7f98xQlH+v3bozu54/lDbP+XK+KHzCulJm797uPceMcrPPCxNw3b66WUH6RrvFZjM9bmdd2bT6FHt9r2smjMsLvpxFLojmPdrJxXoaFKqUnmXXtNKaWySffoU2RwKMr63S1cdtpcALanOcR157EeTl8w+4TrlVIT465Tq7lKqfz08Y9/nDVr1iT9u+OOO3I9LGD8RwWqURxo6SMUifEXb1jExkPtbDuavIBhS0+I1t6QBiulpkCixyrHA1FKTYkf/OAHuR7CsDRYTZEDrb0AnFxbwepFlWxt7KK9L8y6Fw9x5eoFNHfbQ0pPXzDy2klKqbFLVKw0WSmlskuD1RQ52GJP1bK8tpw1S+bww/X7WfuNJ4gZONIxwPI6u5aHd2VvpdQkcYNVbkehlPIhDVYTcLx7kGNdg/YkwSknPz7Q2sfCyhJKi4J88rKVnFxXwY6j3Wyqb+e1hk7a+8KcXFceXxFdKTV5AqLLLSilckOD1QTc/MBWnt51nPmzS/jilat475pF8aORDrT2xVchLy0K2lPDnAf//fRebvnDHpq6BnnP2QtyOXyl8lb8zxzNVUqpLNOjAidg25EuzltaxbzZxXz2l69z/6ZGwPZ1HGjpTXs6mXOdNXV6QxHWLpuc8xIppZKJaPO6UjNRRcXMPy2aBqtx6ugLc7wnxLvOnM8DH3szqxfN5ofr9xONGdr6wvQMRji57sRgdc6SObhnpLlAg5VSUyLevK4lK6VUlulU4Djtchb8PHX+LIIB4e8vXcHH732Vv7z1BfpCESD9CZArigtYNW8W7X1hllSnP4WNUmpi3D9etGKllMdjN0PT1sl9zvlnwZXfHPbmm2++mSVLlvDxj9uz3X3ta1+joKCAZ555ho6ODoaGhvjGN77B1VdfPeqment7ufrqq9M+bt26ddxyyy2ICGeffTZ33303zc3NfPSjH+XAgQMA3HrrrbzpTW+ahBc9Mg1Wo4jFDN/43U4qSgq4du1iFleVAbCn2Qar0+bb5RLetXo+5yyupL0vTFVZITXlRaxeVJn2Ob/4rtPoD0f1ZMpKTRFdeV2p6eG6667jM5/5TDxY/epXv+Lxxx/nU5/6FLNnz6a1tZU3vvGNXHXVVaPuE0tKSnjwwQdPeNyOHTv4xje+wQsvvEBtbS3t7e0AfOpTn+LSSy/lwQcfjJ94ORs0WI3iaNcAP33+IAA7jnbxkxvOB2zFqrK0kLmzigEIBoSHPnFxRs/5Nmc1dqXU1HA/njVXKeUxQmVpqpx77rkcP36co0eP0tLSQlVVFfPnz+ezn/0sf/zjHwkEAhw5coTm5mbmz58/4nMZY/jSl750wuOefvpprrnmGmprawGorrZtNk8//TTr1q0DIBgMUlmZvtgx2TRYjeJIx0D8ctfAUPzynuYeVs2fpVUnpaYhd7kF7bFSKveuueYa7r//fpqamrjuuuu45557aGlpYdOmTRQWFrJs2TIGBwdHfZ7xPi7btHl9FI1OsDq5tpz+cBSw04N7mnpYNU9XTVdqOor3WMVyOw6llJ0O/MUvfsH999/PNddcQ1dXF3PnzqWwsJBnnnmG+vr6jJ5nuMdddtll3HfffbS1tQHEpwIvv/xybr31VgCi0ShdXV3pn3iSabAaxZFOG6xOmVsRD1aH2vroCUVYvUhXTVdqOkpUrJRSuXbmmWfS09PDokWLWLBgAR/60IfYuHEjZ511FuvWreO0007L6HmGe9yZZ57Jl7/8ZS699FLOOeccPve5zwHwve99j2eeeYazzjqL8847jx07dkzZa/TSqcBRNHb0UzermKqyQvrD9mi/LY029Z69eE4uh6aUGoU2rys1PWzdmjgasba2lhdffDHt/UZqMB/pcTfccAM33HBD0nXz5s3joYceGsdoJ0YrVqM40jnAojmllBUVxCtWrzd2UlIYYOXcmb+QmVL5SJdbUErlilasRnGkY4AzF1VSVhRkwAlWWxq7WL2wkoKg5lKlpqNA/KASTVZKzTRbt27l+uuvT7quuLiYDRs25GhEY6PBagSxmOFo5yBXrJ5PWVGQSMwwEI6y/WgXH7xgaa6Hp5QahlaslJq5zjrrLDZv3pzrYYybBqsRtPSGCEdjLJ5TSjhqP6G3NHYyOBTj7MXZWQ9DKTV28eZ1DVZKYYzRpYHGaTx9mjqXlcbuph7aekPxpRYWVZVSVhQE4GBrHwBLqstyNj6l1MjcXUhMk5XyuZKSEtra2vRAjnEwxtDW1kZJScmYHqcVKw9jDF96cCs/f7mBc0+aw9tW2RXSl9dW0DNojwhs6raLkVWW6lun1HQlutyCUgAsXryYxsZGWlpacj2UGamkpITFixeP6TGaDjx2NfXw85cbOGdxJa8d7mRLYxfvPGMey2vL2eucG7DZCVazSwpzOVSl1AjcWQ/9K135XWFhIcuXL8/1MHxFpwI9mrpsaPrKe86In1z5i1faBcjKigqS7jO7VIOVUtOV9lgppXJFK1Ye7jTfwjml/Phv1tLQ0c8pdXatqrLioHOfEIVBobhAM6lS05X2WCmlckWDlUdT1yAiMHdWMYXBQFKDutu83tw9yOySQj3CQqlpTCtWSqlc0bKLR1PXILUVNlSlKiu0GbS9L6zTgEpNc/Eeq9wOQynlQxqsPJq6B5k/O/1hlaVOxQpgVokW+pSaCXQqUCmVbRqsPJq7B5lfmT5YlXmClR4RqNT0FghoyUoplRsarDxGrFgVeoKVrmGl1LSmzetKqVzRYOUYHIrS2T80bMUqEJB4uJpVrBUrpaazgC4QqpTKEQ1WDnd9quEqVpCYDtSKlVLTW+IkzBqtlFLZpcHK4a5hNVzFChIN7NpjpdT0llh5PbfjUEr5jwYrx7YjXQDMy6BipUcFKjW9Ce46VpqslFLZpQkB+O+n93LLH/awat4sTvIsCpqq1Dmtja5jpdT0pgcFKqVyxfcVq1jMcNeL9VyyspaHPvFmikY4VU1ZoU4FKjUTuGdGiMU0WimlsmtCwUpEPi0i20Rku4h8xrmuWkSeEJG9zteqyRnq1Nh6pIuWnhDvO3cRJZ4lFdJJNK9rsFJqOtOKlVIqV8YdrERkNfC/gQuAc4D3iMgK4GbgKWPMSuAp5/tp66mdzQQE3rZq7qj3LSu2U4HaY6XU9JboscrxQJRSvjORitXpwAZjTL8xJgI8C/wFcDVwl3Ofu4D3TmyIU+upXcc5b2kVVeVFo943PhWoFSulpjddbkEplSMTCVbbgEtEpEZEyoB3A0uAecaYY859moB56R4sIjeJyEYR2djS0jKBYUzMnuYe3rA0s9nKxHILWrFSajpzpwKVUirbxh2sjDE7gW8BfwB+D2wGoin3MQzT5mCMuc0Ys9YYs7aurm68w5iQcCTGUNRk3IxeVVZEcUGA8iINVkpNZ6Fz/VoAACAASURBVPHmda1YKaWybEIJwRhzO3A7gIj8K9AINIvIAmPMMRFZAByf+DCnRn84AiSfB3AkN7xpKZeuqkuc4FUpNS0FdIFQpVSOTPSowLnO15Ow/VX3Ag8DNzh3uQF4aCLbmEr9YVtgKy/OLFjNKStizZI5UzkkpdQkcJvXdbUFpVS2TXRO69ciUgMMAR83xnSKyDeBX4nIR4B64NqJDnKquBWrMp3aUyqvxE9powsuKKWybKJTgZekua4NuHwiz5stfaGxVayUUjODnitQKZUrvl55vU8rVkrlpYDouQKVUrnh62DV71asNFgplVfcw0u0x0oplW2+DlbxipVOBSqVVxIVqxwPRCnlO74OVvGjArVipVRe0eZ1pVSu+DpY9YW0YqVUPkosEJrjgSilfMfXwcqtWJVluECoUmrmEEHnApVSWefrYNUXjlBcEKAg6Ou3Qam8JGjFSimVfb5OFP2hKGVFWq1SKh8FRLTHSimVdb4OVn3hiK5hpVSeEtGKlVIq+3wdrPpDUV11Xak8JSLaYqWUyjpfByutWCmVv2zvuiYrpVR2+TpY9Ye1YqVUvrI9VkoplV2+D1ZasVIqP4lATJuslFJZ5vNgFaFcjwpUKi9pxUoplQu+DlZ9oShlxVqxUiof6fqgSqlc8HWw0oqVUnlMIKbJSimVZb4NVrGY0R4rpfJYwD0Ts1JKZZFvg9XAkD1PoB4VqFR+Eq1YKaVywLfBqi8cAaBUK1ZK5aWALhCqlMoB3war/pBTsdIeK6Xykj0JsyYrpVR2+TZYuRUr7bFSKj+JLreglMoB3wartt4wAJWlhTkeiVJqKojoKW2UUtnn22C19UgXAGcsmJ3jkSilpkJAdB0rpVT2+TZYbWnsZFlNGZVlWrFSKh8Joj1WSqms83Gw6uLsxXNyPQyl1BQRrVgppXLAl8HqeM8gx7oGOXtxZa6HopSaInquQKVULvgyWG1ttP1VWrFSKr/pVKBSKtt8Gax2HusG4MyF2riuVL4KBEBLVkqpbPNlsOoejFBaGKS8WNewUipfafO6UioXfBms+kIRPUegUnkuIFqwUkplny+DVX84SqmeykapvCYixDRZKaWyzJfBqi8UoVxPZaNUXtOV15VSueDLYNUfjlKmFSul8pqg61gppbLPl8GqLxzRxnWl8pxdx0qTlVIqu3wZrPpDWrFSKt+JQCyW61EopfzGl8GqL6w9VkrlO0ErVkqp7PNlsOoPRynT5RaUymt6rkClVC5MKFiJyGdFZLuIbBORn4tIiYgsF5ENIrJPRH4pIkWTNdjJokcFKpX/dLkFpVQujDtYicgi4FPAWmPMaiAIvB/4FvBdY8wKoAP4yGQMdLJEY4ZQJEaZBiul8lpAQJcIVUpl20SnAguAUhEpAMqAY8BlwP3O7XcB753gNiZVfzgCoCuvK5XnRNCKlVIq68YdrIwxR4BbgMPYQNUFbAI6jTER526NwKKJDnIy9YejAFqxUirPBUR0gVClVNZNZCqwCrgaWA4sBMqBd43h8TeJyEYR2djS0jLeYYxZX0grVkr5gaAVK6VU9k1kKvDtwEFjTIsxZgh4AHgzMMeZGgRYDBxJ92BjzG3GmLXGmLV1dXUTGMbYuBWr0kINVkrlMxHRDiulVNZNJFgdBt4oImUiIsDlwA7gGeCvnPvcADw0sSFOrkTFSqcClcpneq5ApVQuTKTHagO2Sf1VYKvzXLcBXwQ+JyL7gBrg9kkY56RJ9FhpxUqpfGZ7rHI9CqWU30yobGOM+Srw1ZSrDwAXTOR5p1JfWCtWSvmB7bHSZKWUyi7frbzeH9KKlVJ+oCuvK6VywXfBKl6x0uUWlMprtnldk5VSKrt8F6ziPVa63IJSeU2XW1BK5YLvglVfKEJBQCgK+u6lK+UrARE9o41SKut8ly76w1HKioLYFSKUUvnKntJGk5VSKrt8GKwiekSgUj4Q0AVClVI54Ltg1edUrJRS+U0rVkqpXPBdsOoPacVKKT8QXSBUKZUDvgtWWrFSyh8EPaWNUir7fBes+sMRynQNK6XyXkAPClRK5YD/glVIK1ZK+YGIaI+VUirrfBes+sIRXXVdKR+wU4G5HoVSym98F6z6Q1FddV0pH9DmdaVULvgqWBljtGKllE/ocgtKqVzwVbAKRWLEjJ4nUCk/COjJFZRSOeCrYNUXigBoxUopHxC0eV0plX2+Clb94SiAHhWolA8EAtq8rpTKPl8Fq76wU7HSldeVyntasVJK5YKvgpVWrJTyD9EFQpVSOeCvYBWywUorVkrlP11uQSmVC74KVu5UoFaslMp/AdFzBSqlss9Xwao/Hqy0YqVUvhMgprlKKZVlvgpWfe5UoFaslMp7IoLRLiulVJb5KljFK1baY6VU3hPR5RaUUtnnq2DlVqxKC7VipVS+E7R5XSmVfb4KVv3hCKWFQYJ6rgul8p42ryulcsFXwaovHKVczxOolC/YkzDnehRKKb/xVbDqD0X0iEClfCKgzetKqRzwVbDqC0d1DSulfEIrVkqpXPBVsOoPR3TVdaV8QldeV0rlgq+CVV9IK1ZK+YWgzetKqezzVbAaCEcp1x4rpXzB9lgppVR2+SpY9YUjlOlRgUr5gu2x0millMouXwWrfq1YKeUbdiow16NQSvmNr4JVXyiiPVZK+YRtXtdkpZTKLt8Eq0g0RigS03WslPIJPVegUioXfBOsBoac8wQW+eYlK+Vr2ryulMqFcacMEVklIps9/7pF5DMiUi0iT4jIXudr1WQOeLzCkRgAJXoCZqV8QdDmdaVU9o07WBljdhtj1hhj1gDnAf3Ag8DNwFPGmJXAU873ORdyglVRUCtWSvlBIKALhCqlsm+yUsblwH5jTD1wNXCXc/1dwHsnaRsT4gar4kINVkr5gVaslFK5MFkp4/3Az53L84wxx5zLTcC8SdrGhIQitsequECnApXyA9EeK6VUDkw4WIlIEXAVcF/qbcYe65z2s01EbhKRjSKysaWlZaLDGJXbY1VcoBUrpfzAHhWo0UoplV2TkTKuBF41xjQ73zeLyAIA5+vxdA8yxtxmjFlrjFlbV1c3CcMYWXwqUCtWSvmCLhCqlMqFyQhWHyAxDQjwMHCDc/kG4KFJ2MaEhYac5nWtWCnlCwER7bFSSmXdhFKGiJQD7wAe8Fz9TeAdIrIXeLvzfc4leqw0WCnlByLD9CEopdQUmlDKMMb0GWNqjDFdnuvajDGXG2NWGmPeboxpn/gwJy6sRwUq5Sv2lDa5HsUojmyC758Lg12j31cpNSP4JmVoj5VS/iLO12ndwH5sC7QfgN60rahKqRnIR8FKpwKV8pOA2Gg1nXMVoR77NRbJ7TiUUpPGNykjvvK6BiulfMHJVdO7gV2DlVJ5xzcpQ9exUspfAk6wmsaxCsK99qsGK6Xyhm9ShvZYKeUv4pSspnfFqtt+jUVzOw6l1KTxT7AaiiIChUEZ/c5KqRnPnQqczrmKkFaslMo3/glWkRhFwUD8r1ilVH4TZlLzulaslMoXvgpW2l+llH/EK1bTuctKe6yUyju+SRqhSIziQu2vUsovAvGjAnM7jhHpUYFK5R0fBauoVqyU8pHEVOA0TlbxHiudClQqX/gmaehUoFL+IjNhuYX4UYFasVIqX/gmaYQjMYp0qQWlfMM9UMXEcjyQ4RiTmAo0WrFSKl/4JlhpxUopfwlM9+b1yGAiUGnFSqm84ZukERrSHiul/MRdWGXaNq+71SrQHiul8ohvksaYjgr83efh1XVTOyCl1JQKBKZ583pSsNKKlVL5wlfBqiiY4cvd/Rgcem5qB6SUmlIzq2KlwUqpfOGbYBWORCkuzPDlxiL6QafUDBdvXp+uPVbu4qCgU4FK5RHfBKsxNa/HhvSDTqkZbtqfK1ArVkrlJZ8Fqwx7rLRipdSMN+3PFRjSipVS+cg/wWosRwVGI/pBp9QMlzilzTRNVu7ioKB/yCmVR3wTrMLRsUwFasVKqZlu2q+8rlOBSuUlXwQrY8zYe6x0JWSlZrR48/p0rVglNa9rsFIqX/giWA1FDcaQ2TpWsZg9B4Z+0Ck1o7nLLUzXXEWoBwrL7GX9Q06pvOGLYBWK2A+tjCpWbqDSHiulZrSAzIDm9ZI59rJ+3iiVN3wRrMIRexZWDVZK+YdM9+b1aAgKS0ACWiFXKo/4IliFnGBVlFGwGnK+6gedUjNZvGKV43EMKxqGYBFI0F+fN9Eh2Ptkrkeh1JTxVbDKaB2rqFux8tEHnVJ5aPpXrCIQKIRAgb8+b/b+Ae75S2jbn+uRKDUlfBKsxtFjpc2kSs1okoseq71PwmD36PcDWx0PFjjBKja145pO3IVRvUdFKpVHfBGs4j1WmZwrMD4VqMFKqZkscVRglpLVQCfc81ew5ZeZ3T865FSs/DYVGHa+DuV2HEpNEV8Eq3iPVTCT5RZ0KlCpfJD1BUKHBuzWhvozu390yPZY+W0q0P3jVYOVylP+CFZDY6hYRfWoQKXygdu8nrUeq7EGhvhUoN8qVu77FM7tOJSaIv4IVuNax8pHH3RK5aGsLxAaHWOwik8FFvjrDzmdClR5zhfBqrQoyBkLZlNRXDD6nbXHSqm8kPXm9XhgyLASE58KDPrrYBk3UMU0WKn85Itg9aZTann005dwcl3F6HfWowKVygtZX25hrFNcSUcFTnGF/Lefhh0PTe02wP5B+vKPITLCe6BTgSrP+SJYjYmuY6VUXnB7rLImOsbFhZOmAqf482brr+HAs1O7DYDGV+DRz0P9c8PfR5vXVZ7TYJVKe6yUygturMpexWo8U4GF2Vl5PRrKToXIPSIyEhphLNpjpfKbBqtU8R4rHy3Yp1QeCjifblnrsYqNZyowC83rxtgxZSNYuWFpxGDl/vGqwUrlpwkFKxGZIyL3i8guEdkpIheJSLWIPCEie52vVZM12KzQipVSeUHI8nILY63EJC0QOoXByv0sy0awcgPVSNsaa2VPqRlmohWr7wG/N8acBpwD7ARuBp4yxqwEnnK+nzm0x0qpvJD1BULHutxCUsVqCj9v3AAzUkP5ZG8ro2ClFSuVn8YdrESkEngLcDuAMSZsjOkErgbucu52F/DeiQ4yq/SoQKXyQmK5hWl6VGA0y8EqK1OBbogbYSowXkHTYKXy00QqVsuBFuAOEXlNRH4iIuXAPGPMMec+TcC8iQ4yq2KeI3uyevZWpdRkyv4CoeOdCpziHqtsLm8Qnwoc4T3wBr2uI9DTPPXjmm52/hZuf2f2fjlDPdCyJzvbUhMKVgXAG4BbjTHnAn2kTPsZ+6di2t8cEblJRDaKyMaWlpYJDGOSef9yNNrArtRMlTilTZY2OJYAY4xnKjCQRxUr9z0YqXnd88frg38Hj/2fqR/XdHN0MzRsyF6f2Yb/gdvfnp1tqQkFq0ag0Rizwfn+fmzQahaRBQDO1+PpHmyMuc0Ys9YYs7aurm4Cw5hkUc8HnPZZKTVjxXusst28nsnnhnufvJsKzKR53RNA+9ugv33qxzXdRAaTv061/nYY7NLp1ywZd7AyxjQBDSKyyrnqcmAH8DBwg3PdDUAWlvudRN4POD2tjVIzVtab18ey3IK7g3OnAqeypzO+BEIWpwJH2pZ3gdBIltbXmm4y6UWb1O052xkayM72fC6Dk+eN6JPAPSJSBBwAPowNa78SkY8A9cC1E9xGdnnXVtGKlVIzVvaXWxhDsHI/Z7JRscpkCYTJktFUoKcXLRLKXriYTuIVqyy9dnd7QwNQMjs72/SxCQUrY8xmYG2amy6fyPPmVEynApXKB4F493qWNhgPDBl8biRVrKZ4HatMws6kbSuT5nVPAI36NVhluWIVryRqxSobdOX1VFFtXlcqH4i3eb2/HepfnNoNjqViFfVUrKb6lDbZXDcqk8AQb153pwL9GKyy3GMV0anAbNJglUorVkrlhUC8x8rAxtth3VXTZ1mDbE4FZrOfZ6wLhEYGs9P7Nd3E34MsV6zcczmqKaXBKpX2WCmVF9zm9ZgBBjrtzmwqKwRjqQylNq9nJfBloWKVyVGB3lPsTPXPZLrKdo9VvHndh+91DmiwSqVHBSqVJzwrr4f77FVTuWOJDSV/HUk0tWI1lcEqi8stRMZQsXJ/Jn48KjA+ZapTgflIg1UqXcdKqbwQnwo0JKZAprJ5d9xTgdnqscriVOBI03vu+xTqde7r5x6rLIVKnQrMKg1WqZKmArVipdRMFT9XIFmqWI17KnCqg5WzLROb+s+0TEJcPFh1J+7rt9OHue9PtitWfpx2zQENVqmSTmmjwUqpmcqtWMVieCpWUxmsxnlUYLaa12Hqq0OZrJnl/vEa7k1c57fpwGyuLQaeHiutWGWDBqtUOhWoVF5wFwg1AOFsBquh0SswqUcFTuXSLt7q0VTvyDOaCnRuC3mCld+mA7NdQdIeq6zSYJVKl1tQKi8knStwyJ0KnMoeKzdMmNGn3HIxFQjZC1aZnCtwJlWsBrsS4XwyxINVtpdb0GCVDRqsUiX1WOkCoUrNVEnLLWSlYhVOfzntfUeZCjQGfnk97Hsyu+OaqEymuNzX7p2Wmu69P/deB4//4+Q9X1SDVT7TYJVKK1ZK5YWAeM5p4+7Ep3LH4v28GC3AeKcC0628HgnBzofh4B8nPq5sBqtM+szS3TbdpwK7GqGzYfKeL9tTgdpjlVUarFJpj5VSeSG5YuVMBU7lDtwbGEb77EhdINTEkivk7g5wsHsSxuWpwk/14f2jVWJiUdKevHG6TwWGeyHUM3nPl82pQGOyfwodn9NglUqPClQqL7gVKxPzLLeQjXWsYOxTgZD8eeP2H03Gznw6TQUOd/10r1iF+5J7wiYiGkn8rLOytpjn91KnArNCg1UqPaWNUnnBnQgkGk7syKZ0HasxBKvUBUIhueHd7QkLTaBitfcJuOPdya8511OBw63xNZ2DVcQ59U5osoKV57Vm43V7q1QarLJCg1Wq1FPaGAPPfx866nM3JqXUmLlTgYGot0k6G0cFMvoioalTgZD82eMexTiRilXDBqh/HgY60o9xKsSnAscYrLJ1MuLxiP8sJmFaFpLDVDam5rw/cw1WWaHBKlU0JVj1t8MT/xe2P5C7MSmlxsxdeT2QdPTZVPZYDaW/nE7qOlaQHKziFasJBCu3wuINVpm+/p4m+P650LpvbNsctWLlXB8sTr4+W6d2GQ93GjncOzkrxCcFq2ycv9FbsdLm9WzQYJUqFkn+oAs7H2yTVQZWSmWFOxUY9FappvSowCEIFtnLY+qxSjMVmK55vXHj2JaAcUPZQPuJ2x1Ny25oPwBNWzLfHnh6rIY5TY0bKIvKUh43jZuq3WAVi0xOMPe+1my87mxXyJQGqxPEhqCg1Lkc8fy10pe7MSmlxsxtXg9EsrReUjQMhU5gGNNUoBusvBWrlOmnI5vgJ5fD/qcyH4/72KSpwAyDQTyUdYx8Py9j7POLs1tJ16Pqvu7C8pTrp/FUoLdpfaYdTADJwUorVlmhwSpVLAoFTpk6FklUqsKTeKitUmrKuT1WWatYRYegyAkMY2peT3NU4JBnKtAYOPyS/b7nWObjCaeZCsx0R+4GiMHOzLfnBqmiWfZruupOdLiK1QyYCoTJ2Q9kWrE6+Cd48YeJ7x/6ODx28/i3V1g283qsHvkc/O4foPso3HIqHN+V6xFlRINVqugQFJTYyyaW+HDSipVSM4pbsUoKVlN9rkA3WMUm2Lzuft6YqA1ZjRvt9wNjCDreqlNRRfJ2RxMPZWPYnhukip1glS7EudcVpgSraV2x8nz2T0bFyhsiR5pafPk2WP9vie8bN8KRjWPfnvuel8yZ2qNip0Ljy/Z1t+6B3mZo3pb+foeetweZTRMarFLFIlBYkrgcX09Ge6yUmomyOhUYr1hlEKwkCIHAyMEK7M7c3aGOpYLkfmbFIolxZdojlG4acTTuDry4Ivl7r3iPVcpUYDaXWzj8Eqz/Vub3T/pZTMJ+wP0dDBSM/Lpb99qfg/u7NNA5tqCbur3SOTNvKnCg056ncbDLfj/c7//me5NDaI5psEoV81SstMdKqRkrEHAqVlGnYlU8e/i/2O98Dzz9/ya2wehQoncok6nAYKG9LCM0rwO07YfOw/byeCpW4KlYTeFUoPvc7rZGmgqMV6xk+PtOlS2/hGe/dWJzfbgPfvMxe0Rk0vW96S8DHHkVfvf50U+67eVW54pnDx/0Y1Fo328vx0NF19h+Hi63QlZaNbGpwCe+mqicZktqsBru93+gw/6fmSYVOQ1WqZJ6rKLaY6XUDJU4KtAJKaVVw69j1bQVmrdPbIPRcKJ3KDXANG2Do5s99x2y04AwTPO6J1gdeCZx2d3BZCIpWGUY+FIfO66pwGGmHY+8ao80hMT7VDzbuW8Wg1V/m51iTZ3WO/wibL7nxBNfjzQVuPtReOXHsPcPmW/ffZ9KZg8fKDvrEz+rgQ57v8iA/XmMtuTDnsfh2f/wbM8JGyVz7HOMZ8mIoQF4/j9h+4Njf+x4RYfsfnewK/F7OFywdK8fS4V1CmmwShVNrVhpj5VSM1G8x8qtWJXVpP+LNhZzPrwn+KEc8zave0JS/Ytw+zvgt59KXBf1VKziU4HeipXn8+bQ8/Zr3WmZVyyMSf5jcLi+J2PSVzFC4+ixSq1YpYal+26AJ/85+T7FFYBkt2LV7yw/kfpetu61XzsOJV8/UrBy358NP8p8+/FgVTl8oHTHAvb30g3UsaHRp/NeXQcvePqN3J9L6Rxn++Oo6rivs/f42B87Xu5rNtHEQRsjVawgeWmRHNJglSoWSa5YaY+VUjNS4qhAZ0dUVp1+pxLqAszEglUsag92SZ0KNAZ++dd2Z9jZ4Ll/umA1TMWqaQvMXgSzFmQedIb67Xhc8R6rlMbpe6+FH1184uMnMhXohrihgcT2jIGeZuh1ptncqcCCYvsvq8GqzX5NfS/jwSrlLBsjTQW678+B9dCyJ7PtR7xTgRkGK+9YR/s97WqwvVlDKSdeLnGC1XimA93X2ZfFYOV9zfGp8GFeezxYacVqevL2WJmo9lgpNUO5U4EFkQH7f7qwLH2wGu1Dua8Vfv4BGwyGE6/WpEwFDnRAf6utlg20J3ZqSVOB6SpW/YllC8K9UH2yrThkGnRS/xAsKLG9XN6K1W8/baew2vYnV9hgfM3rqUcFPvxJuPeaxOvxVmfc9ylYbP9lYz0nV1+r/XpCxcoJRp2pwaovEUpOqFh1JMJ0poupRj0Vq+GqR62ekOatWMHo4doN8G4Icn8upRMIVu423fcuU/3t8IsPwY8ugee+O8Zten733J/JcFPh7vj6tWI1PcWiyVOB7gfUUN/YVj1WSuWUeKcCi8qhsDT9TsU7jZCu/+TQc7aXZu/jthfr8IYT7xNNOdrN/b6vxX5dsMZ+7T6auD3oBKpAmgU1w30wa37i+6pldueeacUqNQAUFNtV4d0AE4vCjoecUGASVZzUx4d7M1+iIXUq8PgO21dlzIk7PDeMxCtWWWo6NmYcFas+W10qqjgxsA50Qu0Ke9n9WQ/HDQVJFathAmXrXjv1C06w8ox1pHAd7ktMh/W2JG9vIhUr9//IWKYCw/3ws7+04b2/3U5RjsVguopVmtc+NJDondSpwGnqhB4rzwfUkFatlJop3KnAguiA3ZEPtwN3dxrRcKJ/ZaAj8YeU23B99DVb5Xnks4nHPv5l2PKrE1cUd5cVcHdEC8+1X7uPJG53T38z3HILFfMS31cvT1SsMmk+Tj1hcLAICjzBqm2/fa3LL7Hfp07xeKe8Mm2YT11uwR1Hf/uJO7yi1KnALFWsBrsSC7EmhZVuO01ZPNt+9YaPcK8NzMWzTnxfBzuharmtBva12Om3wTQnaz78EnxruX3fk5rXhwmUbXth0VpAxlax8k43uz/TaGrFahxLLrjvVX9r5gWGA+vh6Ktw9Q9hzQdt71okBH1toz3S8lasRlpuYSzTpFmiwSpVUo9VbPLXMFFKZUXSAqFFZfZUVWmDVcoHc7gPvnsWvH6vva7joP168I82XPUcTdx/053w2t2eak1Kj1VfarDyVKxSpwJTV14vmZ3oRao+2VYcYpHMdoypvUDBwuSKlTttdcrlzjhTqi2hnkRIzHRn5YYj90g/V/uBNBUrT7AKFiV2/g/8HezxHGHXe3xyTnzs8lbmvK+rzalWnfxW+9UbUML99udaVHHi+zrQaY82La+zY33s/9hTD6Uuv9C8zf58j+9IrliZ6InTsP3t9udRt8pOFw50pISMEYJVl2fcvSlTgW7FaqTqYMtuuPt9aSpzzvZNLPOqkNtwvuxiqD3VPnbX7+CWFYkDMkaSLkCmvc7z3uhU4DQVi6SfCoQT/1MppaateI9VdMDuyAtL0h8V6P1gHuiwO9Vwj10iAaDdCVZt+5wdS4d9nlCP/Uxo2pamx8qtWDmBZaEzFdjVmLg9PhU4TMWqsCwRUqqWJyoOmUwHulN5xZX2a7DI9jK54adpqw12yy5OHqf38XOWZL49SISjoork6zsOpqlYOfcJFtvP20jIbnPLL2DXb+1tnYfh26fZ5QMmS1Kw8rwudxpw5TucbXumA8N9noqVZx9gjA05pXNssOprheM7bX9U6pjdQN1xKHE+xXgIT2lgb9tnv9aeakPbmCpWhxOXvcEqUGgP3oCR+6T2PQn7nz5xhXPvNkeb8oxvvxkQ+97UrrTXvXK7/T803ArqXukCZLjnxCDqvZ9OBU5T7geeBBILhLoL+GmwUmrGcCtWBVGn4lBQandiqVMZqRWrbif8uH/9tx9MBBRXb3NiIcmB9sQOraAUkOSKlQRh1kK7k3R3sGmnAlOb18sSjeDVyxMVh0wa2N0AMMuZTgwW2aqVt2I19zSYvdAZp2dnGXWqYpVLMt8epJ8KhPQVq6SpwCK78+9ypknd97Jlj63o1GdQ3ciUN1i5r8sYu3J3aXWiYuVdciHcIYaDzQAAIABJREFUZ4NgcUVy71q4z+4jSqugos7+rN1KV+ryC91O9aaj3laM3EAJJx4Z6Dau1670BKtO+xhk9IpVoMAe+OBtXi8otlVPSCw8mo77ur0BDZL/+Mi0z6qnCcpr7f60xulDq38u/fOnM9CReI8g8f8ldWo6PjaBfp0KnJ5iEfuLGShwjgrsgYq59jadClRq5hAIEqW6Zy/UnJKY4k+dChlMDVZO+Ok8bCtT3Ufg9PfY69wP+p6m5BMiH33Vfo1PuXl6rMrrbIP67MXDTAUOs0BooVMlKauxU0IlTrhLV7HYfC/88vrE924vkNsAHyy0rz8askHi2BaYf459zmBRco+V+wdkvGI1xqnA1IpV+8ETnyNpKtAZlxto3Z2uG2ybttjP3nRHZbbth9vemjx1NxI3WAWLE+/jvifh4LNw6RfszyhYnBKs3B6r2Sm9Z87jS+ZA+VwbDHubbBg6+GziZw2J3rrOevs+ub1lEA9WkWiM+rY+Wz0LFsGcpckVq9IqZ2pwlB6r2QttoO719FgVFNuKVWl1oiLmaj+YmG6NB6uUBv7BTuI14LFUrCqc37/iCrtkSHyc9ekf4zXQaf/vuL8rwwV993ercon2WE1Lxti/JN0To7oVK7eJVJdcUGrGCAicIfUURXth2SX2qEA4MVgNdCSqRt5g1dXg7AAMLL8UTrkMLrjJ3tbblHzqkyNusCpKDlZ9LXQFq2ho77c7vO40U4GSEqyMsQfKFJVB5SKYd6a9vnSYilUsZk/RsvPhREXF/TprgWdchXa7vc22CXn+WSCCKa+jq9UTEt3HzjnJeU9Sttd9NH1DezRluQWgf/Ypw1SsnGmwoKd5PV6xarCvyZ02Pfa6PWDgp++037cfSEwHbbrT9r0Nt/L5c9+F26+Avc5q6m6wql6eeB9f+L4NMWs/YgNwzSk2sLncqcCilIqVuxMvnWMrM+4aXSuvsF9bdiXu25NSsSrwVqzs7+MDrx7h8m8/y8Cxnba6FCxIBKsBZ8oxZcmNrs5OWps9Aa6rASpPsvssJwAd7+gijBPia1Ykv7aW3fD9c2HXI874DtmvJ1SsOhO/D2MJVk7FtKt/iKE5pyRuy7RiVTIn8QdF1dLEWFLvB1Bzsk4FTkvugnqBAvth557Sxv2rT6cClZoxRIQ3BnbYb5a++YQdWdxAh92xupfdHfpAh+1FAruju/5BHir/S/u9t2JVVuupWBXZHaIzLdbfcYzN7YX8x+O7nWA10lSgExYiIftZVFQOV/0XXHOXvd6ZChzsSdl51D+X2CG6O81wr/0MK6txxuVU0iIhW60CG6yAdip5dcduntrpVITc8JCuQtDbAre+GR76OCdIWSA0SoCnepdiOg7aQFNelxiym0+8yy2473tsyIYU789h26/tazz6Gvz3BbDpDhu+tv3a3qchzRIYfa32ZMtHNsE9f2Xfm75WG+ZmL7I76FjMhuKV77RTkmB7m1p3J57H22PV15roRxvwVKzcWQ2wARwSfVvGJE9zOlNzxv35OxWr1xs7icQM4ebdiZ4kb8WqpJJuKthT30AsZmCwm4EfvJn+266w2zDGvsaqZfFm+nAkxsb9x2gbdKpNtSuTK1b1LwDGHrUYiyWWmkg3FVjtHP2Y8VSgrVg1dQ1yxX/+kd8dcyqZi87LLFi5/WtusHL/jw6mVKUGOu24Kpdo8/q05P6VGSyw5flo2K6PEa9YabBSaqYICLwxsJPO0qU0RCp55YhzCH3qOj4DnTb0BIuTK1ZgjwQEqF6OMYZb/tTKkAkS7T5m+2aKKjg6+5zEjiJYYAOMs9zCYEcTrVTy5M5mDoYrob+N8EDvyAuEukf9FZZDaRUP7Rngzd98mk5jqzyPvbIzefyvrrM9oQBt+/jVKw30dHUQKijnjlecEOA2r0fDiSMC569mcCjKrp4SaqSbb/9hj91hO8HqP/7YTHdBNaHXf52oCjz2BVsV2P37pGmXj969ifs2OKHOmQpsNnPYEZqL9LXYyl/lYigswxDgf/3MGYN3fS13ugyg8zD9rYfoM850mXvE5Av/bd/bg3+05/brPkK0aBYtO//E8/tSmrJf/IENbNfeBRhih56jvrGBcEl1ovLTts9+rrtHbYI9Gq/jkJ0GjsWc6mEFnPMBG3jXXW3Dlhs43eZ1R3vVWYQLKjBusAp12+eoPAkiA0Q7G2juh889YCtaxgn6B5rauCSwhfK+BhvuwAlWnTDQTqcpZ2ub0NvZyhM7m4k9/CnmDzVyUvQwkcZNtkLW3wonvdEGvb7jPLunBSJheiIBegaHbDWu5xg/+8l3uP1/vo1xTqrctX8DP3rkeafqKPHf59/87rf88Jufxwx22mnE8jobYl/6ERjD0c4B+sMpzeRg37e+45jyudx090Zae0P8uu9smmovglVXOmExsSzFvuM9RKKpvY8dycEqpWJljOHul+oJ9bTZ+5XV2MdM5lGk46TBCuxZ7R/8+8RfjG6PlVvudsvp2mOl1IxREoALg7vZUrCa/3h8N3dscCpMkUG++tA2vvBv36b3O2uhq4HmoVKGiisTwcr9Y2rnb+3lshrq2/pp6AzRQiXNRw7x6vYddBfU8LOjnoU8PVOBu491Uz7URnDWPPrDUb71mg1Qr760PuWoQHcq0IaHwT67wxkQGyoefO0IRzoH+PoTjcSMcORYE+19TnWoZTdse4Dwmr/BIBw/tJ0v/HoLG3bV0z5URNOgs41gMc39MRpau6BpKwMVS/joffv4s+//iaNDFZxU1MuOY938YUcz0QH7ubepKcJnBv+OYMd+uOdazPbfwPYHiJ12lQ03Ox4G4FBrH7/f3sT+Y061oNgNVtXsMM7OsHGj3TGX1TJEkDDOuNwpsUjIVqjcBv3Ow0Q7Gng+tpoYAYbKF2AIwI7f2NsbNsDWXxErKOW/+t9J3dBRbn/sRQCGojF+seEQsY13wOl/jjn1SkxpNU8/8Qh7DtZzJFSWWGzVqTRuji5P/AzrVtkA1bYvHnIf3dPND/dVYv7yx3B8O+z5Pfc+a8OhKam0PVaO/9o4wI7wPFoPOdVOt3F96UUA9DVup21QmFVug/Iz2xsxxnBu86+5u+ibFBBlqM6d/q0CDOG2ev7UECZcOIvaYD+/eOplAjse5K7IOwiZAnpe+Xnij4Dlb7HjGezi4U0HKGaIEIVsrO+gMWD7nN7f8HXef/TfGdxvH1PQvIX1L70EQHTeauhsINLfyYWvfIaPDf4Y09WYCJD1z8Pvv0jPkZ185D/v58Yf/IG+UOqSEW0Qi9Bk5rClsYuvXnUmnQsu4S97v0Botn2vTcchePbf6fz2Wt7/nd/y2V+9boO9a6CTY+ESmsNOuPZWlYFXD3fyf3+zjQMNDfZ9KquG2BAv7DxEY8c41uqaRBqsAF7/OWy9L1ECDxTaDzs3WLll3uF6rCIheOKfknsuXC170l+vlJpSgeNbqaCfBztO5vHtTQxip14ioX4eeO0I7x54mIruvdDVwPqGIZqHypxgdQSWXGifZKCd2GnvARH+5FREjpsq6usPEO0+xraecp6Jnp3YqNPLFKl/iZdu/yzFEuHytaupm1XMy1F7ZFT9609DbIiuEPx+27ETpgJ/87KtdPzguaM0dw/y4n7bF/TrzcfopoxlHOGBV+00Wc8jX8IUlfOtwb/giKlh/67XEYHIQDddsVIGxZn+DBZyqDNCe3cvbfs3sr5rPhvrO1hcVcbiJUupNF1UlRbwxI5m/rjdLi/xd+9cg6y4nH8t+Sw0voy578Psii3h8+aTmJoVtlIWCfGLVxoIBoRap4XtX/5wiBhCR7CGvYWnEUPARKkfKKGNWYRMAUPGvuaeSIBBU0B0KERTw37656+1T9J+kNKBZvaZRTxS8HZuC1zD7tgi+x5JAHqbMa//kp2Vl/C8se9/4bGN7G7q4eHNR7nzN48RGOzgp62n84GfbKCj5lyW929lYWEvx4bK6Kac6EAnL/7pCfpNMTc92k044lRMalfZr627Gei2P/PnDw/y77/fzbfr7Xpi4d1PUt9oK2xP1w/ZHisgVlbHLze3sN8sxLTutVUYtxJ30v9v787Do6rSxI9/T1VlT0hIyEZWEhISNtlkkX2VVYRmGOxWUXHDwXXsFrUdpad17O7RVn/dbmOjoqK2iorY4saisoc9GHYSIIQQtiQQslTV+f1xbkjEBFGSVEi9n+fJU7duVaXOm3Or8t6zXZNYtXKfJCwkmDm/6gHApxv3cbiknEHudeT7JDGm4n94Yl86R0rLrcQKfKtKsAe2pk+n9kT5nCGi0Myue8c1jKXu7gTs+Bi9czGEJfHOLsXC3abF9Pvt20kMtVOFD48t3MaMRSYpcSg3QaqcgNL97HNHE6QqeKi9mQCQH3Y5uKs4Nv82YjHx25zl5Jy0URaceLZM679ZxFt6Nn87OZPnX5+Hrt1SdMp0K2eXmONvZGY0D43N5FDxGf602iQ9J964HpY+TljpLm4PXs4nmw/xwvKa8V/uMyf4dNcZVh0ynwtnqDXGq2AzHNvDqj2mbCXHizhtC+GdbNPw8bs3lvPO2guczNBILiqxUkrlKqW2KqU2KaWyrH3hSqkvlVK7rNvWDVPURnJyvxnw564yTcvw4xYr/1AzjbqytO7fseMzWPEsrHulZp/bBR/cAn+/HN67oVFDEELUIdf881nhzKDC6cY/wLQQHMpaRFRFHoPsW88+9YQ7iCJngPk+qCgxXUPWGJjpq2IY8+y3vLU6j7iwACr8I2ntOk6STwmh0YncPW1izXvaHOCswHFiD9Od7wMQEtGW34/L5O4J/Tjun0j4sU1UVlayMreE29/cwOc5pruutKwc16oXmbZuCgC7TmgmP7+SCqebjBgzbikrfDzj7as5sGwu77/6FCF5X/FN1LW8l1POXncsgaX7mHhZWzJCygkIDiMuynRRnayEkxXQmlIiKg5yPCSDFbOH8vpNvenXJQPlquQr+yz673yCvXlmnM3Qrql0jQ/j1ZPdyIq7DqdWzI/5LQs2F/FNm2mQn0Xh//al65r7uCW5iN+EbKTA3pb56w5xRvviaB1PWlI8ucqM1Vqy38mW4w6c2PH3N60QC7YcY/meYirKywitOsKSolbooCjIz8KBkwIdwV2nbuAvRX3Z4jbLBeiOVwOgnGeYX9abwOQeaJ8grnEs57UVe3ltZS4DfMwYqbkH27J673G+K08h1VZAR/cuNrna8VVuFXbctD6yht32VI6Uufjye5MMnAxMxI2NZd99x+al7wEwfuxVTO4ex/PLc6lMGoRr11cEcxonNh5dvJ+VheZfaU5ZK8oqXUS160yUPsbnG3afHYv3yMYQzthNPYa1CkZZ3YfpJav4x5cb6KV24EofR3KnPry2ej+T/r6S5acSzrbujeySQGCrNvhVlTDVfx1FOpSSVh14wzUK34pjqD1LWFaVyewFW/nb7nAqcfCM4zmS/E7j4xdA3rEyyoOTcGnFBsdl7HGbnphFfuMA6FK8BJdWrHKZS+lEH1zMQjWMKkyL6oKcMp4Ouhfu3oz2D6PdzlcJV6cI9XHxH/mzWbt2pek+nXe1uU4ksOqID+2jgokJ9adfagR3DEnl41wTT3jZPpaET+U7unGT3xLGdYzg70t3c+xUBWcObMLmqqDU0YaUeNPKtuSANt3jG9+AuVeStSsfh03h7yolq1CzvMD83qcG+zBrWPvzfTM0uoZosRqqte6mtbZONZgNfK21TgO+tu43X3kra7b3LTe31WOsqgcnVq9hUl+LVc4nP7wFc22xrf80A0T3r/rh9F0hROPL/Q4d0R7f1m1JaRPEqD5mkc7ELc/wme9sbNpFQaBpnSglmCJnILrQGuwelohuFcdJQiiKMF9t2w+XMii9DX7hcUSrE7TRx+mUns7oLrGUKZO0bTxYeraFYrufGRxOSDQTu8Ux/Ypk/FP60dO2k+KSYkoqFbGh/vx+oRlrs3n7dtxLHj9b/Cn90sk/eQY/h43HJ3XBpkAN/y9Ox/Zhjuv/cXXuH1mnM5mxux8l5U6ISKWdKuCmjm6Sy7aSdPlY2sebLs0V+0oo1K1JtJkkbtTwkfg5rC5Iq0U+RJcx2bmY35x82ez3DaZrfChaw/QD47k+fD5zZl7PyI7R3JHThRdj5lBU5mag2sIDBfcScGIHsZOfIOv3I8m+4hkyJj1E73bhrKoyA7G7prUjPiEZH/9AOsSb98wt0eSf0gRWHSdAVbLhZBBF9mjceeYkNzbJvNamILS9aUX8yGcMpTqA4zqYd0+kM6RjAmrYwwyxbSRm4zMEHlrNtW3zKfWL5oYx5pI9b+ab7lpXSBx/c17NqgLT7ZphO0CnXoOJCwvg7bX7qXS6mfjSevLckZzK34bPtvfZb0+kb7/B3NA/GbeGbP+eBJQfob/PLrRfKMXlTqa/a1r5Sv1iGNc1lv59TOvU6qw1FBfmAvDuHgcTyh7ha58hBHb7FURl4u55I7c5PqXn5kdxKDeh3SbwwrU9+WTWAMoqnUxfVMxvbfcD4BOTCZ0no4Derg184+7CoA6RFIT35v7KW3FqG2+XdKFHYhhhSZdxe+U9dLTtx/dYDkHBrQj2c/DmzCFsH/AsidNf4W09itPaj/ykieAbjCo+QIFPAl8Vmq7cfB1ByZD/5oCvSVKKCWJTYRX4h3IopAtJHMJt80XdupRyWwBxi2+i4JWpsHfp2S7W5YdsDGjf5uwxfe+IdOZcM5gqewB73LHMLBjLrnbXYjt9hD9Efk15lYv//WIH+9/5T07oYK741V10STUtVS+uOUZO/6c5M+BBOF1E2sEPmN69Fam2Ao7bI3jwjtsgOIY+Rxfg72Ov50uhaTga4XdOBIZY268Dy4AHGuF9GkbeCtMiFZpQ00ddPSuwusXKN8j81DXGyllhVtn1DzWDB4t2QmS6GdwXmghT55nprNkfwMD/bLq4hPBmbhfkrUR1nszLPXthtyliQv25dutcqo7u49mgucRExxDY7Vb49DZ6ZaZSmHMYZQ06n7u1gszWE/jiyAlmj+vMwLRIlu04Qtf4MELWpOF/+ANwc3b85daMu+mT8wR3fJjHw/EzyC44TfSQu8gIyTIzEi2BqVcQ+P27AFTFXc5bU/ow99tdHMxuy4ADJqF50n4rDyTvYcTgofz7mQL8fWz0TGrNmodGEBniB+kfUbbiRU5tX4LP4KdwzttNWKAP/fv0xf75R3TN+asZztDrJrru3Qhb4F/fHyc74DquS/NH7VlCZId+NX+rhN6QOpz9PR7k8bc+5yHHfJICyvH1C6FLvOmGOV3pYmDXDiil+O2VHbgyp5Anc9O4ZeDbPDwgFF4bZ2badbyaYKXoc+WvAbg+sopdp0bA+q/pmZEKabdB8UHisttw2957We3OZKaj5oQ0Kj6FNw+e4T4f05rYv0c3Qg6doltCGIP/7U4effoM89YEco9jHCqgNc4KByMyoyHsdvT3n3D3gQXc7ViAPuKD6jSJmwel8t76fDYVtmdX64G0nzgbv3lllJQHnn1Pe99bmebn4qkvd/LowmzyjpURmNKZoQWrCdKnyW5/F8pmo3PbUKJC/Hgpvx0vAT30NghKYdGtA3j5m71U5rajb4+h9B3cA4pMcjK64AU4sp88YpgzuQePLtzGvkF/hT6m9c025k+UFu5jzMFlHKcV4akmeewcF8qCO/qTU1DCsIzR4LzdjAtTCvrfDd89TaeBkxjQN51HP97GgqODqEgex5NT+xLoZ+dISQVvrg6jvNe1BB38loToy/g2LJPWQb4wcjoAWdFT6XewP/ckJ0Hf16HsBP86lMzSZYf43KcXeWnTuWVQJzbt6AGHdlCsg8gpKMHl1iwuSWIG36JSBuEblcbBkS8R/vksYguX86nvlYysXIIvVeQ7WzEovSaxcthtjL8sjjP2fzDznUIqtC9dBk2GwJVErPkz/4i/ls0byujgyGJJu/sY1ikVgkeyL3cPG3Y7GbM4hKiQXvwzuDs3ly5ElxQRpCroe80jxEaFweUzYOnjZkZm9cxKD7jYxEoDXyilNPCS1vplIFprXb0oymEgut5XN5UDa2H5n+t+7OBaSLzCzDioXi23eh2r6sTKL9isZLt3Gbw5xVzDa8QcyP3WjDOoLIUJz8End8H7N5ozwLzvYOQfzDTthL6w6nmwzsIajFLQd6YZ1PfFIzXTnYXwds5y06WXPJCObWuuXffynRN5YdkeDne4kZi2gYS6XbBvIn0GXMWEbWE4nXYS7Mf561Y/SnVfUtoE8UhaJDabYnim9VWWMRK2zofi/RCVCcBlk+/now1Xk/F9MbN2mCUOFmckQEynH5ar3WDwCaKi90ymDXsIh93GHyd352XHC4xefwvbdRLlPW5AXWVe96cpNbPNIkOsQby+gQQOvY/AofcRBUzqfoaUNkHY46w4cz6BLlMhJIY2rc1lTKqw0z0tEfXvb5hZkb41iQWtk+G6BbRza7J8jzNF9yTrnkFgs9Mm2E5cWAD5J89wZSfT6pMeHcLUngks23mEWcPSIMAHZq0zA76rr3xtCfH3ocegq2DzHHPCGZ4C4SmkFOYx1305fg4bR6P7saUom7S4KG6aOo2Hvyzkg+9PMJYVdMjszOtRbqJC/PAPCiRm4I3oxdvZ2v52Zg5Jhd3HSAg3sagbFpmegSX/jfr+I0g2Ce3wzCieLyzl8NhXSUuO5LKEtWza0Z7SxGGEjH8CwlO4aYCTd9Yd4O21B+gY24qoiX+k4sNZVBVuJW3kTQDWMRDF22sPMM9/HNfzKRzfR1JEEI9P6gJVq2pmekamc7zfg3Rd+QyHXBEcGfMy1/ROZHzXWIL9av3bdfgRMuMjVn/9EaUuOyNtNS0t7doE0a6Ntd6XT60RNUNmQ0QqGV2mgsOX9JgQFm87zKQ+HUziBCSEB/LgWHNsEtUOH+DcMTmd40PZdLCYyxLCIGkEAFcllZN3xh97h/ncnBGFUopW6QPg0Nt0TU/l8+0u5q3K5YuSdszwA5U+GoCuV4zG1Wcn327N4fcfH+SkzZcJvuv5w/jLGZwexbkCOo+jU5dN6PxieiaHQ+LL4PBj6OY3GeqA/fHjGfRrq7MrqR+JN/Xlmc2H8HPYeHLxdu4+NonX/f5C2IHPoOcNxKZbszp73gjf/MVcGH3Ywz9636ai9EVMTVRKxWmt85VSUcCXwJ3AQq11WK3nnNBa/2iclVLqVuBWgMTExJ55eRewEusvte9bM7i8LkrB4AfMbIfFs01L1VXPmVWMi6xpzXduMAuobbNmpBRtN2eqx/eahCyqE/zba/DVo2Y9EDAzKKa8am53fmEW8NPuOovwixXtgNShZl2Qr+dYU4bVT75MCK/g38p8LgMubJjn8KeWsafoNLPHZDC+ayybDpykQ3QIadEhP36y1iZxq54Kbtl2qJhxz31nBqs/NByl6vg8Vl9ipJYVu48y/RVz6ZY3bhlAv9SICyrzjxTthAOrzbpMITGmlX3hLLIyZxOXkERsaMB5X/4/n+VgV4rfjc44u+/+9zaz/XAJi+4ceHaf260pd7oI9L3Ac/PKMrNAq/X3WLXnGNf832r6pUTw4NgMvtlZZJK02ipO/ejyOCXlVUyfu5b7RqYzMC2SOrmqzFCMDmPB7kNB8RleXZHL/aM64Ouw8dHGfD7ZfIhXpvf6Qf0s31nELfOyeG5ad0Z3jrEWai2rWcwU+G7XUa6bu4bnr+nOmKNzzRT/vjPrDfuR99YQGRrCXaM6Xtjf6RfIPXqa99Yf4N4R6TjsFz66Z+Xuozzz1S7euLl3TbdwXVxOTm38gNyYUYz/20oCfe2E+NlZMf4kjo4TzDU4aykpr8LXBv7KWbMobx0qnC6qXPqHiWb+BjM7NHPCj5L0apVON8Vnqoj0rTQnERnjzWe92uFsiOpoFnttREqp9bWGQP3wsYtJrM55k8eAU8AtwBCtdYFSKhZYprXucL7X9urVS2dlZTVIORrMC/1rLhQ5e/8Pv0BzPoF3r4XITLjl6x988JrUu9eZMsb1NK1h923zTDmEaAHue3cT/8ouYNXs4WfP/H+Jhz/cSkwrf+4cfuFdEeVVLro+9gXB/g7WPjT8Z/2DbGyVTjcutybAt+HGrRSVVtD7ia+4d0Q6d/2Mv1NjK6t0/mSyeOJ05UUdH5eqSqebTo8upsqleWB0hmkx9GLnS6x+cVegUioIsGmtS63tUcAfgIXAdOBJ6/bjX/oeHlXdJGtz1FxhvlrmBLh+IURmeC6pAnOpi5xPzJlVdOOdEQnhDR4Yk8EN/ZMv+p/m45O6/OzX+PvY+XWfRKJa+TWrpArA19Hw5YkM8WP+zX3pGh/6009uQhfSAueNSRWY46B9VAh5x07z696Jni5Os3YxY6yigQ+tplQHMF9rvVgptQ74p1JqBpAHTL34YnpA9doyAeF1N0mmDG7a8tQlqiOg4cQ+6DjxJ58uhKhfdCt/olv5//QTG8ljV3X66Se1IL+4u1N4zP2j0imrdBEa6OPpojRrvzix0lrvBS6rY/8xYPjFFKpZqL4wamAz/vBHd6p7WwghhGhgZydwiPNqXm3OzUl1i1VzTqxaJ5uFS8FqvRJCCCGEJ0liVZ/qMVaB4Z4tx/nY7BCVYZLA6ot2CiGEEMJjGmOB0JbBdgl0BQKkjzFLPzi8c0ClEEII0ZxIYlWfS6ErEGBI813UXgghhPA20hVYn7OJVTPuChRCCCFEsyKJVX0uhVmBQgghhGhWJLGqz6UyxkoIIYQQzYYkVvWRrkAhhBBC/EySWNVHWqyEEEII8TNJYlWfS2VWoBBCCCGaDUms6mOzg80HfIM9XRIhhBBCXCIksapPcDREtK/7AsxCCCGEEHWQxKo+gx+AGZ97uhRCCCGEuITIyuv1cfiZHyGEEEKICyQtVkIIIYQQDUQSKyGEEEKIBiKJlRBCCCFEA5HESgghhBCigUhiJYQQQgjRQCSxEkKxpw27AAAF3klEQVQIIYRoIJJYCSGEEEI0EEmshBBCCCEaiCRWQgghhBANRBIrIYQQQogGorTWni4DSqkiIK+R36YNcLSR36M5k/i9N35vjh28O35vjh28O35vjh0aP/4krXVkXQ80i8SqKSilsrTWvTxdDk+R+L03fm+OHbw7fm+OHbw7fm+OHTwbv3QFCiGEEEI0EEmshBBCCCEaiDclVi97ugAeJvF7L2+OHbw7fm+OHbw7fm+OHTwYv9eMsRJCCCGEaGze1GIlhBBCCNGovCKxUkqNVkrtUErtVkrN9nR5moJSKlcptVUptUkplWXtC1dKfamU2mXdtvZ0ORuCUmquUuqIUiq71r46Y1XGc9axsEUp1cNzJW8Y9cT/mFIq36r/TUqpsbUee9CKf4dS6krPlLphKKUSlFJLlVLfK6W2KaXutvZ7Rf2fJ/4WX/9KKX+l1Fql1GYr9jnW/nZKqTVWjO8qpXyt/X7W/d3W48meLP/FOk/8ryml9tWq+27W/hZ17AMopexKqY1KqUXW/eZR91rrFv0D2IE9QArgC2wGOnq6XE0Qdy7Q5px9fwZmW9uzgT95upwNFOsgoAeQ/VOxAmOBzwAF9AXWeLr8jRT/Y8D9dTy3o/UZ8APaWZ8Nu6djuIjYY4Ee1nYIsNOK0Svq/zzxt/j6t+ow2Nr2AdZYdfpPYJq1/0VgprV9B/CitT0NeNfTMTRS/K8BU+p4fos69q2Y7gPmA4us+82i7r2hxao3sFtrvVdrXQm8A0z0cJk8ZSLwurX9OnC1B8vSYLTW3wDHz9ldX6wTgXnaWA2EKaVim6akjaOe+OszEXhHa12htd4H7MZ8Ri5JWusCrfUGa7sUyAHi8JL6P0/89Wkx9W/V4Snrro/1o4FhwPvW/nPrvvqYeB8YrpRSTVTcBnee+OvToo59pVQ8MA54xbqvaCZ17w2JVRxwoNb9g5z/i6el0MAXSqn1SqlbrX3RWusCa/swEO2ZojWJ+mL1puNhltXkP7dWt2+Ljd9q3u+OOXP3uvo/J37wgvq3uoI2AUeALzEtcCe11k7rKbXjOxu79XgxENG0JW5Y58avta6u+8etuv+rUsrP2tei6h54Bvgd4LbuR9BM6t4bEitvNUBr3QMYA/yHUmpQ7Qe1aRP1iimh3hRrLS8AqUA3oAB4yrPFaVxKqWDgA+AerXVJ7ce8of7riN8r6l9r7dJadwPiMS1vGR4uUpM6N36lVGfgQczf4XIgHHjAg0VsFEqp8cARrfV6T5elLt6QWOUDCbXux1v7WjStdb51ewT4EPOlU1jd9GvdHvFcCRtdfbF6xfGgtS60vnTdwP9R093T4uJXSvlgkoq3tNYLrN1eU/91xe9N9Q+gtT4JLAX6Ybq4HNZDteM7G7v1eChwrImL2ihqxT/a6h7WWusK4FVaZt33B65SSuVihvcMA56lmdS9NyRW64A0a7aAL2bg2kIPl6lRKaWClFIh1dvAKCAbE/d062nTgY89U8ImUV+sC4HrrRkyfYHiWl1GLcY5YycmYeofTPzTrFky7YA0YG1Tl6+hWOMk/gHkaK2frvWQV9R/ffF7Q/0rpSKVUmHWdgAwEjPGbCkwxXrauXVffUxMAZZYrZmXpHri317rhEJhxhjVrvsWcexrrR/UWsdrrZMx/9OXaK1/Q3Op+8YcGd9cfjCzIXZi+t8f9nR5miDeFMzMn83AtuqYMX3KXwO7gK+AcE+XtYHifRvT3VGF6VefUV+smBkxf7eOha1AL0+Xv5Hif8OKbwvmSyW21vMftuLfAYzxdPkvMvYBmG6+LcAm62est9T/eeJv8fUPdAU2WjFmA/9l7U/BJIu7gfcAP2u/v3V/t/V4iqdjaKT4l1h1nw28Sc3MwRZ17Nf6OwyhZlZgs6h7WXldCCGEEKKBeENXoBBCCCFEk5DESgghhBCigUhiJYQQQgjRQCSxEkIIIYRoIJJYCSGEEEI0EEmshBBCCCEaiCRWQgghhBANRBIrIYQQQogG8v8BVxaxzASGXPEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjnh7lPC01OT",
        "outputId": "fae0e230-1719-4735-d410-885232870e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "auc = roc_auc_score(test_y, pred_y)\n",
        "print('AUC score for validation set: ', auc)\n",
        "\n",
        "\n",
        "f1_macro = f1_score(test_y, pred_y, average='macro')\n",
        "f1_micro = f1_score(test_y, pred_y, average='micro')\n",
        "\n",
        "print('F1 score (average=macro): {}     F1 score (average=micro): {}'.format(f1_macro, f1_micro))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for validation set:  0.6891891891891893\n",
            "F1 score (average=macro): 0.6559531028906408     F1 score (average=micro): 0.6891891891891891\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
