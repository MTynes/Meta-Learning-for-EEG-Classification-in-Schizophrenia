{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN with Raw EEG - LOO debugged v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_ZRvtEVHxY2",
        "outputId": "816f66db-de29-4e03-b29b-e1540f9f4cf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "raw_data_dir = ''\n",
        "acc_key = 'acc'\n",
        "plot_examples = False # notebook file size will increase by between 30 and 60MB if set to True; <1MB otherwise\n",
        "\n",
        "if  'COLAB_GPU' in os.environ :\n",
        "    acc_key = 'accuracy'\n",
        "    print('Using Google Colab. Setting up environment')\n",
        "    raw_data_dir = '/content/drive/My Drive/Colab Notebooks/' \n",
        "    #raw_data_dir = 'Raw/'\n",
        "\n",
        "    !pip install mne==0.19.2\n",
        "    !pip install pyedflib==0.1.15\n",
        "    !pip install chart_studio==1.0.0\n",
        "\n",
        "\n",
        "    print('\\n \\n To load files from Google Drive, account validation is required.')\n",
        "    #mount to drive -- files should be located in the /Colab Notebooks directory\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    \n",
        "    if not os.path.exists('/content/tmp/eeg_sz/ReadData'):\n",
        "        os.makedirs('/content/tmp/eeg_sz/ReadData')\n",
        "        os.makedirs('/content/tmp/eeg_sz/utils')\n",
        "    # download project utilities and data reader \n",
        "    !curl -u MTynes:08ec0e86b785be94d2cefc791029008c7155da8b https://raw.githubusercontent.com/WinAIML/schizophrenia/master/ReadData/RawDataReader.py > /content/tmp/eeg_sz/ReadData/RawDataReader.py\n",
        "    !curl -u MTynes:08ec0e86b785be94d2cefc791029008c7155da8b https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ModelBuilder.py > /content/tmp/eeg_sz/utils/ModelBuilder.py\n",
        "    !curl -u MTynes:08ec0e86b785be94d2cefc791029008c7155da8b https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ChartBuilder.py > /content/tmp/eeg_sz/utils/ChartBuilder.py\n",
        "    sys.path.append('/content/tmp/eeg_sz/')\n",
        "    \n",
        "elif 'KAGGLE_URL_BASE' in os.environ:\n",
        "    acc_key = 'accuracy'\n",
        "    print('Using Kaggle kernel. Setting up environment')\n",
        "    !pip install update mne==0.19.2\n",
        "    !pip install pyedflib==0.1.15\n",
        "    !pip install chart_studio\n",
        "    !svn checkout https://github.com/WinAIML/schizophrenia/trunk/Data/Raw\n",
        "    raw_data_dir = 'Raw/'\n",
        "    \n",
        "    if not os.path.exists('/kaggle/working/eeg_sz/ReadData'):\n",
        "        os.makedirs('/kaggle/working/eeg_sz/ReadData')\n",
        "        os.makedirs('/kaggle/working/eeg_sz/utils')\n",
        "        # download project utilities and data reader \n",
        "    !curl -u MTynes:08ec0e86b785be94d2cefc791029008c7155da8b https://raw.githubusercontent.com/WinAIML/schizophrenia/master/ReadData/RawDataReader.py > /kaggle/working/eeg_sz/ReadData/RawDataReader.py\n",
        "    !curl -u MTynes:08ec0e86b785be94d2cefc791029008c7155da8b https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ModelBuilder.py > /kaggle/working/eeg_sz/utils/ModelBuilder.py\n",
        "    !curl -u MTynes:08ec0e86b785be94d2cefc791029008c7155da8b https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ChartBuilder.py > /kaggle/working/eeg_sz/utils/ChartBuilder.py\n",
        "    #!wget -O/content/tmp/eeg_sz/utils/ChartBuilder.py -P/utils https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ChartBuilder.py\n",
        "\n",
        "    sys.path.append('/kaggle/working/eeg_sz/')\n",
        "\n",
        "    # Dataset needs to be manually added to the current session. Find the directory name using\n",
        "    # print(os.listdir(\"../input\"))\n",
        "\n",
        "    # Then set the data directory\n",
        "    raw_data_dir = '../input/eeg-in-schizophrenia/Raw/'\n",
        "\n",
        "        \n",
        "else: \n",
        "    # assuming that a local run will be launched only from a github project; \n",
        "    # add the utils and ReadData directories to the temporary path\n",
        "    if 'HOMEPATH' in os.environ:\n",
        "        print('Using homepath ' + os.environ['HOMEPATH'])\n",
        "    raw_data_dir = '../../Data/Raw/'\n",
        "    \n",
        "    from pathlib import Path\n",
        "    import sys\n",
        "    sys.path.append(os.path.realpath('..'))\n",
        "    path = Path(os.getcwd())\n",
        "    sys.path.append(str(path.parent.parent))\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, Conv1D, MaxPooling2D, AveragePooling2D, AveragePooling1D\n",
        "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.layers import Input, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random \n",
        "\n",
        "from importlib import reload  #reload(chart_builder)\n",
        "\n",
        "\n",
        "#################\n",
        "# import project utilities and the raw data reader\n",
        "# Kaggle environment does not accept 'utils' as a file, so it must be accessed seperately\n",
        "\n",
        "import ReadData.RawDataReader as data_reader\n",
        "import utils.ModelBuilder as model_builder\n",
        "import utils.ChartBuilder as chart_builder\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Google Colab. Setting up environment\n",
            "Requirement already satisfied: mne==0.19.2 in /usr/local/lib/python3.6/dist-packages (0.19.2)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne==0.19.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne==0.19.2) (1.18.4)\n",
            "Requirement already satisfied: pyedflib==0.1.15 in /usr/local/lib/python3.6/dist-packages (0.1.15)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from pyedflib==0.1.15) (1.18.4)\n",
            "Requirement already satisfied: chart_studio==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from chart_studio==1.0.0) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from chart_studio==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from chart_studio==1.0.0) (4.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from chart_studio==1.0.0) (1.3.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio==1.0.0) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio==1.0.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio==1.0.0) (1.24.3)\n",
            "\n",
            " \n",
            " To load files from Google Drive, account validation is required.\n",
            "Mounted at /content/drive\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14735  100 14735    0     0   141k      0 --:--:-- --:--:-- --:--:--  142k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  6767  100  6767    0     0   104k      0 --:--:-- --:--:-- --:--:--  104k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  9996  100  9996    0     0   154k      0 --:--:-- --:--:-- --:--:--  154k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo5E3z4YT2h2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "8d6776bd-daeb-43b6-fd0a-20b6dd34ce48"
      },
      "source": [
        "#!curl -u MTynes:08ec0e86b785be94d2cefc791029008c7155da8b https://raw.githubusercontent.com/WinAIML/schizophrenia/master/ReadData/RawDataReader.py > /content/tmp/eeg_sz/ReadData/RawDataReader.py\n",
        "#reload(data_reader)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 14822  100 14822    0     0  66765      0 --:--:-- --:--:-- --:--:-- 66765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ad4QlDxFSV5",
        "outputId": "93ff4254-f12a-423c-98aa-69e8ba6c9c15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "#raw_data_dir = '../input/eeg-in-schizophrenia/Raw/'\n",
        "ignore_list = ['s10', 's11'] #['s12', 's14']  # List of patient files that should be skipped\n",
        "resolution_hz = 250  # Hz resolution - number of frames per second; 250Hz is the selected value for the EEG dataset\n",
        "time_window = resolution_hz * 20 # Seconds of data to include in one slice;\n",
        "\n",
        "all_channels = ['Fp2', 'F8', 'T4', 'T6', 'O2', 'Fp1', 'F7', 'T3', 'T5', 'O1', 'F4',\n",
        "                'C4', 'P4', 'F3', 'C3', 'P3', 'Fz', 'Cz', 'Pz']\n",
        "excluded_channels = [ 'T3', 'T5', 'T6', 'O1', 'F3', 'Fp1', 'Fp2', 'P4', 'F8'] # suggested by tree learner\n",
        "excluded_channels = [ 'T3', 'T4', 'T5', 'T6', 'O1', 'O2', 'F3', 'Fp1', 'Fp2', 'F8', 'Fz', 'F4', 'F7']#'P4'\n",
        "#excluded_channels =  [ 'T4', 'T6', 'O2', 'Fp1', 'Fp2', 'F8','F7', 'T3', 'T5', 'O1', 'F4',\n",
        "#                       'C4', 'F3', 'C3', 'Fz', 'Cz'] #P channels only\n",
        "#excluded_channels = [] # all channels\n",
        "\n",
        "chans = len(all_channels) - len(excluded_channels)\n",
        "data = data_reader.get_raw_data(raw_data_dir, resolution_hz, ignore_list, \n",
        "                                excluded_channels, time_window, remove_outliers=False)\n",
        "#np.save('data', data)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum EEG reading duration:  740  seconds\n",
            "Maximum EEG reading duration:  2170  seconds\n",
            "Median EEG reading duration:  925.0 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Shape of raw data for healthy controls: '"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(14, 125001, 6)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Shape of raw data for schizophrenic patients: '"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(12, 125001, 6)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Selecting training  / testing / validation sets randomly from patient data\n",
            "Splitting data into time windows to improve stability of results\n",
            "(10, 125001, 6)\n",
            "(250, 5000, 6)\n",
            "Shape of X_train:  (450, 5000, 6)\n",
            "Shape of X_validate:  (100, 5000, 6)\n",
            "Shape of X_test:  (100, 5000, 6)\n",
            "Selected indexes for control group: \n",
            "Training:  [4, 7, 13, 2, 9, 6, 3, 1, 0, 5]\n",
            "Testing:  [11, 10]\n",
            "Validation:  [8, 12]\n",
            "\n",
            "Selected indexes for patient group: \n",
            "Training:  [9, 5, 1, 7, 10, 0, 3, 4]\n",
            "Testing:  [2, 8]\n",
            "Validation:  [11, 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9G3ChMwQ_Rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if plot_examples:\n",
        "    random_selection =  data_reader.get_random_participants(raw_data_dir, data, ignore_list, resolution_hz)\n",
        "    chart_builder.plot_random_participants(data, ignore_list, excluded_channels, all_channels, random_selection)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P1L5LqkAXXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding\n",
        "#from keras.regularizers import l2\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# adapted from https://github.com/vlawhern/arl-eegmodels/blob/master/EEGModels.py\n",
        "def CNN(time_steps, nb_features, chans, nb_classes=2, \n",
        "             dropoutRate = 0.55, kernLength = 64, F1 = 8, \n",
        "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
        "    \n",
        "    if dropoutType == 'SpatialDropout1D':\n",
        "        dropoutType = SpatialDropout1D\n",
        "    elif dropoutType == 'Dropout':\n",
        "        dropoutType = Dropout\n",
        "    else:\n",
        "        raise ValueError('dropoutType must be one of SpatialDropout1D '\n",
        "                         'or Dropout, passed as a string.')\n",
        "    print('dropout rate: ', dropoutRate)\n",
        "    input1   = Input(shape = (time_steps, chans))\n",
        "    \n",
        "    pooling_layer1_format = 'channels_first'\n",
        "    pooling_layer2_format = 'channels_last'\n",
        "   \n",
        "\n",
        "    ##################################################################\n",
        "    block1       = Conv1D(4, (4), padding = 'same',\n",
        "                          #activity_regularizer=regularizers.l2(0.01),\n",
        "                                  # input_shape = ( chans, samples),\n",
        "                                   use_bias = False)(input1)\n",
        "    block1       = BatchNormalization(axis = -1)(block1)\n",
        "    block1       = Activation('elu')(block1)\n",
        "    block1       = Conv1D(6, (12), padding='same',\n",
        "                          #activity_regularizer=regularizers.l2(0.01),\n",
        "                          use_bias = False )(block1)\n",
        "    block1       = BatchNormalization(axis = -1)(block1)\n",
        "    block1       = Activation('elu')(block1)\n",
        "    #block1       = AveragePooling1D(pool_size=(4),  name='apl1')(block1)\n",
        "    block2       = dropoutType(dropoutRate)(block1)\n",
        "    \n",
        "    \n",
        "    \"\"\" \n",
        "    block2       = Conv1D(5, ( 16),\n",
        "                          activity_regularizer=regularizers.l2(0.01),\n",
        "                          use_bias = False, padding = 'same' )(block2)\n",
        "    block2       = BatchNormalization(axis = -1)(block2)\n",
        "    block2       = Activation('elu')(block2)\n",
        "    block2       = dropoutType(dropoutRate)(block2)\"\"\"\n",
        "    \n",
        "        \n",
        "    flatten      = Flatten(name = 'flatten')(block2)\n",
        "    \n",
        "    dense        = Dense(nb_classes, name = 'dense', \n",
        "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
        "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
        "    \n",
        "    return Model(inputs=input1, outputs=softmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_ZIuBDvT2iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZnQq_RfHw2o",
        "scrolled": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-D5YLKET2ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the /tmp directory if it doesn't already exist\n",
        "import os\n",
        "if not os.path.exists('tmp'):\n",
        "    os.makedirs('tmp')\n",
        "\n",
        "\n",
        "def rmse (y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred -y_true)))\n",
        "\n",
        "\n",
        "# Construct a learning rate scheduler such that the lr is decreased when the loss remains unchanged after 4 epochs\n",
        "# Adapted from\n",
        "# https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, minimum_learning_rate):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "        self.last_loss_improvement = None\n",
        "        self.loss_unchanged_count = 0\n",
        "        self.minimum_learning_rate = minimum_learning_rate\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "        self.last_loss_improvement = 1.0\n",
        "        self.loss_unchanged_count = 0\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        epoch_loss = logs.get('val_loss')\n",
        "        # track if losses are being updated\n",
        "        if (len(self.losses) > 1) and ((epoch_loss == self.losses[-1]) or (epoch_loss > self.last_loss_improvement)):\n",
        "            self.loss_unchanged_count += 1\n",
        "        else:\n",
        "            self.loss_unchanged_count = 0\n",
        "            self.last_loss_improvement = epoch_loss\n",
        "\n",
        "        self.losses.append(epoch_loss)\n",
        "\n",
        "    # Implement the lr_loss_scheduler within the class so that it can access loss_unchanged_count\n",
        "    def on_epoch_begin(self, batch,\n",
        "                       logs={}):\n",
        "        current_lr = K.get_value(self.model.optimizer.lr)\n",
        "        lr = current_lr - (current_lr / 4)  # propose to decrement lr by 25% of current value\n",
        "        if self.loss_unchanged_count > 3 and lr >= self.minimum_learning_rate:\n",
        "            self.loss_unchanged_count = 0  # reset\n",
        "            K.set_value(self.model.optimizer.lr, lr)  # set for the model\n",
        "            print('Updated learning rate to ', lr)\n",
        "            # return K.get_value(self.model.optimizer.lr)\n",
        "\n",
        "\n",
        "def construct_and_run_model_loo(data, model, optimizer, checkpoint_file_name, epochs=150,\n",
        "                            batch_size=64, loss_type='categorical_crossentropy',\n",
        "                            metrics=['accuracy', rmse], minimum_learning_rate=10.e-6):  # 'mse', 'mae', ):\n",
        "    loss_history = LossHistory(minimum_learning_rate)\n",
        "\n",
        "    # compile the model and set the optimizers\n",
        "    model.compile(loss=loss_type, optimizer=optimizer,\n",
        "                  metrics=metrics)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # count number of parameters in the model\n",
        "    numParams = model.count_params()\n",
        "\n",
        "    # set a valid path for your system to record model checkpoints\n",
        "    checkpointer = ModelCheckpoint(filepath=checkpoint_file_name, verbose=1,\n",
        "                                   save_best_only=True)\n",
        "\n",
        "    # change_lr = tensorflow.keras.callbacks.LearningRateScheduler(lr_loss_scheduler)\n",
        "    print('MB::   Shape of X_train: ', np.asarray(data['X_train']).shape)\n",
        "    print('MB::   Shape of X_validate: ', np.asarray(data['X_validate']).shape)\n",
        "    print('MB::   Shape of X_test: ', np.asarray(data['X_test']).shape)\n",
        "    history = model.fit(data['X_train'], data['Y_train'], batch_size=batch_size, epochs=epochs,\n",
        "                             verbose=2,\n",
        "                             callbacks=[checkpointer, loss_history])\n",
        "\n",
        "    model.load_weights(checkpoint_file_name)\n",
        "\n",
        "    probs = model.predict(data['X_test'])\n",
        "    preds = probs.argmax(axis=-1)\n",
        "    acc = np.mean(preds == data['Y_test'].argmax(axis=-1))\n",
        "    print(\"Classification accuracy: %f \" % acc)\n",
        "    return model, acc, history\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvoN1ac0VUXW",
        "colab_type": "code",
        "outputId": "4e76eccd-69b7-4666-b50c-384ab2e1b2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "import sklearn.decomposition as decomposition\n",
        "\n",
        "def select_denoised_data(patient_data):\n",
        "    all_features = []\n",
        "    \n",
        "    for entry in patient_data:\n",
        "        pca_denoise = decomposition.PCA(n_components=np.asarray(patient_data).shape[2])\n",
        "        pca_denoise.fit(entry.transpose())\n",
        "        denoised_data = pca_denoise.components_#[:14] #select top v components, where v is based on chart of explained variance\n",
        "        all_features.append(np.asarray(denoised_data).transpose()) \n",
        "\n",
        "    return all_features\n",
        "    \n",
        "print('shapes of hc_data and sz_data: ')\n",
        "print(np.asarray(data['hc_data']).shape)\n",
        "print(np.asarray(data['sz_data']).shape)\n",
        "#hcd = np.concatenate([select_denoised_data(data['hc_data']), data['hc_data']], axis=2)\n",
        "#szd = np.concatenate([select_denoised_data(data['sz_data']), data['sz_data']], axis=2)\n",
        "\n",
        "#hcd = select_denoised_data(data['hc_data'])\n",
        "#szd = select_denoised_data(data['sz_data'])\n",
        "#print('shape of hcd: ', np.asarray(hcd).shape)\n",
        "#all_data = np.concatenate([np.asarray(hcd), np.asarray(szd)], axis=0)\n",
        "\n",
        "\n",
        "all_data = np.concatenate([data['hc_data'], data['sz_data']], axis=0)\n",
        "print('Shape of all data: ', np.asarray(all_data).shape)\n",
        "all_labels = [0] * len(data['hc_data']) + [1] * len(data['sz_data'])\n",
        "all_labels = np_utils.to_categorical(all_labels, num_classes=2)\n",
        "print('label 0 and -1 : ' )\n",
        "\n",
        "\n",
        "print(all_labels[0])\n",
        "print(all_labels[-1])"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shapes of hc_data and sz_data: \n",
            "(14, 125001, 6)\n",
            "(12, 125001, 6)\n",
            "Shape of all data:  (26, 125001, 6)\n",
            "label 0 and -1 : \n",
            "[1. 0.]\n",
            "[0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G29WcDjawUmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##print(hcd[0][0])\n",
        "##print(szd[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzWlgJKPT2ik",
        "colab_type": "code",
        "outputId": "e9f1dc62-ad02-477b-f915-659dd3d49473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "#reload(model_builder)\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "import random, string\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "from ReadData.RawDataReader import *\n",
        "\n",
        "def smooth_data(x_train, x_validate, x_test):\n",
        "    # Estimate mean and standard deviation\n",
        "\n",
        "    # use the training data to fit the scaler, as suggested here https://stackoverflow.com/a/50567308\n",
        "    # flatten the features then reintroduce the 3rd dimension\n",
        "    dataset_flattened = flatten_features(x_train)\n",
        "    means = column_means(dataset_flattened)\n",
        "    stdevs = column_stdevs(dataset_flattened, means)\n",
        "    \n",
        "    x_train_shape = np.asarray(x_train).shape\n",
        "    x_validate_shape = np.asarray(x_validate).shape\n",
        "    x_test_shape = np.asarray(x_test).shape\n",
        "    # set outliers to median values for each channel\n",
        "    print('Removing outliers by channel')\n",
        "    x_train = standardize_dataset(flatten_features(x_train),means, stdevs)\n",
        "    x_train = x_train.reshape(x_train_shape)\n",
        "    x_validate = standardize_dataset(flatten_features(x_validate), means, stdevs)  # use means and stdevs from training\n",
        "    x_validate = x_validate.reshape(x_validate_shape)\n",
        "    x_test = standardize_dataset(flatten_features(x_test), means, stdevs)\n",
        "    x_test = x_test.reshape(x_test_shape)\n",
        "    return x_train, x_validate, x_test\n",
        "\n",
        "# from https://stackoverflow.com/questions/2030053/random-strings-in-python\n",
        "def random_string(length):\n",
        "   letters = string.ascii_lowercase\n",
        "   return ''.join(random.choice(letters) for i in range(length))\n",
        "\n",
        "def leave_one_out(data, all_data, all_labels, model, time_window, checkpoint_file_path, chans, \n",
        "                  optimizer='Adam', remove_outliers=False):\n",
        "    #model.summary()\n",
        "\n",
        "    model_list, test_acc_list, history_list = [], [], []\n",
        "    offset = 0#16 #len(data['hc_data'] + 3)#limit to participants with the worse scores\n",
        "\n",
        "    for i, subject_data in enumerate(all_data[offset:]): \n",
        "        print('\\n\\nBeginning training for subject ', str(i))\n",
        "        x_test =  np.array([subject_data])\n",
        "        y_test = np.array([all_labels[offset :][i]])\n",
        "        print('shape of x_test: ', np.asarray(x_test).shape)\n",
        "\n",
        "        \n",
        "        # get all other data\n",
        "        ###train_val_data =  np.setdiff1d(all_data,x_validate)\n",
        "        ###train_val_data = train_val_data.reshape(all_data.shape[0] - 1, all_data.shape[1], all_data.shape[2]) #26, 125001, 19)\n",
        "        print('shape of all data originally: ', np.asarray(all_data).shape)\n",
        "        train_val_data = np.delete(all_data.copy(), i + offset, axis=0)\n",
        "        print('shape of train_val_data after removing subject i: ', np.asarray(train_val_data).shape)\n",
        "        train_val_labels =  np.delete(all_labels.copy(), i + offset, axis=0)\n",
        "        \n",
        "        # split the data for this iteration into the hc and sz groups\n",
        "        # to provide more equal distribution for the train and validation sets\n",
        "        len_hc = len(data['hc_data']) \n",
        "        len_iter_hc = len_hc - 1 if i <= len_hc -1 else len_hc\n",
        "        print('i: {}, length of hc for this iteration: {}'.format(i, len_iter_hc))\n",
        "        hc_iter_data = train_val_data[:len_iter_hc]\n",
        "        hc_iter_labels = train_val_labels[:len_iter_hc]\n",
        "        sz_iter_data = train_val_data[len_iter_hc:]\n",
        "        sz_iter_labels = train_val_labels[len_iter_hc:]\n",
        "\n",
        "        # determine training and validation sets\n",
        "        #x_train, x_validate, y_train, y_validate = \\\n",
        "        #        train_test_split(train_val_data, train_val_labels, test_size=0.2, random_state=1)\n",
        "        hc_x_train, hc_x_validate, hc_y_train, hc_y_validate = \\\n",
        "                train_test_split(hc_iter_data, hc_iter_labels, test_size=0.5, random_state=1)\n",
        "        sz_x_train, sz_x_validate, sz_y_train, sz_y_validate = \\\n",
        "                train_test_split(sz_iter_data, sz_iter_labels, test_size=0.5, random_state=1)\n",
        "        x_train = np.concatenate([hc_x_train, sz_x_train], axis=0)\n",
        "        y_train = np.concatenate([hc_y_train, sz_y_train], axis=0)\n",
        "        x_validate = np.concatenate([hc_x_validate, sz_x_validate], axis=0)\n",
        "        y_validate = np.concatenate([hc_y_validate, sz_y_validate], axis=0)\n",
        "\n",
        "        # remove outliers\n",
        "        if remove_outliers:\n",
        "          print('Removing outliers')\n",
        "          x_train, x_validate, x_test = smooth_data(x_train, x_validate, x_test)\n",
        "          print('Shape of x_train: ', np.asarray(x_train).shape)\n",
        "          \n",
        "        print('shape of x_train after removal of target: ', np.asarray(x_train).shape)\n",
        "        # apply time window\n",
        "        x_train = chunk_list(np.asarray(x_train), time_window)\n",
        "        x_validate = chunk_list(x_validate, time_window)\n",
        "        x_test = chunk_list(x_test, time_window)\n",
        "        \n",
        "        print('shape of x_train: ', np.asarray(x_train).shape)\n",
        "        print('shape of x_validate: ', np.asarray(x_validate).shape)\n",
        "        print('shape of x_test: ', np.asarray(x_test).shape)\n",
        "        # Update labels - copy the label for each time window of the sample\n",
        "        #print('y test before split update: ')\n",
        "        #print(y_test)\n",
        "        y_train = [l for l in y_train for _ in np.arange(len(x_test))]\n",
        "        y_validate = [l for l in y_validate for _ in np.arange(len(x_test))]\n",
        "        y_test = [l for l in y_test for _ in np.arange(len(x_test))]\n",
        "        #print('y_test after split update: ')\n",
        "        #print(y_test)\n",
        "        \n",
        "        # update the values in the data dictionary\n",
        "        data['X_train'] = np.array(x_train) #np.asarray(x_train)#.reshape(500, 5000, 19)\n",
        "        data['Y_train'] = np.array(y_train)\n",
        "        data['X_validate'] = np.array(x_validate) #x_validate#.reshape(150, 5000, 19)\n",
        "        data['Y_validate'] = np.array(y_validate)\n",
        "        data['X_test'] = np.array(x_test) #.reshape(25, 5000, 19)\n",
        "        data['Y_test'] = np.array(y_test)\n",
        "                    \n",
        "        filepath = checkpoint_file_path + str(i) + random_string(10) + '.h5'\n",
        "\n",
        "        #checkpoint = ModelCheckpoint(filepath, #monitor='val_acc', \n",
        "        #                             verbose=0, save_best_only=True, save_weights_only=True, mode='auto',period=1)\n",
        "        #initialize and ensure that model is reset\n",
        "        \"\"\"mdl = tf.keras.models.clone_model(model) \n",
        "        mdl.load_weights(empty_weights_file)\n",
        "        K.get_session().close()\n",
        "        K.set_session(tf.Session())\n",
        "        K.get_session().run(tf.global_variables_initializer())\n",
        "        \"\"\"\n",
        "        mdl = CNN(time_steps=time_window, chans=chans, nb_features=1, nb_classes=2 )\n",
        "\n",
        "        \n",
        "        completed_model, test_acc, history = model_builder.construct_and_run_model_loo(data, mdl, optimizer, filepath, \n",
        "                                                        epochs=50, batch_size=32, loss_type='SquaredHinge')\n",
        "        \n",
        "        #tf.reset_default_graph()  \n",
        "        reload(tf)\n",
        "        reload(K)\n",
        "        #reload(Checkpoint)\n",
        "        #sess = tf.s.Session(config=tf.ConfigProto()) \n",
        "        #sess.close()\n",
        "        #tf.global_variables_initializer().run() \n",
        "        #history = model_builder.construct_and_run_model(model, )\n",
        "        model_list.append(completed_model)\n",
        "        test_acc_list.append(test_acc)\n",
        "        history_list.append(history)\n",
        "    return model_list, test_acc_list, history_list\n",
        "        \n",
        "# def plot_loo(history_list)     \n",
        "\n",
        "\n",
        "### CNN\n",
        "\n",
        "# Declare model, optimizer and checkpoint file\n",
        "model = CNN(time_steps=time_window, chans=chans*2, nb_features=1, nb_classes=2 )\n",
        "cnn_opt_adam = tf.keras.optimizers.Adam(lr=0.000009,  #0.00002, \n",
        "                                beta_1=0.95,\n",
        "                                beta_2=0.95,\n",
        "                                epsilon=1e-07)\n",
        "cnn_checkpoint = '/tmp/CNN_checkpoint'\n",
        "\n",
        "\n",
        "model_list, test_acc_list, history_list = leave_one_out(data, all_data, all_labels, model, \n",
        "                                                        time_window, cnn_checkpoint, chans=chans, optimizer=cnn_opt_adam)\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.08277 to 1.08158, saving model to /tmp/CNN_checkpoint5dxiszofzjk.h5\n",
            "10/10 - 0s - loss: 0.7814 - accuracy: 0.9533 - rmse: 0.2491 - val_loss: 1.0816 - val_accuracy: 0.6954 - val_rmse: 0.4365\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.08158 to 1.08123, saving model to /tmp/CNN_checkpoint5dxiszofzjk.h5\n",
            "10/10 - 0s - loss: 0.7850 - accuracy: 0.9467 - rmse: 0.2603 - val_loss: 1.0812 - val_accuracy: 0.6954 - val_rmse: 0.4366\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.08123\n",
            "10/10 - 0s - loss: 0.7758 - accuracy: 0.9433 - rmse: 0.2612 - val_loss: 1.0814 - val_accuracy: 0.6954 - val_rmse: 0.4369\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.08123 to 1.08102, saving model to /tmp/CNN_checkpoint5dxiszofzjk.h5\n",
            "10/10 - 0s - loss: 0.7519 - accuracy: 0.9733 - rmse: 0.2360 - val_loss: 1.0810 - val_accuracy: 0.6892 - val_rmse: 0.4371\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7618 - accuracy: 0.9667 - rmse: 0.2470 - val_loss: 1.0825 - val_accuracy: 0.6831 - val_rmse: 0.4378\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7606 - accuracy: 0.9633 - rmse: 0.2382 - val_loss: 1.0822 - val_accuracy: 0.6831 - val_rmse: 0.4379\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7463 - accuracy: 0.9667 - rmse: 0.2360 - val_loss: 1.0821 - val_accuracy: 0.6800 - val_rmse: 0.4381\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7344 - accuracy: 0.9900 - rmse: 0.2185 - val_loss: 1.0812 - val_accuracy: 0.6831 - val_rmse: 0.4380\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7351 - accuracy: 0.9767 - rmse: 0.2285 - val_loss: 1.0835 - val_accuracy: 0.6708 - val_rmse: 0.4389\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7213 - accuracy: 0.9767 - rmse: 0.2148 - val_loss: 1.0822 - val_accuracy: 0.6708 - val_rmse: 0.4386\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7338 - accuracy: 0.9733 - rmse: 0.2201 - val_loss: 1.0818 - val_accuracy: 0.6738 - val_rmse: 0.4387\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7261 - accuracy: 0.9800 - rmse: 0.2113 - val_loss: 1.0822 - val_accuracy: 0.6738 - val_rmse: 0.4391\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7129 - accuracy: 0.9867 - rmse: 0.2004 - val_loss: 1.0821 - val_accuracy: 0.6738 - val_rmse: 0.4394\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7057 - accuracy: 0.9900 - rmse: 0.1954 - val_loss: 1.0815 - val_accuracy: 0.6738 - val_rmse: 0.4395\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.08102\n",
            "10/10 - 0s - loss: 0.7026 - accuracy: 0.9867 - rmse: 0.1944 - val_loss: 1.0813 - val_accuracy: 0.6738 - val_rmse: 0.4397\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.08102 to 1.08087, saving model to /tmp/CNN_checkpoint5dxiszofzjk.h5\n",
            "10/10 - 0s - loss: 0.7069 - accuracy: 0.9900 - rmse: 0.1981 - val_loss: 1.0809 - val_accuracy: 0.6800 - val_rmse: 0.4399\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 1.08087 to 1.08078, saving model to /tmp/CNN_checkpoint5dxiszofzjk.h5\n",
            "10/10 - 0s - loss: 0.6993 - accuracy: 0.9867 - rmse: 0.1871 - val_loss: 1.0808 - val_accuracy: 0.6769 - val_rmse: 0.4401\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 1.08078 to 1.08063, saving model to /tmp/CNN_checkpoint5dxiszofzjk.h5\n",
            "10/10 - 0s - loss: 0.6887 - accuracy: 0.9967 - rmse: 0.1806 - val_loss: 1.0806 - val_accuracy: 0.6769 - val_rmse: 0.4404\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.08063\n",
            "10/10 - 0s - loss: 0.6894 - accuracy: 0.9933 - rmse: 0.1807 - val_loss: 1.0812 - val_accuracy: 0.6738 - val_rmse: 0.4408\n",
            "Classification accuracy: 0.920000 \n",
            "\n",
            "\n",
            "Beginning training for subject  6\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 6, length of hc for this iteration: 13\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_799\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_800 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1625 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1512 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1512 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1626 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1513 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1513 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_877 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23400, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.2450 - accuracy: 0.5233 - rmse: 0.5003 - val_loss: 1.2340 - val_accuracy: 0.5015 - val_rmse: 0.4861\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23400 to 1.22209, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.2001 - accuracy: 0.6033 - rmse: 0.4832 - val_loss: 1.2221 - val_accuracy: 0.4985 - val_rmse: 0.4774\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.22209 to 1.21425, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.1554 - accuracy: 0.6433 - rmse: 0.4588 - val_loss: 1.2143 - val_accuracy: 0.4831 - val_rmse: 0.4712\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.21425 to 1.20765, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.1180 - accuracy: 0.7067 - rmse: 0.4415 - val_loss: 1.2076 - val_accuracy: 0.4862 - val_rmse: 0.4670\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.20765 to 1.20059, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.1004 - accuracy: 0.7133 - rmse: 0.4419 - val_loss: 1.2006 - val_accuracy: 0.4985 - val_rmse: 0.4637\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.20059 to 1.19291, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.0764 - accuracy: 0.7833 - rmse: 0.4278 - val_loss: 1.1929 - val_accuracy: 0.5200 - val_rmse: 0.4610\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.19291 to 1.18483, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.0571 - accuracy: 0.7600 - rmse: 0.4202 - val_loss: 1.1848 - val_accuracy: 0.5600 - val_rmse: 0.4586\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.18483 to 1.17658, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.0301 - accuracy: 0.8400 - rmse: 0.3995 - val_loss: 1.1766 - val_accuracy: 0.5754 - val_rmse: 0.4566\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.17658 to 1.16792, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.0317 - accuracy: 0.8000 - rmse: 0.4115 - val_loss: 1.1679 - val_accuracy: 0.6123 - val_rmse: 0.4545\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.16792 to 1.16022, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 1.0106 - accuracy: 0.8267 - rmse: 0.3862 - val_loss: 1.1602 - val_accuracy: 0.6431 - val_rmse: 0.4531\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.16022 to 1.15223, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.9776 - accuracy: 0.8567 - rmse: 0.3738 - val_loss: 1.1522 - val_accuracy: 0.6431 - val_rmse: 0.4514\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.15223 to 1.14477, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.9594 - accuracy: 0.8833 - rmse: 0.3588 - val_loss: 1.1448 - val_accuracy: 0.6831 - val_rmse: 0.4498\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.14477 to 1.13798, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.9645 - accuracy: 0.8800 - rmse: 0.3673 - val_loss: 1.1380 - val_accuracy: 0.7046 - val_rmse: 0.4484\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.13798 to 1.13180, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.9440 - accuracy: 0.9033 - rmse: 0.3572 - val_loss: 1.1318 - val_accuracy: 0.7169 - val_rmse: 0.4472\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.13180 to 1.12637, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.9433 - accuracy: 0.8800 - rmse: 0.3549 - val_loss: 1.1264 - val_accuracy: 0.7138 - val_rmse: 0.4462\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.12637 to 1.12160, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.9101 - accuracy: 0.8967 - rmse: 0.3357 - val_loss: 1.1216 - val_accuracy: 0.7138 - val_rmse: 0.4454\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.12160 to 1.11794, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.9047 - accuracy: 0.8867 - rmse: 0.3339 - val_loss: 1.1179 - val_accuracy: 0.7169 - val_rmse: 0.4450\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.11794 to 1.11438, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8953 - accuracy: 0.9167 - rmse: 0.3264 - val_loss: 1.1144 - val_accuracy: 0.7200 - val_rmse: 0.4445\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.11438 to 1.11128, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8908 - accuracy: 0.9000 - rmse: 0.3268 - val_loss: 1.1113 - val_accuracy: 0.7231 - val_rmse: 0.4441\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.11128 to 1.10888, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8570 - accuracy: 0.9333 - rmse: 0.3021 - val_loss: 1.1089 - val_accuracy: 0.7200 - val_rmse: 0.4440\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.10888 to 1.10656, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8519 - accuracy: 0.9200 - rmse: 0.3019 - val_loss: 1.1066 - val_accuracy: 0.7169 - val_rmse: 0.4437\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.10656 to 1.10442, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8406 - accuracy: 0.9133 - rmse: 0.2975 - val_loss: 1.1044 - val_accuracy: 0.7138 - val_rmse: 0.4437\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.10442 to 1.10284, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8396 - accuracy: 0.9567 - rmse: 0.2948 - val_loss: 1.1028 - val_accuracy: 0.7077 - val_rmse: 0.4437\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.10284 to 1.10153, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8232 - accuracy: 0.9433 - rmse: 0.2794 - val_loss: 1.1015 - val_accuracy: 0.7077 - val_rmse: 0.4439\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.10153 to 1.09975, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8132 - accuracy: 0.9300 - rmse: 0.2747 - val_loss: 1.0998 - val_accuracy: 0.7015 - val_rmse: 0.4437\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.09975 to 1.09868, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8224 - accuracy: 0.9367 - rmse: 0.2807 - val_loss: 1.0987 - val_accuracy: 0.6923 - val_rmse: 0.4437\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.09868 to 1.09819, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.8160 - accuracy: 0.9333 - rmse: 0.2726 - val_loss: 1.0982 - val_accuracy: 0.6923 - val_rmse: 0.4439\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.09819 to 1.09735, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.7986 - accuracy: 0.9633 - rmse: 0.2641 - val_loss: 1.0973 - val_accuracy: 0.6862 - val_rmse: 0.4439\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.09735 to 1.09647, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.7936 - accuracy: 0.9600 - rmse: 0.2606 - val_loss: 1.0965 - val_accuracy: 0.6831 - val_rmse: 0.4440\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.09647 to 1.09631, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.7883 - accuracy: 0.9333 - rmse: 0.2547 - val_loss: 1.0963 - val_accuracy: 0.6862 - val_rmse: 0.4442\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.09631 to 1.09610, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.7613 - accuracy: 0.9767 - rmse: 0.2341 - val_loss: 1.0961 - val_accuracy: 0.6862 - val_rmse: 0.4445\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.09610 to 1.09592, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.7557 - accuracy: 0.9767 - rmse: 0.2300 - val_loss: 1.0959 - val_accuracy: 0.6800 - val_rmse: 0.4448\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.09592 to 1.09550, saving model to /tmp/CNN_checkpoint6fjtwybcybc.h5\n",
            "10/10 - 0s - loss: 0.7627 - accuracy: 0.9667 - rmse: 0.2432 - val_loss: 1.0955 - val_accuracy: 0.6769 - val_rmse: 0.4450\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.7493 - accuracy: 0.9700 - rmse: 0.2334 - val_loss: 1.0956 - val_accuracy: 0.6769 - val_rmse: 0.4453\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.7497 - accuracy: 0.9667 - rmse: 0.2300 - val_loss: 1.0958 - val_accuracy: 0.6769 - val_rmse: 0.4458\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.7369 - accuracy: 0.9733 - rmse: 0.2249 - val_loss: 1.0969 - val_accuracy: 0.6708 - val_rmse: 0.4465\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.7341 - accuracy: 0.9900 - rmse: 0.2138 - val_loss: 1.0966 - val_accuracy: 0.6738 - val_rmse: 0.4468\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.7279 - accuracy: 0.9933 - rmse: 0.2146 - val_loss: 1.0959 - val_accuracy: 0.6738 - val_rmse: 0.4469\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.7289 - accuracy: 0.9833 - rmse: 0.2195 - val_loss: 1.0957 - val_accuracy: 0.6738 - val_rmse: 0.4473\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.7127 - accuracy: 0.9900 - rmse: 0.2093 - val_loss: 1.0968 - val_accuracy: 0.6769 - val_rmse: 0.4480\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.6996 - accuracy: 0.9867 - rmse: 0.2007 - val_loss: 1.0987 - val_accuracy: 0.6677 - val_rmse: 0.4489\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.7111 - accuracy: 0.9833 - rmse: 0.2026 - val_loss: 1.0990 - val_accuracy: 0.6708 - val_rmse: 0.4496\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.7033 - accuracy: 0.9833 - rmse: 0.1954 - val_loss: 1.0988 - val_accuracy: 0.6677 - val_rmse: 0.4500\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.6992 - accuracy: 0.9900 - rmse: 0.1864 - val_loss: 1.0988 - val_accuracy: 0.6677 - val_rmse: 0.4505\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.6855 - accuracy: 0.9933 - rmse: 0.1860 - val_loss: 1.0991 - val_accuracy: 0.6677 - val_rmse: 0.4511\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.6927 - accuracy: 0.9867 - rmse: 0.1864 - val_loss: 1.0987 - val_accuracy: 0.6708 - val_rmse: 0.4513\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.6945 - accuracy: 0.9867 - rmse: 0.1925 - val_loss: 1.0987 - val_accuracy: 0.6708 - val_rmse: 0.4516\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.6756 - accuracy: 0.9967 - rmse: 0.1736 - val_loss: 1.0985 - val_accuracy: 0.6708 - val_rmse: 0.4517\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.6783 - accuracy: 0.9900 - rmse: 0.1812 - val_loss: 1.0989 - val_accuracy: 0.6738 - val_rmse: 0.4520\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.09550\n",
            "10/10 - 0s - loss: 0.6689 - accuracy: 0.9967 - rmse: 0.1776 - val_loss: 1.1003 - val_accuracy: 0.6646 - val_rmse: 0.4525\n",
            "Classification accuracy: 0.880000 \n",
            "\n",
            "\n",
            "Beginning training for subject  7\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 7, length of hc for this iteration: 13\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_800\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_801 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1627 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1514 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1514 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1628 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1515 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1515 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_878 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.25601, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.2391 - accuracy: 0.5500 - rmse: 0.5027 - val_loss: 1.2560 - val_accuracy: 0.5262 - val_rmse: 0.4981\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.25601 to 1.24388, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.2196 - accuracy: 0.5700 - rmse: 0.4895 - val_loss: 1.2439 - val_accuracy: 0.5077 - val_rmse: 0.4893\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.24388 to 1.23676, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.1828 - accuracy: 0.6300 - rmse: 0.4729 - val_loss: 1.2368 - val_accuracy: 0.5015 - val_rmse: 0.4838\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.23676 to 1.23214, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.1543 - accuracy: 0.6233 - rmse: 0.4586 - val_loss: 1.2321 - val_accuracy: 0.4954 - val_rmse: 0.4803\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.23214 to 1.22827, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.1342 - accuracy: 0.7133 - rmse: 0.4500 - val_loss: 1.2283 - val_accuracy: 0.4985 - val_rmse: 0.4780\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.22827 to 1.22337, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.0922 - accuracy: 0.7433 - rmse: 0.4272 - val_loss: 1.2234 - val_accuracy: 0.5231 - val_rmse: 0.4758\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.22337 to 1.21796, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.0974 - accuracy: 0.7400 - rmse: 0.4340 - val_loss: 1.2180 - val_accuracy: 0.5354 - val_rmse: 0.4734\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.21796 to 1.21240, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.0699 - accuracy: 0.7967 - rmse: 0.4254 - val_loss: 1.2124 - val_accuracy: 0.5477 - val_rmse: 0.4713\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.21240 to 1.20656, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.0473 - accuracy: 0.8067 - rmse: 0.4079 - val_loss: 1.2066 - val_accuracy: 0.5692 - val_rmse: 0.4693\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.20656 to 1.20048, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.0256 - accuracy: 0.8400 - rmse: 0.3949 - val_loss: 1.2005 - val_accuracy: 0.5692 - val_rmse: 0.4673\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.20048 to 1.19444, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.0098 - accuracy: 0.8700 - rmse: 0.3902 - val_loss: 1.1944 - val_accuracy: 0.5908 - val_rmse: 0.4654\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.19444 to 1.18829, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 1.0024 - accuracy: 0.8600 - rmse: 0.3857 - val_loss: 1.1883 - val_accuracy: 0.6369 - val_rmse: 0.4634\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.18829 to 1.18236, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.9819 - accuracy: 0.9000 - rmse: 0.3733 - val_loss: 1.1824 - val_accuracy: 0.6431 - val_rmse: 0.4616\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.18236 to 1.17664, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.9788 - accuracy: 0.8867 - rmse: 0.3706 - val_loss: 1.1766 - val_accuracy: 0.6585 - val_rmse: 0.4599\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.17664 to 1.17142, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.9534 - accuracy: 0.9133 - rmse: 0.3553 - val_loss: 1.1714 - val_accuracy: 0.6523 - val_rmse: 0.4584\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.17142 to 1.16642, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.9482 - accuracy: 0.9233 - rmse: 0.3596 - val_loss: 1.1664 - val_accuracy: 0.6615 - val_rmse: 0.4567\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.16642 to 1.16221, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.9184 - accuracy: 0.9333 - rmse: 0.3316 - val_loss: 1.1622 - val_accuracy: 0.6646 - val_rmse: 0.4554\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.16221 to 1.15818, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.9066 - accuracy: 0.9367 - rmse: 0.3218 - val_loss: 1.1582 - val_accuracy: 0.6708 - val_rmse: 0.4542\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.15818 to 1.15391, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8837 - accuracy: 0.9467 - rmse: 0.3138 - val_loss: 1.1539 - val_accuracy: 0.6862 - val_rmse: 0.4529\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.15391 to 1.14978, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8786 - accuracy: 0.9467 - rmse: 0.3090 - val_loss: 1.1498 - val_accuracy: 0.6985 - val_rmse: 0.4517\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.14978 to 1.14598, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8737 - accuracy: 0.9600 - rmse: 0.3053 - val_loss: 1.1460 - val_accuracy: 0.7015 - val_rmse: 0.4504\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.14598 to 1.14238, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8478 - accuracy: 0.9567 - rmse: 0.2899 - val_loss: 1.1424 - val_accuracy: 0.6985 - val_rmse: 0.4493\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.14238 to 1.13896, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8678 - accuracy: 0.9300 - rmse: 0.3071 - val_loss: 1.1390 - val_accuracy: 0.6985 - val_rmse: 0.4481\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.13896 to 1.13579, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8372 - accuracy: 0.9433 - rmse: 0.2830 - val_loss: 1.1358 - val_accuracy: 0.7077 - val_rmse: 0.4470\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.13579 to 1.13321, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8284 - accuracy: 0.9600 - rmse: 0.2773 - val_loss: 1.1332 - val_accuracy: 0.7169 - val_rmse: 0.4463\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.13321 to 1.13056, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8239 - accuracy: 0.9600 - rmse: 0.2729 - val_loss: 1.1306 - val_accuracy: 0.7138 - val_rmse: 0.4454\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.13056 to 1.12785, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8209 - accuracy: 0.9600 - rmse: 0.2810 - val_loss: 1.1279 - val_accuracy: 0.7138 - val_rmse: 0.4444\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.12785 to 1.12552, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8065 - accuracy: 0.9633 - rmse: 0.2650 - val_loss: 1.1255 - val_accuracy: 0.7077 - val_rmse: 0.4436\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.12552 to 1.12344, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.8056 - accuracy: 0.9633 - rmse: 0.2642 - val_loss: 1.1234 - val_accuracy: 0.7108 - val_rmse: 0.4429\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.12344 to 1.12140, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7857 - accuracy: 0.9633 - rmse: 0.2524 - val_loss: 1.1214 - val_accuracy: 0.7108 - val_rmse: 0.4422\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.12140 to 1.11941, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7759 - accuracy: 0.9733 - rmse: 0.2474 - val_loss: 1.1194 - val_accuracy: 0.7077 - val_rmse: 0.4416\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.11941 to 1.11745, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7692 - accuracy: 0.9667 - rmse: 0.2415 - val_loss: 1.1175 - val_accuracy: 0.7046 - val_rmse: 0.4409\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.11745 to 1.11595, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7736 - accuracy: 0.9733 - rmse: 0.2461 - val_loss: 1.1159 - val_accuracy: 0.7015 - val_rmse: 0.4404\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.11595 to 1.11437, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7577 - accuracy: 0.9767 - rmse: 0.2312 - val_loss: 1.1144 - val_accuracy: 0.7077 - val_rmse: 0.4399\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.11437 to 1.11309, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7590 - accuracy: 0.9767 - rmse: 0.2358 - val_loss: 1.1131 - val_accuracy: 0.7077 - val_rmse: 0.4395\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.11309 to 1.11151, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7501 - accuracy: 0.9667 - rmse: 0.2284 - val_loss: 1.1115 - val_accuracy: 0.7077 - val_rmse: 0.4390\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.11151 to 1.11017, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7525 - accuracy: 0.9867 - rmse: 0.2388 - val_loss: 1.1102 - val_accuracy: 0.7138 - val_rmse: 0.4386\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.11017 to 1.10947, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7401 - accuracy: 0.9900 - rmse: 0.2192 - val_loss: 1.1095 - val_accuracy: 0.7108 - val_rmse: 0.4385\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.10947 to 1.10884, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7356 - accuracy: 0.9733 - rmse: 0.2216 - val_loss: 1.1088 - val_accuracy: 0.7077 - val_rmse: 0.4384\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.10884 to 1.10814, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7285 - accuracy: 0.9967 - rmse: 0.2147 - val_loss: 1.1081 - val_accuracy: 0.7108 - val_rmse: 0.4384\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.10814 to 1.10784, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7154 - accuracy: 0.9867 - rmse: 0.2026 - val_loss: 1.1078 - val_accuracy: 0.7138 - val_rmse: 0.4385\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.10784 to 1.10712, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7168 - accuracy: 0.9900 - rmse: 0.2061 - val_loss: 1.1071 - val_accuracy: 0.7169 - val_rmse: 0.4384\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.10712 to 1.10625, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7055 - accuracy: 0.9867 - rmse: 0.1977 - val_loss: 1.1062 - val_accuracy: 0.7169 - val_rmse: 0.4382\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.10625 to 1.10523, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.7119 - accuracy: 0.9967 - rmse: 0.2034 - val_loss: 1.1052 - val_accuracy: 0.7169 - val_rmse: 0.4379\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.10523 to 1.10467, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.6889 - accuracy: 1.0000 - rmse: 0.1846 - val_loss: 1.1047 - val_accuracy: 0.7077 - val_rmse: 0.4378\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.10467 to 1.10365, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.6996 - accuracy: 0.9967 - rmse: 0.1924 - val_loss: 1.1037 - val_accuracy: 0.7169 - val_rmse: 0.4376\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.10365 to 1.10327, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.6957 - accuracy: 0.9867 - rmse: 0.1900 - val_loss: 1.1033 - val_accuracy: 0.7138 - val_rmse: 0.4376\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 1.10327 to 1.10277, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.6882 - accuracy: 0.9967 - rmse: 0.1794 - val_loss: 1.1028 - val_accuracy: 0.7169 - val_rmse: 0.4375\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 1.10277 to 1.10248, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.6934 - accuracy: 0.9900 - rmse: 0.1890 - val_loss: 1.1025 - val_accuracy: 0.7138 - val_rmse: 0.4376\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss improved from 1.10248 to 1.10217, saving model to /tmp/CNN_checkpoint7rgjgfkeggd.h5\n",
            "10/10 - 0s - loss: 0.6919 - accuracy: 0.9900 - rmse: 0.1885 - val_loss: 1.1022 - val_accuracy: 0.7138 - val_rmse: 0.4377\n",
            "Classification accuracy: 0.960000 \n",
            "\n",
            "\n",
            "Beginning training for subject  8\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 8, length of hc for this iteration: 13\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_801\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_802 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1629 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1516 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1516 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1630 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1517 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1517 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_879 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23198, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 1.2774 - accuracy: 0.5067 - rmse: 0.5230 - val_loss: 1.2320 - val_accuracy: 0.5662 - val_rmse: 0.4897\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23198 to 1.22487, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 1.2257 - accuracy: 0.5833 - rmse: 0.4891 - val_loss: 1.2249 - val_accuracy: 0.5508 - val_rmse: 0.4822\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.22487 to 1.22302, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 1.1837 - accuracy: 0.6000 - rmse: 0.4772 - val_loss: 1.2230 - val_accuracy: 0.5015 - val_rmse: 0.4786\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.22302 to 1.22270, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 1.1358 - accuracy: 0.6667 - rmse: 0.4561 - val_loss: 1.2227 - val_accuracy: 0.4800 - val_rmse: 0.4761\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.22270\n",
            "10/10 - 0s - loss: 1.1306 - accuracy: 0.6167 - rmse: 0.4517 - val_loss: 1.2228 - val_accuracy: 0.4615 - val_rmse: 0.4749\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.22270\n",
            "10/10 - 0s - loss: 1.0907 - accuracy: 0.6367 - rmse: 0.4341 - val_loss: 1.2233 - val_accuracy: 0.4646 - val_rmse: 0.4741\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.22270\n",
            "10/10 - 0s - loss: 1.0880 - accuracy: 0.6467 - rmse: 0.4344 - val_loss: 1.2234 - val_accuracy: 0.4615 - val_rmse: 0.4739\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.22270\n",
            "10/10 - 0s - loss: 1.0549 - accuracy: 0.6700 - rmse: 0.4200 - val_loss: 1.2231 - val_accuracy: 0.4615 - val_rmse: 0.4736\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.22270 to 1.22260, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 1.0665 - accuracy: 0.6467 - rmse: 0.4295 - val_loss: 1.2226 - val_accuracy: 0.4615 - val_rmse: 0.4733\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.22260 to 1.22164, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 1.0460 - accuracy: 0.6733 - rmse: 0.4173 - val_loss: 1.2216 - val_accuracy: 0.4738 - val_rmse: 0.4730\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.22164 to 1.22079, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 1.0393 - accuracy: 0.7067 - rmse: 0.4126 - val_loss: 1.2208 - val_accuracy: 0.4738 - val_rmse: 0.4729\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.22079 to 1.21975, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 1.0233 - accuracy: 0.7100 - rmse: 0.4035 - val_loss: 1.2198 - val_accuracy: 0.4923 - val_rmse: 0.4728\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.21975 to 1.21896, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.9932 - accuracy: 0.7667 - rmse: 0.3885 - val_loss: 1.2190 - val_accuracy: 0.5046 - val_rmse: 0.4728\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.21896 to 1.21836, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 1.0061 - accuracy: 0.7400 - rmse: 0.3896 - val_loss: 1.2184 - val_accuracy: 0.5138 - val_rmse: 0.4730\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.21836 to 1.21760, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.9671 - accuracy: 0.8133 - rmse: 0.3620 - val_loss: 1.2176 - val_accuracy: 0.5200 - val_rmse: 0.4729\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.21760 to 1.21698, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.9741 - accuracy: 0.8167 - rmse: 0.3789 - val_loss: 1.2170 - val_accuracy: 0.5292 - val_rmse: 0.4728\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.21698 to 1.21666, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.9525 - accuracy: 0.8433 - rmse: 0.3640 - val_loss: 1.2167 - val_accuracy: 0.5415 - val_rmse: 0.4731\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.21666 to 1.21623, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.9387 - accuracy: 0.8800 - rmse: 0.3585 - val_loss: 1.2162 - val_accuracy: 0.5354 - val_rmse: 0.4733\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.21623 to 1.21580, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.9294 - accuracy: 0.8867 - rmse: 0.3526 - val_loss: 1.2158 - val_accuracy: 0.5446 - val_rmse: 0.4736\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.21580 to 1.21537, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.9211 - accuracy: 0.9133 - rmse: 0.3381 - val_loss: 1.2154 - val_accuracy: 0.5446 - val_rmse: 0.4739\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.21537 to 1.21500, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.9144 - accuracy: 0.9000 - rmse: 0.3381 - val_loss: 1.2150 - val_accuracy: 0.5385 - val_rmse: 0.4742\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.21500 to 1.21476, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8991 - accuracy: 0.9300 - rmse: 0.3269 - val_loss: 1.2148 - val_accuracy: 0.5385 - val_rmse: 0.4744\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.21476 to 1.21451, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8912 - accuracy: 0.9400 - rmse: 0.3257 - val_loss: 1.2145 - val_accuracy: 0.5446 - val_rmse: 0.4747\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.21451 to 1.21437, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8752 - accuracy: 0.9467 - rmse: 0.3147 - val_loss: 1.2144 - val_accuracy: 0.5385 - val_rmse: 0.4752\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.21437 to 1.21413, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8653 - accuracy: 0.9633 - rmse: 0.3087 - val_loss: 1.2141 - val_accuracy: 0.5415 - val_rmse: 0.4757\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.21413 to 1.21410, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8588 - accuracy: 0.9667 - rmse: 0.2985 - val_loss: 1.2141 - val_accuracy: 0.5446 - val_rmse: 0.4760\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.21410 to 1.21379, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8518 - accuracy: 0.9767 - rmse: 0.2974 - val_loss: 1.2138 - val_accuracy: 0.5477 - val_rmse: 0.4762\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.21379 to 1.21303, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8425 - accuracy: 0.9667 - rmse: 0.2890 - val_loss: 1.2130 - val_accuracy: 0.5600 - val_rmse: 0.4760\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.21303 to 1.21213, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8374 - accuracy: 0.9733 - rmse: 0.2842 - val_loss: 1.2121 - val_accuracy: 0.5692 - val_rmse: 0.4757\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.21213 to 1.21104, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8199 - accuracy: 0.9833 - rmse: 0.2791 - val_loss: 1.2110 - val_accuracy: 0.5723 - val_rmse: 0.4753\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.21104 to 1.21002, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8169 - accuracy: 0.9800 - rmse: 0.2738 - val_loss: 1.2100 - val_accuracy: 0.5754 - val_rmse: 0.4750\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.21002 to 1.20864, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8018 - accuracy: 0.9867 - rmse: 0.2656 - val_loss: 1.2086 - val_accuracy: 0.5754 - val_rmse: 0.4743\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.20864 to 1.20757, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7988 - accuracy: 0.9833 - rmse: 0.2677 - val_loss: 1.2076 - val_accuracy: 0.6031 - val_rmse: 0.4745\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.20757 to 1.20638, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.8008 - accuracy: 0.9900 - rmse: 0.2622 - val_loss: 1.2064 - val_accuracy: 0.6031 - val_rmse: 0.4740\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.20638 to 1.20558, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7851 - accuracy: 0.9900 - rmse: 0.2519 - val_loss: 1.2056 - val_accuracy: 0.6031 - val_rmse: 0.4738\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.20558 to 1.20470, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7728 - accuracy: 0.9933 - rmse: 0.2419 - val_loss: 1.2047 - val_accuracy: 0.6062 - val_rmse: 0.4737\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.20470 to 1.20355, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7660 - accuracy: 0.9967 - rmse: 0.2399 - val_loss: 1.2035 - val_accuracy: 0.6062 - val_rmse: 0.4732\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.20355 to 1.20289, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7609 - accuracy: 1.0000 - rmse: 0.2364 - val_loss: 1.2029 - val_accuracy: 0.6154 - val_rmse: 0.4732\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.20289 to 1.20239, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7550 - accuracy: 0.9900 - rmse: 0.2341 - val_loss: 1.2024 - val_accuracy: 0.6215 - val_rmse: 0.4732\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.20239 to 1.20195, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7578 - accuracy: 1.0000 - rmse: 0.2299 - val_loss: 1.2019 - val_accuracy: 0.6246 - val_rmse: 0.4734\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.20195 to 1.20130, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7444 - accuracy: 0.9967 - rmse: 0.2230 - val_loss: 1.2013 - val_accuracy: 0.6215 - val_rmse: 0.4735\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.20130 to 1.20051, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7405 - accuracy: 0.9967 - rmse: 0.2219 - val_loss: 1.2005 - val_accuracy: 0.6308 - val_rmse: 0.4734\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.20051 to 1.19942, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7297 - accuracy: 0.9967 - rmse: 0.2142 - val_loss: 1.1994 - val_accuracy: 0.6277 - val_rmse: 0.4731\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.19942 to 1.19848, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7160 - accuracy: 1.0000 - rmse: 0.2087 - val_loss: 1.1985 - val_accuracy: 0.6246 - val_rmse: 0.4735\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.19848 to 1.19725, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7202 - accuracy: 1.0000 - rmse: 0.2032 - val_loss: 1.1973 - val_accuracy: 0.6277 - val_rmse: 0.4732\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.19725 to 1.19592, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7096 - accuracy: 1.0000 - rmse: 0.1964 - val_loss: 1.1959 - val_accuracy: 0.6277 - val_rmse: 0.4728\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.19592 to 1.19464, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7087 - accuracy: 1.0000 - rmse: 0.1946 - val_loss: 1.1946 - val_accuracy: 0.6277 - val_rmse: 0.4725\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 1.19464 to 1.19321, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7062 - accuracy: 1.0000 - rmse: 0.1925 - val_loss: 1.1932 - val_accuracy: 0.6215 - val_rmse: 0.4721\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 1.19321 to 1.19204, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.7069 - accuracy: 1.0000 - rmse: 0.1991 - val_loss: 1.1920 - val_accuracy: 0.6185 - val_rmse: 0.4718\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss improved from 1.19204 to 1.19162, saving model to /tmp/CNN_checkpoint8lsvgswccpt.h5\n",
            "10/10 - 0s - loss: 0.6962 - accuracy: 1.0000 - rmse: 0.1858 - val_loss: 1.1916 - val_accuracy: 0.6338 - val_rmse: 0.4720\n",
            "Classification accuracy: 0.240000 \n",
            "\n",
            "\n",
            "Beginning training for subject  9\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 9, length of hc for this iteration: 13\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_802\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_803 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1631 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1518 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1518 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1632 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1519 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1519 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_880 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.24421, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.2270 - accuracy: 0.5833 - rmse: 0.4973 - val_loss: 1.2442 - val_accuracy: 0.4831 - val_rmse: 0.4966\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.24421 to 1.23949, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.1935 - accuracy: 0.5967 - rmse: 0.4751 - val_loss: 1.2395 - val_accuracy: 0.4831 - val_rmse: 0.4929\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.23949 to 1.23632, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.1669 - accuracy: 0.6133 - rmse: 0.4662 - val_loss: 1.2363 - val_accuracy: 0.4769 - val_rmse: 0.4908\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.23632 to 1.23305, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.1288 - accuracy: 0.6933 - rmse: 0.4504 - val_loss: 1.2331 - val_accuracy: 0.4831 - val_rmse: 0.4893\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.23305 to 1.22931, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.1141 - accuracy: 0.7033 - rmse: 0.4439 - val_loss: 1.2293 - val_accuracy: 0.4892 - val_rmse: 0.4883\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.22931 to 1.22522, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.1021 - accuracy: 0.7300 - rmse: 0.4341 - val_loss: 1.2252 - val_accuracy: 0.4954 - val_rmse: 0.4874\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.22522 to 1.22065, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.0857 - accuracy: 0.7400 - rmse: 0.4268 - val_loss: 1.2206 - val_accuracy: 0.5292 - val_rmse: 0.4865\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.22065 to 1.21542, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.0544 - accuracy: 0.8033 - rmse: 0.4136 - val_loss: 1.2154 - val_accuracy: 0.5446 - val_rmse: 0.4853\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.21542 to 1.21021, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.0516 - accuracy: 0.8000 - rmse: 0.4110 - val_loss: 1.2102 - val_accuracy: 0.5815 - val_rmse: 0.4844\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.21021 to 1.20509, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 1.0339 - accuracy: 0.8367 - rmse: 0.4014 - val_loss: 1.2051 - val_accuracy: 0.6092 - val_rmse: 0.4836\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.20509 to 1.20024, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.9953 - accuracy: 0.8867 - rmse: 0.3765 - val_loss: 1.2002 - val_accuracy: 0.6154 - val_rmse: 0.4828\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.20024 to 1.19572, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.9933 - accuracy: 0.8667 - rmse: 0.3822 - val_loss: 1.1957 - val_accuracy: 0.6308 - val_rmse: 0.4820\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.19572 to 1.19246, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.9726 - accuracy: 0.8800 - rmse: 0.3665 - val_loss: 1.1925 - val_accuracy: 0.6462 - val_rmse: 0.4818\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.19246 to 1.18942, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.9538 - accuracy: 0.8833 - rmse: 0.3600 - val_loss: 1.1894 - val_accuracy: 0.6338 - val_rmse: 0.4816\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.18942 to 1.18659, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.9474 - accuracy: 0.8733 - rmse: 0.3523 - val_loss: 1.1866 - val_accuracy: 0.6338 - val_rmse: 0.4814\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.18659 to 1.18411, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.9378 - accuracy: 0.9000 - rmse: 0.3420 - val_loss: 1.1841 - val_accuracy: 0.6185 - val_rmse: 0.4810\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.18411 to 1.18189, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.9280 - accuracy: 0.8967 - rmse: 0.3416 - val_loss: 1.1819 - val_accuracy: 0.6215 - val_rmse: 0.4806\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.18189 to 1.18019, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.9105 - accuracy: 0.9067 - rmse: 0.3310 - val_loss: 1.1802 - val_accuracy: 0.6185 - val_rmse: 0.4804\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.18019 to 1.17891, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.8867 - accuracy: 0.9133 - rmse: 0.3190 - val_loss: 1.1789 - val_accuracy: 0.6154 - val_rmse: 0.4802\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.17891 to 1.17807, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.9008 - accuracy: 0.8967 - rmse: 0.3262 - val_loss: 1.1781 - val_accuracy: 0.6185 - val_rmse: 0.4801\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.17807 to 1.17696, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.8809 - accuracy: 0.9167 - rmse: 0.3128 - val_loss: 1.1770 - val_accuracy: 0.6154 - val_rmse: 0.4798\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.17696 to 1.17598, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.8688 - accuracy: 0.9100 - rmse: 0.3112 - val_loss: 1.1760 - val_accuracy: 0.6154 - val_rmse: 0.4795\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.17598 to 1.17552, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.8621 - accuracy: 0.9200 - rmse: 0.3013 - val_loss: 1.1755 - val_accuracy: 0.6185 - val_rmse: 0.4793\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.17552 to 1.17510, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.8543 - accuracy: 0.9000 - rmse: 0.2946 - val_loss: 1.1751 - val_accuracy: 0.6185 - val_rmse: 0.4792\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.17510 to 1.17496, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.8547 - accuracy: 0.9300 - rmse: 0.2964 - val_loss: 1.1750 - val_accuracy: 0.6154 - val_rmse: 0.4791\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.17496\n",
            "10/10 - 0s - loss: 0.8370 - accuracy: 0.9167 - rmse: 0.2930 - val_loss: 1.1750 - val_accuracy: 0.6185 - val_rmse: 0.4791\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.17496\n",
            "10/10 - 0s - loss: 0.8332 - accuracy: 0.9067 - rmse: 0.2874 - val_loss: 1.1750 - val_accuracy: 0.6215 - val_rmse: 0.4790\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.17496 to 1.17458, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.8265 - accuracy: 0.9433 - rmse: 0.2829 - val_loss: 1.1746 - val_accuracy: 0.6185 - val_rmse: 0.4789\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.17458 to 1.17455, saving model to /tmp/CNN_checkpoint9oariawdxfr.h5\n",
            "10/10 - 0s - loss: 0.8147 - accuracy: 0.9267 - rmse: 0.2752 - val_loss: 1.1746 - val_accuracy: 0.6185 - val_rmse: 0.4788\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.8090 - accuracy: 0.9333 - rmse: 0.2700 - val_loss: 1.1750 - val_accuracy: 0.6154 - val_rmse: 0.4789\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.8041 - accuracy: 0.9233 - rmse: 0.2648 - val_loss: 1.1755 - val_accuracy: 0.6154 - val_rmse: 0.4791\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7991 - accuracy: 0.9467 - rmse: 0.2633 - val_loss: 1.1760 - val_accuracy: 0.6154 - val_rmse: 0.4792\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7862 - accuracy: 0.9300 - rmse: 0.2551 - val_loss: 1.1767 - val_accuracy: 0.6123 - val_rmse: 0.4794\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7878 - accuracy: 0.9667 - rmse: 0.2504 - val_loss: 1.1770 - val_accuracy: 0.6092 - val_rmse: 0.4795\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7732 - accuracy: 0.9567 - rmse: 0.2459 - val_loss: 1.1770 - val_accuracy: 0.6092 - val_rmse: 0.4796\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7674 - accuracy: 0.9633 - rmse: 0.2460 - val_loss: 1.1776 - val_accuracy: 0.6092 - val_rmse: 0.4798\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7636 - accuracy: 0.9433 - rmse: 0.2445 - val_loss: 1.1772 - val_accuracy: 0.6092 - val_rmse: 0.4797\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7585 - accuracy: 0.9433 - rmse: 0.2337 - val_loss: 1.1772 - val_accuracy: 0.6062 - val_rmse: 0.4797\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7531 - accuracy: 0.9467 - rmse: 0.2348 - val_loss: 1.1771 - val_accuracy: 0.6092 - val_rmse: 0.4797\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7450 - accuracy: 0.9700 - rmse: 0.2233 - val_loss: 1.1777 - val_accuracy: 0.6092 - val_rmse: 0.4798\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7360 - accuracy: 0.9667 - rmse: 0.2173 - val_loss: 1.1787 - val_accuracy: 0.6092 - val_rmse: 0.4801\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7360 - accuracy: 0.9633 - rmse: 0.2254 - val_loss: 1.1794 - val_accuracy: 0.6092 - val_rmse: 0.4803\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7279 - accuracy: 0.9567 - rmse: 0.2105 - val_loss: 1.1800 - val_accuracy: 0.6092 - val_rmse: 0.4805\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7298 - accuracy: 0.9700 - rmse: 0.2099 - val_loss: 1.1802 - val_accuracy: 0.6092 - val_rmse: 0.4805\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7261 - accuracy: 0.9867 - rmse: 0.2096 - val_loss: 1.1804 - val_accuracy: 0.6062 - val_rmse: 0.4807\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7329 - accuracy: 0.9367 - rmse: 0.2124 - val_loss: 1.1802 - val_accuracy: 0.6062 - val_rmse: 0.4806\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7142 - accuracy: 0.9767 - rmse: 0.1992 - val_loss: 1.1814 - val_accuracy: 0.6000 - val_rmse: 0.4808\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7118 - accuracy: 0.9800 - rmse: 0.1998 - val_loss: 1.1806 - val_accuracy: 0.6031 - val_rmse: 0.4805\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7028 - accuracy: 0.9867 - rmse: 0.1927 - val_loss: 1.1798 - val_accuracy: 0.6031 - val_rmse: 0.4803\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.17455\n",
            "10/10 - 0s - loss: 0.7068 - accuracy: 0.9767 - rmse: 0.1959 - val_loss: 1.1795 - val_accuracy: 0.6031 - val_rmse: 0.4801\n",
            "Classification accuracy: 0.960000 \n",
            "\n",
            "\n",
            "Beginning training for subject  10\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 10, length of hc for this iteration: 13\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_803\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_804 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1633 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1520 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1520 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1634 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1521 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1521 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_881 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23470, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.2250 - accuracy: 0.5800 - rmse: 0.4954 - val_loss: 1.2347 - val_accuracy: 0.4800 - val_rmse: 0.4776\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23470 to 1.22950, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.1878 - accuracy: 0.6433 - rmse: 0.4754 - val_loss: 1.2295 - val_accuracy: 0.4831 - val_rmse: 0.4685\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.22950 to 1.22820, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.1466 - accuracy: 0.6867 - rmse: 0.4579 - val_loss: 1.2282 - val_accuracy: 0.4800 - val_rmse: 0.4632\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.22820 to 1.22611, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.1218 - accuracy: 0.7133 - rmse: 0.4481 - val_loss: 1.2261 - val_accuracy: 0.4769 - val_rmse: 0.4594\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.22611 to 1.22029, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.0967 - accuracy: 0.7100 - rmse: 0.4377 - val_loss: 1.2203 - val_accuracy: 0.4769 - val_rmse: 0.4563\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.22029 to 1.20833, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.0619 - accuracy: 0.7667 - rmse: 0.4224 - val_loss: 1.2083 - val_accuracy: 0.4954 - val_rmse: 0.4540\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.20833 to 1.20106, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.0735 - accuracy: 0.7400 - rmse: 0.4340 - val_loss: 1.2011 - val_accuracy: 0.5262 - val_rmse: 0.4514\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.20106 to 1.18898, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.0310 - accuracy: 0.7767 - rmse: 0.4140 - val_loss: 1.1890 - val_accuracy: 0.5508 - val_rmse: 0.4497\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.18898 to 1.18144, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.0183 - accuracy: 0.8033 - rmse: 0.3997 - val_loss: 1.1814 - val_accuracy: 0.5662 - val_rmse: 0.4475\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.18144 to 1.17342, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 1.0021 - accuracy: 0.8033 - rmse: 0.3985 - val_loss: 1.1734 - val_accuracy: 0.6062 - val_rmse: 0.4454\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.17342 to 1.16535, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.9909 - accuracy: 0.8333 - rmse: 0.3858 - val_loss: 1.1654 - val_accuracy: 0.6185 - val_rmse: 0.4439\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.16535 to 1.15824, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.9745 - accuracy: 0.8633 - rmse: 0.3794 - val_loss: 1.1582 - val_accuracy: 0.6338 - val_rmse: 0.4423\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.15824 to 1.15187, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.9712 - accuracy: 0.8667 - rmse: 0.3838 - val_loss: 1.1519 - val_accuracy: 0.6462 - val_rmse: 0.4407\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.15187 to 1.14598, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.9560 - accuracy: 0.8600 - rmse: 0.3593 - val_loss: 1.1460 - val_accuracy: 0.6585 - val_rmse: 0.4395\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.14598 to 1.14020, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.9396 - accuracy: 0.8800 - rmse: 0.3535 - val_loss: 1.1402 - val_accuracy: 0.6615 - val_rmse: 0.4383\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.14020 to 1.13480, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.9104 - accuracy: 0.8833 - rmse: 0.3313 - val_loss: 1.1348 - val_accuracy: 0.6585 - val_rmse: 0.4370\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.13480 to 1.12892, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.9025 - accuracy: 0.8833 - rmse: 0.3377 - val_loss: 1.1289 - val_accuracy: 0.6615 - val_rmse: 0.4357\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.12892 to 1.12452, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8873 - accuracy: 0.9333 - rmse: 0.3285 - val_loss: 1.1245 - val_accuracy: 0.6585 - val_rmse: 0.4347\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.12452 to 1.12055, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8922 - accuracy: 0.9100 - rmse: 0.3237 - val_loss: 1.1205 - val_accuracy: 0.6738 - val_rmse: 0.4340\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.12055 to 1.11662, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8746 - accuracy: 0.9167 - rmse: 0.3179 - val_loss: 1.1166 - val_accuracy: 0.6954 - val_rmse: 0.4333\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.11662 to 1.11242, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8731 - accuracy: 0.9200 - rmse: 0.3164 - val_loss: 1.1124 - val_accuracy: 0.7108 - val_rmse: 0.4323\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.11242 to 1.10867, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8603 - accuracy: 0.9200 - rmse: 0.3096 - val_loss: 1.1087 - val_accuracy: 0.7169 - val_rmse: 0.4316\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.10867 to 1.10596, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8547 - accuracy: 0.9167 - rmse: 0.2999 - val_loss: 1.1060 - val_accuracy: 0.7262 - val_rmse: 0.4312\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.10596 to 1.10351, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8339 - accuracy: 0.9267 - rmse: 0.2863 - val_loss: 1.1035 - val_accuracy: 0.7262 - val_rmse: 0.4310\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.10351 to 1.10170, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8235 - accuracy: 0.9533 - rmse: 0.2793 - val_loss: 1.1017 - val_accuracy: 0.7231 - val_rmse: 0.4309\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.10170 to 1.09977, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8158 - accuracy: 0.9533 - rmse: 0.2745 - val_loss: 1.0998 - val_accuracy: 0.7169 - val_rmse: 0.4307\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.09977 to 1.09799, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8080 - accuracy: 0.9667 - rmse: 0.2666 - val_loss: 1.0980 - val_accuracy: 0.7200 - val_rmse: 0.4306\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.09799 to 1.09587, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.8080 - accuracy: 0.9533 - rmse: 0.2724 - val_loss: 1.0959 - val_accuracy: 0.7231 - val_rmse: 0.4302\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.09587 to 1.09378, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7973 - accuracy: 0.9633 - rmse: 0.2708 - val_loss: 1.0938 - val_accuracy: 0.7262 - val_rmse: 0.4297\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.09378 to 1.09222, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7784 - accuracy: 0.9700 - rmse: 0.2514 - val_loss: 1.0922 - val_accuracy: 0.7292 - val_rmse: 0.4295\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.09222 to 1.09034, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7835 - accuracy: 0.9633 - rmse: 0.2515 - val_loss: 1.0903 - val_accuracy: 0.7231 - val_rmse: 0.4290\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.09034 to 1.08880, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7732 - accuracy: 0.9800 - rmse: 0.2501 - val_loss: 1.0888 - val_accuracy: 0.7231 - val_rmse: 0.4286\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.08880 to 1.08851, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7809 - accuracy: 0.9633 - rmse: 0.2473 - val_loss: 1.0885 - val_accuracy: 0.7292 - val_rmse: 0.4288\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.08851 to 1.08809, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7664 - accuracy: 0.9867 - rmse: 0.2482 - val_loss: 1.0881 - val_accuracy: 0.7323 - val_rmse: 0.4291\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.08809 to 1.08705, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7625 - accuracy: 0.9767 - rmse: 0.2383 - val_loss: 1.0871 - val_accuracy: 0.7323 - val_rmse: 0.4289\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.08705 to 1.08697, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7462 - accuracy: 0.9800 - rmse: 0.2291 - val_loss: 1.0870 - val_accuracy: 0.7385 - val_rmse: 0.4292\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.08697 to 1.08534, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7399 - accuracy: 0.9733 - rmse: 0.2227 - val_loss: 1.0853 - val_accuracy: 0.7354 - val_rmse: 0.4288\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.08534 to 1.08333, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7228 - accuracy: 0.9833 - rmse: 0.2085 - val_loss: 1.0833 - val_accuracy: 0.7354 - val_rmse: 0.4282\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.08333 to 1.08108, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7358 - accuracy: 0.9733 - rmse: 0.2234 - val_loss: 1.0811 - val_accuracy: 0.7323 - val_rmse: 0.4275\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.08108 to 1.08059, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7256 - accuracy: 0.9800 - rmse: 0.2136 - val_loss: 1.0806 - val_accuracy: 0.7323 - val_rmse: 0.4277\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.08059 to 1.07943, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7183 - accuracy: 0.9733 - rmse: 0.2079 - val_loss: 1.0794 - val_accuracy: 0.7323 - val_rmse: 0.4275\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.07943 to 1.07881, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7242 - accuracy: 0.9667 - rmse: 0.2101 - val_loss: 1.0788 - val_accuracy: 0.7292 - val_rmse: 0.4275\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.07881 to 1.07876, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7204 - accuracy: 0.9633 - rmse: 0.2051 - val_loss: 1.0788 - val_accuracy: 0.7262 - val_rmse: 0.4277\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.07876 to 1.07802, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7072 - accuracy: 0.9733 - rmse: 0.2038 - val_loss: 1.0780 - val_accuracy: 0.7292 - val_rmse: 0.4276\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.07802 to 1.07700, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.6923 - accuracy: 0.9800 - rmse: 0.1869 - val_loss: 1.0770 - val_accuracy: 0.7292 - val_rmse: 0.4274\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.07700 to 1.07587, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7037 - accuracy: 0.9900 - rmse: 0.1995 - val_loss: 1.0759 - val_accuracy: 0.7292 - val_rmse: 0.4271\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.07587 to 1.07429, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.6983 - accuracy: 0.9867 - rmse: 0.1886 - val_loss: 1.0743 - val_accuracy: 0.7292 - val_rmse: 0.4266\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 1.07429 to 1.07273, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.6929 - accuracy: 0.9967 - rmse: 0.1876 - val_loss: 1.0727 - val_accuracy: 0.7262 - val_rmse: 0.4262\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 1.07273 to 1.07209, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.6814 - accuracy: 0.9967 - rmse: 0.1845 - val_loss: 1.0721 - val_accuracy: 0.7231 - val_rmse: 0.4261\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss improved from 1.07209 to 1.07130, saving model to /tmp/CNN_checkpoint10qjvqhldxjn.h5\n",
            "10/10 - 0s - loss: 0.7007 - accuracy: 0.9800 - rmse: 0.1968 - val_loss: 1.0713 - val_accuracy: 0.7262 - val_rmse: 0.4260\n",
            "Classification accuracy: 0.840000 \n",
            "\n",
            "\n",
            "Beginning training for subject  11\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 11, length of hc for this iteration: 13\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_804\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_805 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1635 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1522 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1522 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1636 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1523 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1523 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_882 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23521, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.2653 - accuracy: 0.5200 - rmse: 0.5154 - val_loss: 1.2352 - val_accuracy: 0.5046 - val_rmse: 0.4877\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23521 to 1.22807, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.2103 - accuracy: 0.5567 - rmse: 0.4876 - val_loss: 1.2281 - val_accuracy: 0.4831 - val_rmse: 0.4791\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.22807 to 1.22464, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.1514 - accuracy: 0.6533 - rmse: 0.4620 - val_loss: 1.2246 - val_accuracy: 0.4769 - val_rmse: 0.4739\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.22464 to 1.22085, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.1181 - accuracy: 0.7033 - rmse: 0.4419 - val_loss: 1.2209 - val_accuracy: 0.4800 - val_rmse: 0.4706\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.22085 to 1.21582, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.1139 - accuracy: 0.6500 - rmse: 0.4445 - val_loss: 1.2158 - val_accuracy: 0.4862 - val_rmse: 0.4683\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.21582 to 1.21038, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.0720 - accuracy: 0.7633 - rmse: 0.4284 - val_loss: 1.2104 - val_accuracy: 0.4985 - val_rmse: 0.4660\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.21038 to 1.20444, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.0532 - accuracy: 0.7533 - rmse: 0.4211 - val_loss: 1.2044 - val_accuracy: 0.5077 - val_rmse: 0.4642\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.20444 to 1.19841, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.0456 - accuracy: 0.7267 - rmse: 0.4127 - val_loss: 1.1984 - val_accuracy: 0.5262 - val_rmse: 0.4628\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.19841 to 1.19205, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.0349 - accuracy: 0.7533 - rmse: 0.4067 - val_loss: 1.1921 - val_accuracy: 0.5477 - val_rmse: 0.4615\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.19205 to 1.18394, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.0305 - accuracy: 0.7800 - rmse: 0.4075 - val_loss: 1.1839 - val_accuracy: 0.5877 - val_rmse: 0.4608\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.18394 to 1.17987, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 1.0066 - accuracy: 0.7967 - rmse: 0.3962 - val_loss: 1.1799 - val_accuracy: 0.6092 - val_rmse: 0.4603\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.17987 to 1.17546, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.9883 - accuracy: 0.8400 - rmse: 0.3870 - val_loss: 1.1755 - val_accuracy: 0.6277 - val_rmse: 0.4596\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.17546 to 1.17183, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.9934 - accuracy: 0.7933 - rmse: 0.3829 - val_loss: 1.1718 - val_accuracy: 0.6431 - val_rmse: 0.4594\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.17183 to 1.16898, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.9612 - accuracy: 0.8800 - rmse: 0.3635 - val_loss: 1.1690 - val_accuracy: 0.6738 - val_rmse: 0.4594\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.16898 to 1.16610, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.9657 - accuracy: 0.8800 - rmse: 0.3668 - val_loss: 1.1661 - val_accuracy: 0.6862 - val_rmse: 0.4591\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.16610 to 1.16290, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.9359 - accuracy: 0.8933 - rmse: 0.3521 - val_loss: 1.1629 - val_accuracy: 0.6892 - val_rmse: 0.4587\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.16290 to 1.16028, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.9274 - accuracy: 0.9000 - rmse: 0.3491 - val_loss: 1.1603 - val_accuracy: 0.6923 - val_rmse: 0.4584\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.16028 to 1.15862, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.9303 - accuracy: 0.9000 - rmse: 0.3505 - val_loss: 1.1586 - val_accuracy: 0.7015 - val_rmse: 0.4585\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.15862 to 1.15723, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.9266 - accuracy: 0.8833 - rmse: 0.3440 - val_loss: 1.1572 - val_accuracy: 0.7046 - val_rmse: 0.4588\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.15723 to 1.15587, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.9030 - accuracy: 0.9367 - rmse: 0.3288 - val_loss: 1.1559 - val_accuracy: 0.6985 - val_rmse: 0.4591\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.15587 to 1.15409, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8910 - accuracy: 0.9200 - rmse: 0.3241 - val_loss: 1.1541 - val_accuracy: 0.7015 - val_rmse: 0.4591\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.15409 to 1.15235, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8741 - accuracy: 0.9533 - rmse: 0.3128 - val_loss: 1.1524 - val_accuracy: 0.7077 - val_rmse: 0.4588\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.15235 to 1.14986, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8538 - accuracy: 0.9633 - rmse: 0.2999 - val_loss: 1.1499 - val_accuracy: 0.7046 - val_rmse: 0.4584\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.14986 to 1.14764, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8730 - accuracy: 0.9367 - rmse: 0.3167 - val_loss: 1.1476 - val_accuracy: 0.6985 - val_rmse: 0.4584\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.14764 to 1.14704, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8484 - accuracy: 0.9700 - rmse: 0.2929 - val_loss: 1.1470 - val_accuracy: 0.7015 - val_rmse: 0.4585\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.14704 to 1.14591, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8377 - accuracy: 0.9733 - rmse: 0.2861 - val_loss: 1.1459 - val_accuracy: 0.6985 - val_rmse: 0.4585\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.14591 to 1.14438, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8351 - accuracy: 0.9767 - rmse: 0.2888 - val_loss: 1.1444 - val_accuracy: 0.6985 - val_rmse: 0.4583\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.14438 to 1.14314, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8148 - accuracy: 0.9700 - rmse: 0.2715 - val_loss: 1.1431 - val_accuracy: 0.6954 - val_rmse: 0.4581\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.14314 to 1.14204, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8204 - accuracy: 0.9767 - rmse: 0.2787 - val_loss: 1.1420 - val_accuracy: 0.6954 - val_rmse: 0.4581\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.14204 to 1.14136, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8077 - accuracy: 0.9833 - rmse: 0.2714 - val_loss: 1.1414 - val_accuracy: 0.6923 - val_rmse: 0.4582\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.14136 to 1.14073, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.8019 - accuracy: 0.9767 - rmse: 0.2627 - val_loss: 1.1407 - val_accuracy: 0.6923 - val_rmse: 0.4583\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.14073 to 1.14019, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7979 - accuracy: 0.9767 - rmse: 0.2600 - val_loss: 1.1402 - val_accuracy: 0.6923 - val_rmse: 0.4584\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.14019 to 1.13969, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7840 - accuracy: 0.9800 - rmse: 0.2569 - val_loss: 1.1397 - val_accuracy: 0.6862 - val_rmse: 0.4586\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.13969\n",
            "10/10 - 0s - loss: 0.7781 - accuracy: 0.9967 - rmse: 0.2503 - val_loss: 1.1399 - val_accuracy: 0.6831 - val_rmse: 0.4591\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.13969 to 1.13967, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7785 - accuracy: 0.9867 - rmse: 0.2492 - val_loss: 1.1397 - val_accuracy: 0.6800 - val_rmse: 0.4593\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.13967\n",
            "10/10 - 0s - loss: 0.7799 - accuracy: 0.9700 - rmse: 0.2453 - val_loss: 1.1400 - val_accuracy: 0.6800 - val_rmse: 0.4598\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.13967 to 1.13928, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7638 - accuracy: 0.9900 - rmse: 0.2364 - val_loss: 1.1393 - val_accuracy: 0.6800 - val_rmse: 0.4597\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.13928 to 1.13863, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7591 - accuracy: 0.9900 - rmse: 0.2313 - val_loss: 1.1386 - val_accuracy: 0.6800 - val_rmse: 0.4597\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.13863 to 1.13766, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7549 - accuracy: 0.9933 - rmse: 0.2280 - val_loss: 1.1377 - val_accuracy: 0.6800 - val_rmse: 0.4596\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.13766 to 1.13641, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7492 - accuracy: 0.9900 - rmse: 0.2256 - val_loss: 1.1364 - val_accuracy: 0.6800 - val_rmse: 0.4593\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.13641 to 1.13499, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7402 - accuracy: 0.9867 - rmse: 0.2275 - val_loss: 1.1350 - val_accuracy: 0.6769 - val_rmse: 0.4590\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.13499 to 1.13466, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7268 - accuracy: 1.0000 - rmse: 0.2099 - val_loss: 1.1347 - val_accuracy: 0.6769 - val_rmse: 0.4591\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.13466 to 1.13432, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7358 - accuracy: 0.9867 - rmse: 0.2144 - val_loss: 1.1343 - val_accuracy: 0.6769 - val_rmse: 0.4593\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.13432 to 1.13352, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7328 - accuracy: 0.9933 - rmse: 0.2145 - val_loss: 1.1335 - val_accuracy: 0.6800 - val_rmse: 0.4592\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.13352 to 1.13274, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7133 - accuracy: 0.9967 - rmse: 0.1950 - val_loss: 1.1327 - val_accuracy: 0.6800 - val_rmse: 0.4591\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.13274 to 1.13186, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7152 - accuracy: 0.9933 - rmse: 0.2051 - val_loss: 1.1319 - val_accuracy: 0.6800 - val_rmse: 0.4590\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.13186 to 1.13099, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7139 - accuracy: 0.9933 - rmse: 0.2041 - val_loss: 1.1310 - val_accuracy: 0.6800 - val_rmse: 0.4589\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 1.13099 to 1.13074, saving model to /tmp/CNN_checkpoint11yszdngohtk.h5\n",
            "10/10 - 0s - loss: 0.7141 - accuracy: 0.9867 - rmse: 0.2005 - val_loss: 1.1307 - val_accuracy: 0.6800 - val_rmse: 0.4591\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.13074\n",
            "10/10 - 0s - loss: 0.7021 - accuracy: 0.9900 - rmse: 0.1997 - val_loss: 1.1316 - val_accuracy: 0.6769 - val_rmse: 0.4601\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.13074\n",
            "10/10 - 0s - loss: 0.6919 - accuracy: 1.0000 - rmse: 0.1804 - val_loss: 1.1313 - val_accuracy: 0.6800 - val_rmse: 0.4601\n",
            "Classification accuracy: 1.000000 \n",
            "\n",
            "\n",
            "Beginning training for subject  12\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 12, length of hc for this iteration: 13\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_805\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_806 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1637 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1524 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1524 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1638 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1525 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1525 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_883 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.25240, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 1s - loss: 1.2692 - accuracy: 0.5200 - rmse: 0.5145 - val_loss: 1.2524 - val_accuracy: 0.4831 - val_rmse: 0.4996\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.25240 to 1.24339, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.2461 - accuracy: 0.5467 - rmse: 0.5033 - val_loss: 1.2434 - val_accuracy: 0.4985 - val_rmse: 0.4952\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.24339 to 1.23770, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.1883 - accuracy: 0.6333 - rmse: 0.4744 - val_loss: 1.2377 - val_accuracy: 0.4892 - val_rmse: 0.4926\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.23770 to 1.23314, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.1762 - accuracy: 0.6433 - rmse: 0.4687 - val_loss: 1.2331 - val_accuracy: 0.4800 - val_rmse: 0.4908\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.23314 to 1.22856, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.1384 - accuracy: 0.7100 - rmse: 0.4527 - val_loss: 1.2286 - val_accuracy: 0.4831 - val_rmse: 0.4891\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.22856 to 1.22271, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.1113 - accuracy: 0.7367 - rmse: 0.4376 - val_loss: 1.2227 - val_accuracy: 0.5138 - val_rmse: 0.4866\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.22271 to 1.21655, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.1056 - accuracy: 0.7700 - rmse: 0.4353 - val_loss: 1.2166 - val_accuracy: 0.5538 - val_rmse: 0.4840\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.21655 to 1.20963, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.0880 - accuracy: 0.7667 - rmse: 0.4254 - val_loss: 1.2096 - val_accuracy: 0.5815 - val_rmse: 0.4812\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.20963 to 1.20363, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.0612 - accuracy: 0.8267 - rmse: 0.4161 - val_loss: 1.2036 - val_accuracy: 0.6462 - val_rmse: 0.4793\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.20363 to 1.19614, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.0448 - accuracy: 0.8267 - rmse: 0.4060 - val_loss: 1.1961 - val_accuracy: 0.6831 - val_rmse: 0.4762\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.19614 to 1.18889, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.0325 - accuracy: 0.8467 - rmse: 0.4014 - val_loss: 1.1889 - val_accuracy: 0.7077 - val_rmse: 0.4734\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.18889 to 1.18248, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 1.0138 - accuracy: 0.8900 - rmse: 0.3878 - val_loss: 1.1825 - val_accuracy: 0.7231 - val_rmse: 0.4710\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.18248 to 1.17638, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.9975 - accuracy: 0.8767 - rmse: 0.3789 - val_loss: 1.1764 - val_accuracy: 0.7108 - val_rmse: 0.4688\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.17638 to 1.17103, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.9822 - accuracy: 0.8800 - rmse: 0.3705 - val_loss: 1.1710 - val_accuracy: 0.7015 - val_rmse: 0.4670\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.17103 to 1.16614, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.9660 - accuracy: 0.8900 - rmse: 0.3625 - val_loss: 1.1661 - val_accuracy: 0.6985 - val_rmse: 0.4654\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.16614 to 1.16166, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.9562 - accuracy: 0.9133 - rmse: 0.3534 - val_loss: 1.1617 - val_accuracy: 0.6923 - val_rmse: 0.4639\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.16166 to 1.15743, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.9494 - accuracy: 0.8833 - rmse: 0.3566 - val_loss: 1.1574 - val_accuracy: 0.6892 - val_rmse: 0.4624\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.15743 to 1.15678, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.9289 - accuracy: 0.8967 - rmse: 0.3510 - val_loss: 1.1568 - val_accuracy: 0.6677 - val_rmse: 0.4626\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.15678 to 1.15380, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.9212 - accuracy: 0.9167 - rmse: 0.3375 - val_loss: 1.1538 - val_accuracy: 0.6492 - val_rmse: 0.4616\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.15380 to 1.15134, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.9175 - accuracy: 0.8867 - rmse: 0.3336 - val_loss: 1.1513 - val_accuracy: 0.6492 - val_rmse: 0.4607\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.15134 to 1.14928, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.9095 - accuracy: 0.9067 - rmse: 0.3328 - val_loss: 1.1493 - val_accuracy: 0.6462 - val_rmse: 0.4600\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.14928 to 1.14807, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8883 - accuracy: 0.9167 - rmse: 0.3218 - val_loss: 1.1481 - val_accuracy: 0.6431 - val_rmse: 0.4597\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.14807 to 1.14553, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8588 - accuracy: 0.9600 - rmse: 0.2960 - val_loss: 1.1455 - val_accuracy: 0.6431 - val_rmse: 0.4587\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.14553 to 1.14382, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8683 - accuracy: 0.9200 - rmse: 0.3048 - val_loss: 1.1438 - val_accuracy: 0.6431 - val_rmse: 0.4581\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.14382 to 1.14219, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8527 - accuracy: 0.9300 - rmse: 0.3038 - val_loss: 1.1422 - val_accuracy: 0.6400 - val_rmse: 0.4575\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.14219 to 1.14063, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8394 - accuracy: 0.9567 - rmse: 0.2849 - val_loss: 1.1406 - val_accuracy: 0.6400 - val_rmse: 0.4570\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.14063 to 1.13950, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8464 - accuracy: 0.9467 - rmse: 0.2875 - val_loss: 1.1395 - val_accuracy: 0.6400 - val_rmse: 0.4566\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.13950 to 1.13837, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8395 - accuracy: 0.9567 - rmse: 0.2861 - val_loss: 1.1384 - val_accuracy: 0.6369 - val_rmse: 0.4564\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.13837 to 1.13777, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8301 - accuracy: 0.9533 - rmse: 0.2810 - val_loss: 1.1378 - val_accuracy: 0.6308 - val_rmse: 0.4563\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.13777 to 1.13775, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8243 - accuracy: 0.9533 - rmse: 0.2836 - val_loss: 1.1377 - val_accuracy: 0.6277 - val_rmse: 0.4564\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.13775 to 1.13732, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8138 - accuracy: 0.9467 - rmse: 0.2737 - val_loss: 1.1373 - val_accuracy: 0.6308 - val_rmse: 0.4564\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.13732 to 1.13633, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.8099 - accuracy: 0.9500 - rmse: 0.2722 - val_loss: 1.1363 - val_accuracy: 0.6308 - val_rmse: 0.4562\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.13633 to 1.13581, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7947 - accuracy: 0.9767 - rmse: 0.2559 - val_loss: 1.1358 - val_accuracy: 0.6308 - val_rmse: 0.4560\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.13581 to 1.13493, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7913 - accuracy: 0.9533 - rmse: 0.2559 - val_loss: 1.1349 - val_accuracy: 0.6277 - val_rmse: 0.4558\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.13493 to 1.13436, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7790 - accuracy: 0.9733 - rmse: 0.2481 - val_loss: 1.1344 - val_accuracy: 0.6308 - val_rmse: 0.4557\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.13436\n",
            "10/10 - 0s - loss: 0.7843 - accuracy: 0.9533 - rmse: 0.2587 - val_loss: 1.1347 - val_accuracy: 0.6277 - val_rmse: 0.4559\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.13436 to 1.13342, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7721 - accuracy: 0.9767 - rmse: 0.2400 - val_loss: 1.1334 - val_accuracy: 0.6277 - val_rmse: 0.4554\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.13342 to 1.13339, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7758 - accuracy: 0.9733 - rmse: 0.2481 - val_loss: 1.1334 - val_accuracy: 0.6246 - val_rmse: 0.4554\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.13339 to 1.13326, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7633 - accuracy: 0.9667 - rmse: 0.2344 - val_loss: 1.1333 - val_accuracy: 0.6246 - val_rmse: 0.4554\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.13326 to 1.13243, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7676 - accuracy: 0.9733 - rmse: 0.2409 - val_loss: 1.1324 - val_accuracy: 0.6277 - val_rmse: 0.4550\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.13243 to 1.13144, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7548 - accuracy: 0.9600 - rmse: 0.2313 - val_loss: 1.1314 - val_accuracy: 0.6338 - val_rmse: 0.4546\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.13144 to 1.13024, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7458 - accuracy: 0.9733 - rmse: 0.2243 - val_loss: 1.1302 - val_accuracy: 0.6338 - val_rmse: 0.4541\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.13024 to 1.12955, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7400 - accuracy: 0.9700 - rmse: 0.2216 - val_loss: 1.1296 - val_accuracy: 0.6338 - val_rmse: 0.4539\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.12955 to 1.12927, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7305 - accuracy: 0.9867 - rmse: 0.2128 - val_loss: 1.1293 - val_accuracy: 0.6308 - val_rmse: 0.4539\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.12927 to 1.12782, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7309 - accuracy: 0.9867 - rmse: 0.2120 - val_loss: 1.1278 - val_accuracy: 0.6400 - val_rmse: 0.4535\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.12782 to 1.12746, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7319 - accuracy: 0.9767 - rmse: 0.2128 - val_loss: 1.1275 - val_accuracy: 0.6369 - val_rmse: 0.4534\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.12746 to 1.12706, saving model to /tmp/CNN_checkpoint12zzbnpjytop.h5\n",
            "10/10 - 0s - loss: 0.7165 - accuracy: 0.9867 - rmse: 0.2014 - val_loss: 1.1271 - val_accuracy: 0.6369 - val_rmse: 0.4534\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.12706\n",
            "10/10 - 0s - loss: 0.7139 - accuracy: 0.9767 - rmse: 0.1985 - val_loss: 1.1276 - val_accuracy: 0.6338 - val_rmse: 0.4536\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.12706\n",
            "10/10 - 0s - loss: 0.7115 - accuracy: 0.9933 - rmse: 0.2014 - val_loss: 1.1275 - val_accuracy: 0.6338 - val_rmse: 0.4537\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.12706\n",
            "10/10 - 0s - loss: 0.7118 - accuracy: 0.9867 - rmse: 0.2045 - val_loss: 1.1278 - val_accuracy: 0.6308 - val_rmse: 0.4539\n",
            "Classification accuracy: 1.000000 \n",
            "\n",
            "\n",
            "Beginning training for subject  13\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 13, length of hc for this iteration: 13\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_806\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_807 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1639 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1526 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1526 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1640 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1527 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1527 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_884 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.22188, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 1s - loss: 1.2299 - accuracy: 0.5533 - rmse: 0.5014 - val_loss: 1.2219 - val_accuracy: 0.5138 - val_rmse: 0.4867\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.22188 to 1.21212, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 1.1885 - accuracy: 0.6400 - rmse: 0.4734 - val_loss: 1.2121 - val_accuracy: 0.5015 - val_rmse: 0.4777\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.21212 to 1.20405, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 1.1463 - accuracy: 0.6633 - rmse: 0.4541 - val_loss: 1.2040 - val_accuracy: 0.4892 - val_rmse: 0.4718\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.20405 to 1.19533, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 1.1053 - accuracy: 0.7167 - rmse: 0.4381 - val_loss: 1.1953 - val_accuracy: 0.4892 - val_rmse: 0.4674\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.19533 to 1.18511, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 1.0704 - accuracy: 0.7667 - rmse: 0.4152 - val_loss: 1.1851 - val_accuracy: 0.5046 - val_rmse: 0.4636\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.18511 to 1.17386, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 1.0386 - accuracy: 0.7667 - rmse: 0.4024 - val_loss: 1.1739 - val_accuracy: 0.5692 - val_rmse: 0.4602\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.17386 to 1.16207, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 1.0205 - accuracy: 0.7833 - rmse: 0.3993 - val_loss: 1.1621 - val_accuracy: 0.6185 - val_rmse: 0.4568\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.16207 to 1.15026, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.9998 - accuracy: 0.7833 - rmse: 0.3926 - val_loss: 1.1503 - val_accuracy: 0.6800 - val_rmse: 0.4539\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.15026 to 1.13892, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.9760 - accuracy: 0.7967 - rmse: 0.3799 - val_loss: 1.1389 - val_accuracy: 0.7138 - val_rmse: 0.4511\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.13892 to 1.12861, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.9752 - accuracy: 0.7667 - rmse: 0.3850 - val_loss: 1.1286 - val_accuracy: 0.7292 - val_rmse: 0.4488\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.12861 to 1.11966, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.9405 - accuracy: 0.7867 - rmse: 0.3638 - val_loss: 1.1197 - val_accuracy: 0.7538 - val_rmse: 0.4467\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.11966 to 1.11271, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.9433 - accuracy: 0.8033 - rmse: 0.3691 - val_loss: 1.1127 - val_accuracy: 0.7477 - val_rmse: 0.4452\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.11271 to 1.10705, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.9217 - accuracy: 0.8333 - rmse: 0.3525 - val_loss: 1.1070 - val_accuracy: 0.7446 - val_rmse: 0.4440\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.10705 to 1.10576, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.8981 - accuracy: 0.8300 - rmse: 0.3481 - val_loss: 1.1058 - val_accuracy: 0.7200 - val_rmse: 0.4447\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.10576 to 1.10217, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.8969 - accuracy: 0.8500 - rmse: 0.3344 - val_loss: 1.1022 - val_accuracy: 0.7231 - val_rmse: 0.4438\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.10217 to 1.09922, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.8741 - accuracy: 0.8633 - rmse: 0.3231 - val_loss: 1.0992 - val_accuracy: 0.7200 - val_rmse: 0.4431\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.09922 to 1.09756, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.8794 - accuracy: 0.8633 - rmse: 0.3292 - val_loss: 1.0976 - val_accuracy: 0.7108 - val_rmse: 0.4427\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.09756 to 1.09635, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.8720 - accuracy: 0.8600 - rmse: 0.3252 - val_loss: 1.0963 - val_accuracy: 0.6985 - val_rmse: 0.4424\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.09635 to 1.09575, saving model to /tmp/CNN_checkpoint13czlentngbm.h5\n",
            "10/10 - 0s - loss: 0.8591 - accuracy: 0.8667 - rmse: 0.3230 - val_loss: 1.0958 - val_accuracy: 0.6923 - val_rmse: 0.4423\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.8604 - accuracy: 0.8600 - rmse: 0.3242 - val_loss: 1.0962 - val_accuracy: 0.6738 - val_rmse: 0.4426\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.8554 - accuracy: 0.8633 - rmse: 0.3084 - val_loss: 1.0965 - val_accuracy: 0.6738 - val_rmse: 0.4428\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.8316 - accuracy: 0.9033 - rmse: 0.2981 - val_loss: 1.0968 - val_accuracy: 0.6738 - val_rmse: 0.4430\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.8310 - accuracy: 0.8700 - rmse: 0.2974 - val_loss: 1.0970 - val_accuracy: 0.6738 - val_rmse: 0.4432\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.8064 - accuracy: 0.9100 - rmse: 0.2853 - val_loss: 1.1041 - val_accuracy: 0.6646 - val_rmse: 0.4455\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.8126 - accuracy: 0.9200 - rmse: 0.2822 - val_loss: 1.1036 - val_accuracy: 0.6646 - val_rmse: 0.4455\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.8047 - accuracy: 0.9133 - rmse: 0.2771 - val_loss: 1.1037 - val_accuracy: 0.6646 - val_rmse: 0.4456\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7826 - accuracy: 0.9433 - rmse: 0.2590 - val_loss: 1.1038 - val_accuracy: 0.6646 - val_rmse: 0.4457\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7882 - accuracy: 0.9233 - rmse: 0.2577 - val_loss: 1.1031 - val_accuracy: 0.6646 - val_rmse: 0.4456\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7862 - accuracy: 0.9067 - rmse: 0.2622 - val_loss: 1.1028 - val_accuracy: 0.6646 - val_rmse: 0.4457\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7739 - accuracy: 0.9400 - rmse: 0.2704 - val_loss: 1.1109 - val_accuracy: 0.6523 - val_rmse: 0.4481\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7659 - accuracy: 0.9200 - rmse: 0.2461 - val_loss: 1.1118 - val_accuracy: 0.6554 - val_rmse: 0.4485\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7450 - accuracy: 0.9533 - rmse: 0.2291 - val_loss: 1.1118 - val_accuracy: 0.6554 - val_rmse: 0.4486\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7479 - accuracy: 0.9433 - rmse: 0.2339 - val_loss: 1.1104 - val_accuracy: 0.6585 - val_rmse: 0.4484\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7441 - accuracy: 0.9600 - rmse: 0.2273 - val_loss: 1.1087 - val_accuracy: 0.6585 - val_rmse: 0.4479\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7475 - accuracy: 0.9667 - rmse: 0.2312 - val_loss: 1.1067 - val_accuracy: 0.6585 - val_rmse: 0.4474\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7407 - accuracy: 0.9667 - rmse: 0.2248 - val_loss: 1.1058 - val_accuracy: 0.6585 - val_rmse: 0.4473\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7223 - accuracy: 0.9700 - rmse: 0.2155 - val_loss: 1.1059 - val_accuracy: 0.6585 - val_rmse: 0.4474\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7055 - accuracy: 0.9767 - rmse: 0.2033 - val_loss: 1.1047 - val_accuracy: 0.6585 - val_rmse: 0.4471\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7093 - accuracy: 0.9633 - rmse: 0.2020 - val_loss: 1.1042 - val_accuracy: 0.6585 - val_rmse: 0.4470\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7097 - accuracy: 0.9667 - rmse: 0.2005 - val_loss: 1.1027 - val_accuracy: 0.6585 - val_rmse: 0.4465\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7026 - accuracy: 0.9833 - rmse: 0.1922 - val_loss: 1.1007 - val_accuracy: 0.6554 - val_rmse: 0.4460\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.6990 - accuracy: 0.9833 - rmse: 0.1964 - val_loss: 1.0990 - val_accuracy: 0.6646 - val_rmse: 0.4456\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.7026 - accuracy: 0.9800 - rmse: 0.2033 - val_loss: 1.0988 - val_accuracy: 0.6677 - val_rmse: 0.4456\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.6767 - accuracy: 0.9800 - rmse: 0.1770 - val_loss: 1.0987 - val_accuracy: 0.6646 - val_rmse: 0.4457\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.6769 - accuracy: 0.9867 - rmse: 0.1893 - val_loss: 1.1065 - val_accuracy: 0.6585 - val_rmse: 0.4477\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.6790 - accuracy: 0.9800 - rmse: 0.1737 - val_loss: 1.1053 - val_accuracy: 0.6554 - val_rmse: 0.4475\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.6875 - accuracy: 0.9933 - rmse: 0.1883 - val_loss: 1.1043 - val_accuracy: 0.6585 - val_rmse: 0.4473\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.6743 - accuracy: 0.9933 - rmse: 0.1781 - val_loss: 1.1042 - val_accuracy: 0.6585 - val_rmse: 0.4474\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.6732 - accuracy: 0.9833 - rmse: 0.1765 - val_loss: 1.1031 - val_accuracy: 0.6585 - val_rmse: 0.4471\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.09575\n",
            "10/10 - 0s - loss: 0.6542 - accuracy: 0.9833 - rmse: 0.1764 - val_loss: 1.1112 - val_accuracy: 0.6523 - val_rmse: 0.4491\n",
            "Classification accuracy: 1.000000 \n",
            "\n",
            "\n",
            "Beginning training for subject  14\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 14, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_807\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_808 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1641 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1528 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1528 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1642 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1529 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1529 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_885 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23042, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 1s - loss: 1.2886 - accuracy: 0.4800 - rmse: 0.5239 - val_loss: 1.2304 - val_accuracy: 0.5200 - val_rmse: 0.4942\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23042 to 1.21708, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 1.2370 - accuracy: 0.5367 - rmse: 0.4969 - val_loss: 1.2171 - val_accuracy: 0.5077 - val_rmse: 0.4836\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.21708 to 1.20650, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 1.1807 - accuracy: 0.6800 - rmse: 0.4697 - val_loss: 1.2065 - val_accuracy: 0.5292 - val_rmse: 0.4764\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.20650 to 1.19578, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 1.1446 - accuracy: 0.7367 - rmse: 0.4504 - val_loss: 1.1958 - val_accuracy: 0.5538 - val_rmse: 0.4703\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.19578 to 1.18454, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 1.1003 - accuracy: 0.7367 - rmse: 0.4317 - val_loss: 1.1845 - val_accuracy: 0.5877 - val_rmse: 0.4654\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.18454 to 1.17260, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 1.0701 - accuracy: 0.7667 - rmse: 0.4216 - val_loss: 1.1726 - val_accuracy: 0.6554 - val_rmse: 0.4610\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.17260 to 1.16289, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 1.0435 - accuracy: 0.8033 - rmse: 0.4096 - val_loss: 1.1629 - val_accuracy: 0.7415 - val_rmse: 0.4592\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.16289 to 1.15140, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 1.0206 - accuracy: 0.7967 - rmse: 0.3984 - val_loss: 1.1514 - val_accuracy: 0.7600 - val_rmse: 0.4557\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.15140 to 1.14081, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 0.9827 - accuracy: 0.8267 - rmse: 0.3755 - val_loss: 1.1408 - val_accuracy: 0.7662 - val_rmse: 0.4526\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.14081 to 1.13224, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 0.9752 - accuracy: 0.8467 - rmse: 0.3604 - val_loss: 1.1322 - val_accuracy: 0.7385 - val_rmse: 0.4502\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.13224 to 1.12787, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 0.9432 - accuracy: 0.8233 - rmse: 0.3650 - val_loss: 1.1279 - val_accuracy: 0.7292 - val_rmse: 0.4499\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.12787 to 1.12198, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 0.9353 - accuracy: 0.8567 - rmse: 0.3490 - val_loss: 1.1220 - val_accuracy: 0.7015 - val_rmse: 0.4482\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.12198 to 1.11740, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 0.9107 - accuracy: 0.8667 - rmse: 0.3349 - val_loss: 1.1174 - val_accuracy: 0.6985 - val_rmse: 0.4468\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.11740 to 1.11424, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 0.9090 - accuracy: 0.8567 - rmse: 0.3264 - val_loss: 1.1142 - val_accuracy: 0.6831 - val_rmse: 0.4459\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.11424 to 1.11178, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 0.8898 - accuracy: 0.8533 - rmse: 0.3322 - val_loss: 1.1118 - val_accuracy: 0.6769 - val_rmse: 0.4453\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.11178 to 1.11036, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 0.8892 - accuracy: 0.8367 - rmse: 0.3310 - val_loss: 1.1104 - val_accuracy: 0.6585 - val_rmse: 0.4449\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.11036 to 1.10975, saving model to /tmp/CNN_checkpoint14hnzqfukxzf.h5\n",
            "10/10 - 0s - loss: 0.8649 - accuracy: 0.8767 - rmse: 0.3212 - val_loss: 1.1098 - val_accuracy: 0.6554 - val_rmse: 0.4449\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.8588 - accuracy: 0.8733 - rmse: 0.3141 - val_loss: 1.1105 - val_accuracy: 0.6492 - val_rmse: 0.4454\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.8490 - accuracy: 0.8867 - rmse: 0.3112 - val_loss: 1.1108 - val_accuracy: 0.6492 - val_rmse: 0.4457\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.8414 - accuracy: 0.8933 - rmse: 0.3085 - val_loss: 1.1121 - val_accuracy: 0.6431 - val_rmse: 0.4463\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.8365 - accuracy: 0.8800 - rmse: 0.3047 - val_loss: 1.1141 - val_accuracy: 0.6431 - val_rmse: 0.4471\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.8284 - accuracy: 0.9033 - rmse: 0.3034 - val_loss: 1.1157 - val_accuracy: 0.6338 - val_rmse: 0.4478\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.8131 - accuracy: 0.9067 - rmse: 0.2859 - val_loss: 1.1162 - val_accuracy: 0.6308 - val_rmse: 0.4481\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.8163 - accuracy: 0.9033 - rmse: 0.2929 - val_loss: 1.1174 - val_accuracy: 0.6308 - val_rmse: 0.4486\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.8038 - accuracy: 0.8933 - rmse: 0.2808 - val_loss: 1.1188 - val_accuracy: 0.6277 - val_rmse: 0.4492\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.8002 - accuracy: 0.9033 - rmse: 0.2853 - val_loss: 1.1212 - val_accuracy: 0.6246 - val_rmse: 0.4501\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7865 - accuracy: 0.9100 - rmse: 0.2734 - val_loss: 1.1219 - val_accuracy: 0.6246 - val_rmse: 0.4504\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7754 - accuracy: 0.9133 - rmse: 0.2657 - val_loss: 1.1231 - val_accuracy: 0.6215 - val_rmse: 0.4509\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7758 - accuracy: 0.9133 - rmse: 0.2527 - val_loss: 1.1234 - val_accuracy: 0.6215 - val_rmse: 0.4511\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7691 - accuracy: 0.9167 - rmse: 0.2584 - val_loss: 1.1236 - val_accuracy: 0.6215 - val_rmse: 0.4513\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7605 - accuracy: 0.9333 - rmse: 0.2468 - val_loss: 1.1242 - val_accuracy: 0.6246 - val_rmse: 0.4516\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7471 - accuracy: 0.9133 - rmse: 0.2379 - val_loss: 1.1249 - val_accuracy: 0.6246 - val_rmse: 0.4519\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7428 - accuracy: 0.9267 - rmse: 0.2457 - val_loss: 1.1265 - val_accuracy: 0.6246 - val_rmse: 0.4526\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7415 - accuracy: 0.9233 - rmse: 0.2349 - val_loss: 1.1267 - val_accuracy: 0.6246 - val_rmse: 0.4528\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7368 - accuracy: 0.9400 - rmse: 0.2312 - val_loss: 1.1273 - val_accuracy: 0.6246 - val_rmse: 0.4531\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7466 - accuracy: 0.9467 - rmse: 0.2401 - val_loss: 1.1287 - val_accuracy: 0.6246 - val_rmse: 0.4537\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7164 - accuracy: 0.9367 - rmse: 0.2196 - val_loss: 1.1301 - val_accuracy: 0.6246 - val_rmse: 0.4543\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7109 - accuracy: 0.9500 - rmse: 0.2155 - val_loss: 1.1298 - val_accuracy: 0.6246 - val_rmse: 0.4543\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7195 - accuracy: 0.9367 - rmse: 0.2234 - val_loss: 1.1307 - val_accuracy: 0.6246 - val_rmse: 0.4547\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7069 - accuracy: 0.9433 - rmse: 0.2130 - val_loss: 1.1331 - val_accuracy: 0.6246 - val_rmse: 0.4557\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7036 - accuracy: 0.9500 - rmse: 0.2121 - val_loss: 1.1332 - val_accuracy: 0.6246 - val_rmse: 0.4558\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.6981 - accuracy: 0.9533 - rmse: 0.2037 - val_loss: 1.1329 - val_accuracy: 0.6215 - val_rmse: 0.4558\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.7025 - accuracy: 0.9633 - rmse: 0.2036 - val_loss: 1.1325 - val_accuracy: 0.6246 - val_rmse: 0.4558\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.6969 - accuracy: 0.9533 - rmse: 0.2039 - val_loss: 1.1333 - val_accuracy: 0.6246 - val_rmse: 0.4562\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.6878 - accuracy: 0.9633 - rmse: 0.1982 - val_loss: 1.1328 - val_accuracy: 0.6246 - val_rmse: 0.4561\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.6853 - accuracy: 0.9567 - rmse: 0.1948 - val_loss: 1.1327 - val_accuracy: 0.6246 - val_rmse: 0.4562\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.6837 - accuracy: 0.9800 - rmse: 0.1858 - val_loss: 1.1322 - val_accuracy: 0.6246 - val_rmse: 0.4561\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.6677 - accuracy: 0.9567 - rmse: 0.1907 - val_loss: 1.1344 - val_accuracy: 0.6246 - val_rmse: 0.4570\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.6674 - accuracy: 0.9667 - rmse: 0.1789 - val_loss: 1.1355 - val_accuracy: 0.6246 - val_rmse: 0.4575\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.10975\n",
            "10/10 - 0s - loss: 0.6813 - accuracy: 0.9700 - rmse: 0.1878 - val_loss: 1.1343 - val_accuracy: 0.6246 - val_rmse: 0.4570\n",
            "Classification accuracy: 0.080000 \n",
            "\n",
            "\n",
            "Beginning training for subject  15\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 15, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_808\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_809 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1643 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1530 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1530 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1644 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1531 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1531 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_886 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23936, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 1s - loss: 1.2810 - accuracy: 0.4833 - rmse: 0.5205 - val_loss: 1.2394 - val_accuracy: 0.5046 - val_rmse: 0.4981\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23936 to 1.22664, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 1.2261 - accuracy: 0.5567 - rmse: 0.4950 - val_loss: 1.2266 - val_accuracy: 0.4985 - val_rmse: 0.4890\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.22664 to 1.21607, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 1.1782 - accuracy: 0.6867 - rmse: 0.4685 - val_loss: 1.2161 - val_accuracy: 0.5138 - val_rmse: 0.4827\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.21607 to 1.20648, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 1.1564 - accuracy: 0.6900 - rmse: 0.4600 - val_loss: 1.2065 - val_accuracy: 0.5354 - val_rmse: 0.4780\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.20648 to 1.19671, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 1.1198 - accuracy: 0.7300 - rmse: 0.4402 - val_loss: 1.1967 - val_accuracy: 0.5846 - val_rmse: 0.4739\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.19671 to 1.18669, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 1.0946 - accuracy: 0.7567 - rmse: 0.4321 - val_loss: 1.1867 - val_accuracy: 0.6369 - val_rmse: 0.4702\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.18669 to 1.17637, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 1.0662 - accuracy: 0.7700 - rmse: 0.4159 - val_loss: 1.1764 - val_accuracy: 0.6800 - val_rmse: 0.4666\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.17637 to 1.16591, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 1.0589 - accuracy: 0.7733 - rmse: 0.4092 - val_loss: 1.1659 - val_accuracy: 0.7323 - val_rmse: 0.4632\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.16591 to 1.15613, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 1.0248 - accuracy: 0.8067 - rmse: 0.4011 - val_loss: 1.1561 - val_accuracy: 0.7354 - val_rmse: 0.4600\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.15613 to 1.14734, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.9967 - accuracy: 0.8100 - rmse: 0.3857 - val_loss: 1.1473 - val_accuracy: 0.7385 - val_rmse: 0.4572\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.14734 to 1.14059, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.9961 - accuracy: 0.8067 - rmse: 0.3845 - val_loss: 1.1406 - val_accuracy: 0.7292 - val_rmse: 0.4551\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.14059 to 1.13424, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.9626 - accuracy: 0.8233 - rmse: 0.3637 - val_loss: 1.1342 - val_accuracy: 0.7108 - val_rmse: 0.4528\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.13424 to 1.12906, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.9465 - accuracy: 0.8333 - rmse: 0.3619 - val_loss: 1.1291 - val_accuracy: 0.6985 - val_rmse: 0.4509\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.12906 to 1.12548, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.9345 - accuracy: 0.8067 - rmse: 0.3583 - val_loss: 1.1255 - val_accuracy: 0.6892 - val_rmse: 0.4496\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.12548 to 1.12296, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.9346 - accuracy: 0.8167 - rmse: 0.3538 - val_loss: 1.1230 - val_accuracy: 0.6615 - val_rmse: 0.4485\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.12296 to 1.12116, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.9209 - accuracy: 0.8233 - rmse: 0.3465 - val_loss: 1.1212 - val_accuracy: 0.6585 - val_rmse: 0.4477\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.12116 to 1.12017, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.9123 - accuracy: 0.8267 - rmse: 0.3466 - val_loss: 1.1202 - val_accuracy: 0.6523 - val_rmse: 0.4471\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.12017 to 1.11892, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.8894 - accuracy: 0.8367 - rmse: 0.3294 - val_loss: 1.1189 - val_accuracy: 0.6431 - val_rmse: 0.4463\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.11892 to 1.11792, saving model to /tmp/CNN_checkpoint15evbgdpwwby.h5\n",
            "10/10 - 0s - loss: 0.8878 - accuracy: 0.8400 - rmse: 0.3347 - val_loss: 1.1179 - val_accuracy: 0.6431 - val_rmse: 0.4457\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.8775 - accuracy: 0.8500 - rmse: 0.3279 - val_loss: 1.1249 - val_accuracy: 0.6277 - val_rmse: 0.4484\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.8613 - accuracy: 0.8500 - rmse: 0.3176 - val_loss: 1.1247 - val_accuracy: 0.6246 - val_rmse: 0.4481\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.8602 - accuracy: 0.8533 - rmse: 0.3078 - val_loss: 1.1243 - val_accuracy: 0.6246 - val_rmse: 0.4477\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.8329 - accuracy: 0.8800 - rmse: 0.3009 - val_loss: 1.1240 - val_accuracy: 0.6246 - val_rmse: 0.4473\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.8389 - accuracy: 0.8667 - rmse: 0.3039 - val_loss: 1.1235 - val_accuracy: 0.6246 - val_rmse: 0.4468\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.8348 - accuracy: 0.8800 - rmse: 0.3031 - val_loss: 1.1226 - val_accuracy: 0.6246 - val_rmse: 0.4462\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.8164 - accuracy: 0.9000 - rmse: 0.2876 - val_loss: 1.1225 - val_accuracy: 0.6277 - val_rmse: 0.4460\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.8133 - accuracy: 0.9033 - rmse: 0.2864 - val_loss: 1.1224 - val_accuracy: 0.6277 - val_rmse: 0.4458\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.8044 - accuracy: 0.9067 - rmse: 0.2779 - val_loss: 1.1224 - val_accuracy: 0.6277 - val_rmse: 0.4457\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7963 - accuracy: 0.9200 - rmse: 0.2745 - val_loss: 1.1226 - val_accuracy: 0.6277 - val_rmse: 0.4457\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7834 - accuracy: 0.9333 - rmse: 0.2654 - val_loss: 1.1228 - val_accuracy: 0.6308 - val_rmse: 0.4458\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7680 - accuracy: 0.9233 - rmse: 0.2544 - val_loss: 1.1234 - val_accuracy: 0.6308 - val_rmse: 0.4459\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7888 - accuracy: 0.9100 - rmse: 0.2652 - val_loss: 1.1235 - val_accuracy: 0.6308 - val_rmse: 0.4459\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7777 - accuracy: 0.9200 - rmse: 0.2700 - val_loss: 1.1252 - val_accuracy: 0.6308 - val_rmse: 0.4464\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7665 - accuracy: 0.9233 - rmse: 0.2497 - val_loss: 1.1259 - val_accuracy: 0.6308 - val_rmse: 0.4468\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7563 - accuracy: 0.9400 - rmse: 0.2395 - val_loss: 1.1271 - val_accuracy: 0.6308 - val_rmse: 0.4473\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7523 - accuracy: 0.9433 - rmse: 0.2386 - val_loss: 1.1282 - val_accuracy: 0.6308 - val_rmse: 0.4477\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7465 - accuracy: 0.9367 - rmse: 0.2353 - val_loss: 1.1308 - val_accuracy: 0.6277 - val_rmse: 0.4485\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7471 - accuracy: 0.9500 - rmse: 0.2355 - val_loss: 1.1317 - val_accuracy: 0.6277 - val_rmse: 0.4489\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7251 - accuracy: 0.9533 - rmse: 0.2231 - val_loss: 1.1317 - val_accuracy: 0.6277 - val_rmse: 0.4489\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7326 - accuracy: 0.9400 - rmse: 0.2203 - val_loss: 1.1320 - val_accuracy: 0.6277 - val_rmse: 0.4489\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7325 - accuracy: 0.9433 - rmse: 0.2336 - val_loss: 1.1310 - val_accuracy: 0.6308 - val_rmse: 0.4487\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7216 - accuracy: 0.9600 - rmse: 0.2263 - val_loss: 1.1321 - val_accuracy: 0.6277 - val_rmse: 0.4491\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7217 - accuracy: 0.9567 - rmse: 0.2191 - val_loss: 1.1326 - val_accuracy: 0.6369 - val_rmse: 0.4495\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7070 - accuracy: 0.9533 - rmse: 0.2119 - val_loss: 1.1327 - val_accuracy: 0.6369 - val_rmse: 0.4497\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7009 - accuracy: 0.9700 - rmse: 0.2024 - val_loss: 1.1319 - val_accuracy: 0.6369 - val_rmse: 0.4495\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.7122 - accuracy: 0.9700 - rmse: 0.2071 - val_loss: 1.1321 - val_accuracy: 0.6369 - val_rmse: 0.4498\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.6986 - accuracy: 0.9667 - rmse: 0.1905 - val_loss: 1.1324 - val_accuracy: 0.6369 - val_rmse: 0.4501\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.6916 - accuracy: 0.9667 - rmse: 0.1904 - val_loss: 1.1322 - val_accuracy: 0.6400 - val_rmse: 0.4502\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.6905 - accuracy: 0.9733 - rmse: 0.1905 - val_loss: 1.1331 - val_accuracy: 0.6400 - val_rmse: 0.4506\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.11792\n",
            "10/10 - 0s - loss: 0.6909 - accuracy: 0.9633 - rmse: 0.1913 - val_loss: 1.1347 - val_accuracy: 0.6369 - val_rmse: 0.4512\n",
            "Classification accuracy: 0.080000 \n",
            "\n",
            "\n",
            "Beginning training for subject  16\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 16, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_809\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_810 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1645 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1532 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1532 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1646 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1533 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1533 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_887 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.25503, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 1s - loss: 1.2839 - accuracy: 0.4867 - rmse: 0.5227 - val_loss: 1.2550 - val_accuracy: 0.4646 - val_rmse: 0.5026\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.25503 to 1.24725, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.2365 - accuracy: 0.5067 - rmse: 0.4996 - val_loss: 1.2473 - val_accuracy: 0.4892 - val_rmse: 0.4973\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.24725 to 1.24452, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.1999 - accuracy: 0.5733 - rmse: 0.4830 - val_loss: 1.2445 - val_accuracy: 0.4738 - val_rmse: 0.4958\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.24452 to 1.24233, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.1793 - accuracy: 0.6167 - rmse: 0.4751 - val_loss: 1.2423 - val_accuracy: 0.4677 - val_rmse: 0.4951\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.24233 to 1.24007, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.1535 - accuracy: 0.6500 - rmse: 0.4663 - val_loss: 1.2401 - val_accuracy: 0.4677 - val_rmse: 0.4944\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.24007 to 1.23808, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.1264 - accuracy: 0.7033 - rmse: 0.4490 - val_loss: 1.2381 - val_accuracy: 0.4862 - val_rmse: 0.4943\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.23808 to 1.23525, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.1239 - accuracy: 0.7233 - rmse: 0.4472 - val_loss: 1.2353 - val_accuracy: 0.5108 - val_rmse: 0.4937\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.23525 to 1.23196, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.1001 - accuracy: 0.7333 - rmse: 0.4393 - val_loss: 1.2320 - val_accuracy: 0.5508 - val_rmse: 0.4930\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.23196 to 1.22965, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.0594 - accuracy: 0.7967 - rmse: 0.4157 - val_loss: 1.2296 - val_accuracy: 0.5908 - val_rmse: 0.4928\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.22965 to 1.22733, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.0594 - accuracy: 0.8100 - rmse: 0.4168 - val_loss: 1.2273 - val_accuracy: 0.6123 - val_rmse: 0.4926\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.22733 to 1.22419, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.0422 - accuracy: 0.8367 - rmse: 0.4068 - val_loss: 1.2242 - val_accuracy: 0.6154 - val_rmse: 0.4920\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.22419 to 1.22245, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.0155 - accuracy: 0.8567 - rmse: 0.3898 - val_loss: 1.2224 - val_accuracy: 0.6369 - val_rmse: 0.4920\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.22245 to 1.22016, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 1.0242 - accuracy: 0.8600 - rmse: 0.3926 - val_loss: 1.2202 - val_accuracy: 0.6154 - val_rmse: 0.4916\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.22016 to 1.21755, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 0.9941 - accuracy: 0.8800 - rmse: 0.3751 - val_loss: 1.2176 - val_accuracy: 0.6338 - val_rmse: 0.4911\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.21755 to 1.21578, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 0.9773 - accuracy: 0.9033 - rmse: 0.3646 - val_loss: 1.2158 - val_accuracy: 0.6308 - val_rmse: 0.4909\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.21578 to 1.21335, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 0.9495 - accuracy: 0.9433 - rmse: 0.3468 - val_loss: 1.2133 - val_accuracy: 0.6308 - val_rmse: 0.4904\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.21335 to 1.21116, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 0.9484 - accuracy: 0.9100 - rmse: 0.3494 - val_loss: 1.2112 - val_accuracy: 0.6215 - val_rmse: 0.4900\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.21116 to 1.20941, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 0.9435 - accuracy: 0.9100 - rmse: 0.3504 - val_loss: 1.2094 - val_accuracy: 0.6215 - val_rmse: 0.4898\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.20941 to 1.20756, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 0.9096 - accuracy: 0.9167 - rmse: 0.3270 - val_loss: 1.2076 - val_accuracy: 0.6154 - val_rmse: 0.4894\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.20756 to 1.20586, saving model to /tmp/CNN_checkpoint16hjjzpjdrlz.h5\n",
            "10/10 - 0s - loss: 0.9008 - accuracy: 0.9300 - rmse: 0.3224 - val_loss: 1.2059 - val_accuracy: 0.6154 - val_rmse: 0.4890\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8921 - accuracy: 0.9333 - rmse: 0.3219 - val_loss: 1.2086 - val_accuracy: 0.6062 - val_rmse: 0.4904\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8829 - accuracy: 0.9633 - rmse: 0.3153 - val_loss: 1.2082 - val_accuracy: 0.5969 - val_rmse: 0.4905\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8601 - accuracy: 0.9533 - rmse: 0.3029 - val_loss: 1.2118 - val_accuracy: 0.5846 - val_rmse: 0.4919\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8464 - accuracy: 0.9633 - rmse: 0.2849 - val_loss: 1.2121 - val_accuracy: 0.5815 - val_rmse: 0.4920\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8396 - accuracy: 0.9400 - rmse: 0.2824 - val_loss: 1.2139 - val_accuracy: 0.5846 - val_rmse: 0.4927\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8330 - accuracy: 0.9600 - rmse: 0.2797 - val_loss: 1.2157 - val_accuracy: 0.5815 - val_rmse: 0.4933\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8258 - accuracy: 0.9400 - rmse: 0.2832 - val_loss: 1.2162 - val_accuracy: 0.5785 - val_rmse: 0.4935\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8180 - accuracy: 0.9667 - rmse: 0.2728 - val_loss: 1.2161 - val_accuracy: 0.5785 - val_rmse: 0.4934\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8217 - accuracy: 0.9567 - rmse: 0.2774 - val_loss: 1.2168 - val_accuracy: 0.5785 - val_rmse: 0.4935\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8060 - accuracy: 0.9500 - rmse: 0.2718 - val_loss: 1.2166 - val_accuracy: 0.5785 - val_rmse: 0.4934\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.8043 - accuracy: 0.9533 - rmse: 0.2636 - val_loss: 1.2166 - val_accuracy: 0.5785 - val_rmse: 0.4933\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7870 - accuracy: 0.9733 - rmse: 0.2511 - val_loss: 1.2170 - val_accuracy: 0.5785 - val_rmse: 0.4934\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7777 - accuracy: 0.9633 - rmse: 0.2416 - val_loss: 1.2175 - val_accuracy: 0.5785 - val_rmse: 0.4936\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7669 - accuracy: 0.9767 - rmse: 0.2333 - val_loss: 1.2175 - val_accuracy: 0.5785 - val_rmse: 0.4935\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7782 - accuracy: 0.9733 - rmse: 0.2498 - val_loss: 1.2172 - val_accuracy: 0.5785 - val_rmse: 0.4935\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7611 - accuracy: 0.9667 - rmse: 0.2387 - val_loss: 1.2174 - val_accuracy: 0.5785 - val_rmse: 0.4937\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7596 - accuracy: 0.9633 - rmse: 0.2313 - val_loss: 1.2179 - val_accuracy: 0.5754 - val_rmse: 0.4939\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7361 - accuracy: 0.9833 - rmse: 0.2153 - val_loss: 1.2189 - val_accuracy: 0.5754 - val_rmse: 0.4941\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7293 - accuracy: 0.9833 - rmse: 0.2126 - val_loss: 1.2188 - val_accuracy: 0.5754 - val_rmse: 0.4941\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7341 - accuracy: 0.9633 - rmse: 0.2105 - val_loss: 1.2182 - val_accuracy: 0.5754 - val_rmse: 0.4940\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7283 - accuracy: 0.9767 - rmse: 0.2072 - val_loss: 1.2188 - val_accuracy: 0.5754 - val_rmse: 0.4942\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7186 - accuracy: 0.9800 - rmse: 0.2073 - val_loss: 1.2186 - val_accuracy: 0.5785 - val_rmse: 0.4942\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7173 - accuracy: 0.9733 - rmse: 0.2012 - val_loss: 1.2190 - val_accuracy: 0.5754 - val_rmse: 0.4943\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7169 - accuracy: 0.9900 - rmse: 0.2053 - val_loss: 1.2199 - val_accuracy: 0.5754 - val_rmse: 0.4947\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7135 - accuracy: 0.9700 - rmse: 0.2030 - val_loss: 1.2197 - val_accuracy: 0.5754 - val_rmse: 0.4947\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7063 - accuracy: 0.9833 - rmse: 0.1908 - val_loss: 1.2206 - val_accuracy: 0.5723 - val_rmse: 0.4951\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.7010 - accuracy: 0.9833 - rmse: 0.1915 - val_loss: 1.2211 - val_accuracy: 0.5754 - val_rmse: 0.4953\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.6960 - accuracy: 0.9833 - rmse: 0.1824 - val_loss: 1.2229 - val_accuracy: 0.5754 - val_rmse: 0.4960\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.6727 - accuracy: 0.9900 - rmse: 0.1865 - val_loss: 1.2320 - val_accuracy: 0.5723 - val_rmse: 0.4982\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.20586\n",
            "10/10 - 0s - loss: 0.6816 - accuracy: 0.9833 - rmse: 0.1767 - val_loss: 1.2325 - val_accuracy: 0.5723 - val_rmse: 0.4985\n",
            "Classification accuracy: 0.240000 \n",
            "\n",
            "\n",
            "Beginning training for subject  17\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 17, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_810\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_811 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1647 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1534 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1534 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1648 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1535 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1535 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_888 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.21426, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 1s - loss: 1.2537 - accuracy: 0.5033 - rmse: 0.5108 - val_loss: 1.2143 - val_accuracy: 0.5385 - val_rmse: 0.4775\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.21426 to 1.20028, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 1.1902 - accuracy: 0.6133 - rmse: 0.4744 - val_loss: 1.2003 - val_accuracy: 0.5046 - val_rmse: 0.4659\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.20028 to 1.19079, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 1.1590 - accuracy: 0.6767 - rmse: 0.4599 - val_loss: 1.1908 - val_accuracy: 0.5169 - val_rmse: 0.4600\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.19079 to 1.18063, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 1.1193 - accuracy: 0.7433 - rmse: 0.4409 - val_loss: 1.1806 - val_accuracy: 0.5477 - val_rmse: 0.4549\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.18063 to 1.16932, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 1.0804 - accuracy: 0.7700 - rmse: 0.4206 - val_loss: 1.1693 - val_accuracy: 0.5908 - val_rmse: 0.4503\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.16932 to 1.15733, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 1.0581 - accuracy: 0.7667 - rmse: 0.4141 - val_loss: 1.1573 - val_accuracy: 0.6277 - val_rmse: 0.4462\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.15733 to 1.14569, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 1.0405 - accuracy: 0.7900 - rmse: 0.4078 - val_loss: 1.1457 - val_accuracy: 0.6862 - val_rmse: 0.4430\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.14569 to 1.13490, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 1.0182 - accuracy: 0.7867 - rmse: 0.3952 - val_loss: 1.1349 - val_accuracy: 0.7138 - val_rmse: 0.4400\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.13490 to 1.12499, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 0.9965 - accuracy: 0.7800 - rmse: 0.3901 - val_loss: 1.1250 - val_accuracy: 0.7415 - val_rmse: 0.4373\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.12499 to 1.11701, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 0.9788 - accuracy: 0.7967 - rmse: 0.3778 - val_loss: 1.1170 - val_accuracy: 0.7323 - val_rmse: 0.4355\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.11701 to 1.10998, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 0.9502 - accuracy: 0.8367 - rmse: 0.3666 - val_loss: 1.1100 - val_accuracy: 0.7323 - val_rmse: 0.4337\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.10998 to 1.10469, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 0.9402 - accuracy: 0.8433 - rmse: 0.3558 - val_loss: 1.1047 - val_accuracy: 0.7415 - val_rmse: 0.4324\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.10469 to 1.10051, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 0.9225 - accuracy: 0.8467 - rmse: 0.3366 - val_loss: 1.1005 - val_accuracy: 0.7200 - val_rmse: 0.4314\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.10051 to 1.09811, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 0.9152 - accuracy: 0.8467 - rmse: 0.3528 - val_loss: 1.0981 - val_accuracy: 0.7108 - val_rmse: 0.4310\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.09811 to 1.09578, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 0.9042 - accuracy: 0.8400 - rmse: 0.3361 - val_loss: 1.0958 - val_accuracy: 0.6954 - val_rmse: 0.4303\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.09578 to 1.09484, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 0.9005 - accuracy: 0.8667 - rmse: 0.3429 - val_loss: 1.0948 - val_accuracy: 0.6954 - val_rmse: 0.4302\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.09484 to 1.09443, saving model to /tmp/CNN_checkpoint17micrubwawk.h5\n",
            "10/10 - 0s - loss: 0.8802 - accuracy: 0.8633 - rmse: 0.3305 - val_loss: 1.0944 - val_accuracy: 0.6831 - val_rmse: 0.4302\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.8684 - accuracy: 0.8633 - rmse: 0.3208 - val_loss: 1.0953 - val_accuracy: 0.6769 - val_rmse: 0.4308\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.8644 - accuracy: 0.8633 - rmse: 0.3130 - val_loss: 1.0967 - val_accuracy: 0.6738 - val_rmse: 0.4314\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.8437 - accuracy: 0.8633 - rmse: 0.3045 - val_loss: 1.0990 - val_accuracy: 0.6554 - val_rmse: 0.4324\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.8689 - accuracy: 0.8500 - rmse: 0.3242 - val_loss: 1.1011 - val_accuracy: 0.6492 - val_rmse: 0.4333\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.8316 - accuracy: 0.8767 - rmse: 0.3078 - val_loss: 1.1069 - val_accuracy: 0.6431 - val_rmse: 0.4357\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.8292 - accuracy: 0.8867 - rmse: 0.3030 - val_loss: 1.1077 - val_accuracy: 0.6431 - val_rmse: 0.4360\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.8142 - accuracy: 0.8800 - rmse: 0.2821 - val_loss: 1.1084 - val_accuracy: 0.6400 - val_rmse: 0.4362\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.8182 - accuracy: 0.8867 - rmse: 0.2917 - val_loss: 1.1087 - val_accuracy: 0.6400 - val_rmse: 0.4363\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.8115 - accuracy: 0.8833 - rmse: 0.2887 - val_loss: 1.1136 - val_accuracy: 0.6338 - val_rmse: 0.4380\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7973 - accuracy: 0.9100 - rmse: 0.2757 - val_loss: 1.1150 - val_accuracy: 0.6308 - val_rmse: 0.4385\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7953 - accuracy: 0.9067 - rmse: 0.2686 - val_loss: 1.1163 - val_accuracy: 0.6308 - val_rmse: 0.4390\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7872 - accuracy: 0.9033 - rmse: 0.2720 - val_loss: 1.1178 - val_accuracy: 0.6308 - val_rmse: 0.4396\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7929 - accuracy: 0.9000 - rmse: 0.2711 - val_loss: 1.1213 - val_accuracy: 0.6277 - val_rmse: 0.4408\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7805 - accuracy: 0.9300 - rmse: 0.2721 - val_loss: 1.1228 - val_accuracy: 0.6277 - val_rmse: 0.4414\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7692 - accuracy: 0.9200 - rmse: 0.2663 - val_loss: 1.1233 - val_accuracy: 0.6277 - val_rmse: 0.4416\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7723 - accuracy: 0.9233 - rmse: 0.2519 - val_loss: 1.1218 - val_accuracy: 0.6277 - val_rmse: 0.4412\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7471 - accuracy: 0.9400 - rmse: 0.2366 - val_loss: 1.1208 - val_accuracy: 0.6308 - val_rmse: 0.4409\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7387 - accuracy: 0.9433 - rmse: 0.2303 - val_loss: 1.1204 - val_accuracy: 0.6369 - val_rmse: 0.4408\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7454 - accuracy: 0.9367 - rmse: 0.2476 - val_loss: 1.1244 - val_accuracy: 0.6246 - val_rmse: 0.4423\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7301 - accuracy: 0.9400 - rmse: 0.2226 - val_loss: 1.1235 - val_accuracy: 0.6277 - val_rmse: 0.4420\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7323 - accuracy: 0.9500 - rmse: 0.2264 - val_loss: 1.1223 - val_accuracy: 0.6338 - val_rmse: 0.4417\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7103 - accuracy: 0.9633 - rmse: 0.2082 - val_loss: 1.1221 - val_accuracy: 0.6338 - val_rmse: 0.4417\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7222 - accuracy: 0.9600 - rmse: 0.2165 - val_loss: 1.1225 - val_accuracy: 0.6369 - val_rmse: 0.4419\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7288 - accuracy: 0.9533 - rmse: 0.2252 - val_loss: 1.1208 - val_accuracy: 0.6431 - val_rmse: 0.4414\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.7248 - accuracy: 0.9533 - rmse: 0.2253 - val_loss: 1.1207 - val_accuracy: 0.6462 - val_rmse: 0.4414\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.6981 - accuracy: 0.9667 - rmse: 0.1993 - val_loss: 1.1213 - val_accuracy: 0.6462 - val_rmse: 0.4417\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.6929 - accuracy: 0.9667 - rmse: 0.1942 - val_loss: 1.1217 - val_accuracy: 0.6462 - val_rmse: 0.4419\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.6994 - accuracy: 0.9800 - rmse: 0.2003 - val_loss: 1.1213 - val_accuracy: 0.6462 - val_rmse: 0.4419\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.6866 - accuracy: 0.9600 - rmse: 0.1980 - val_loss: 1.1217 - val_accuracy: 0.6462 - val_rmse: 0.4421\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.6843 - accuracy: 0.9767 - rmse: 0.1993 - val_loss: 1.1243 - val_accuracy: 0.6431 - val_rmse: 0.4431\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.6862 - accuracy: 0.9800 - rmse: 0.1921 - val_loss: 1.1246 - val_accuracy: 0.6431 - val_rmse: 0.4433\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.6933 - accuracy: 0.9700 - rmse: 0.1992 - val_loss: 1.1259 - val_accuracy: 0.6431 - val_rmse: 0.4439\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.09443\n",
            "10/10 - 0s - loss: 0.6789 - accuracy: 0.9700 - rmse: 0.1887 - val_loss: 1.1256 - val_accuracy: 0.6400 - val_rmse: 0.4439\n",
            "Classification accuracy: 0.680000 \n",
            "\n",
            "\n",
            "Beginning training for subject  18\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 18, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_811\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_812 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1649 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1536 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1536 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1650 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1537 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1537 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_889 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.22117, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 1s - loss: 1.1991 - accuracy: 0.6200 - rmse: 0.4823 - val_loss: 1.2212 - val_accuracy: 0.4677 - val_rmse: 0.4721\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.22117 to 1.21821, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 1.1510 - accuracy: 0.6967 - rmse: 0.4570 - val_loss: 1.2182 - val_accuracy: 0.4615 - val_rmse: 0.4660\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.21821 to 1.21251, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 1.1009 - accuracy: 0.7533 - rmse: 0.4342 - val_loss: 1.2125 - val_accuracy: 0.4615 - val_rmse: 0.4611\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.21251 to 1.20206, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 1.0508 - accuracy: 0.7933 - rmse: 0.4137 - val_loss: 1.2021 - val_accuracy: 0.4677 - val_rmse: 0.4566\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.20206 to 1.18675, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 1.0280 - accuracy: 0.7933 - rmse: 0.4034 - val_loss: 1.1867 - val_accuracy: 0.4954 - val_rmse: 0.4524\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.18675 to 1.16931, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 1.0120 - accuracy: 0.7700 - rmse: 0.4002 - val_loss: 1.1693 - val_accuracy: 0.5538 - val_rmse: 0.4481\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.16931 to 1.15137, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 0.9765 - accuracy: 0.8300 - rmse: 0.3805 - val_loss: 1.1514 - val_accuracy: 0.6431 - val_rmse: 0.4442\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.15137 to 1.13439, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 0.9733 - accuracy: 0.7767 - rmse: 0.3814 - val_loss: 1.1344 - val_accuracy: 0.7169 - val_rmse: 0.4407\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.13439 to 1.11965, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 0.9462 - accuracy: 0.8167 - rmse: 0.3608 - val_loss: 1.1196 - val_accuracy: 0.7262 - val_rmse: 0.4382\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.11965 to 1.10723, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 0.9271 - accuracy: 0.8167 - rmse: 0.3599 - val_loss: 1.1072 - val_accuracy: 0.7262 - val_rmse: 0.4362\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.10723 to 1.09791, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 0.9237 - accuracy: 0.8167 - rmse: 0.3599 - val_loss: 1.0979 - val_accuracy: 0.7354 - val_rmse: 0.4353\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.09791 to 1.09195, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 0.8939 - accuracy: 0.8400 - rmse: 0.3380 - val_loss: 1.0919 - val_accuracy: 0.7354 - val_rmse: 0.4352\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.09195 to 1.08829, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 0.8768 - accuracy: 0.8333 - rmse: 0.3322 - val_loss: 1.0883 - val_accuracy: 0.7169 - val_rmse: 0.4357\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.08829 to 1.08681, saving model to /tmp/CNN_checkpoint18wotvumloob.h5\n",
            "10/10 - 0s - loss: 0.8783 - accuracy: 0.8433 - rmse: 0.3384 - val_loss: 1.0868 - val_accuracy: 0.7077 - val_rmse: 0.4367\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.8746 - accuracy: 0.8500 - rmse: 0.3317 - val_loss: 1.0883 - val_accuracy: 0.6800 - val_rmse: 0.4387\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.8612 - accuracy: 0.8467 - rmse: 0.3230 - val_loss: 1.0915 - val_accuracy: 0.6677 - val_rmse: 0.4412\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.8318 - accuracy: 0.8767 - rmse: 0.2952 - val_loss: 1.0958 - val_accuracy: 0.6585 - val_rmse: 0.4438\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.8298 - accuracy: 0.8767 - rmse: 0.2882 - val_loss: 1.1011 - val_accuracy: 0.6585 - val_rmse: 0.4468\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.8082 - accuracy: 0.8867 - rmse: 0.2852 - val_loss: 1.1052 - val_accuracy: 0.6585 - val_rmse: 0.4490\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.8161 - accuracy: 0.8633 - rmse: 0.2904 - val_loss: 1.1092 - val_accuracy: 0.6554 - val_rmse: 0.4511\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.8067 - accuracy: 0.9000 - rmse: 0.2906 - val_loss: 1.1126 - val_accuracy: 0.6523 - val_rmse: 0.4530\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.8113 - accuracy: 0.8800 - rmse: 0.2881 - val_loss: 1.1173 - val_accuracy: 0.6400 - val_rmse: 0.4553\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7904 - accuracy: 0.8767 - rmse: 0.2758 - val_loss: 1.1214 - val_accuracy: 0.6308 - val_rmse: 0.4573\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7915 - accuracy: 0.9000 - rmse: 0.2912 - val_loss: 1.1261 - val_accuracy: 0.6246 - val_rmse: 0.4594\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7918 - accuracy: 0.8933 - rmse: 0.2816 - val_loss: 1.1311 - val_accuracy: 0.6215 - val_rmse: 0.4615\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7482 - accuracy: 0.9200 - rmse: 0.2559 - val_loss: 1.1457 - val_accuracy: 0.6123 - val_rmse: 0.4666\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7721 - accuracy: 0.8967 - rmse: 0.2583 - val_loss: 1.1507 - val_accuracy: 0.6092 - val_rmse: 0.4685\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7606 - accuracy: 0.9100 - rmse: 0.2553 - val_loss: 1.1535 - val_accuracy: 0.6092 - val_rmse: 0.4696\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7441 - accuracy: 0.9367 - rmse: 0.2417 - val_loss: 1.1566 - val_accuracy: 0.6062 - val_rmse: 0.4708\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7360 - accuracy: 0.9300 - rmse: 0.2376 - val_loss: 1.1583 - val_accuracy: 0.6062 - val_rmse: 0.4717\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7328 - accuracy: 0.9333 - rmse: 0.2336 - val_loss: 1.1621 - val_accuracy: 0.6031 - val_rmse: 0.4732\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7386 - accuracy: 0.9100 - rmse: 0.2405 - val_loss: 1.1646 - val_accuracy: 0.6031 - val_rmse: 0.4742\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7314 - accuracy: 0.9133 - rmse: 0.2323 - val_loss: 1.1658 - val_accuracy: 0.6031 - val_rmse: 0.4748\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7368 - accuracy: 0.9100 - rmse: 0.2365 - val_loss: 1.1671 - val_accuracy: 0.6000 - val_rmse: 0.4753\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7158 - accuracy: 0.9433 - rmse: 0.2246 - val_loss: 1.1683 - val_accuracy: 0.6000 - val_rmse: 0.4760\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7268 - accuracy: 0.9300 - rmse: 0.2342 - val_loss: 1.1684 - val_accuracy: 0.6000 - val_rmse: 0.4761\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7043 - accuracy: 0.9533 - rmse: 0.2103 - val_loss: 1.1693 - val_accuracy: 0.6000 - val_rmse: 0.4764\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7016 - accuracy: 0.9533 - rmse: 0.2049 - val_loss: 1.1704 - val_accuracy: 0.6031 - val_rmse: 0.4768\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.7019 - accuracy: 0.9533 - rmse: 0.2064 - val_loss: 1.1717 - val_accuracy: 0.6031 - val_rmse: 0.4773\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6903 - accuracy: 0.9667 - rmse: 0.2021 - val_loss: 1.1717 - val_accuracy: 0.6031 - val_rmse: 0.4775\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6877 - accuracy: 0.9600 - rmse: 0.1987 - val_loss: 1.1722 - val_accuracy: 0.6031 - val_rmse: 0.4779\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6964 - accuracy: 0.9500 - rmse: 0.2006 - val_loss: 1.1727 - val_accuracy: 0.6031 - val_rmse: 0.4781\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6811 - accuracy: 0.9633 - rmse: 0.1926 - val_loss: 1.1730 - val_accuracy: 0.6031 - val_rmse: 0.4782\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6727 - accuracy: 0.9767 - rmse: 0.1895 - val_loss: 1.1739 - val_accuracy: 0.6031 - val_rmse: 0.4786\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6759 - accuracy: 0.9700 - rmse: 0.1832 - val_loss: 1.1727 - val_accuracy: 0.6031 - val_rmse: 0.4785\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6769 - accuracy: 0.9633 - rmse: 0.1859 - val_loss: 1.1735 - val_accuracy: 0.6031 - val_rmse: 0.4788\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6638 - accuracy: 0.9633 - rmse: 0.1748 - val_loss: 1.1738 - val_accuracy: 0.6031 - val_rmse: 0.4790\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6712 - accuracy: 0.9800 - rmse: 0.1791 - val_loss: 1.1736 - val_accuracy: 0.6031 - val_rmse: 0.4791\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6637 - accuracy: 0.9767 - rmse: 0.1699 - val_loss: 1.1730 - val_accuracy: 0.6031 - val_rmse: 0.4791\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.08681\n",
            "10/10 - 0s - loss: 0.6772 - accuracy: 0.9500 - rmse: 0.1809 - val_loss: 1.1739 - val_accuracy: 0.6031 - val_rmse: 0.4794\n",
            "Classification accuracy: 0.920000 \n",
            "\n",
            "\n",
            "Beginning training for subject  19\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 19, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_812\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_813 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1651 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1538 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1538 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1652 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1539 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1539 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_890 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.24184, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 1s - loss: 1.2437 - accuracy: 0.5433 - rmse: 0.5035 - val_loss: 1.2418 - val_accuracy: 0.5138 - val_rmse: 0.4964\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.24184 to 1.23669, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 1.2123 - accuracy: 0.6067 - rmse: 0.4858 - val_loss: 1.2367 - val_accuracy: 0.5077 - val_rmse: 0.4919\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.23669 to 1.23105, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 1.1582 - accuracy: 0.7200 - rmse: 0.4577 - val_loss: 1.2311 - val_accuracy: 0.5138 - val_rmse: 0.4894\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.23105 to 1.22496, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 1.1173 - accuracy: 0.7533 - rmse: 0.4426 - val_loss: 1.2250 - val_accuracy: 0.5200 - val_rmse: 0.4873\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.22496 to 1.21710, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 1.0919 - accuracy: 0.7633 - rmse: 0.4271 - val_loss: 1.2171 - val_accuracy: 0.5569 - val_rmse: 0.4851\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.21710 to 1.20887, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 1.0692 - accuracy: 0.7567 - rmse: 0.4231 - val_loss: 1.2089 - val_accuracy: 0.6000 - val_rmse: 0.4834\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.20887 to 1.20041, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 1.0437 - accuracy: 0.8000 - rmse: 0.4075 - val_loss: 1.2004 - val_accuracy: 0.6185 - val_rmse: 0.4817\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.20041 to 1.19219, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 1.0142 - accuracy: 0.8033 - rmse: 0.3981 - val_loss: 1.1922 - val_accuracy: 0.6400 - val_rmse: 0.4799\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.19219 to 1.18521, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 0.9931 - accuracy: 0.8200 - rmse: 0.3790 - val_loss: 1.1852 - val_accuracy: 0.6400 - val_rmse: 0.4784\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.18521 to 1.17995, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 0.9801 - accuracy: 0.8233 - rmse: 0.3810 - val_loss: 1.1800 - val_accuracy: 0.6431 - val_rmse: 0.4774\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.17995 to 1.17630, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 0.9689 - accuracy: 0.8233 - rmse: 0.3704 - val_loss: 1.1763 - val_accuracy: 0.6492 - val_rmse: 0.4766\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.17630 to 1.17403, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 0.9510 - accuracy: 0.8333 - rmse: 0.3597 - val_loss: 1.1740 - val_accuracy: 0.6308 - val_rmse: 0.4762\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.17403 to 1.17284, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 0.9429 - accuracy: 0.8467 - rmse: 0.3555 - val_loss: 1.1728 - val_accuracy: 0.6215 - val_rmse: 0.4758\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.17284 to 1.17238, saving model to /tmp/CNN_checkpoint19boskqyocam.h5\n",
            "10/10 - 0s - loss: 0.9236 - accuracy: 0.8467 - rmse: 0.3569 - val_loss: 1.1724 - val_accuracy: 0.6154 - val_rmse: 0.4755\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8938 - accuracy: 0.8733 - rmse: 0.3322 - val_loss: 1.1732 - val_accuracy: 0.6123 - val_rmse: 0.4756\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8969 - accuracy: 0.8600 - rmse: 0.3315 - val_loss: 1.1738 - val_accuracy: 0.6123 - val_rmse: 0.4755\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8842 - accuracy: 0.8667 - rmse: 0.3321 - val_loss: 1.1753 - val_accuracy: 0.6092 - val_rmse: 0.4757\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8713 - accuracy: 0.8733 - rmse: 0.3199 - val_loss: 1.1780 - val_accuracy: 0.6000 - val_rmse: 0.4763\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8622 - accuracy: 0.8867 - rmse: 0.3178 - val_loss: 1.1815 - val_accuracy: 0.5938 - val_rmse: 0.4771\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8515 - accuracy: 0.8900 - rmse: 0.3100 - val_loss: 1.1845 - val_accuracy: 0.5908 - val_rmse: 0.4778\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8390 - accuracy: 0.8900 - rmse: 0.3046 - val_loss: 1.1867 - val_accuracy: 0.5877 - val_rmse: 0.4783\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8318 - accuracy: 0.8700 - rmse: 0.3037 - val_loss: 1.1912 - val_accuracy: 0.5877 - val_rmse: 0.4793\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8166 - accuracy: 0.8800 - rmse: 0.2884 - val_loss: 1.1938 - val_accuracy: 0.5908 - val_rmse: 0.4796\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8255 - accuracy: 0.8933 - rmse: 0.2877 - val_loss: 1.1950 - val_accuracy: 0.5908 - val_rmse: 0.4798\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.8133 - accuracy: 0.8933 - rmse: 0.2859 - val_loss: 1.1969 - val_accuracy: 0.5877 - val_rmse: 0.4802\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7996 - accuracy: 0.9167 - rmse: 0.2845 - val_loss: 1.1986 - val_accuracy: 0.5908 - val_rmse: 0.4805\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7895 - accuracy: 0.9267 - rmse: 0.2682 - val_loss: 1.2002 - val_accuracy: 0.5908 - val_rmse: 0.4809\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7888 - accuracy: 0.9200 - rmse: 0.2689 - val_loss: 1.2017 - val_accuracy: 0.5908 - val_rmse: 0.4813\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7865 - accuracy: 0.9333 - rmse: 0.2698 - val_loss: 1.2029 - val_accuracy: 0.5908 - val_rmse: 0.4816\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7698 - accuracy: 0.9300 - rmse: 0.2592 - val_loss: 1.2051 - val_accuracy: 0.5908 - val_rmse: 0.4822\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7560 - accuracy: 0.9167 - rmse: 0.2489 - val_loss: 1.2081 - val_accuracy: 0.5908 - val_rmse: 0.4829\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7645 - accuracy: 0.9333 - rmse: 0.2594 - val_loss: 1.2085 - val_accuracy: 0.5908 - val_rmse: 0.4830\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7444 - accuracy: 0.9567 - rmse: 0.2244 - val_loss: 1.2093 - val_accuracy: 0.5908 - val_rmse: 0.4833\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7506 - accuracy: 0.9233 - rmse: 0.2427 - val_loss: 1.2109 - val_accuracy: 0.5908 - val_rmse: 0.4836\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7368 - accuracy: 0.9533 - rmse: 0.2363 - val_loss: 1.2106 - val_accuracy: 0.5908 - val_rmse: 0.4835\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7319 - accuracy: 0.9600 - rmse: 0.2254 - val_loss: 1.2099 - val_accuracy: 0.5908 - val_rmse: 0.4834\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7306 - accuracy: 0.9533 - rmse: 0.2252 - val_loss: 1.2112 - val_accuracy: 0.5908 - val_rmse: 0.4837\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7306 - accuracy: 0.9533 - rmse: 0.2371 - val_loss: 1.2121 - val_accuracy: 0.5908 - val_rmse: 0.4840\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7206 - accuracy: 0.9567 - rmse: 0.2268 - val_loss: 1.2127 - val_accuracy: 0.5908 - val_rmse: 0.4841\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7104 - accuracy: 0.9500 - rmse: 0.2169 - val_loss: 1.2147 - val_accuracy: 0.5877 - val_rmse: 0.4846\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7174 - accuracy: 0.9567 - rmse: 0.2208 - val_loss: 1.2132 - val_accuracy: 0.5877 - val_rmse: 0.4842\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7117 - accuracy: 0.9500 - rmse: 0.2240 - val_loss: 1.2188 - val_accuracy: 0.5846 - val_rmse: 0.4853\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7007 - accuracy: 0.9733 - rmse: 0.2104 - val_loss: 1.2182 - val_accuracy: 0.5846 - val_rmse: 0.4853\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.7003 - accuracy: 0.9667 - rmse: 0.2016 - val_loss: 1.2161 - val_accuracy: 0.5846 - val_rmse: 0.4848\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.6861 - accuracy: 0.9667 - rmse: 0.1929 - val_loss: 1.2149 - val_accuracy: 0.5877 - val_rmse: 0.4846\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.6961 - accuracy: 0.9633 - rmse: 0.2017 - val_loss: 1.2139 - val_accuracy: 0.5846 - val_rmse: 0.4845\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.6836 - accuracy: 0.9700 - rmse: 0.2028 - val_loss: 1.2211 - val_accuracy: 0.5846 - val_rmse: 0.4859\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.6877 - accuracy: 0.9700 - rmse: 0.1904 - val_loss: 1.2180 - val_accuracy: 0.5846 - val_rmse: 0.4852\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.6899 - accuracy: 0.9733 - rmse: 0.1975 - val_loss: 1.2167 - val_accuracy: 0.5846 - val_rmse: 0.4850\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.17238\n",
            "10/10 - 0s - loss: 0.6830 - accuracy: 0.9767 - rmse: 0.1873 - val_loss: 1.2148 - val_accuracy: 0.5846 - val_rmse: 0.4846\n",
            "Classification accuracy: 0.000000 \n",
            "\n",
            "\n",
            "Beginning training for subject  20\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 20, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_813\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_814 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1653 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1540 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1540 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1654 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1541 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1541 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_891 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.25901, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 1s - loss: 1.2182 - accuracy: 0.5900 - rmse: 0.4952 - val_loss: 1.2590 - val_accuracy: 0.4708 - val_rmse: 0.5025\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.25901 to 1.24406, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 0s - loss: 1.2015 - accuracy: 0.6167 - rmse: 0.4790 - val_loss: 1.2441 - val_accuracy: 0.4892 - val_rmse: 0.4919\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.24406 to 1.23585, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 0s - loss: 1.1767 - accuracy: 0.6933 - rmse: 0.4729 - val_loss: 1.2359 - val_accuracy: 0.5077 - val_rmse: 0.4860\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.23585 to 1.22922, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 0s - loss: 1.1464 - accuracy: 0.7167 - rmse: 0.4564 - val_loss: 1.2292 - val_accuracy: 0.4985 - val_rmse: 0.4819\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.22922 to 1.22356, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 1s - loss: 1.1276 - accuracy: 0.7200 - rmse: 0.4500 - val_loss: 1.2236 - val_accuracy: 0.5169 - val_rmse: 0.4793\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.22356 to 1.21824, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 0s - loss: 1.1030 - accuracy: 0.7600 - rmse: 0.4350 - val_loss: 1.2182 - val_accuracy: 0.5354 - val_rmse: 0.4775\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.21824 to 1.21335, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 1s - loss: 1.0668 - accuracy: 0.7933 - rmse: 0.4215 - val_loss: 1.2133 - val_accuracy: 0.5754 - val_rmse: 0.4766\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.21335 to 1.20819, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 0s - loss: 1.0533 - accuracy: 0.8100 - rmse: 0.4123 - val_loss: 1.2082 - val_accuracy: 0.6338 - val_rmse: 0.4753\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.20819 to 1.20445, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 0s - loss: 1.0516 - accuracy: 0.8000 - rmse: 0.4062 - val_loss: 1.2045 - val_accuracy: 0.6831 - val_rmse: 0.4751\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.20445 to 1.20164, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 1s - loss: 1.0286 - accuracy: 0.8533 - rmse: 0.3972 - val_loss: 1.2016 - val_accuracy: 0.6954 - val_rmse: 0.4751\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.20164 to 1.19874, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 0s - loss: 1.0085 - accuracy: 0.8367 - rmse: 0.3900 - val_loss: 1.1987 - val_accuracy: 0.6738 - val_rmse: 0.4752\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.19874 to 1.19637, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 1s - loss: 1.0000 - accuracy: 0.8567 - rmse: 0.3796 - val_loss: 1.1964 - val_accuracy: 0.6677 - val_rmse: 0.4753\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.19637 to 1.19462, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 0s - loss: 0.9735 - accuracy: 0.8867 - rmse: 0.3640 - val_loss: 1.1946 - val_accuracy: 0.6338 - val_rmse: 0.4756\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.19462 to 1.19284, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 1s - loss: 0.9636 - accuracy: 0.8767 - rmse: 0.3618 - val_loss: 1.1928 - val_accuracy: 0.6369 - val_rmse: 0.4756\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.19284 to 1.19140, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 0s - loss: 0.9518 - accuracy: 0.8833 - rmse: 0.3514 - val_loss: 1.1914 - val_accuracy: 0.6400 - val_rmse: 0.4757\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.19140 to 1.18962, saving model to /tmp/CNN_checkpoint20fkpzthwamc.h5\n",
            "10/10 - 1s - loss: 0.9402 - accuracy: 0.8867 - rmse: 0.3465 - val_loss: 1.1896 - val_accuracy: 0.6338 - val_rmse: 0.4754\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.9049 - accuracy: 0.9200 - rmse: 0.3377 - val_loss: 1.1940 - val_accuracy: 0.6154 - val_rmse: 0.4783\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.9097 - accuracy: 0.9133 - rmse: 0.3315 - val_loss: 1.1937 - val_accuracy: 0.6123 - val_rmse: 0.4785\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8966 - accuracy: 0.9067 - rmse: 0.3214 - val_loss: 1.1947 - val_accuracy: 0.6092 - val_rmse: 0.4793\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8985 - accuracy: 0.9133 - rmse: 0.3273 - val_loss: 1.1961 - val_accuracy: 0.6062 - val_rmse: 0.4802\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8658 - accuracy: 0.9367 - rmse: 0.3030 - val_loss: 1.1963 - val_accuracy: 0.6031 - val_rmse: 0.4804\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8634 - accuracy: 0.9133 - rmse: 0.3033 - val_loss: 1.1959 - val_accuracy: 0.6031 - val_rmse: 0.4802\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8534 - accuracy: 0.9533 - rmse: 0.2943 - val_loss: 1.1959 - val_accuracy: 0.6031 - val_rmse: 0.4803\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8316 - accuracy: 0.9400 - rmse: 0.2850 - val_loss: 1.1974 - val_accuracy: 0.6031 - val_rmse: 0.4809\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8297 - accuracy: 0.9200 - rmse: 0.2812 - val_loss: 1.1982 - val_accuracy: 0.6000 - val_rmse: 0.4812\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8231 - accuracy: 0.9300 - rmse: 0.2744 - val_loss: 1.1976 - val_accuracy: 0.6000 - val_rmse: 0.4809\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8256 - accuracy: 0.9400 - rmse: 0.2756 - val_loss: 1.1969 - val_accuracy: 0.6000 - val_rmse: 0.4806\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.8271 - accuracy: 0.9400 - rmse: 0.2798 - val_loss: 1.1974 - val_accuracy: 0.6000 - val_rmse: 0.4808\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7908 - accuracy: 0.9567 - rmse: 0.2520 - val_loss: 1.1972 - val_accuracy: 0.6000 - val_rmse: 0.4807\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7910 - accuracy: 0.9567 - rmse: 0.2566 - val_loss: 1.1970 - val_accuracy: 0.6000 - val_rmse: 0.4805\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7846 - accuracy: 0.9533 - rmse: 0.2425 - val_loss: 1.1975 - val_accuracy: 0.6000 - val_rmse: 0.4807\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7626 - accuracy: 0.9767 - rmse: 0.2351 - val_loss: 1.1983 - val_accuracy: 0.6000 - val_rmse: 0.4809\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7736 - accuracy: 0.9500 - rmse: 0.2415 - val_loss: 1.1995 - val_accuracy: 0.5969 - val_rmse: 0.4813\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7547 - accuracy: 0.9667 - rmse: 0.2452 - val_loss: 1.2070 - val_accuracy: 0.5785 - val_rmse: 0.4837\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7773 - accuracy: 0.9600 - rmse: 0.2468 - val_loss: 1.2064 - val_accuracy: 0.5815 - val_rmse: 0.4834\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7516 - accuracy: 0.9767 - rmse: 0.2293 - val_loss: 1.2058 - val_accuracy: 0.5846 - val_rmse: 0.4831\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7506 - accuracy: 0.9700 - rmse: 0.2302 - val_loss: 1.2056 - val_accuracy: 0.5846 - val_rmse: 0.4830\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7308 - accuracy: 0.9667 - rmse: 0.2139 - val_loss: 1.2037 - val_accuracy: 0.5877 - val_rmse: 0.4822\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7300 - accuracy: 0.9767 - rmse: 0.2168 - val_loss: 1.2025 - val_accuracy: 0.5877 - val_rmse: 0.4817\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7431 - accuracy: 0.9700 - rmse: 0.2238 - val_loss: 1.2021 - val_accuracy: 0.5846 - val_rmse: 0.4815\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7397 - accuracy: 0.9433 - rmse: 0.2226 - val_loss: 1.2021 - val_accuracy: 0.5815 - val_rmse: 0.4814\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7315 - accuracy: 0.9667 - rmse: 0.2110 - val_loss: 1.2025 - val_accuracy: 0.5815 - val_rmse: 0.4816\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7209 - accuracy: 0.9600 - rmse: 0.2168 - val_loss: 1.2040 - val_accuracy: 0.5846 - val_rmse: 0.4822\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7120 - accuracy: 0.9800 - rmse: 0.1965 - val_loss: 1.2046 - val_accuracy: 0.5815 - val_rmse: 0.4824\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7176 - accuracy: 0.9733 - rmse: 0.2041 - val_loss: 1.2053 - val_accuracy: 0.5846 - val_rmse: 0.4828\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7118 - accuracy: 0.9767 - rmse: 0.2015 - val_loss: 1.2044 - val_accuracy: 0.5908 - val_rmse: 0.4825\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7017 - accuracy: 0.9800 - rmse: 0.1943 - val_loss: 1.2036 - val_accuracy: 0.5938 - val_rmse: 0.4822\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.6964 - accuracy: 0.9633 - rmse: 0.1894 - val_loss: 1.2066 - val_accuracy: 0.5877 - val_rmse: 0.4833\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.6811 - accuracy: 0.9867 - rmse: 0.1840 - val_loss: 1.2100 - val_accuracy: 0.5846 - val_rmse: 0.4847\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.18962\n",
            "10/10 - 0s - loss: 0.7012 - accuracy: 0.9767 - rmse: 0.1885 - val_loss: 1.2097 - val_accuracy: 0.5877 - val_rmse: 0.4847\n",
            "Classification accuracy: 0.480000 \n",
            "\n",
            "\n",
            "Beginning training for subject  21\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 21, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_814\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_815 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1655 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1542 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1542 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1656 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1543 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1543 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_892 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.25643, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.2896 - accuracy: 0.4700 - rmse: 0.5275 - val_loss: 1.2564 - val_accuracy: 0.5077 - val_rmse: 0.5075\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.25643 to 1.23817, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 0s - loss: 1.2529 - accuracy: 0.4833 - rmse: 0.5056 - val_loss: 1.2382 - val_accuracy: 0.5046 - val_rmse: 0.4946\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.23817 to 1.22578, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.1881 - accuracy: 0.6433 - rmse: 0.4772 - val_loss: 1.2258 - val_accuracy: 0.5046 - val_rmse: 0.4865\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.22578 to 1.21612, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.1483 - accuracy: 0.6600 - rmse: 0.4605 - val_loss: 1.2161 - val_accuracy: 0.5138 - val_rmse: 0.4815\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.21612 to 1.20655, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.1218 - accuracy: 0.6867 - rmse: 0.4443 - val_loss: 1.2066 - val_accuracy: 0.5631 - val_rmse: 0.4772\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.20655 to 1.19832, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.1226 - accuracy: 0.7200 - rmse: 0.4498 - val_loss: 1.1983 - val_accuracy: 0.6123 - val_rmse: 0.4745\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.19832 to 1.19103, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.1064 - accuracy: 0.6833 - rmse: 0.4463 - val_loss: 1.1910 - val_accuracy: 0.6677 - val_rmse: 0.4723\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.19103 to 1.18438, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.0767 - accuracy: 0.7233 - rmse: 0.4298 - val_loss: 1.1844 - val_accuracy: 0.6954 - val_rmse: 0.4705\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.18438 to 1.17819, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.0648 - accuracy: 0.7667 - rmse: 0.4252 - val_loss: 1.1782 - val_accuracy: 0.7354 - val_rmse: 0.4688\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.17819 to 1.17493, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.0600 - accuracy: 0.7533 - rmse: 0.4153 - val_loss: 1.1749 - val_accuracy: 0.7077 - val_rmse: 0.4685\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.17493 to 1.17176, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.0378 - accuracy: 0.7967 - rmse: 0.4063 - val_loss: 1.1718 - val_accuracy: 0.6923 - val_rmse: 0.4679\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.17176 to 1.16890, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.0001 - accuracy: 0.8700 - rmse: 0.3914 - val_loss: 1.1689 - val_accuracy: 0.6862 - val_rmse: 0.4673\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.16890 to 1.16755, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 1.0216 - accuracy: 0.8033 - rmse: 0.3973 - val_loss: 1.1676 - val_accuracy: 0.6831 - val_rmse: 0.4674\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.16755 to 1.16653, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 0.9755 - accuracy: 0.8833 - rmse: 0.3766 - val_loss: 1.1665 - val_accuracy: 0.6646 - val_rmse: 0.4675\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.16653 to 1.16583, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 0.9653 - accuracy: 0.8967 - rmse: 0.3652 - val_loss: 1.1658 - val_accuracy: 0.6462 - val_rmse: 0.4676\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.16583 to 1.16545, saving model to /tmp/CNN_checkpoint21jltncwhqrv.h5\n",
            "10/10 - 1s - loss: 0.9630 - accuracy: 0.8700 - rmse: 0.3687 - val_loss: 1.1654 - val_accuracy: 0.6400 - val_rmse: 0.4677\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.9446 - accuracy: 0.9333 - rmse: 0.3500 - val_loss: 1.1656 - val_accuracy: 0.6246 - val_rmse: 0.4679\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.9178 - accuracy: 0.9300 - rmse: 0.3346 - val_loss: 1.1659 - val_accuracy: 0.6215 - val_rmse: 0.4682\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.9223 - accuracy: 0.9167 - rmse: 0.3423 - val_loss: 1.1666 - val_accuracy: 0.6185 - val_rmse: 0.4685\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8925 - accuracy: 0.9400 - rmse: 0.3104 - val_loss: 1.1676 - val_accuracy: 0.6031 - val_rmse: 0.4690\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8955 - accuracy: 0.9333 - rmse: 0.3257 - val_loss: 1.1676 - val_accuracy: 0.6031 - val_rmse: 0.4689\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8631 - accuracy: 0.9467 - rmse: 0.3022 - val_loss: 1.1681 - val_accuracy: 0.6092 - val_rmse: 0.4690\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8744 - accuracy: 0.9400 - rmse: 0.3054 - val_loss: 1.1682 - val_accuracy: 0.6123 - val_rmse: 0.4689\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8594 - accuracy: 0.9500 - rmse: 0.2967 - val_loss: 1.1680 - val_accuracy: 0.6123 - val_rmse: 0.4686\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8576 - accuracy: 0.9367 - rmse: 0.3004 - val_loss: 1.1676 - val_accuracy: 0.6123 - val_rmse: 0.4681\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8695 - accuracy: 0.9133 - rmse: 0.3084 - val_loss: 1.1693 - val_accuracy: 0.6092 - val_rmse: 0.4686\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8320 - accuracy: 0.9500 - rmse: 0.2797 - val_loss: 1.1705 - val_accuracy: 0.6092 - val_rmse: 0.4688\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8284 - accuracy: 0.9567 - rmse: 0.2715 - val_loss: 1.1715 - val_accuracy: 0.6092 - val_rmse: 0.4690\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7918 - accuracy: 0.9667 - rmse: 0.2678 - val_loss: 1.1809 - val_accuracy: 0.6031 - val_rmse: 0.4719\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8073 - accuracy: 0.9600 - rmse: 0.2661 - val_loss: 1.1810 - val_accuracy: 0.5969 - val_rmse: 0.4717\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.8086 - accuracy: 0.9467 - rmse: 0.2647 - val_loss: 1.1816 - val_accuracy: 0.6000 - val_rmse: 0.4715\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7851 - accuracy: 0.9567 - rmse: 0.2465 - val_loss: 1.1823 - val_accuracy: 0.6000 - val_rmse: 0.4716\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7912 - accuracy: 0.9400 - rmse: 0.2536 - val_loss: 1.1825 - val_accuracy: 0.6000 - val_rmse: 0.4714\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7780 - accuracy: 0.9533 - rmse: 0.2436 - val_loss: 1.1832 - val_accuracy: 0.6000 - val_rmse: 0.4713\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7497 - accuracy: 0.9800 - rmse: 0.2385 - val_loss: 1.1924 - val_accuracy: 0.5938 - val_rmse: 0.4739\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7648 - accuracy: 0.9700 - rmse: 0.2316 - val_loss: 1.1918 - val_accuracy: 0.5938 - val_rmse: 0.4734\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7724 - accuracy: 0.9533 - rmse: 0.2410 - val_loss: 1.1915 - val_accuracy: 0.5938 - val_rmse: 0.4731\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7564 - accuracy: 0.9600 - rmse: 0.2258 - val_loss: 1.1918 - val_accuracy: 0.5969 - val_rmse: 0.4729\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7537 - accuracy: 0.9533 - rmse: 0.2254 - val_loss: 1.1916 - val_accuracy: 0.6000 - val_rmse: 0.4725\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7323 - accuracy: 0.9667 - rmse: 0.2101 - val_loss: 1.1921 - val_accuracy: 0.6000 - val_rmse: 0.4725\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7406 - accuracy: 0.9567 - rmse: 0.2174 - val_loss: 1.1928 - val_accuracy: 0.6000 - val_rmse: 0.4726\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7307 - accuracy: 0.9667 - rmse: 0.2124 - val_loss: 1.1934 - val_accuracy: 0.6000 - val_rmse: 0.4726\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7343 - accuracy: 0.9533 - rmse: 0.2162 - val_loss: 1.1936 - val_accuracy: 0.6000 - val_rmse: 0.4725\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7281 - accuracy: 0.9600 - rmse: 0.2141 - val_loss: 1.1943 - val_accuracy: 0.5969 - val_rmse: 0.4726\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7154 - accuracy: 0.9633 - rmse: 0.1970 - val_loss: 1.1951 - val_accuracy: 0.5969 - val_rmse: 0.4727\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.6999 - accuracy: 0.9833 - rmse: 0.1925 - val_loss: 1.1953 - val_accuracy: 0.5969 - val_rmse: 0.4725\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.6996 - accuracy: 0.9733 - rmse: 0.1929 - val_loss: 1.1956 - val_accuracy: 0.5969 - val_rmse: 0.4723\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7035 - accuracy: 0.9767 - rmse: 0.1930 - val_loss: 1.1953 - val_accuracy: 0.5969 - val_rmse: 0.4721\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.7085 - accuracy: 0.9667 - rmse: 0.1938 - val_loss: 1.1954 - val_accuracy: 0.5969 - val_rmse: 0.4719\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.16545\n",
            "10/10 - 0s - loss: 0.6918 - accuracy: 0.9633 - rmse: 0.1903 - val_loss: 1.1962 - val_accuracy: 0.5938 - val_rmse: 0.4720\n",
            "Classification accuracy: 0.200000 \n",
            "\n",
            "\n",
            "Beginning training for subject  22\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 22, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_815\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_816 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1657 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1544 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1544 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1658 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1545 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1545 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_893 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.22529, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 1.2734 - accuracy: 0.5100 - rmse: 0.5134 - val_loss: 1.2253 - val_accuracy: 0.5200 - val_rmse: 0.4872\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.22529 to 1.21330, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 0s - loss: 1.1929 - accuracy: 0.6333 - rmse: 0.4778 - val_loss: 1.2133 - val_accuracy: 0.5385 - val_rmse: 0.4797\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.21330 to 1.20078, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 1.1632 - accuracy: 0.6733 - rmse: 0.4603 - val_loss: 1.2008 - val_accuracy: 0.5508 - val_rmse: 0.4731\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.20078 to 1.18852, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 1.1351 - accuracy: 0.7133 - rmse: 0.4493 - val_loss: 1.1885 - val_accuracy: 0.5785 - val_rmse: 0.4679\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.18852 to 1.17585, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 1.1205 - accuracy: 0.7233 - rmse: 0.4455 - val_loss: 1.1759 - val_accuracy: 0.6431 - val_rmse: 0.4632\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.17585 to 1.16472, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 1.0886 - accuracy: 0.7367 - rmse: 0.4318 - val_loss: 1.1647 - val_accuracy: 0.6862 - val_rmse: 0.4598\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.16472 to 1.15207, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 1.0551 - accuracy: 0.7967 - rmse: 0.4116 - val_loss: 1.1521 - val_accuracy: 0.7354 - val_rmse: 0.4555\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.15207 to 1.14143, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 1.0367 - accuracy: 0.8133 - rmse: 0.4058 - val_loss: 1.1414 - val_accuracy: 0.7662 - val_rmse: 0.4523\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.14143 to 1.13062, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 1.0200 - accuracy: 0.7933 - rmse: 0.3953 - val_loss: 1.1306 - val_accuracy: 0.7692 - val_rmse: 0.4488\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.13062 to 1.12223, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 1.0047 - accuracy: 0.7967 - rmse: 0.3847 - val_loss: 1.1222 - val_accuracy: 0.7662 - val_rmse: 0.4463\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.12223 to 1.11436, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 0.9689 - accuracy: 0.8333 - rmse: 0.3684 - val_loss: 1.1144 - val_accuracy: 0.7569 - val_rmse: 0.4438\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.11436 to 1.10805, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 0.9655 - accuracy: 0.8067 - rmse: 0.3714 - val_loss: 1.1080 - val_accuracy: 0.7354 - val_rmse: 0.4419\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.10805 to 1.10356, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 0.9590 - accuracy: 0.8000 - rmse: 0.3674 - val_loss: 1.1036 - val_accuracy: 0.7138 - val_rmse: 0.4406\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.10356 to 1.10081, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 0.9469 - accuracy: 0.8233 - rmse: 0.3506 - val_loss: 1.1008 - val_accuracy: 0.6954 - val_rmse: 0.4399\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.10081 to 1.09819, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 0.9384 - accuracy: 0.8233 - rmse: 0.3549 - val_loss: 1.0982 - val_accuracy: 0.6862 - val_rmse: 0.4391\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.09819 to 1.09656, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 0.9061 - accuracy: 0.8200 - rmse: 0.3375 - val_loss: 1.0966 - val_accuracy: 0.6738 - val_rmse: 0.4386\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.09656 to 1.09542, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 0.9041 - accuracy: 0.8367 - rmse: 0.3401 - val_loss: 1.0954 - val_accuracy: 0.6708 - val_rmse: 0.4383\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.09542 to 1.09526, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 0.8772 - accuracy: 0.8667 - rmse: 0.3274 - val_loss: 1.0953 - val_accuracy: 0.6585 - val_rmse: 0.4384\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.09526 to 1.09480, saving model to /tmp/CNN_checkpoint22eoadhdgyyp.h5\n",
            "10/10 - 1s - loss: 0.8790 - accuracy: 0.8533 - rmse: 0.3221 - val_loss: 1.0948 - val_accuracy: 0.6585 - val_rmse: 0.4382\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8731 - accuracy: 0.8633 - rmse: 0.3231 - val_loss: 1.0948 - val_accuracy: 0.6615 - val_rmse: 0.4382\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8603 - accuracy: 0.8800 - rmse: 0.3066 - val_loss: 1.0951 - val_accuracy: 0.6585 - val_rmse: 0.4383\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8542 - accuracy: 0.8767 - rmse: 0.3040 - val_loss: 1.0963 - val_accuracy: 0.6523 - val_rmse: 0.4387\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8396 - accuracy: 0.8767 - rmse: 0.2982 - val_loss: 1.0967 - val_accuracy: 0.6554 - val_rmse: 0.4388\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8349 - accuracy: 0.8767 - rmse: 0.2968 - val_loss: 1.0972 - val_accuracy: 0.6523 - val_rmse: 0.4390\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8414 - accuracy: 0.8867 - rmse: 0.2973 - val_loss: 1.0976 - val_accuracy: 0.6523 - val_rmse: 0.4391\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8138 - accuracy: 0.8900 - rmse: 0.2862 - val_loss: 1.0985 - val_accuracy: 0.6554 - val_rmse: 0.4394\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8110 - accuracy: 0.9000 - rmse: 0.2837 - val_loss: 1.0993 - val_accuracy: 0.6523 - val_rmse: 0.4396\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8145 - accuracy: 0.8967 - rmse: 0.2804 - val_loss: 1.0994 - val_accuracy: 0.6523 - val_rmse: 0.4397\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.8110 - accuracy: 0.9367 - rmse: 0.2761 - val_loss: 1.0997 - val_accuracy: 0.6523 - val_rmse: 0.4398\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7977 - accuracy: 0.9133 - rmse: 0.2731 - val_loss: 1.0999 - val_accuracy: 0.6523 - val_rmse: 0.4398\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7849 - accuracy: 0.9267 - rmse: 0.2647 - val_loss: 1.1000 - val_accuracy: 0.6523 - val_rmse: 0.4398\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7807 - accuracy: 0.9267 - rmse: 0.2618 - val_loss: 1.1003 - val_accuracy: 0.6523 - val_rmse: 0.4399\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7693 - accuracy: 0.9500 - rmse: 0.2480 - val_loss: 1.1014 - val_accuracy: 0.6523 - val_rmse: 0.4403\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7561 - accuracy: 0.9333 - rmse: 0.2356 - val_loss: 1.1029 - val_accuracy: 0.6523 - val_rmse: 0.4410\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7543 - accuracy: 0.9500 - rmse: 0.2473 - val_loss: 1.1041 - val_accuracy: 0.6523 - val_rmse: 0.4414\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7565 - accuracy: 0.9433 - rmse: 0.2355 - val_loss: 1.1044 - val_accuracy: 0.6523 - val_rmse: 0.4415\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7450 - accuracy: 0.9533 - rmse: 0.2189 - val_loss: 1.1054 - val_accuracy: 0.6492 - val_rmse: 0.4418\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7419 - accuracy: 0.9567 - rmse: 0.2344 - val_loss: 1.1061 - val_accuracy: 0.6492 - val_rmse: 0.4421\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7435 - accuracy: 0.9667 - rmse: 0.2218 - val_loss: 1.1054 - val_accuracy: 0.6492 - val_rmse: 0.4418\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7344 - accuracy: 0.9667 - rmse: 0.2244 - val_loss: 1.1052 - val_accuracy: 0.6492 - val_rmse: 0.4418\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7177 - accuracy: 0.9633 - rmse: 0.2065 - val_loss: 1.1044 - val_accuracy: 0.6492 - val_rmse: 0.4414\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7249 - accuracy: 0.9500 - rmse: 0.2114 - val_loss: 1.1037 - val_accuracy: 0.6523 - val_rmse: 0.4411\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7175 - accuracy: 0.9733 - rmse: 0.2074 - val_loss: 1.1043 - val_accuracy: 0.6523 - val_rmse: 0.4413\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7150 - accuracy: 0.9867 - rmse: 0.2050 - val_loss: 1.1042 - val_accuracy: 0.6523 - val_rmse: 0.4413\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.7069 - accuracy: 0.9700 - rmse: 0.2018 - val_loss: 1.1053 - val_accuracy: 0.6523 - val_rmse: 0.4417\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.6964 - accuracy: 0.9933 - rmse: 0.1914 - val_loss: 1.1067 - val_accuracy: 0.6523 - val_rmse: 0.4423\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.6929 - accuracy: 0.9833 - rmse: 0.1913 - val_loss: 1.1076 - val_accuracy: 0.6554 - val_rmse: 0.4426\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.6939 - accuracy: 0.9833 - rmse: 0.1907 - val_loss: 1.1077 - val_accuracy: 0.6554 - val_rmse: 0.4427\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.6983 - accuracy: 0.9867 - rmse: 0.1945 - val_loss: 1.1073 - val_accuracy: 0.6554 - val_rmse: 0.4426\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.09480\n",
            "10/10 - 0s - loss: 0.6863 - accuracy: 0.9867 - rmse: 0.1910 - val_loss: 1.1069 - val_accuracy: 0.6554 - val_rmse: 0.4426\n",
            "Classification accuracy: 0.160000 \n",
            "\n",
            "\n",
            "Beginning training for subject  23\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 23, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_816\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_817 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1659 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1546 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1546 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1660 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1547 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1547 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_894 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23525, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.2488 - accuracy: 0.5333 - rmse: 0.5089 - val_loss: 1.2352 - val_accuracy: 0.5138 - val_rmse: 0.4882\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23525 to 1.23043, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 0s - loss: 1.2183 - accuracy: 0.5567 - rmse: 0.4910 - val_loss: 1.2304 - val_accuracy: 0.5169 - val_rmse: 0.4842\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.23043 to 1.22535, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.2112 - accuracy: 0.6100 - rmse: 0.4868 - val_loss: 1.2253 - val_accuracy: 0.5077 - val_rmse: 0.4813\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.22535 to 1.21996, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.1806 - accuracy: 0.6533 - rmse: 0.4713 - val_loss: 1.2200 - val_accuracy: 0.5077 - val_rmse: 0.4795\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.21996 to 1.21342, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.1504 - accuracy: 0.6900 - rmse: 0.4577 - val_loss: 1.2134 - val_accuracy: 0.5046 - val_rmse: 0.4777\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.21342 to 1.20522, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.1270 - accuracy: 0.7367 - rmse: 0.4470 - val_loss: 1.2052 - val_accuracy: 0.5231 - val_rmse: 0.4753\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.20522 to 1.19657, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.0977 - accuracy: 0.7467 - rmse: 0.4286 - val_loss: 1.1966 - val_accuracy: 0.5569 - val_rmse: 0.4735\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.19657 to 1.18744, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.0916 - accuracy: 0.7533 - rmse: 0.4263 - val_loss: 1.1874 - val_accuracy: 0.5908 - val_rmse: 0.4714\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.18744 to 1.17749, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.0528 - accuracy: 0.8100 - rmse: 0.4093 - val_loss: 1.1775 - val_accuracy: 0.6092 - val_rmse: 0.4688\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.17749 to 1.16769, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.0334 - accuracy: 0.8100 - rmse: 0.3960 - val_loss: 1.1677 - val_accuracy: 0.6677 - val_rmse: 0.4662\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.16769 to 1.15787, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.0129 - accuracy: 0.8300 - rmse: 0.3856 - val_loss: 1.1579 - val_accuracy: 0.6892 - val_rmse: 0.4635\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.15787 to 1.14848, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 1.0022 - accuracy: 0.8300 - rmse: 0.3886 - val_loss: 1.1485 - val_accuracy: 0.7108 - val_rmse: 0.4608\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.14848 to 1.14025, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.9997 - accuracy: 0.8100 - rmse: 0.3844 - val_loss: 1.1402 - val_accuracy: 0.7138 - val_rmse: 0.4585\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.14025 to 1.13297, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.9803 - accuracy: 0.8333 - rmse: 0.3731 - val_loss: 1.1330 - val_accuracy: 0.7262 - val_rmse: 0.4565\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.13297 to 1.12673, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.9532 - accuracy: 0.8433 - rmse: 0.3579 - val_loss: 1.1267 - val_accuracy: 0.7354 - val_rmse: 0.4548\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.12673 to 1.12156, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.9483 - accuracy: 0.8633 - rmse: 0.3606 - val_loss: 1.1216 - val_accuracy: 0.7292 - val_rmse: 0.4534\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.12156 to 1.11636, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.9287 - accuracy: 0.8633 - rmse: 0.3487 - val_loss: 1.1164 - val_accuracy: 0.7446 - val_rmse: 0.4519\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.11636 to 1.11196, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.9128 - accuracy: 0.8733 - rmse: 0.3400 - val_loss: 1.1120 - val_accuracy: 0.7354 - val_rmse: 0.4507\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.11196 to 1.10796, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.9027 - accuracy: 0.8867 - rmse: 0.3292 - val_loss: 1.1080 - val_accuracy: 0.7292 - val_rmse: 0.4495\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.10796 to 1.10451, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.8912 - accuracy: 0.8800 - rmse: 0.3277 - val_loss: 1.1045 - val_accuracy: 0.7323 - val_rmse: 0.4484\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.10451 to 1.10291, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.8984 - accuracy: 0.8667 - rmse: 0.3320 - val_loss: 1.1029 - val_accuracy: 0.7292 - val_rmse: 0.4482\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.10291 to 1.10054, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.8695 - accuracy: 0.9133 - rmse: 0.3089 - val_loss: 1.1005 - val_accuracy: 0.7231 - val_rmse: 0.4476\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.10054 to 1.09792, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.8734 - accuracy: 0.9033 - rmse: 0.3120 - val_loss: 1.0979 - val_accuracy: 0.7231 - val_rmse: 0.4466\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.09792 to 1.09586, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.8606 - accuracy: 0.8833 - rmse: 0.3078 - val_loss: 1.0959 - val_accuracy: 0.7231 - val_rmse: 0.4460\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.09586 to 1.09479, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.8472 - accuracy: 0.9033 - rmse: 0.2986 - val_loss: 1.0948 - val_accuracy: 0.7200 - val_rmse: 0.4455\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.09479 to 1.09445, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.8489 - accuracy: 0.9167 - rmse: 0.2998 - val_loss: 1.0945 - val_accuracy: 0.7231 - val_rmse: 0.4455\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.09445\n",
            "10/10 - 0s - loss: 0.8241 - accuracy: 0.9267 - rmse: 0.2810 - val_loss: 1.0949 - val_accuracy: 0.7231 - val_rmse: 0.4457\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.09445 to 1.09351, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 0s - loss: 0.8158 - accuracy: 0.9433 - rmse: 0.2824 - val_loss: 1.0935 - val_accuracy: 0.7200 - val_rmse: 0.4453\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.09351 to 1.09204, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.8110 - accuracy: 0.9300 - rmse: 0.2797 - val_loss: 1.0920 - val_accuracy: 0.7138 - val_rmse: 0.4447\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.09204 to 1.09040, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.8068 - accuracy: 0.9533 - rmse: 0.2759 - val_loss: 1.0904 - val_accuracy: 0.7108 - val_rmse: 0.4441\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.09040 to 1.08833, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7954 - accuracy: 0.9433 - rmse: 0.2672 - val_loss: 1.0883 - val_accuracy: 0.7138 - val_rmse: 0.4432\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.08833 to 1.08613, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7915 - accuracy: 0.9433 - rmse: 0.2541 - val_loss: 1.0861 - val_accuracy: 0.7169 - val_rmse: 0.4424\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.08613 to 1.08580, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7824 - accuracy: 0.9533 - rmse: 0.2570 - val_loss: 1.0858 - val_accuracy: 0.7169 - val_rmse: 0.4424\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.08580 to 1.08492, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7653 - accuracy: 0.9600 - rmse: 0.2459 - val_loss: 1.0849 - val_accuracy: 0.7169 - val_rmse: 0.4421\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.08492 to 1.08307, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7656 - accuracy: 0.9633 - rmse: 0.2386 - val_loss: 1.0831 - val_accuracy: 0.7169 - val_rmse: 0.4413\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.08307 to 1.08184, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7547 - accuracy: 0.9667 - rmse: 0.2339 - val_loss: 1.0818 - val_accuracy: 0.7169 - val_rmse: 0.4408\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.08184 to 1.08095, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7415 - accuracy: 0.9767 - rmse: 0.2241 - val_loss: 1.0809 - val_accuracy: 0.7169 - val_rmse: 0.4405\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.08095 to 1.07955, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7446 - accuracy: 0.9700 - rmse: 0.2232 - val_loss: 1.0796 - val_accuracy: 0.7108 - val_rmse: 0.4400\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.07955 to 1.07926, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7380 - accuracy: 0.9800 - rmse: 0.2177 - val_loss: 1.0793 - val_accuracy: 0.7077 - val_rmse: 0.4400\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.07926 to 1.07921, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7275 - accuracy: 0.9833 - rmse: 0.2119 - val_loss: 1.0792 - val_accuracy: 0.7077 - val_rmse: 0.4403\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.07921 to 1.07918, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.7217 - accuracy: 0.9800 - rmse: 0.2102 - val_loss: 1.0792 - val_accuracy: 0.7015 - val_rmse: 0.4406\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.07918\n",
            "10/10 - 0s - loss: 0.7171 - accuracy: 0.9800 - rmse: 0.2071 - val_loss: 1.0792 - val_accuracy: 0.6985 - val_rmse: 0.4407\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.07918\n",
            "10/10 - 0s - loss: 0.7082 - accuracy: 0.9900 - rmse: 0.1997 - val_loss: 1.0793 - val_accuracy: 0.6985 - val_rmse: 0.4407\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.07918 to 1.07906, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 0s - loss: 0.7092 - accuracy: 0.9833 - rmse: 0.2054 - val_loss: 1.0791 - val_accuracy: 0.6985 - val_rmse: 0.4408\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.07906 to 1.07826, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.6983 - accuracy: 0.9900 - rmse: 0.1906 - val_loss: 1.0783 - val_accuracy: 0.6985 - val_rmse: 0.4406\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.07826 to 1.07663, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.6949 - accuracy: 0.9933 - rmse: 0.1861 - val_loss: 1.0766 - val_accuracy: 0.7046 - val_rmse: 0.4401\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.07663 to 1.07504, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.6902 - accuracy: 0.9933 - rmse: 0.1857 - val_loss: 1.0750 - val_accuracy: 0.7046 - val_rmse: 0.4396\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 1.07504 to 1.07444, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.6886 - accuracy: 1.0000 - rmse: 0.1805 - val_loss: 1.0744 - val_accuracy: 0.7046 - val_rmse: 0.4395\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 1.07444 to 1.07285, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.6794 - accuracy: 0.9967 - rmse: 0.1735 - val_loss: 1.0729 - val_accuracy: 0.7108 - val_rmse: 0.4390\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss improved from 1.07285 to 1.07197, saving model to /tmp/CNN_checkpoint23dcbpawopbc.h5\n",
            "10/10 - 1s - loss: 0.6777 - accuracy: 0.9933 - rmse: 0.1707 - val_loss: 1.0720 - val_accuracy: 0.7108 - val_rmse: 0.4388\n",
            "Classification accuracy: 0.960000 \n",
            "\n",
            "\n",
            "Beginning training for subject  24\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 24, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_817\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_818 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1661 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1548 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1548 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1662 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1549 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1549 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_895 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.25085, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.2467 - accuracy: 0.5133 - rmse: 0.5071 - val_loss: 1.2509 - val_accuracy: 0.5077 - val_rmse: 0.5059\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.25085 to 1.23687, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.2256 - accuracy: 0.5600 - rmse: 0.4909 - val_loss: 1.2369 - val_accuracy: 0.5015 - val_rmse: 0.4956\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.23687 to 1.22589, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.2072 - accuracy: 0.6033 - rmse: 0.4862 - val_loss: 1.2259 - val_accuracy: 0.4923 - val_rmse: 0.4876\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.22589 to 1.21779, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.1681 - accuracy: 0.6567 - rmse: 0.4664 - val_loss: 1.2178 - val_accuracy: 0.4923 - val_rmse: 0.4828\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.21779 to 1.21091, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.1438 - accuracy: 0.6633 - rmse: 0.4540 - val_loss: 1.2109 - val_accuracy: 0.5015 - val_rmse: 0.4797\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.21091 to 1.20465, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.1202 - accuracy: 0.7200 - rmse: 0.4433 - val_loss: 1.2047 - val_accuracy: 0.5046 - val_rmse: 0.4775\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.20465 to 1.19817, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.0999 - accuracy: 0.7467 - rmse: 0.4331 - val_loss: 1.1982 - val_accuracy: 0.5292 - val_rmse: 0.4758\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.19817 to 1.19242, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.0839 - accuracy: 0.8000 - rmse: 0.4229 - val_loss: 1.1924 - val_accuracy: 0.5631 - val_rmse: 0.4748\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.19242 to 1.18685, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.0477 - accuracy: 0.8200 - rmse: 0.4095 - val_loss: 1.1868 - val_accuracy: 0.5846 - val_rmse: 0.4739\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.18685 to 1.18220, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.0380 - accuracy: 0.8433 - rmse: 0.3996 - val_loss: 1.1822 - val_accuracy: 0.6154 - val_rmse: 0.4737\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.18220 to 1.17740, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.0117 - accuracy: 0.8667 - rmse: 0.3874 - val_loss: 1.1774 - val_accuracy: 0.6154 - val_rmse: 0.4733\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.17740 to 1.17262, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 1.0012 - accuracy: 0.8867 - rmse: 0.3818 - val_loss: 1.1726 - val_accuracy: 0.6431 - val_rmse: 0.4727\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.17262 to 1.16877, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.9833 - accuracy: 0.8967 - rmse: 0.3676 - val_loss: 1.1688 - val_accuracy: 0.6554 - val_rmse: 0.4727\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.16877 to 1.16556, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.9591 - accuracy: 0.9033 - rmse: 0.3537 - val_loss: 1.1656 - val_accuracy: 0.6708 - val_rmse: 0.4727\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.16556 to 1.16137, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.9488 - accuracy: 0.9133 - rmse: 0.3485 - val_loss: 1.1614 - val_accuracy: 0.6923 - val_rmse: 0.4720\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.16137 to 1.15719, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.9386 - accuracy: 0.9100 - rmse: 0.3469 - val_loss: 1.1572 - val_accuracy: 0.7015 - val_rmse: 0.4713\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.15719 to 1.15341, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.9163 - accuracy: 0.9267 - rmse: 0.3301 - val_loss: 1.1534 - val_accuracy: 0.6954 - val_rmse: 0.4706\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.15341 to 1.14999, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 0s - loss: 0.9090 - accuracy: 0.9267 - rmse: 0.3281 - val_loss: 1.1500 - val_accuracy: 0.6985 - val_rmse: 0.4701\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.14999 to 1.14599, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.8855 - accuracy: 0.9533 - rmse: 0.3155 - val_loss: 1.1460 - val_accuracy: 0.7077 - val_rmse: 0.4692\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.14599 to 1.14206, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.8815 - accuracy: 0.9500 - rmse: 0.3072 - val_loss: 1.1421 - val_accuracy: 0.7046 - val_rmse: 0.4683\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.14206 to 1.13892, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.8588 - accuracy: 0.9500 - rmse: 0.2975 - val_loss: 1.1389 - val_accuracy: 0.7077 - val_rmse: 0.4677\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.13892 to 1.13504, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.8467 - accuracy: 0.9533 - rmse: 0.2877 - val_loss: 1.1350 - val_accuracy: 0.7077 - val_rmse: 0.4667\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.13504 to 1.13129, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.8332 - accuracy: 0.9633 - rmse: 0.2819 - val_loss: 1.1313 - val_accuracy: 0.7077 - val_rmse: 0.4657\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.13129 to 1.12824, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.8288 - accuracy: 0.9733 - rmse: 0.2817 - val_loss: 1.1282 - val_accuracy: 0.7046 - val_rmse: 0.4650\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.12824 to 1.12591, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.8160 - accuracy: 0.9533 - rmse: 0.2700 - val_loss: 1.1259 - val_accuracy: 0.7046 - val_rmse: 0.4647\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.12591 to 1.12350, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.8134 - accuracy: 0.9633 - rmse: 0.2669 - val_loss: 1.1235 - val_accuracy: 0.7015 - val_rmse: 0.4642\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.12350 to 1.12205, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7946 - accuracy: 0.9833 - rmse: 0.2569 - val_loss: 1.1220 - val_accuracy: 0.7015 - val_rmse: 0.4642\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.12205 to 1.12023, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7920 - accuracy: 0.9667 - rmse: 0.2517 - val_loss: 1.1202 - val_accuracy: 0.6985 - val_rmse: 0.4639\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.12023 to 1.11884, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7809 - accuracy: 0.9700 - rmse: 0.2484 - val_loss: 1.1188 - val_accuracy: 0.6923 - val_rmse: 0.4638\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.11884 to 1.11811, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7584 - accuracy: 0.9967 - rmse: 0.2385 - val_loss: 1.1181 - val_accuracy: 0.6892 - val_rmse: 0.4639\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.11811 to 1.11783, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7681 - accuracy: 0.9800 - rmse: 0.2460 - val_loss: 1.1178 - val_accuracy: 0.6892 - val_rmse: 0.4642\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.11783 to 1.11639, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7535 - accuracy: 0.9767 - rmse: 0.2279 - val_loss: 1.1164 - val_accuracy: 0.6892 - val_rmse: 0.4639\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.11639 to 1.11536, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7472 - accuracy: 0.9900 - rmse: 0.2262 - val_loss: 1.1154 - val_accuracy: 0.6923 - val_rmse: 0.4639\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.11536 to 1.11444, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7387 - accuracy: 0.9933 - rmse: 0.2149 - val_loss: 1.1144 - val_accuracy: 0.6892 - val_rmse: 0.4638\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.11444 to 1.11384, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7390 - accuracy: 0.9933 - rmse: 0.2179 - val_loss: 1.1138 - val_accuracy: 0.6892 - val_rmse: 0.4639\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.11384 to 1.11233, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7374 - accuracy: 0.9800 - rmse: 0.2174 - val_loss: 1.1123 - val_accuracy: 0.6892 - val_rmse: 0.4637\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.11233 to 1.11096, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7242 - accuracy: 0.9900 - rmse: 0.2062 - val_loss: 1.1110 - val_accuracy: 0.6892 - val_rmse: 0.4636\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.11096 to 1.11011, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7061 - accuracy: 0.9933 - rmse: 0.1961 - val_loss: 1.1101 - val_accuracy: 0.6923 - val_rmse: 0.4636\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.11011 to 1.10949, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7063 - accuracy: 0.9967 - rmse: 0.1947 - val_loss: 1.1095 - val_accuracy: 0.6923 - val_rmse: 0.4637\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.10949 to 1.10848, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.7077 - accuracy: 0.9967 - rmse: 0.1929 - val_loss: 1.1085 - val_accuracy: 0.6892 - val_rmse: 0.4636\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.10848\n",
            "10/10 - 0s - loss: 0.6906 - accuracy: 0.9933 - rmse: 0.1889 - val_loss: 1.1087 - val_accuracy: 0.6892 - val_rmse: 0.4639\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.10848 to 1.10779, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 0s - loss: 0.6962 - accuracy: 0.9967 - rmse: 0.1904 - val_loss: 1.1078 - val_accuracy: 0.6892 - val_rmse: 0.4639\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.10779 to 1.10734, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.6868 - accuracy: 0.9967 - rmse: 0.1851 - val_loss: 1.1073 - val_accuracy: 0.6923 - val_rmse: 0.4640\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.10734\n",
            "10/10 - 0s - loss: 0.6745 - accuracy: 0.9967 - rmse: 0.1749 - val_loss: 1.1074 - val_accuracy: 0.6862 - val_rmse: 0.4642\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.10734 to 1.10645, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 0s - loss: 0.6752 - accuracy: 1.0000 - rmse: 0.1704 - val_loss: 1.1064 - val_accuracy: 0.6892 - val_rmse: 0.4641\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.10645 to 1.10566, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.6650 - accuracy: 1.0000 - rmse: 0.1603 - val_loss: 1.1057 - val_accuracy: 0.6892 - val_rmse: 0.4640\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.10566 to 1.10546, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.6693 - accuracy: 0.9967 - rmse: 0.1654 - val_loss: 1.1055 - val_accuracy: 0.6892 - val_rmse: 0.4642\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.10546\n",
            "10/10 - 0s - loss: 0.6671 - accuracy: 1.0000 - rmse: 0.1659 - val_loss: 1.1057 - val_accuracy: 0.6800 - val_rmse: 0.4646\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 1.10546 to 1.10493, saving model to /tmp/CNN_checkpoint24lxaconcmmt.h5\n",
            "10/10 - 1s - loss: 0.6566 - accuracy: 1.0000 - rmse: 0.1574 - val_loss: 1.1049 - val_accuracy: 0.6800 - val_rmse: 0.4645\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.10493\n",
            "10/10 - 0s - loss: 0.6570 - accuracy: 1.0000 - rmse: 0.1577 - val_loss: 1.1062 - val_accuracy: 0.6738 - val_rmse: 0.4652\n",
            "Classification accuracy: 0.840000 \n",
            "\n",
            "\n",
            "Beginning training for subject  25\n",
            "shape of x_test:  (1, 125001, 6)\n",
            "shape of all data originally:  (26, 125001, 6)\n",
            "shape of train_val_data after removing subject i:  (25, 125001, 6)\n",
            "i: 25, length of hc for this iteration: 14\n",
            "shape of x_train after removal of target:  (12, 125001, 6)\n",
            "shape of x_train:  (300, 5000, 6)\n",
            "shape of x_validate:  (325, 5000, 6)\n",
            "shape of x_test:  (25, 5000, 6)\n",
            "dropout rate:  0.55\n",
            "Model: \"model_818\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_819 (InputLayer)       [(None, 5000, 6)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1663 (Conv1D)         (None, 5000, 4)           96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1550 (Ba (None, 5000, 4)           16        \n",
            "_________________________________________________________________\n",
            "activation_1550 (Activation) (None, 5000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1664 (Conv1D)         (None, 5000, 6)           288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1551 (Ba (None, 5000, 6)           24        \n",
            "_________________________________________________________________\n",
            "activation_1551 (Activation) (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "dropout_896 (Dropout)        (None, 5000, 6)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 60002     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 60,426\n",
            "Trainable params: 60,406\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "MB::   Shape of X_train:  (300, 5000, 6)\n",
            "MB::   Shape of X_validate:  (325, 5000, 6)\n",
            "MB::   Shape of X_test:  (25, 5000, 6)\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23712, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.3022 - accuracy: 0.5100 - rmse: 0.5323 - val_loss: 1.2371 - val_accuracy: 0.5200 - val_rmse: 0.5040\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23712 to 1.23052, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.2561 - accuracy: 0.5067 - rmse: 0.5088 - val_loss: 1.2305 - val_accuracy: 0.5292 - val_rmse: 0.4960\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.23052 to 1.22472, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.2411 - accuracy: 0.5667 - rmse: 0.4985 - val_loss: 1.2247 - val_accuracy: 0.5508 - val_rmse: 0.4908\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.22472 to 1.21814, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.1974 - accuracy: 0.6333 - rmse: 0.4785 - val_loss: 1.2181 - val_accuracy: 0.5692 - val_rmse: 0.4863\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.21814 to 1.21037, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.1725 - accuracy: 0.6867 - rmse: 0.4662 - val_loss: 1.2104 - val_accuracy: 0.6062 - val_rmse: 0.4819\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.21037 to 1.20280, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.1426 - accuracy: 0.7033 - rmse: 0.4488 - val_loss: 1.2028 - val_accuracy: 0.6308 - val_rmse: 0.4782\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.20280 to 1.19501, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.1250 - accuracy: 0.7167 - rmse: 0.4404 - val_loss: 1.1950 - val_accuracy: 0.6462 - val_rmse: 0.4746\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.19501 to 1.18758, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.0986 - accuracy: 0.7300 - rmse: 0.4295 - val_loss: 1.1876 - val_accuracy: 0.6769 - val_rmse: 0.4715\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.18758 to 1.17961, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.0744 - accuracy: 0.7700 - rmse: 0.4209 - val_loss: 1.1796 - val_accuracy: 0.7015 - val_rmse: 0.4682\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.17961 to 1.17211, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.0594 - accuracy: 0.7867 - rmse: 0.4083 - val_loss: 1.1721 - val_accuracy: 0.7077 - val_rmse: 0.4651\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.17211 to 1.16498, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.0444 - accuracy: 0.7967 - rmse: 0.4017 - val_loss: 1.1650 - val_accuracy: 0.7138 - val_rmse: 0.4621\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.16498 to 1.15868, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 1.0283 - accuracy: 0.7833 - rmse: 0.3938 - val_loss: 1.1587 - val_accuracy: 0.7015 - val_rmse: 0.4595\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.15868 to 1.15312, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.9860 - accuracy: 0.8400 - rmse: 0.3729 - val_loss: 1.1531 - val_accuracy: 0.7077 - val_rmse: 0.4573\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.15312 to 1.14826, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.9835 - accuracy: 0.8200 - rmse: 0.3754 - val_loss: 1.1483 - val_accuracy: 0.7138 - val_rmse: 0.4553\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.14826 to 1.14386, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.9622 - accuracy: 0.8333 - rmse: 0.3623 - val_loss: 1.1439 - val_accuracy: 0.7138 - val_rmse: 0.4536\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.14386 to 1.14053, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.9476 - accuracy: 0.8433 - rmse: 0.3540 - val_loss: 1.1405 - val_accuracy: 0.7138 - val_rmse: 0.4524\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.14053 to 1.13733, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.9325 - accuracy: 0.8467 - rmse: 0.3433 - val_loss: 1.1373 - val_accuracy: 0.7077 - val_rmse: 0.4511\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.13733 to 1.13494, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.9192 - accuracy: 0.8600 - rmse: 0.3356 - val_loss: 1.1349 - val_accuracy: 0.6923 - val_rmse: 0.4503\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.13494 to 1.13345, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.8984 - accuracy: 0.8900 - rmse: 0.3259 - val_loss: 1.1334 - val_accuracy: 0.6862 - val_rmse: 0.4498\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.13345 to 1.13144, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.8888 - accuracy: 0.9067 - rmse: 0.3175 - val_loss: 1.1314 - val_accuracy: 0.6892 - val_rmse: 0.4491\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.13144 to 1.13060, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.8905 - accuracy: 0.8800 - rmse: 0.3186 - val_loss: 1.1306 - val_accuracy: 0.6831 - val_rmse: 0.4489\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.13060 to 1.12949, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.8714 - accuracy: 0.9000 - rmse: 0.3091 - val_loss: 1.1295 - val_accuracy: 0.6831 - val_rmse: 0.4487\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.12949 to 1.12931, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.8564 - accuracy: 0.9100 - rmse: 0.3003 - val_loss: 1.1293 - val_accuracy: 0.6800 - val_rmse: 0.4487\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.12931 to 1.12913, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.8498 - accuracy: 0.9133 - rmse: 0.2976 - val_loss: 1.1291 - val_accuracy: 0.6800 - val_rmse: 0.4488\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.12913 to 1.12880, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.8351 - accuracy: 0.9333 - rmse: 0.2887 - val_loss: 1.1288 - val_accuracy: 0.6677 - val_rmse: 0.4489\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.12880 to 1.12837, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.8306 - accuracy: 0.9367 - rmse: 0.2851 - val_loss: 1.1284 - val_accuracy: 0.6646 - val_rmse: 0.4490\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.12837 to 1.12835, saving model to /tmp/CNN_checkpoint25pukjdtlkib.h5\n",
            "10/10 - 1s - loss: 0.8152 - accuracy: 0.9267 - rmse: 0.2745 - val_loss: 1.1284 - val_accuracy: 0.6585 - val_rmse: 0.4494\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.8139 - accuracy: 0.9367 - rmse: 0.2744 - val_loss: 1.1291 - val_accuracy: 0.6554 - val_rmse: 0.4500\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.8065 - accuracy: 0.9667 - rmse: 0.2576 - val_loss: 1.1292 - val_accuracy: 0.6492 - val_rmse: 0.4504\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7879 - accuracy: 0.9567 - rmse: 0.2564 - val_loss: 1.1300 - val_accuracy: 0.6492 - val_rmse: 0.4509\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7848 - accuracy: 0.9633 - rmse: 0.2595 - val_loss: 1.1307 - val_accuracy: 0.6492 - val_rmse: 0.4515\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7781 - accuracy: 0.9567 - rmse: 0.2485 - val_loss: 1.1317 - val_accuracy: 0.6462 - val_rmse: 0.4521\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7643 - accuracy: 0.9567 - rmse: 0.2372 - val_loss: 1.1327 - val_accuracy: 0.6431 - val_rmse: 0.4529\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7549 - accuracy: 0.9567 - rmse: 0.2383 - val_loss: 1.1339 - val_accuracy: 0.6431 - val_rmse: 0.4536\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7445 - accuracy: 0.9667 - rmse: 0.2274 - val_loss: 1.1346 - val_accuracy: 0.6400 - val_rmse: 0.4543\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7382 - accuracy: 0.9800 - rmse: 0.2224 - val_loss: 1.1344 - val_accuracy: 0.6431 - val_rmse: 0.4548\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7400 - accuracy: 0.9800 - rmse: 0.2170 - val_loss: 1.1343 - val_accuracy: 0.6431 - val_rmse: 0.4552\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7368 - accuracy: 0.9700 - rmse: 0.2204 - val_loss: 1.1341 - val_accuracy: 0.6400 - val_rmse: 0.4556\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7163 - accuracy: 0.9900 - rmse: 0.2078 - val_loss: 1.1348 - val_accuracy: 0.6369 - val_rmse: 0.4562\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7183 - accuracy: 0.9800 - rmse: 0.2097 - val_loss: 1.1359 - val_accuracy: 0.6369 - val_rmse: 0.4569\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7067 - accuracy: 0.9900 - rmse: 0.1900 - val_loss: 1.1364 - val_accuracy: 0.6369 - val_rmse: 0.4574\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7086 - accuracy: 0.9767 - rmse: 0.2041 - val_loss: 1.1383 - val_accuracy: 0.6369 - val_rmse: 0.4583\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.7071 - accuracy: 0.9933 - rmse: 0.1964 - val_loss: 1.1393 - val_accuracy: 0.6308 - val_rmse: 0.4591\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.6885 - accuracy: 0.9933 - rmse: 0.1758 - val_loss: 1.1391 - val_accuracy: 0.6308 - val_rmse: 0.4593\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.6894 - accuracy: 0.9933 - rmse: 0.1828 - val_loss: 1.1388 - val_accuracy: 0.6277 - val_rmse: 0.4594\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.6920 - accuracy: 0.9833 - rmse: 0.1875 - val_loss: 1.1391 - val_accuracy: 0.6277 - val_rmse: 0.4598\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.6884 - accuracy: 0.9867 - rmse: 0.1789 - val_loss: 1.1393 - val_accuracy: 0.6277 - val_rmse: 0.4602\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.6769 - accuracy: 0.9900 - rmse: 0.1688 - val_loss: 1.1397 - val_accuracy: 0.6338 - val_rmse: 0.4606\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.6725 - accuracy: 0.9900 - rmse: 0.1673 - val_loss: 1.1411 - val_accuracy: 0.6308 - val_rmse: 0.4613\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.12835\n",
            "10/10 - 0s - loss: 0.6750 - accuracy: 0.9933 - rmse: 0.1691 - val_loss: 1.1424 - val_accuracy: 0.6277 - val_rmse: 0.4619\n",
            "Classification accuracy: 1.000000 \n",
            "CPU times: user 8min 29s, sys: 1min 1s, total: 9min 30s\n",
            "Wall time: 7min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzxgvsBZ9qj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGulD6pdT2is",
        "colab_type": "code",
        "outputId": "ca74876e-9340-4951-f533-aaf402fcb9d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def print_model_metrics_loo(history_list, acc_key):\n",
        "    print('Diagrammed History of Model Metrics')\n",
        "\n",
        "    # summarize history for accuracy\n",
        "    for h in history_list:\n",
        "        plt.plot(h.history[acc_key], color='black')\n",
        "        plt.plot(h.history['val_' + acc_key], color='blue')\n",
        "    plt.title('Accuracy of all Models over Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # summarize history for RMSE\n",
        "    for h in history_list:\n",
        "        plt.plot(h.history['rmse'], color='black')\n",
        "        plt.plot(h.history['val_rmse'], color='blue')\n",
        "    plt.title('Root Mean Square Error of all Models over Epochs')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # summarize loss history\n",
        "    for h in history_list:\n",
        "        plt.plot(h.history['loss'], color='black')\n",
        "        plt.plot(h.history['val_loss'], color='blue')\n",
        "    plt.title('All model Losses over Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "print('\\nMean test accuracy: ', '{0:.2f}'.format(np.mean(test_acc_list)) )\n",
        "print('\\nTest accuracy for individual runs: ')\n",
        "print(test_acc_list)\n",
        "print('\\n')\n",
        "\n",
        "print_model_metrics_loo(history_list,     acc_key )"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean test accuracy:  0.67\n",
            "\n",
            "Test accuracy for individual runs: \n",
            "[0.48, 0.96, 0.96, 0.96, 0.52, 0.92, 0.88, 0.96, 0.24, 0.96, 0.84, 1.0, 1.0, 1.0, 0.08, 0.08, 0.24, 0.68, 0.92, 0.0, 0.48, 0.2, 0.16, 0.96, 0.84, 1.0]\n",
            "\n",
            "\n",
            "Diagrammed History of Model Metrics\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOxdd3gUxfv/zJXkLpeeQHoB0oNJqKEEQxMpAgLSRboggsJPv6JSpARBBSlfQEQEvgI2bHQFFERFqgKKVOkQlGaAhJr7/P642/E2d5dAFBDZz/PMc3s7szOzs7vvO/O2ESShQYMGDRruXejudAc0aNCgQcOdhcYINGjQoOEeh8YINGjQoOEeh8YINGjQoOEeh8YINGjQoOEeh8YINGjQoOEeh8YINNx1EELUFkLsE0JcFEI8fJPXdhNCfOvwn0KIuL+/l8X24YbaFELUFUIcux19ulshhIi1j6fhTvflbobGCO5CCCHWCiHOCSE873Rf7hBGAZhK0pvkZ7eqEfs4UwiRXuT8p/bzdW9V23cr7OOSb2fSSnruTvdLQ/HQGMFdBiFELIA6AAigxW1u+58y64oBsPM2tbUXwGPKHyFEEICaAE7dpvb/kSjhXUi3M2klvXrbOqahVNAYwd2HxwBsADAXQFfHDCFElBDiEyHEKSHEGSHEVIe83kKIXUKIC0KIX4QQle3nVWIKIcRcIUSO/biuEOKYEGKwEOIkgDlCiAAhxFJ7G+fsx5EO1wcKIeYIIU7Y8z+zn/9ZCNHcoZxRCHFaCFHJ1U3a+7tfCHFWCLFYCBFuP/8rgPIAlthnm06rIiHE80KIXx3utdVNj/KfWACgvRBCb//fEcCnAK46tOcphJhkv+cT9mNPh/z/CCFy7Xk9ivTVUwgxXghxRAjxmxBihhDC7GZMBgshjtvva48QooGbcn5CiHfsz+iwEGKoEEJnb+sPIURFh7JlhBCXhBBl7f8fEkJss5dbL4RIcyh7yN6HHQDyb3ZiIIQYIYT4SAjxgf0efnBcbQkhku2rsD+EEDuFEC0c8sxCiAn2+8kTQnxbZJw628fwtBBiiMN11YUQW4QQ5+3j+/rN9PmeAUkt3UUJwH4A/QBUAXANQIj9vB7AdgATAVgAmABk2fPaAjgOoBoAASAOQIw9jwDiHOqfCyDHflwXwHUArwDwBGAGEASgDQAvAD4AFgL4zOH6ZQA+ABAAwAgg237+OQAfOJRrCeAnN/dYH8BpAJXt7f4XwDqH/EMAGhYzRm0BhMM20WkPIB9AmD2vG4BvHcqq7r9IPWsB9AKwEkAT+7lNsK0IjgGoaz83CjbmXBZAGQDrAYy25zUG8BuAivbn8q5jm/bntRhAoH08lwAY6zD+x+zHiQCOAgi3/48FUMFNv98BsMheXyxsq5qe9rzZAMY4lH0SwOf240oAfgeQCdv71NU+1p4O474NQBQAs5u2ixvPEbC9s4/Y341nARy0Hxthe7dfBOBhfwcuAEi0XzvN/jwi7H2rZX83Yu1tvgXb+5kO4AqAZPt13wPoYj/2BlDjTn/D/8R0xzugpZt4WECW/UMKtv/fDWCQ/VgRVxhcXPcFgKfd1FkSI7gKwFRMnzIAnLMfhwGwAghwUS7c/mH72v9/BOA5N3W+DeBVh//e9vuOtf8/hGIYgYv6tgFoaT/uhptnBI8CeA9AEoC99jxHRvArgKYO1z0I4JD9eDaAcQ55CUqbsDHlfDgQdPtzPOgw/gojiIONSDcEYCzmXvX2Z5bicK4PgLX244YAfnXI+w7AY/bjN2BnYA75e/AnMz8EoEcJY00A5wH84ZAetOeNALDBoawOQC5sos46AE4C0Dnkv2e/RgfgEmwip6LtxdrbjHQ4twlAB/vxOgAjYf9mtOQ6aaKhuwtdAawkedr+/138KR6KAnCY5HUX10XBRqxKg1MkLyt/hBBeQog37Uv087B9aP520UkUgLMkzxWthOQJ2IhOGyGEP4AmsIldXCEcwGGHay8COAPbbLBECCEecxBv/AHbbDz4Rq51g09gm6H2BzCvpP7aj8Md8o4WyVNQBraV1VaHvn5uP68Cyf0ABsJGGH8XQryviMuKIBi22XXR/ihjtwaAlxAiU9j0TRmwiboAm+7lGaUv9v5EOdwLityLO1Qm6e+QvnB1PUkrbAw13J6O2s8V7XcwbCvc4t7hkw7HBbBNHgCgJ2zMd7cQYrMQ4qEb6P89h3+K8k9DCbDLQ9sB0Nvl9YBtaexvl7MeBRAthDC4YAZHAVRwU3UBbMRIQShsH6eCouFpn4FNTJFJ8qQQIgPAj7DNbo8CCBRC+JP8w0Vb/4Nthm0A8D3J4276dAI2ogQAEEJYYBNJuSsPh7IxsIkJGtjbKBRCbLP3r1QgWSCEWAHgCbgeR6W/igI72n4OsM14oxzKRjscn4ZtpptazFg49uNdAO8KIXwBvAmbyK5LkWKnYVs9xQD4xaHN4/Y6CoUQH8Km6/gNwFKSF+zljsImNhpTXDdK6mcJkGMhhNABiMSfYxUlhNA5MINo2MRapwFchm3st99MYyT3Aehob6s1gI+EEEEk8//abfy7oK0I7h48DKAQQApss7gMAMkAvoFNgbwJNqIzTghhEUKYhBC17dfOAvCsEKKKsCHOTjABm9ikkxBCL4RoDCC7hH74wEa8/hBCBAJ4SckgmQtgBYDpwqZUNgoh7ne49jPY5P5PwybHdof3AHQXQmTYla4vA9hI8lAJfQNscnjCbtUjhOgO24rgr+JF2EQkrvrwHoChdsVrMIDhAObb8z4E0E0IkSKE8IJ6vKywMa2JDsraCCHEg0UbEEIkCiHq28fjMmzPwFq0HMlCe5tjhBA+9uf8fw79AWwryfYAOtuPFbwFoK99tSDs71EzIYRPycNzw6gihGhtVzQPhE2evwHARtgmJc/Z35u6AJoDeN8+TrMBvC6ECLe/qzXFDZhPCyEeFUKUsdehTE6cxu1eh8YI7h50BTCH5BGSJ5UEYCpsH7SA7cOJA3AEtll9ewAguRDAGNg++guwEeRAe71P26/7w15PSXb5k2BTyp2G7QP+vEh+F9hmpLthk2kPVDJIXgLwMYBysIlbXILkagDD7GVzYZsJdiihX8q1vwCYAJuS8DcA98EmkvpLIHmC5LdusnMAbAGwA8BPAH6wnwPJFbCN2VewKUO/KnLtYPv5DXZR22rYVlxF4QlgHGzjfhI2xfQLbvozADbdwwEA38L23Gc73MtGe344bIxbOb8FQG/Y3qlz9n51c9NGcdgu1H4EkxzyFsH2Xp6D7V1pTfIayauwvYdN7Pc4HTbdxW77dc/CNrabAZyFbTV0I/SrMYCdQoiLACbDpju4VIp7+ldD2BUqGjTcFgghhgNIIPnone6LhtsLIcQI2BTz2rP/h0HTEWi4bbCLknrCWa6tQYOGOwhNNKThtkAI0Rs2ZeQKkuvudH80aNDwJzTRkAYNGjTc49BWBBo0aNBwj+Ou0xEEBwczNjb2TndDgwYNGu4qbN269TRJJ2dF4C5kBLGxsdiyZcud7oYGDRo03FUQQhx2l6eJhjRo0KDhHofGCDRo0KDhHofGCDRo0KDhHsddpyNwhWvXruHYsWO4fPlyyYU13BBMJhMiIyNhNBrvdFc0aNBwi/GvYATHjh2Dj48PYmNjIUSpg0xqsIMkzpw5g2PHjqFcuXJ3ujsaNGi4xbhloiEhxGwhxO9CiJ/d5AshxBRh245wh7BvnVgaXL58GUFBQRoT+JsghEBQUJC2wtKg4R7BrdQRzIUt8p87NAEQb0+Pw7Y7UqmhMYG/F9p4atBw7+CWiYZIrrPvgOQOLQG8Q1uMiw1CCH8hRJg9pr0GDf86kMQHH3yAtLQ0pKSk3OnulIhff/0VixYtQnx8PNLS0hAdHf23TRDOnz+Pn376CTt27IC3tzc6dOgg9VGFhYX4+uuvsW7dOlit6q0DLl68iJ07dyIuLg6NGjXCAw88AC8vL1dN4PTp09ixYwfeffddmEwmtG3bFmlpaQgICHBZ/uLFi1i+fDm++uor7N69W7ZttVqRl5eHc+fO4eLFi9Dr9fDw8IDBYFCNh7+/P6Kjo5GQkABvb2+XbRQUFGD37t3YuXMn/vjjDxiNRhiNRuj1+mLHy2q14sKFC+jatSumTJlSbNnS4JbGGrIzgqUknTYGEUIshW0v12/t/78EMNgeE71o2cdhWzUgOjq6yuHDar+IXbt2ITk5+W/v/43izJkzaNCgAQDg5MmT0Ov1KFPG5sC3adMmeHh4uL12y5YteOedd27Jw/2ruNPj+m/DuHHj8MILL8DX1xefffYZ6tWrV+q6rly5grVr16Jhw4YlEpHSYOPGjWjSpAnOnftz11E/Pz+kpaUhLS0NlSpVQvPmzVG2bNli6yksLMSePXvw3nvvYf/+/Th79iz27t2LQ4cOqcolJCSgb9++yM3Nxbx583Dy5EnXFbqA2WxGWFgYkpOTUVhYiGPHjuHo0aPIy8tzWd7LywsBAQEIDAwESeTm5iIvLw/Xr7va5fWfhfDwcBw/XuJmdi4hhNhKsqrLzFu5ITJsG0v/7CZvKYAsh/9fAqhaUp1VqlRhUfzyyy9O5+4UXnrpJb722muqc9euXbtDvflr+CeN692OmTNnEgDbtGnD1NRUenh48MMPPyx1fU888QQB8JFHHuGlS5fk+evXr3Pz5s08ePAgrVZrqepevnw5PT09qdfrCYDh4eFs2bIlH3roIaamptJsNhMAdTodmzZtynfffZf5+fk8e/Ys165dyylTprBnz55MTU2lwWAgbDvGyWQ0GhkbG8vGjRuzS5curF69umzrZpOHhweNRmOprr2RpNfr3dZvMpkYHBxMb29veS48PJyxsbH09fWlTqdzeZ0QotT9eeSRR0r9zgDYQne02l3G35FKYARvAujo8H8PgLCS6rxbGEHXrl3Zp08fVq9enYMGDeLGjRtZo0YNZmRksGbNmty9ezdJcs2aNWzWrJm8tnv37szOzma5cuU4efLkO3kr/6hxvZuxcOFC6nQ6NmnShFevXuXZs2eZlZVFIQT/+9//3nR9K1asIADWqFGDAFi3bl1+8803fPbZZxkeHi6Jhq+vL2vXrs1+/fpxxowZXL9+PS9fvuxU36VLl7hu3TpOnTqVdevWvWGiFBISQovF4pK4KYRdr9ezatWqfO6559i2bVsmJCTQYrG4JIZGo9EtkdTr9SqmUqZMGQKgxWJheHi4iuiaTCaZ17dvXy5YsIArV67kxIkTGRAQQA8PDz7++OOMiooqNUH+K8T8ryRvb+9Sv4fFMYI7aT66GEB/IcT7ADIB5PFv0A8MHDgQ27Zt+8udc0RGRgYmTZpUcsEiOHbsGNavXw+9Xo/z58/jm2++gcFgwOrVq/Hiiy/i448/drpm9+7dWLNmDS5cuIDExEQ88cQTmi3/XYxVq1ahU6dOqFmzJj766CMYjUYEBARg5cqV6NixIwYMGIDc3Fzk5OQAcK2kv3r1qjw+c+YMevTogZSUFLzzzjsYPnw4PvjgA9SpUwd6vR7NmjVD27ZtkZ+fj+3bt2PHjh2YN28eLlyw7U/v5+eH9u3bo0uXLqhVqxY2b96MTp064cCBA6o29Xo9rFarMklzid9++w0AEBoaCovFgmPHjuHKlSsAgNq1a6NLly5o0qQJBg8ejFdffbXEsbp27RoiIiIQEhKCH374wak/juNw6tQpGAwGXLt2DSdOnIDFYsGlS5dgNpuRn5+PxMREREZGYvHixZgxYwYAICoqClWrVsUvv/yCmTNnyvHW6XQoLCyU7QCQ/4UQLseguHG5lahUqdItqfeWMQIhxHsA6gIIFkIcg23TbiMAkJwBYDmAprDti1oAoPut6sudQtu2beWLlZeXh65du2Lfvn0QQuDatWsur2nWrBk8PT3h6emJsmXL4rfffkNkZOTt7LaGvwmbNm1Cq1atkJSUhCVLlqiUmmazGR999BH69euHl19+GTNnzkTlypUxbtw4/Pzzz5KI79ixQxJcR+Tm5iIhIQEAkJycjAMHDqBs2bJ47bXX5HnARrC+//57jBs3DsuWLcP58+fx1ltvYebMmfDy8sKlS5cQEhKCevXqYc2aNfK6wsJCGI1GCCEQFRUFADh69KiKGDdu3BiHDx/Grl278Oyzz2Lo0KHYsGEDkpKSEB4ejrfffhsVK1bEH3/8AUcIIRAaGoro6GhERkbi22+/RV5eHmrVqoU1a9bgxIkTTvertJuYmIiKFStixYoVKCgokPn5+fmq3z179uDSpUuoXLky+vfvj8LCQqxfvx7r169X6Q5ISqKv3Lcj7hTBd4dboQ8CcGtFQ7ci3U2ioYULF8rzXbt2laKegwcPMiYmhqSzaMhRv5CamsqDBw/etr4XxT9pXG8nTp8+za+++oqTJk1ijx49WLVqVdarV0+K824EO3fuZGBgIMuXL88TJ06QJE+dOsX69evzpZdeotVqpdVq5cyZM13KoE0mE6tUqcLu3btz9OjRHDNmDNu1a0cAzMjIYGhoKPV6PcPDw9mlSxeOHDmSAQEBDA4O5saNG7l3714OHz6c5cuXl3V6enoyJCSkRPGDxWLhY489RgCMiYkhAEZGRnLWrFnct28fZ8+eTV9fXwJgjx492KdPHwJglSpVuGfPHn700UdMSEhwKd7x9vbm/PnzSZK7d+9mUlISjUajFCUVJ3IRQjA6OpoxMTEsV66cPF+lShV26dKFFovFpU7ibk5Fx6NBgwalfq9xp3QEtyLdrYzg4Ycf5kcffSTLaIzgn4MrV67ws88+Y9u2bRkREaH68MqUKcMGDRowKCiIXl5enDVrVrFKWKvVysWLFzM8PJyhoaH89ddfSZLnz59ntWrV5IfdqVMntm7dmgDYsGFDzpgxgwkJCTQYDFy0aJGTgcGqVatUClwAbpWYjsSjfPnyNBqNjIqKYrt27di7d2/6+/vTaDTSx8dHdZ1Op+OQIUO4detW+vj4sGrVqrx06RLXrFnD6tWrEwArVqzImTNnslGjRlJp/MADD7Bv376q/rhT/iYmJhIAk5KSZD89PT1viAjeSLJYLAwODpZ6guKSXq+/qTYMBkOJfXZMXl5eUrfh5+cn9Rg6nc5JkVyrVi2Gh4czKCiI3bt3V42v43j279+/1O+5xghuI9wxgvXr1zM+Pp4ZGRkcMmSIxgjuMKxWK9evX88nnniCgYGBkug/+uijfO2117hy5UqePHlSlj927Bjr169PAGzbti3Pnj3rVOf69etZp04dAmBCQgK3b98ur61cuTKFECxXrhxjY2MlocvJyWFhYSFJ8vfff2fZsmWZnp7Oy5cv8/jx4xw/fjzT0tJURKNChQr08fGRxKRChQqSwCqE5kYJnDJLL1euHI8dO8YzZ86wfPny9PHxYbNmzVihQgWmp6fz/vvvZ9WqVaVy+GaTl5eXSwIfHx/PPn360MPDw+kaZdVhNBpZpUqVEpnFjdyzl5eXvAedTsfAwEDVdWXLlr2h+zEajSprIVdtl4aRRUdHs1u3bjx37hytVitzcnJUTO3hhx8u9TuvMQINpcLdPK75+fkcN24cn3vuOaf01FNPsUKFCgRAs9nMjh07ctmyZbx69apTPVarlZ9//jnnzZvH69evc+zYsTQYDIyOjuY333xD0ibiUGb3gYGB7N69O5955hk2btyYoaGhxX74FSpUUDH7999/nwAYGxsrCYlCJENDQzlnzhy52tizZw9nzJgh23jwwQcls3JnuqikhIQEbtiwgWvXrpXilOjoaCfiVdJ/x3ZupSWNXq9n165d+eKLLzIyMpLR0dFOKxpXyWQyMSgoyCXRdrSw0ul0fOWVV0pcSdSqVcvleQ8PD0ZHR/OJJ57gmDFjWKlSpWLrEUJQCKFalYSGhkpRXnBwMIOCgpyua9OmTam/CY0RaCgV7uZxVeTWJpPJKZnNZjZs2JBz585lXl6e2zo2bdqkMqecMGECSXLjxo2sUKEChRBMTk6mEII6nU4lDjEYDAwMDHSSWQshmJmZyYCAANW5Fi1asGPHjipxgHKtEILp6ek8fvw44+Pj6e/vz6VLl3LBggXMzc3lxYsXOXToUKdZtYeHBy0WC81ms8uZc1Exk3Le39+fANisWTPOnDmTK1eu5PLlyzlo0CBJwG6WkAshVMS4JOIdExNDg8HA+++/n3FxcS4ZAwAGBAS47JPZbFatQhxTcHCw1H0oKT4+3iVTK8m/oWrVqhw7diynTZvGRYsW8eDBgzx+/Lhq5eTt7a2qp1KlSpw8eTKfeeaZYlcggYGBfPjhh9m/f3/279+fbdu25aefflrqb0JjBBpKhbt1XJctW0YAfOaZZ0p1/b59+9i2bVsCNnHRf//7X/l/7ty5JMlz585JEY/RaGRwcDD9/PxcftC+vr4cPnw4N23axE2bNvHcuXO8evUqp02bpiKO7pyX/P39uXv3bt533300Go2sWLGiaiabkpKialsIwRo1ajgxoaSkJJdENS4ujj169HAigkWT0WiUxPJGZPDFrUq8vb1drkCU9uvXr8/69eu7nBUXl8xmM+vUqaOS4SvjUKNGDb7wwgt89NFHZd+8vLyYkpLitt8xMTEcP348+/fv71J89Xenkpzj7kqHsluRNEZw+3A3juupU6cYGhrKihUrqjxuHXH69GmX3t779+9nnz59aDAYaLFYOHz4cJ4/f54XLlzgJ598wsTERAohGBcXpyI0QggGBASwTJkyTgSyWbNmtFqtvHLlCp999lkCYEREBNesWUOSvHDhghMRjoyMZFZWlltiEBIS4lIsoqxMOnfuTKPRyMTERDnzVRiOp6cnQ0NDiyXS4eHhzMnJkczFaDTeNEEuyoC6detGT09Pent7q1ZDSlJ0HO5m8SUxHMf7UY49PT1VK6yijOHvIuxms5lPPvkkmzdvftOrJYPBwOHDh/PEiRMcMmSIU5+U+ry9vdm7d2+V3upmoTECDaXC3TauVquVbdq0odFo5I8//iiVsI7Yv38/LRYLExIS+NFHH9FqtTI3N1clAurTpw9zc3N5/fp1zpw502l2qdPpGBYWpiI+3t7erF69Olu1aiVnmA8//DDPnTvHH374QcqMO3XqxJiYGAohWL16ddarV++GLFDcpdDQUDZq1EhlJqoQQ4UJVKhQgRcuXODx48eZl5fH/fv3U6fT0Wg0slmzZvKaZ599llOnTiXwp6L2RpWnRcVixTEaX19flyIXIYQk3EVFWTdKtJWxvFExVNHrHnroIa5evZpz5szh1KlT2bNnT1mX0iej0SjNV2/EXNVsNnPKlCnctGkT27dvTwAMCgqiTqfjqlWruGrVKlauXJkAmJaWxtdee42TJ0+WkwHHVUKLFi1K/X1ojEBDqXC3jes777xDABwzZgxHjhxJDw8PRkREsGnTpnz++ee5YMEC1qhRg0IIaSkUFBSk+sAB8KWXXuLixYuZmpqq+phTU1N5+PDhvxSawB0BAmz28K5msIBNru3qfHZ2Nhs0aCDvITExUWVBBNhm5GPHjuWRI0dIko8//rjMGz58ONevX8/PP/+cpE0v8lcY040ko9HIyMhIAjYRkyOhi4qKore3N728vNi1a1c+9thjLi2V0tPTS2QQCnNUfC5K6leLFi04fvx4ZmZmuu33Qw89xGbNmkkG4Ofnx6ZNm8oyERERfOaZZwiATz31FBcuXChNiEny6tWrvP/++2kymThu3Dg2atSIgE0ENW/ePNXkxWq18sEHH6TZbObq1av5zDPPcOvWraX+PjRGoKFU+KeM65UrV9i9e3dmZmby888/d2nHf/jwYfr6+rJq1apyJtWqVSt26dKFaWlpLmWvjrNOV7LzsLAwAuDjjz/O5cuXUwjBNm3aOIl/9Hq9TOnp6U5Ep0KFChw6dCjHjx/P8ePH88MPP+Tu3bs5ffp0WUaZQSvXuiJwJpOJvr6+Tnl6vZ4eHh5MS0vjxYsXuWDBApk3YMAAlaWLMg4mk0nW4+HhQQ8Pj2IZgDtC6uHhoZoVO1riAJCMrWnTppw6dSr79u0rLbbcJbPZzPj4eIaEhKjqfvfdd7ly5UqOHDlSxexCQ0Pdyta9vb3p7e3tpAcoOq6ODDgyMpLdunWT42MwGPjUU0/x999/l+/b77//ztq1a6tWPh4eHly3bh1r167NmJgYt8EmT548Kf1VAgMD+frrr7uMAUWSx48fZ0BAADMzM/9y8EqNEdxi1K1bV86oFEycOJF9+/Z1WT47O5ubN28mSTZp0oTnzp1zKuMqimlRfPrpp9y5c6f8P2zYMK5atepmu+8Wd3pcSZsjVsOGDVXEMSkpiXPnzmV+fj6XLFnC9u3by1mWr68vvb29OW/ePFnHuXPnuGjRInp7ezvJcBs2bMgxY8Y4LfF9fHxoNptZo0YN+ZEOHDjQLTFRZPuunJS6deum0ldcvHiR8+bNcykrL0nGrBD9ksrqdDoGBAQwMjJSBqdztITp3bs3H3/8cSem4mj9VLR+ZVXSpEkTuaIym83s1KkTFy1aJGe3oaGhbNy4sSR0xd3PjabQ0FCOGTOGhw4dImkjkE899ZTquRW13HLFxIQQHDx4MGvXrn1D4/3QQw+pZvSO+O677wjYVgEGg4Emk0m2lZOTU+x7vWPHDr766qsuv/2iUEyKR40aVWLZ4qAxgluMN998k926dVOdy8zM5Ndff+2yvCMjcIcbYQRFndb+btzpcT158iSrVKkiHaSio6NLlBX7+/uzYcOGbNmyJR988EFGR0e7LOfh4SEVrtOmTXNZxmAwcNeuXZw0aRK7dOniRNQsFgu9vLxYrVo1OSNVCEHNmjU5c+ZMlax9zpw5HDhwoJNCtEaNGhw1ahSHDx/OM2fOsHLlyrIenU7H0NBQaQJakkOXwWBgeHi4SsZsMBic2tTpdE4zcw8PD6lXUJiUh4cHy5YtK9t96aWXWL16dXp4eLB37948fvy4fF4XL17kwIEDuXnzZl67do0PPPCAE0G2WCwMDAxk2bJlGRISUuxKQ5ltlytXTjrqAWBqaqrMUyypYmNjWb58ebeiNcAmxtm2bRtJm9hl/vz57N+/P7/88ksWFBRw+/bt/N///seWLVsyJSWFX3zxRbHvZzIA/00AACAASURBVEFBgWxvyZIlzM3NlZZkFouFI0aM4Pnz5/+Wb6FTp040GAzcsmVLqevQGMEtxpkzZ1imTBleuXKFpC2WUFRUFPv27csqVaowJSWFw4cPl+UdGUFMTAxPnTpFkszJyWF8fDxr167NDh06SEYwc+ZMVq1alWlpaWzdujXz8/P53XffMSAggLGxsUxPT+f+/ftVjGH16tXMyMhgxYoV2b17dzmrjYmJ4fDhw1mpUiVWrFiRu3btcntfd3Jc9+/fzwoVKtBsNjMsLIzBwcHs06cPBwwYwI4dOzqFggBspp5paWlMT09neno6K1euzI4dO3LAgAEUQkhRT0JCgpzdK4pbhTi+9tprToTV3QxTp9Nxw4YNzM3NlTJvwOZ5rOC3336TKwVHIqz8xsfH88qVK1y1ahXbtGnjpAswmUyquh1TcHCwS4c1VwpX5X+jRo1ueJbu6+vLvn37ymtnzJjBESNGqOpWHPKWLl3KzZs3Mycnh8uWLePgwYNpMplkufvvv1+K9K5fv84xY8aoxCp+fn586aWXpM/CpEmT6O3tLRlp8+bNuWXLFubk5LBu3bocMmQIFy5cyKeeekoqc81ms2RYkZGRXLt2LceOHUuTycTAwEDm5+f/be/ntWvX2KpVK9n/Q4cO8ZdffiEAPvnkk2zTpo2cAAwdOpSffPIJ9+/f79KA4UZw9uxZJicnyzA1pcE9xQiefprMzv5709NPlzzIzZo142effUaSHDt2LJ955hmeOXOGpO3Fz87OliEHXDGCLVu2sGLFiszPz2deXh4rVKggGcHp06dlO0OGDOGUKVNIOq8IlP+XLl1iZGQk9+zZQ5Ls0qULJ06cKNtTrp82bRp79uzp9p7+KiO4fPkyFyxYcFOyzRUrVvB///sfy5Yty8DAQLmEB2zyXn9/f/r6+konIseNSV5//XWn+q5fv85q1aq5VLYWlSvXrVuXo0aNckkUXYkQIiIiePLkSaalpdFisUgLmypVqvDChQuyD4cOHWJ4eDj1ej11Oh19fHzkyubrr79mQUGBXF041t+lSxdJOM6dO8d+/frJvAoVKhS7OjAYDMXK/B31HO7EI/Xq1ZMmqZ9++ik//PBDOW6PPPII582bxy5durg1+axXrx69vb1pNptpMpmYk5PDnj17qkxfY2Nj2bZtW5crvbi4OB46dIiTJk2ih4cHw8LCOH/+fObk5DApKYmAbeXQvHlzVZC79PR0Of6rV6+WDKdLly7FOhDeKKxWK3v27EnApmwHwNGjR7NHjx40m81Sl/D999/LMXR8h2vWrMk+ffrw1Vdf5YQJE5zSjBkz+Mcffzi1q+kI7gJGMH/+fHbo0IEkmZ6ezi1btvCNN95gpUqVeN999zE4OJjvvfceSdeMYOLEiRw2bJisb9CgQZIRrF27lllZWaxYsSJjY2PZp08fku4ZwbZt21inTh15fvXq1WzVqpVs79ixYyTJDRs2FBvN8K8yAmV2fSMb7Jw/f15GvARs1jSK1Yevr6+0qDh8+DAjIyMZEhLCffv2MT8/n2vWrGHdunUZEhLiNOtTFLKKMtjT05PLli3jl19+yc6dO6s+0qJiClcmkI4zYWUmazQa2aJFCwLgyJEjqdPp+MADD3DHjh0ybMWMGTOc6qpbty4/+ugjp81gAgICmJCQ4HQviqxfp9Nx27Zt/OKLL2g0GtmoUSP+5z//cfIgdpUc70lZaQghnJiGI7Fu3rw5k5OTi63XXfLw8OCCBQvciugUxpKSkiJXeZmZmfzpp5/kCuLs2bMcOnSoSuwTHR3N9PR0Jwuu++67T475oUOHGBQUxJSUFA4bNow6nY7ly5fnxo0bi30XT506xRUrVridwT/33HMEIL/X7OxsRkZG0mg08sknn3Qqf/HiRW7cuJFvvfUWBwwYwPvvv196b7tLQUFBnDhxolslcmlwTzGCO4ULFy6wTJky3Lp1K+Pj43ngwAFWqFBBBifr2rUr58yZQ/LmGUFsbKyUbc6ZM4ddu3aVdZaGESiiqM2bNzM7O9vtPf2Vcb1y5Yq0IAkMDCxWKbZw4UKV4tSRKJnNZim++v3335mYmChlvYWFhXzooYckswBsVjIKAfnpp5/o4+OjWg388MMPPHXqlPzAFeLjSEDT09OZlJTkdkat1+tpMpno5eVFIQSHDBlCABw4cCBJNdE3Go1MS0tz63XsLinbWBYUFHDHjh2cN28eAdsqpEyZMiqR0M8//0yS/PHHH2k2m5mYmEiDwcDU1FR27txZPgNXxOfNN99kfHy8y/45OpQp59wFf9PpdKxZsyYnTpzI7t27F+t5HB8fz19//ZV5eXnMy8uThNtqtXLy5Mly9p+Tk8PWrVvL1UJiYiKrVasmn0FKSgo7dOjAl19+mUuXLuXhw4flO1VQUMDKlSvT19dXroy//fZbRkdH02AwcOzYsSoiX1BQwA8++IDNmzdXiQMtFgtr1KjBxx9/nFOnTuULL7xAAOzXr598z2bPni3HwJ1iuSisVqu8/6Jp06ZN0kAiNjaW8+fPL7VIyREaI7hNaNeuHdPT0zl8+HBu27aNaWlpLCws5MmTJ6WykHTNCLZu3cr77ruPBQUFPH/+POPi4iQjCAoK4m+//carV6+yYcOGkhH079+fs2fPlu07ioaioqK4b98+eX7SpEmq9shbywiUj2PcuHEUQvC5555T5f/888/s16+fijg5eoTGxcVJKxAvLy8OGTKEVapUoclk4rp160jaFOrKtdWrV1cpFx0dpZTzjz32GA8cOEAvLy82b96cn3/+uRORioiI4OzZsyVj6tixoyp8tMI0+vfvL0VBer2egYGBfPDBB508cM1mc6li5BuNRr799ttSoauIwjZs2CCZgpIUsR9JmVe3bl3++OOP0ut248aNXLZsGfV6vYrBeXl58a233nJpXimEkApff39/li1bVt5Lo0aNeOzYMbZs2ZKATdeibB+ppJCQEFasWFHFFP7zn/+U+O58//33Uu6v1+tZu3ZtLl26VBLe48ePu/UaJ21Etlu3bgTARYsWqfLOnTsn93WoX78+lyxZwh49esiJRHh4OJ999lmuWrWKs2bN4lNPPcXs7GzVRKVDhw4qwnz+/Hl6e3tLicDfhZUrV0pHxIyMjBKV1yVBYwS3CZ9++ikByBls165dGR8fz/r167NVq1bFMgJSrSzu2LGjZATTp09nbGwsq1Wrxv79+0tG8O233zI5OZkZGRk3pSy+1YygsLCQycnJTE9Plx+lp6cnDx48yNOnT/Phhx92IjiKrFhRfgPg2LFjuX//fumNqdfruXTpUpLkkiVLJKFV6lHs5YvO5A0GAw0GA/Py8tihQweXhFkJK6HUFxMTw4SEBKakpPDEiROSwBsMBpUDkatUrlw5tmjRwu2KIikpSeWsBthEAY42/u7qFkKoZPLKbLlZs2Yqs85GjRpJ4v7KK6/wxx9/ZEhICMPCwmg0GpmVleUkVtHpdHz11Vdl+8pKSrHYUURnGRkZ8llbrVa+8cYbNJlMLFu2LB9//HHqdDq2bt1aEm6r1colS5bIlUtxOH36tHT669ixo0pHlJ2dzVmzZrmUnztCsQJzNNBwhNVq5ezZs6WOxdvbm926dePq1at5/fp1t9ccPXqU33//vUtZ/d69e/8W/UNRFBYWcsGCBdIayZUe7EahMQINpUJpx3Xx4sUEwAULFpAkjx49SrPZzPT0dJXsWYnP70osERERofoof/jhB3733XckbR+dn58f4+Pj3RJMLy8vduzYURLGRx55hBs2bJDtOpYdMWIEt27dKhmE4kPwn//8hwDkpiyKQjgsLMzJTFGZeXt4eLBOnTr08fGhEELl+FS9enWOGTPGbZAzk8nE999/X2Uq6aqcu+RK9FOpUiV++eWX9PHxYXh4OMuUKaMSWSqiIwB8/vnnaTabWb58efr7+7NOnTr83//+p2JoJpNJTiQc8fPPP/O+++4jAKakpJTKbPLQoUNMTEykp6cnP/nkE3n+119/5ahRo+Tz9vT0ZNu2bblo0SJpqafgu+++k8y6JHHKgQMHuHjx4r/VmuhW4fLly5w0aZLKXPdmoTECDaVCacc1KyuLMTExvHr1Kq9du8ZZs2ZJBuAYhyYmJoZJSUlMSkpyaQUzevRoXr58mZ988gnbtGnD3r178/z580xNTaW/v7+cuTZu3JiPPvqo6tonn3ySV69elQS7cuXKKhGPY1C30aNHkySXLl3KFStWMDc3lxkZGU7BzBYsWMD169e7jZiZmpoqiabRaOS8efOkniQ2NlYlaw8KClJtONOwYUOuXLmSBQUFKusgd6lFixZSAeu4giiq8Hb0HlZ2Wfvpp5/ks7pw4QKzsrJkOOfo6GguXryYY8eOJeDsKfzKK6+4fe4FBQWcMmWKdPq6GezYsYPh4eH08/Nz639jtVq5ceNGDhgwQK5WgoKC2K9fP65fv57Hjx9naGioitFp+BMaI9BQKpRmXBVvy0mTJnHx4sVy9puenq4irDqdju3atZNJCRYXHR3N119/XUXAlFk6ACk2UM4HBgbKtjt06KCaPT/xxBMEoBIvKKsDhekoxPiNN96Q9Vy7do2DBg1SXdO5c2cOHTrUSaxUdDUTFhbGOXPmMC4uTuYJIVQKa0dTSbPZzF69ehGwmTc6hphW2s3MzJQWQ0r/SZtp7IgRI24o4qW3tzdDQ0OlrubkyZOcNm2aql+u9k5QxjIhIYHR0dHFyuZLi6+//pp+fn4MDw/njh07buiaq1evcunSpezQoYNkhIoC35HRafgT9wQjKG4fWQ03D6vVWipG0LJlS/r6+rJmzZoEbBYic+fOZWpqqorQZGVlccGCBbx48SJJShv1Xr16qTYmB2ymn7/88otqdqoo75TNYhQlac+ePZ1ERq1bt5ZEzWAwMDs7W86ed+/eLRXLXbt25YwZM1TtK05orghkUbNL5Xzv3r351FNPOV3XpEkTnjlzhpcuXZL6DMcNVhQmoYQryM7O5qpVqxgaGkpPT09poujj48Pdu3czPz+fzZs3d7kScJWU8S+68lK2qiy6WYuiqM/JySEAuen834Xr169z1qxZ9PT0ZFJSUqlWEiSZl5fHuXPnsnnz5k7KYQ1/4l/PCA4cOMBTp05pzOBvgtVq5alTp3jgwIGbum758uWSiISEhPCNN97guXPnWKtWLRmUzdVM9bHHHmNGRoYUnVSvXp3vvPMOlyxZQiEEjUajiuAqiladTsfly5eze/fuUj5fEjF0JNiOs/Ki55KTk7lp0yYWFhayUaNG0lQUsIl5irYVGBjolhiXKVOG+/fvl+N0/vx5qZw+deoUZ8yYwezsbLl6UupRvFOTk5OlqGbChAkyhpCj7sKRyTqKoBRLHsWM1dH6JTExUTK9+Ph4lSnm0aNHabVaWVBQwKioKFapUqVEmfvRo0c5Y8YMrlu3rtiyVquVy5cvlzqFOnXqqJwmNdwaFMcIDPgXIDIyEseOHcOpU6fudFf+NTCZTIiMjLyhsrt27cKgQYPwxRdfAAAGDx6MoUOHorCwEI0bN8aGDRsA/PmcACAmJgZz587F/PnzsWDBAly+fBkAIITA9u3b4evri4CAAGRmZsrrAaBBgwb48ssvIYSAp6cnmjZtCgAwGAxo3rw5MjMzkZqailGjRmHjxo0u+2v7JoCXXnoJM2fORG5uLry8vHDp0iUAgF6vx/Tp01GtWjWcOXMG//d//4eNGzeioKAA4eHhOHToEMxmM8aMGYNevXph5cqVmD9/PlatWuXUlsViwalTp7Bu3TpUqFBBjs/169fx9NNPIygoCC1atEBsbCzeeOMN/PLLLygsLIQQAh9//DHq1KmD+Ph45OTkwMvLC8OGDUNBQQHOnTuH48ePAwCCgoJw5MgRWCwWDBkyBOPHj8eAAQNQqVIl9OjRAzqdDteuXcORI0fg4eEBvV6PwsJC7NmzB3FxcRg5ciSqVKmC9PR0REREQAgh+z958mQcPXoU77zzDnQ6ndP9nT9/Hp988gnmz5+Pr776So5tbGwsOnfujEcffRRJSUmy/ObNm/Hcc89h7dq1KF++PN5//320bdvWZd0abiPccYh/anK1ItBwZ5CXl8chQ4aoFKoGg4HVqlVjVlaWambatGlT1azez8+Py5cvV9n7uwpVUHSW7TjzdSxft25dnjlzhoWFhdJD2dUuX0Vn/iaTyW2oBnehjaOiolQhiUnbLPf5559XlVP6p/hDfPPNN/zss8/keGVnZ7vdZ8BVCg4OZrt27Thr1iy5f3CTJk3kOCmycceV8bFjx1RWSIo83Z1vQ0BAALOzs/nUU09xxowZ9PHxcdoMxVE+ryjjK1SowJdeekk6vzVq1EjeZ9WqVTlhwgSn7T+LWvxouLXAv100pOH24sqVK5w8ebKKiFWtWpVCCNarV8+JoHt4eKg2Q6lWrVqJppA3khQFcp06dWgwGBgRESGJTf369Z2IuiuCrzCu7OxsSfgVpbYSZ0cpq8joFU9VBb/99pvKt6BixYrcvn07r1+/zlq1arlV5ipx8mvVqiXj8SjjNW7cOJWDXVhYmMxXiK7i0QxAxo9yhevXr6tCaBsMBlaqVInZ2dnU6XQsV64cFy5cyGnTprFPnz6sUaOGHCslAqvVauWmTZs4YMAAKW4KDAzkE088wfXr17sUy544cYITJkyQTlFeXl4cNmzYLbG311Ay7hgjANAYwB4A+wE87yI/BsCXAHYAWAsgsqQ6NUZw51BYWMh3331XypVr1KhBDw8PPvDAA7RYLNLpSjGVrFWrFj/++GMajUYZghgAV6xYIc0ZFesck8nEMmXKyDLlypUrVuavEO2goCD6+Pjwgw8+kD4DRU0elfpatmxJHx8fJicnc/HixRwxYoRL2/v4+Hg++OCD9PLykmaVCqEv6qT0xRdfqDZQ8fb2Zm5uLvPy8jhnzhy3PgFZWVmMiIhwySRSU1NZvnx5CiHo7+9PIQR37tzJvLw8zp49m/Xr15fXeXh4sEaNGjcUgmDDhg1cv369yiFq1apV0otXGaNhw4bxww8/5OrVq/nFF19w9OjRMqibp6cnH3nkEX722Wc3NaPfu3evS/8DDbcPd4QRANAD+BVAeQAeALYDSClSZiGArvbj+gDmlVSvxghuPw4cOMCRI0fKGXhaWhqXLl3KypUrMzAwUEaCDA4O5uuvv86YmBiV+MRx67+KFSuyfv369PPz4/Hjx6WIQ8l/6KGH+OWXXzIzM1Mlmqlbty69vb1d7qHr5eUlvWRdeeUuW7aMJLlo0SI543fMN5lMkhgmJCTw4YcfdorVbzAYWKZMGWnlRP7pwRofHy83pPn88885ZMgQuSoKDw9nVlZWsSae5cuXZ/v27Vm+fHmXKxcvLy8ZsXLatGn85ptvuHPnTjZu3Jh6vf6GTS7dYdeuXRwzZgzbt2/P5ORkl6u17OxsvvXWWze0kYqGfybuFCOoCeALh/8vAHihSJmdAKLsxwLA+ZLq1RjBrYXVamWHDh3Yr18/TpkyxckGHwD79u0rw+8qM+q0tDTm5eWxYcOG9PT05ObNm7llyxampKSoiKAi046IiFARdb1ez9DQUMbExDAmJoY6nY4mk4mZmZkcN24cAZt8XzGXdExKna6SY3TVpk2bqohcSkqK3NHt+vXrnDBhAgHbBvOFhYU8cOCAkyw9KSmJy5Yt4/z58yXjUswumzZtKsVlSuyaosnT05OBgYHU6XT08/Pj1KlTefHiRe7du5dCCGZkZBAAX375ZRmxsn///szOzna5enn22Wf/9negoKCAW7Zs4ezZszlp0qRSm3Vq+GfhTjGCRwDMcvjfBcDUImXeBfC0/bi1/eUOclHX4wC2ANgSHR19K8fqnsfMmTOdZqtdunQhAHbv3l2GXXAk7iEhIezZs6fctPvtt99mfn4+Y2Nj3eoCHGfuBoOBHTt2ZIcOHRgSEiIJZpkyZXj06FGS5GeffcY333zTbex7xxQVFSWZg6+vL7dt28ajR4/KfCWAmxIt1BGKmWb//v1VMnjH0BhKysjIkMHNFEV4zZo1ZXTQMWPG8KOPPmJERIRT3KGi2yf6+/vLcy+++KLLZ2O1WnnkyBEuXbqUL7/8MgcNGqRaoWjQUBz+yYwgHMAnAH4EMBnAMQD+xdWrrQhuDU6cOCEVusrM29/fn56enjSZTKxcuTIvXbrE3bt3S+JuNpud5PjKPs1KVEpXqVGjRmzevLmMh//+++/z+++/Z7ly5ajX66UTV0ZGhirA2CuvvCL7p3gNFyWsBoOBn3/+OXU6HTt37iz3LlCcyADbngG9evWi0WhU2feTNmKrMDRPT08aDAaWK1eOnTt3ZosWLZyc3ZRUsWJFvvfee4yLi6O/vz937NjB/fv3S+c2i8XCNm3aMCUlhTVq1OCjjz7KVq1asW7duszIyJB6jT59+mj+MBpuCe4UIyhRNFSkvDeAYyXVqzGCvweFhYWcM2cOf/75Zw4dOpReXl6SmI4YMYKkTcGnyKsbN27M2bNny5m8Ulav17NPnz5ShLJu3TqVhVDRJIRgVlYWf/rpJwK2DUZGjx5NvV7P2NhYdu/enYAt3ILiBHX8+HF+/fXXkgH16tWLrVu3dqpb6UNgYCANBgOHDRvGTZs2qWbzERERLCws5IkTJ+jl5aXaVlKB1Wpl1apVCfypTyhTpgzDw8Op0+mkvkDZV3fkyJE8e/YsMzIyaDKZOHLkSGZmZrrUC/j5+TE2NtZl6tu3r9volxo0/FXcKUZgAHAAQDn8qSxOLVImGIDOfjwGwKiS6tUYwc3h2rVr/Oqrr5ysSpSQ2Qqxat++PRs3bkx/f39+9dVX3Lt3Lx955BEKIdiiRQsVUXMMu6B4qoaHhzMsLEwlAilbtixDQ0PlzN/Ly8spdpASW6d169aqUA9Wq5VffPEFLRYLo6Kiit12sbhUo0YNldJ52rRpcgyU/XfXr19Pkty4cSO/++47Xr58WbXSadmyJXft2sXQ0FBGRERImfnmzZvZrVs3Nm/eXCqbizI9b29vjhgxgkuWLOGRI0e02b6GO4Y7wghs7aIpgL2wWQ8NsZ8bBaCF/fgRAPvsZWYB8CypTo0R3Bxef/11ArbdsxyJkKLgVAiYYn/fu3dvGo1GORNWzAaDgoLo5+cnCbK3t7dkDpUrV3YrCjIYDFIpPHToUL7//vuqYGwWi4WDBw9meHg4jUYjJ0yYIJnWvn375CYijkmJq28ymdi3b19aLBauWLGCXbt2lWWCgoKkVY8jw6tZs6aUq1+8eJFhYWFMS0tTKZwVJuDp6cmMjAwaDAaGhIQwMDCQ69ev5+TJk53i8sAu/lFs7JOSkmgwGLh169Y78tw1aCiKO8YIbkXSGMHNIS0tTRLvMWPGkCSfffZZFQFznG1HREQ4xdq3WCxOHr5CCNapU8dlUDZHYlpcioiIYN++fSmEYEJCArdu3cqzZ89y2rRpUjRTtE0vLy8pAgoJCeHo0aO5e/dukuTOnTsphJD5Re/jscceo06nY+PGjZmfn8/Dhw/L4HgWi4UvvPCC3ABEScpOaYDNP8JxHJKTk3n//fcTsFkuFQ12l5OTcycfvQYNKmiM4B7Ftm3bCNi8TpV4/YoFEGBzXJoxY4ZqJu1qRn+z4hiz2Uyz2cycnBwZIG7o0KH85ptvZPrvf/8rPU67du3KM2fO8MKFC3LDesek1+t58OBBrlq1ip6enjQajYyJiZFE2GAw8JVXXmG7du3o7e3NzZs3uzTfrF27tlN4aSGEDF/seH7EiBFOm8orKSUlhUuWLJEb1o8aNYqvvfYaAZuy99y5c9y2bZsmBtLwj4LGCO5RDBo0iEajkadPn+bVq1dVG48LIeTWgYqZpKvYOorVTNHolkX35i0ueXp6Si/UCxcuuBT3FJfmzZsn70kJHdGlSxeStl2tHnnkEVn2ySeflBu7pKWlSdGXu7hBN5NCQ0Pp4eFBb29vBgYG0sPDg5MmTeLbb79NAGzXrp2m7NXwj4XGCO5BXLt2jWXLlmWrVq1Ikl9++aWMdQ/YlLOkjTB7e3vL8xEREQwKCuKcOXP4448/8vz582zcuLGKIGZlZXH79u1O4qLo6GgOGjSIY8aMYaNGjSQjefjhh3n16lVOnz5d5UTm4+PjdsVhMpno4+PDevXqyZn15s2bqdPppIL5gw8+IKm28lFEUr169VKJrYKDg52C3ikWUMrqwXGfAcCm7H7uuec4ZswYzp8/nwUFBezdu7eso23btnz33Xep0+nYqFEjLYiahn80NEZwD2Lp0qUEwMmTJ/P++++n2WyWMmydTkez2cwGDRpI8Qpg85IFbHb2pM3EtGPHjgQg4/j07dtXimsUMVBRIp6ZmckpU6bIePl9+/aVbSsz9NjYWF64cIH/+9//WK1aNdX1jmKaZs2acfny5bx8+TKrVKnC0NBQ/v7776xZsyYtFgt/+uknaYrqSPhTUlJUCu/HH39cbgajJHfObpmZmRw/fjwtFgsDAwP56aefct++fbKfPXr0UG08U6NGDV64cOEOP3ENGoqHxgjuQbRr145BQUGqjdKVGfCYMWMYGhoqzyvhHRTLoZCQENapU0fqE15++WU5S963b5/KqkZRrk6cOFFa3ijEXqfTSZFMVFSUZDSAbY/eonGBwsPDOWHCBA4ePJiAzRrJcecuwKaAtVqtcn/auLg41q9fX7Y1d+5cJz+GPXv2cO/evfTy8mKDBg3Yp08fTp8+nZcvX2azZs1oMBg4YMAAVq5cme3bt5dB2fbs2SPFaSaTif7+/ly4cKEc488//5w9e/bkmTNn7tRj1qDhhqExgnsMZ8+epaenp4wT5O3tzYYNG0rC2KpVK7n7VUnJZDJJUYzZbJaE3TEwWlhYGK9fv06r1cqZM2fSbDbT399ftRtW0eS4H64SMM5ROWswGJiVleXSKikwMJBZWVkq/wYPDw+uEN7ZZAAAIABJREFUXLmSly9flk5per2eDz74IK9du8bMzEwGBATw2LFjcpyU7S3Hjh3rdiyvXLnC559/ni1atODhw4dvx+PToOGWQGME9xjefPNNlfjmjTfekLL4unXrut2I5UaT4nSmEGFFD6Hgl19+kaKkvyMZjUaaTCYZ0sKVSMdisbBChQoqvUVAQAB//PFHjh49mgD43nvvyT4eOXKEfn5+rF27tqbg1XBPQGME9xhq1aolFaP/93//x/vuu08S0ZMnT3Lt2rVOhLQocQ0NDaXFYuGoUaNU5w0GAzdv3syEhAR6enrKdiZMmMDffvuNBQUFbN++vapei8UiA70lJCSwsLCQVquVhw4dkspXRwctk8nEzp07MyoqijqdjsOGDePJkyd58OBBnjx5kv369aPBYJB7Gijt6HQ6JiYmEgAXLlzIa9euccuWLTKonYLCwkLWr1+fFovFKdaQBg3/VmiM4B7A9evXef78ee7bt08S1JSUFA4bNkyKdR599FGSVOkNHOXver2ekyZN4q5du7hz507q9XonBWvRVLduXekPUJShtG/fXuodlDRnzhzZ54KCAoaFhTE1NVWuLgYNGsSCggKStk3eFR8Ho9FIDw8PGRPpiSeeYG5uLq1WK/Pz83ny5ElpqRQcHMxTp06xoKCASUlJjIiI4NmzZ+U4KTb/b7311m1/Tho03ClojOAewODBg2mxWGS8HqPRyA0bNtDDw0OaVm7cuJHLli1TEe02bdpIccrMmTNVdSoWQspKwGAwyH15fXx8VFs5Om7vWJQheHl50dfXl2FhYSoTy4kTJ0p9gRCCCxYscLqvtWvX0mw2y3p9fHycwjZcuHCBeXl5nDp1quxrWFiYVF7369ePvXr1YvXq1aVFUvPmzTWHLw33FDRG8C+H4jPgOPN+++232aBBA/r6+jIuLo7Vq1dnfn6+Kjja7Nmz5Yw7PDzcqV5lRy+FuLZo0YLh4eEy7ELv3r1VO5cpqWzZsvz000+5atUqNm/eXDKa1157TdZ9+PBhlV3/6NGjndr/+OOP6enpyeTkZG7YsIEzZ86UzMtqtfLHH3/kgw8+eEN6hqCgINavX58DBw7knDlztDj+Gu45aIzgX45Vq1ZJ2bpC+Dp16kQAktDPmzdPZTkUEhLCb7/9Vs7ca9Soweeff55ZWVk0Go3Fbq2oRBN1TBEREW7Lx8XF0WKxcPr06Rw0aBAbNGgg+2qxWJienq7aR5ckp0+fTiEEa9asqTLPHD9+PAGwUqVKFEIwMDCQQ4YMYY8ePQiAnTt35oQJE/jyyy+zS5cuXLRoEU+cOKHN/jXc89AYwb8cRQO0PfDAA9JqxmAwsHbt2szJyVGVady4sVPYBUW0YzKZpNy+qBVO0Vk28GcoaaVewOac1qlTJ6dQFGazmZUrV6bZbGZISAiFENywYYO8F6vVKrfBfOihh5ifny/zTp8+zYEDB0rm1b59e7mHblZWFmNiYnj16tXbPv4aNNwN0BjBXYjhw4fLOPnF4Y033nCagTt66vr7+/Pdd98tVmyi2PErxHfkyJHs06ePFAkpeUajUdbtuOOXkgYMGMDCwkJV7J/g4GDqdDq++eab3L17N69fv86uXbtKnUKfPn1I2ix51q1bJ5XLPXr04OnTp/nNN99w2rRp7N27N319fanT6di1a1cmJiYyMDCQBw8e5HfffUfA5kWtQYMG19AYwV2G48ePE7B51hYn0vj4448lwVVEOQqhNhgMbm35XW2CDoD169fn3r175X9l3wDAFo9HiUPkGCE0PT2d1apVY2pqKt9++23pxOaos+jVq5dTn8PDw1mmTBlu2LCBQ4YMkR7KRqORiYmJTvH+AwIC2KZNGxkob9++ffTz82NGRgYbN27MwMBATe6vQUMx0BjBXYYPP/xQEsDVq1e7LPPll1/SaDSqZuzh4eFMSkqSjGH16tWSmN9oOGlX+wh4eXlJPYRjOVfOaQaDgW3btuWRI0f44YcfMiMjg/v27SNJ5ubm0t/fX8YnUvb/FUIwNTVVip6SkpLYoUMHjh07lsuWLePRo0ddMsSlS5dKBjhs2LBb+kw0aLjboTGCfzC+//57p20kn376aZrNZoaGhrJRo0aqvCNHjnDZsmX09vaWhFORmSv7+JrNZvr6+jIkJES1YnCnAJ44caJkIK6Sj48P27RpI9tR6vH19WV2dja9vLzo7e3NZs2asXLlyrJPDzzwAKdMmcLnn3+ejRs3dmIylSpVYs+ePaUTWPXq1bl27dqbGr9x48YxKiqKv//++19+Fho0/JuhMYJ/KNatW0cAnDt3rup81apVmZ2dzXHjxhEAf/jhB5Lk9u3babFYqNPpVGIbwLa5uk6no16v53fffce33nrrhlYAPj4+TE5OZlxcnFOeQvANBoPKL+CBBx7g3LlzZWTSOnXqqOLw7Nq1i0OHDlWJexRRkV6v58iRI/nxxx+zTp06BMD4+HguXLiw1JY9RRmpBg0anKExgn8oBg4cKAmrgosXL1Kv1/PFF1/kuXPn6OPjw44dO3L//v2qGb67NGnSJB4/flzuDFacCKh///4qHYByPGzYMD722GPyv2Jd5OXlxTVr1nDFihWMiYmhXq/n4MGDmZub6zIMs9Vq5caNG6UTmhCC5cuXl5ZIISEhnD59umbpo0HDbYDGCP6BsFqtLFeunPTOPXnyJEnyq6++IgAuW7aMpG1/Yb1ez6ioKJUDlmNyF1ffVVLs93v06EEPDw9J5BXRkE6n+3/2vjs8iup7/53dzW5674UEAiQh9F6kowJig1BEpYkioqAIqKCCKFhRUVRUxC5KUYoKokgTkCq9hd47hPRkd8/vjzezs5tsQir6/fz2fZ77JLs7c+fOzL2nn3PFYrHIuHHjHLQC1eRUUt9xcXFy1113yejRo2Xw4MFSr149h9/DwsKkR48eMmHCBPnhhx9cNfxdcOEmwsUI/oPYuXOnALBtcDJjxgwREXn55ZdFURRbbZzdu3c7lHIojhFER0fL9OnTi2xM76yp2cXt2rWTs2fP2mz0qhkoNzfX4TuACWfq/40bN5Y33nhDZsyYYWsTJ06U1q1bO2Qu2zf7rGIXXHDh5sPFCP6DUBO8Tp8+LfXq1ZM2bdqIiEjXrl2lbt26IiKSmZlpC8e0b87KSIeGhkrNmjWLOIRVBlKYQN95552SnZ0tIiLTpk1z+M2+HpF9S0lJKWLLv3LliowbN85WZiI8PFzuvPNO6dWrlzRu3Fh0Op3ce++9rsxeF1z4l+FiBP9BNGvWTJo3by4iIlOmTBEAcuTIEfH19ZUhQ4bI8OHDpUmTJk4jfapVq1YqM5C3t7coiiJubm4O9YAURZHBgweLiEhOTo4kJCQ4RBUlJSXZjr3vvvtEURQxGAxy7Ngx2/izs7PljTfeEH9/f1EURYKCghxKXCiKIgkJCTJgwADXDl4uuPAfgIsR/MegJoxNmTJFREQOHz4sAEswq7b24oi7oigOYZg6nU7atm1bhGF4enraIozsfQs9evSwOW/vueeeIuUp7PMN9Hq9VKtWTSIiIsTDw0NuvfVWyc/Ply+++MKWjdy9e3fp3r27+Pj4yMiRI2XWrFmyadMmh9IQLrjgwr+Pf40RAOgK4ACAQwCedfJ7NQArAfwDYCeA7jfq83+BEahlIdQsWRGRFi1a2LZldKYFqMS8pGJwzlqLFi0c/Avdu3eXhx9+2KGf4pLNAgICxGQyyebNm21jjoyMFIAZzCtXrhSr1SpRUVHSt2/ff/GJuuCCCzfCv8IIAOgBHAZQA4ARwA4AdQod8wmA4QX/1wFw7Eb9/i8wgm7dukl8fLxYLBb5/fff5fz586Vy8hZuCQkJtlBMe9NOcHCwAIzPt/cN2JuU2rZtazvXaDQ65AzYX+Ozzz4TEUY59ezZUxISEmTu3Lk2m79akuKjjz76Nx+pCy64cAOUxAgMqDo0B3BIRI4AgKIo3wO4G8Beu2MEgG/B/34AzlTheP4TSE9Px4oVKzBixAjMnz8fffv2BQAoilLmvg4cOGD7X0Sg1+thsVhw7do13H777XjuuefQoUMHuLm5IT8/HydOnEDbtm1x9OhRrF27FgDg6+uL69ev2/oxm82247t164YhQ4bYxrdgwYIiY1i1ahUAoGPHjmUevwsuuPDfgK4K+44CcNLu86mC7+wxCcADiqKcAvArgCeqcDz/Cfz222/Iy8tDjx49MGrUKNv3ZNhlQ8uWLTFu3DgAJOgWiwUGgwExMTH48ssvMWLECPj6+iI/Px/u7u5Ys2YNli1bhvr169v6MJlMAIAffvgBU6dOtTEBAPj0009vOIaVK1ciPDwctWvXLvP4XXDBhf8GqpIRlAb3AfhCRKIBdAfwtaIoRcakKMojiqJsURRly8WLF2/6ICsTixYtQmBgIM6ePYtz587Zvvf29i5TP4MGDcI999yD2bNnw2Aw2KR6nU6HH3/8EV9++SX27NmD9PR0AEC7du2QkJCAW2+9FUuXLsUHH3yAHTt2oF27dggLC0OvXr3w3HPPYeLEiQCA2NhYREUV5tuOEBGsWrUKHTt2LJdG44ILLvxHUJzNqKINQCsAv9l9fg7Ac4WO2QMgxu7zEQChJfX7b/sIrFar3HbbbTabfOHWvHlzSUtLczhnyZIlEhsbK8eOHZOAgAB58MEHJT4+3iHyx9/f32ETGADy9ttvl8pXYB+2+fXXX8vatWsd+lL/9/DwEDc3N5k/f76IME/B09NThg8fbhvrmTNnRK/XS79+/W74LPbv3y8A5OOPP67ch+yCCy5UOvAv+Qg2A6ilKEp1AKcB9APQv9AxJwB0BvCFoihJANwB/KdF/jVr1mD58uXo168fatWq5fBbdnY23nnnHQwaNAjz58+HTkfl5r333sPx48fx6KOP4urVqwgKCsLhw4dt59WtWxc7d+506MtgMGD48OEYPXq07TvVnh8VFYW0tDR07twZixYtgk6nw+zZswEAW7ZswYABAxxMTWPHjsUnn3yCK1euwMvLC2azGQDNVFlZWejVq5ft2IiICPz0009ITEy84bNw+QdccOF/BMVxiMpooLnnIBg9NKHgu8kA7hItUmgdGFG0HcBtN+rz39YIunfvLiEhIZKVleX0d1WKnzp1qoiInDp1ShRFsYV/Go1GB23AYDBI/fr1i0j5Hh4eRWr1tGrVSoKCgmTXrl226B6j0SgbNmyQzz//XHx8fIqEl5pMJvHz85OIiAj55ZdfbKUiBg8eLPfee68EBQUV2S+4tOjbt69ERka6soZdcOH/AOBKKKscqPWBXn755WKPsVqttmzcZcuWyfjx453mA6itY8eOtnLM9s1ZbL+fn5/cf//98vvvv9vMPWPHjpWXX37ZFtuv7jvs6+tr2384Li5Ojh49KiIieXl5MmHCBBvDeOihh8r1LKxWq4SFhcn9999frvNdcMGFmwsXI6gkDBgwQDw9PW9YMiEjI0Pq169vS8gqTNDVppZ/KLyJvPqb+r+9vT8iIkL0er2YTCbR6XS2zWl69Ohhqw7aq1cv2/FBQUG2HcLssWrVKmnbtq1s3bq1XM9i7969AkA+/fTTcp3vggsu3Fy4GEEl4MSJE2IwGGTUqFGlOv7QoUM2Ah8cHFzEEQywzv+sWbNsn+3rAalNzQp2dr7a/P39bRvV3H333RIYGGirD7R9+/YqeR4ffvihAJBDhw5VSf8uuOBC5aIkRvBvh4/+n8G7774LEXFw3paE1atX2+LxL126hLCwsCIhlmazGS+99JLtc15eHgAgPDy8SH9WqxUA8Oqrr2LQoEG27/39/XHt2jWkpaUhICAASUlJuHLlCkQEr7zyCho0aFCm+ywtVq5ciejoaNSoUaNK+nfBBRduIorjEP/V9m9oBFeuXBFvb2954IEHSjwuLy9Pzp8/L5s2bbJt+qIWZyvcFEWRlJSUG4aGenl52TaNCQgIkHr16olerxdFUeTbb7+Vr776SgBuBH/s2DGbFhIeHi5ms7lKnofVapWQkBB58MEHq6R/F1xwofIBl0ZQMXz00UfIyMjA2LFjiz1GRJCSkoKwsDC0bNkSIoL8/Hz4+fnZwkgLH79nz54i36uZvgDg7u6FzMxMhIR0BjAB4eF/YtcuwGIxoX7977Bnzz0YOfJPBAe3wtGjx9GyZUubFjJ27Fjo9fpy3a86OYrDvn37cPHiRXTo0KFc/bvgggv/MRTHIf6r7WZrBNnZ2RIaGipdu3Yt8bhPPvmkVMlfxTXHHcjcBFgsivJSwedTAoj4+PxR8Hm0RETkCiC2pig5AqwWT88U8fDwlKtXr5brfi0WizRs2FBGjx5d7DEzZswQgPsnuOCCC/83gIpoBIqi3Oms7MP/L/jqq69w4cIFW00fZzh8+LBD3aCkpCQoioImTZqU6hpGo9HmAwAAX99JAO6En98ChIS0hE7XH8BIpKdPLDjiHVy86AfAB4899iVmzwYaNPgLQAyysubB23sP1q/3RwlCfbHYvHkztm/fjrfffhtLly51esyqVatQrVo1xMXFlf0CLrjgwn8OpSHwfQGkKoryhqIoN043/R+CxWLBW2+9hWbNmhVrBjlz5gxuueUWZGdnA2DNoH379kFEcOXKlRL7V003wcHBtnM9PRNw/fqTMBq34dq1nbh4sQGs1jXo0iUewDro9XrExm6C2dwEQAYuXPgZXl5zsWPHrWjYsB+AoTAaI3HHHUCLFsCvv6JMDGHBggVwc3NDYmIihgwZgsuXLzv8brVaXfWFXHDhfww3ZAQi8gCARmB28BeKomwoKALnU+Wj+5exaNEipKamYty4cUWIXnp6Ol566SVUr14d586ds9n2d+zYgXr16iEsLMyhqJwzPPvss4iPj7cVjMvMzERY2A8ATMjLWw4AuPdeM4xGI3x8VgMAevfujeDgWQBWoG7dSVi4cCH69euH+Ph4XL58Fh07HsHRo0bMmgVcvAjccQfQqhVw/vyN71dEMH/+fHTu3BnfffcdLl++jOHDhzv4C/bu3YtLly65/AMuuPC/hOJsRoUbgCAATwI4BmApgFQAT5T2/MpqN8tHYLVapUWLFhIfH18k+ub777+X0NBQW/RPs2bNBIA0b97clmj1+uuvF7L7OzZ1u8kOHTrYvnN371tg8z8o4eEJ0qRJE0lISJC2bdva+ho9erQAkO7d/xFAJDy8p8N1fvrpJ9s48/JEJk8W0etFqlcXOXGi5Hvetm2bAJBZs2aJiMjUqVMFgHzzzTe2Y9577z0BYMtUdsEFF/5vABVJKANwF4CfAOwCMBYF1UEBeKIUO4pVdrtZjGD37t0CQN577z2H748ePSomk0maNGki1atXl4iICKlevboAkPXr18uzzz4rer1eHn74YafEPzAwUABI7969ZfLkyXZE3Fd0uvcFaG07/vXXXxcAthIUycnJYjKZ5M4775SsLIv4+R0X4JR8/fViGTRokLRv396BaWVkiCQlaQ5lQOTWW0U+/VTk0qWi9zxhwgTR6/Vy8eJFERExm83SunVr8fPzkxMFXKRnz54SFxdXdQ/eBRdcqBJUlBF8CaBdMb91vtH5ld1uFiOYNGmSKIoiZ8+edfi+f//+4uHhYSP0kyZNEgASHR0tZrNZoqKipGPHjk7LRqAgOqhu3boCQH7++eeC45SCSCGIwRApsbGxcvz4cZv0rWoPcXFxEhISIufOnZNp06YJ0Fh0OosMGlR0/FaryIABIooi8scfIqNH8237+/OvXk+m8MILIt9/L7Jjh1Vq1aornTp1cujn0KFD4uXlJZ06dRKz2SyBgYEyyNkFXXDBhf80KsoIqgNwt/vsASDuRudVVbtZjKBevXrStm1bh+82bdokAKRv376iKIoMGzbMpg1MmzZNli9fLgCkUaNGxZqFPDw85PDhwxIdHW13jLcAT0nNmn+Lm5ubjBkzRkREbr/9dgkKCrKdp5p+/vzzT9Hr9dKzZ08ZP94qgMjPPzuOf/Zsvt1Jk/jZahV57DF+9/zzIs8+K1KnjohOZ68x5EtY2BXp2VNk3TqtLzU09qGHHhIA8uWXX1bo2aankwH9+ivH5YILLlQ9KsoItgAw2n02Ath8o/Oqqt0MRnDgwAEBINOnT7d9Z7VapV27dhIaGioeHh5iMBhk5MiRArAO0Pnz56VPnz7i6enpQPgLVxENCgqS8PBwu+/iBMgWIFeSk+8QADJ//nzJyMgQo9FoK1qnKIoMHjxYPvvsgnh7j5SEhHpy/fp1yckRqVtXJDJSRE0d2LVLxMNDpFMnEXv3Rn6+SLdu1Aa++or+g9RUkR07RHr1mi/Ay9KtW7aEhYkEBmo+BavVKj169LCN+fjx4+V+tsePizRooDGf5s1dDMEFF24GKsoItjv5bseNzquqdjMYgeokPXnypO27hQsXCgCZMGGCzcSjMoE77rhDDh8+LIqiiI+Pj82RDEBq1apl+1+tKKpVFtULcFwAkXvu2WI77vTp07J48WIHBhITEyMbNlwXRWEiWUREnnz0kcjRoyIzZtAE1LChyMGDIomJImFhIoWsWiIisnMnibxKiOvWFbl2zVEDOnhQxNtbpHVrkZwckSNHRL7++px4eQVLRESNcj/X9etFQkNFfH1FFi8W+eQTkdhYF0P4X4DVKrJ9u8jUqZyPK1eKXLjwb4/KBXuUxAhKs0PZRUVR7hKRxQCgKMrdAC6V4rz/s1iwYAFatmyJ6OhoAEB+fj7GjRuHxMREW26ATqeD1WqFxWLB0qVLkZSUBBFBenq6bZ9gvV6P48eP2/o1GAx46qmnsHHjRqxevRrA3QBiUK2aBd991xg1a0bizJkzuHr1KpYsWWILWRURTJs2F7176yBiRrVqV3D1ajiGD3cc9/btgLqH/A8/AOHhwIEDwPz5wIULwNq1PAYA3NzY9u4FevTIxK5d+/Duu2/h1Clg2TKgUSMe7+MDsGpFGIAVyMrKxS+/MCxVxcaNwNatQNeuQHE16L7+Ghg6FIiJAVatApKS+P3AgcBXXwGvvAJ07w40bw489RTQowdQxm2cXbjJEAF27gTmzQPmzgVSU4seExIC1KkDJCfzf2fw8dGOiYkBXOkpNx8KGUUJByhKPIBvAUQCUACcBDBARA5V/fCKomnTprJly5Yq6//o0aOoUaMG3nzzTYwZMwYA8MEHH+Dxxx/HkiVLMGrUKBw5cgSKosDb29uWSGY2mxEVFYXc3FxcukQ+mZiYiP379wMg45g4cSLeffddXL16FVFRUfDxScX+/R5YuBC4+24gKioKly9fRkxMDE6fvoDsbOYXuLmtRn5+O9sYFUXQrJmCkBAS8qNHgagoIDQU+Ocf7V58fICMjJITytzcVEI/E40b34Ft22IAAJGRgE4HnDoFPP440K8fEBcH3HUXcPAg8NdfQHY28NJLZBwqmjQBevdmq1EDsFqBCROA114DOnQgUwoKKjqOvDwyhClTgGPHAA8PoFs3oE8foHNnYN064OxZMpA6dQBfXzK5PXuYL1G7Nr93EZKKIydHe7YnTzqfP1euAAsXkvjrdHy3ffoA997L+bRnD9vevdr/BekyJcLbm++xTh0gPh4wlHEz3ZgYMpSEBM4hFzQoirJVRJo6/e1GjMCuE28AEJGMShxbmVHVjGDatGkYM2YMjhw5gurVqyMtLQ01a9ZEvXr1sHz5cphMJlitVhgMBhgMBgwaNAgGgwEzZswosV8/Pz+kpaXBy8sLJpMJ+/cfQFRUMNzcuEDOnTuN6OhoVKtWDSdOnAAKlDVFqY1evXbixx8VWK2HAdSC0Qh07AioFSD++AMYN06T9gtDUYDhw4Hx40ngz5/nwnzrLZWI5wEwIiICGDGCRLx2bRKEli1JDLZv5yI7cwZo2JBjzs0FgoOBsWMpwf/6KyXDzZt53SZNAD8/4M8/gYcfBmbMANLSeO3UVDKu5GSgenVArY9nsZDof/cd+7p6tWzvT5Uu69QB6tWjlpGQULY+/suwWoETJ0hgz50jk4yNLX9/eXmcP+vWaUT78GFepyQUJv6hoeUfw+XLjgxD/b80SZAlja9GDU3TSE7m/4mJxTMIqxU4fpzXPnr0xs+gtAgM5LWTkgBPz8rpszyoMCNQFOUOAMng5vIAABGZXGkjLAOqmhG0atUKeXl52Lp1KwBg/PjxePXVV7F161ZcvXoVXbp0AQC0adMG69atw59//omUlBS0bNkS69atQ25uLnJycor0GxISgnbt2mHBggX45Zdf4O/fHW3a0Jwya9ZpDBw4ECtWrIDJZILZrIfFkgvAgsmTp2DJkuewbVsagEwkJkagfn0d5swBHnwQaN2appnvvuN1zGbA3R0YNoxawquvcqEFB5Mg7ttHaU5FQEAarl71g05nhtVqwIIFQM+e2u+pqUDjxkD9+sA77wATJ2oaQGQkTUKFt084doyS//ff03TQvDkJ/b59lN4Lw92dCzQ5mX/37QOWLAHS0yn5R0eT6KWlARERQEAA+8vIoJaQmcl+atXimCwWjlslJPXra1pKcUxBBFizhpKwM/j4cCEnJnK8VQ2V4NsTxr172dT7VdG8uXZ/pWEKKvGfOxdYtAi4do2Sd61aRQmnPZO2h15PbbIqkZtbtvIoFotGyO1bairXBaAxCPX+fH053/bs4d+srKq5F4ACWVyc4/NNTr4xg7h+XZsDbdpwDpbv+hVgBIqizASTxzoCmAUgBcAmEXmofMOpGKqSEZw6dQoxMTGYMmUKxo8fjxMnTiAhIQEpKSn4+uuv0bt3b8yfPx8AzT5WqxUjRozAqFGj8OKLL2Ly5Mk230FhvPXWWxg7diweeeQRzJw5E/fdR0KZkvI2fvnleRvzUBQFBkMNmM2+8PJKxbhxF/HCCyYA88FHXzKaNePijoggwR46FDh9mr8FBAC9elFSTkoigzh06D288EIMgHthMJAgrFnDflR8/TUwYAAnclAQNYD4eEqDXboehLvgAAAgAElEQVRQG0lLI5GtVQswGqk53HMPtQNf36KTv3ZtTTOxlwZPnuQ17r2X/bdvT//G7t0kgA0aOBInEZ43bx7bvn0cZ/v2HJvVCvz2GyVegEwhJYUL0v78n35ybuMuDEUBatbU7qNBA+D226n5ACQk+/fTfFZQEbwIoqJ4bmgor1+Y4KtEyZ7gR0QUJdIBAcDPP5Ogb9vG45o35zuOiCh6XbMZWL1aI/5+fnxHvXtTs7gZDO7fQF4e323hZ6wyiKgox2ebnMz5XRmMToTzt7C2c+CANj8UhXNaHUO1atTK1HNOndL6e+cd4MknyzeWkhhBaaKGdhb66w1g7Y3Oq6pWlVFD06dPFwBy4MABERF58MEHxWQy2cIl/f39HSJ5Jk+eLLGxsdKoUSPx9fV1+M1+a8kuXbpIeHi4xMfHS3p6ulitIgEBVgH2CwC56667xMvLSwDIPfcMFGCLKIoijz76ohgMVtHrrxQkgVnFx4dRNkFBjBQCGCU0Z47Iww/zc9euIg8+yP/r1BFZtEjEZOLn/v0Zx9+3Lz8bjWelRo3h0qKF2BLNgoMZVioismkT+1CjjJ5+mvkI7dszssg+axkQMRhYzsLdXcTNTeSZZxh5dCNYrSInT4osXCjy5psiDz0k0qqViJ9f0Wu4uzNC6v77RaZM4TmpqQyP3bVL5MUXtYxqRRHp0EHklVcYLtumTdH+ytL0eo7J11fLwdDpGKUVGqq9k9I0g6FwHodIeLhI584iI0eKfPyxyNq1IjfYIltERA4dEnntNZEmTUq+pp+fyMCBzDspzXv5X0Zurkha2r9z7bw8kb17RebPF3npJZE+fRjB5+amzfFGjTjHp07lGj50yDEcvKxACVFDpdEINolIc0VR/gbQE8BlAHtEpGb5+FLFUJUaQfv27XHlyhXs2rXLtvXjU089hWnTpuHq1asIDAwEAHh4eCA7OxsdO3bEypUrb9hvq1atsGHDBnz00Ud49NFHsXGjoGVLBcBQ9OuXiaVLlyItLQ3du3dH48a/4JVXHobR+A3c3I4jMzMUwBUAgbjrLmDxYppN3n0XWLGC/X/8MfDII/z/sceAjz7i/8OHA2+/TUnviy+AwYP5fWAgzUM9eqTj55/PAEhAly7Arl2aOcVgoPS8YwdNP5MnAy++SO3Cw4MmiGrVKPnv3k2psn17mhwWL6YKbrGQ/FSrRv/E4MHsd+tWSqb5+ZR8VJNHWpr2zOyjTVQJ2N1dO9Zeg1Bhb2KqU4eOx9RUjmn/fkpebdtS2tuyhfcbFsbn1Ls3YLcnUBFcuVLUjn3sGH/T6djMZmoqDRvSZ5KTQ80gNZX3WRBXAIBakrc3n09ammaSiIvTzDxNm5bP8X3uXFHz0ZUrwKFDfHdVbdIpDomJfPY3E9eu8V2Vx9d0yy18r6XBzp2c7yX5IFSozvirV3l8WJj2nvPzqUGEhzs3yVUEFdUIXgDgD6AXgHMAzgKYfKPzqqpVlUZw9uxZURRFJk6cKCIi69evFwCyZMkSEdGya51lDHt4eIiXl5cMGzbM9p26EX2NGjVseQNdunQREZGmTTcJcF4CA+sLAFvJiblz50m1amdEUYyi0w0vkPwXi8n0l4SFWcXbm9JirVqUHD77jNKujw8l4SFDKE3ExlJaDwkRWb5cZM8eEYuFeQH2ki3wvgDuAlyukJRcuBmNIo0bi9xxB8erlrVwJi17eYnccgu1jA8+EPnuO5HVqymtlQZpaSIbNvBZjB5NbSgmxvEaJhO/Cwx0HEOtWiLvvus836IkZGSIvPUWNSf7+0hKEklO1u5X1dwaNxa5916Rp57i9QoUThusVpHTp5kN3q0bNQVAJC5OZOxYkTVrmOtRGly4ILJqFZ/liBGcHyEhlfduK9oaNqSEq2qclYWrV5kN/8knIqNGsXxKZGTFxlq3rsi8eVw7xeGvv0S6dNHOURSR+HiRu+5i9v7XX4t8+63I+PEi99zDOVdYCwwM5BoYNkxk+nSRpUtFVqxw3k6dKv8zQnk1goINaVqKyPqCzyaw3ERasSdVMapKI5g5cyaGDx+OXbt2oW7dupg9ezYeeughHD58GDVq1ECjRo2w3UlYTq1atZCamop69eph//79yM/Ph6enJ7IKRLyEhAQcOHAA7dq1w5o1a/DEE2Px/vvdAQyAopzChAkTEBAQgKeffhqLFp3H3Xe/DUV5EyIHkZQUgH37ugDYhtatgb//puM0K4s27VtuYXRDvXqU8tLSgGefBcaMoV3/+efpUAVody+0tQCA9QB+A/BSpT9PZ9DpaLP39KT9Pj0dWLmSGsqAAZTuf/yRy0N1Xtr7FaKjnUvI7u70OXh5ad+lpQHffkv7+aZNlMYVhX0D/N/TU5OcO3SgFN6nDx3rzpCZCcycCbzxBqW2du0YTqvXazbdvXtvHO2i19MB37EjtaiAAH4fGEiJ+fp12vHnzQN+/11zdIaEUGOoUYM25YgISpBHjmjXtnfG+/oW1aoKlNqbgsOHqbWuWMF5Whjh4XzuKSn0s5Qmb0SV8Avb3M+c0Y7x9KQPzN7mHxJSNu1q/36GMh84ANStyyCJnj01DWHdOmDSJGqboaH0m8XGOo7r4EHt3en1RZ3xAQG8jv193Ehzee014JlnSn8f9qios/gfEWlUvktXPqqKEXTp0gUnT57E/v37oSgKxowZgw8++AAZGRnQ6XQwGo0wq28VgI+PD7KysmC1WlH4GaqmI3vs2rULbdq0wfXrcQD2AQjDDz98gz592qNfv35Yv349unffjY8/joHJ1BW5ud+jbt17cfToEAB3IidHQcuWnIC//MKwSICEtVkzOgtvvRXw9+fvWVmc/Eaj5iwGrAAOAkiEXn8AFkvREBpvb4152BNO9bOnJ/DCC5qD1j5AymDQJn6dOnT4XrnCRbpqFYmztzdV54sX6Wi97z5g+nRG/wAkjCkpPEddHEeOlC6UT43ISEgg01y/nvffuDHDYBs25P3s3Mm+t23TCKfJxCgVNzcSpTvv1BzAOTlc8IsWkXn5+3M89nHx1ao5OvsMBt7TsWMkgseO8Z5usNyg15OA63R8D7m5N75vReE5MTEcQ8uWvIekJI34qRE1oaGlT9RTTRg3GnPhc5Yt49zYu5fXb9eOTDYggN9t3sxnf6lQWqrRyDlbowYTGuvU4dw9fJjtyBFHRufpqYUK2wsMsbGlN+mUBIuFiZmTJ2sM4bHHKKyoDGDcOODRRx2FEBWqk9pqpaBSnOkxL4/Mcu5c5mZcu1b8mF59lcJeeVBRRvAWgA0AfpQbHVz03K4ApgPQA5glIq8V+v0dMBoJYGRSqIj4l9RnVTCCS5cuITw8HM888wymTJkCAOjevTvOnj2Lf/75B1u3bkXTptrzUxTFgfh36NABjz32GPr06QOj0QiLxQKLxQIAcHNzQ1JSEsaNG4cHHngAAKDT3YWgoM9x/nxgQUhZHJo1a4Vly5ogI2MsgM2IiEjE2bP1oCiHUbu2DidOcOLXr89JoyiUUAcM4MRUibafH9C/PyXbJk2Ahg3P4MiRSLCSeASAlqDPIQB09wRCUXTo2pUMZelSLQ9AhZ+fZr/X67lA+IwoKVWvTqIYHg68/z4XTnY2J/6kSWQIeXlkYsuWMa8gPV3TEIxGoG9fEs4//mDf/v5c1DVrUsJevZp9Go28TmSk1kQYQnv0KBeROr6qgJsbF7UaWRIVRSlOlez27y/KHFXNRg0V9PfnmI8eZYTW2rX2zJrPTVGK9hMdrflmfH35LEwmRpXs20ciW9gP4eVF5nz1Kv+aTHxvvXvTj+FTaHupnBxg+XISpcWL+Z7KCnvi37On8wgm9VqrVlFw+ecfEvpLl4qPtrJHSAj779uXIZWVaU+3WjkWdR5ZLMyR+fBDvjNnDODiRcew7NLgyBEyzIUL+X58fflO2rShUOPsntSkyfKgoowgHYAXADOAHDC7WETE9wbn6UHx81YApwBsBnCfiOwt5vgnADQSkSEl9VsVjOCzzz7D0KFDsXXrVjRu3BgAUL16dej1esTHx2Pbtm22bGEVOp0OvXr1wqJFi3Ds2DGsXbsWffv2BQB4enoiOzvbxizuueceLFy4EIqig8gM6PVe6NFjAD7++DweffRRLFy4EFFRg3D69HIACQD+gJfXR9DrfZCV9SDMZgVt25JgrF1LgjlvHiXUvDyaRvr2pQN0zx4S56FDgc6dBQcPWmEwLMTzz6eiceP6WLr0Fnz0kQ8ABW5uzBr+/HNNCqlZk0RJr2e285w5XBju7ryW1UqJPjsbeOIJOqMLZ39mZtI5/MEHNybKRiP7bdiQDu3MTOYgbNxIZ25ZCZHKEGvU4II9c4bO07w8x+MMBhJBReE1VOKj05HhZmeXnqGYTGQKtWrx+fn783oJCVy0hZ2zyclc9CpEeK9paVzoauZ1ZqYW425vDlGd1AAZS+/emlb43XeOuRBGI+/D/l5UBqzXU7C4+26O/ddfNeIfGEgGfuutJTvRC0On41iKI/6lwbVrHMuWLST4QUGOZp30dAoMK1eSmYSEMAv9jjuo/RmNRfsMDCxZE7JagQ0byAAXLHBkzIWhKHxeaub8iRNl15xUeHhwznh703R7+DDfldGoCRz22k7NmmXPttbGXQmZxeW4aCsAk0Tk9oLPzwGAiLxazPHrAUwUkd9L6rcqGEH37t2xb98+W+mIzMxMeBfMmjp16mDv3qK8y8vLCxaLBf3790eLFi3w5JNPIjs72xYhpCgK3NzckJeXB51OBxHBsGGbMHNmUwC1MGTITKSmvoSNGzciLy8PHh5PIDv7fSjKQojcjZo1X8CJE5MQEKCH2UzC1L07Iz+2b6eafe0aVeh160ioc3MZPfTVV6qpIxvAcXz44WYMH/4gLl/mtpWqqUV99e7uJJoqwfTwIFFJTKT2cccdnJj2RDksjJJ6nTqMbW7VylG6XL+epSVWreLnyEgyHTV+X6/nGIcM4TUNBmoVer2jROjnR8JSowbHt3Ejr6vTaVEonp78be1anmM0OkrTXl4kmJ068fr5+dQwfvuNxNbPj7bq2rVZOmPjRj4fNW+isAmjMmA0su/4eDLB9u1p0ikN0c3MpMnht98oEJw4of0WGck8gv79STh8fHgvx45pDGX3bmp9hw9rpjyA9xsZyed9++1FczbsYTI5MjMVasZ5WXDpUlG7v32cfWUhOprMOTGR7zoxkWNdvJj5GOfO8b107kwG6CzJKyODfputWytvXuh0JPAqwY+J4RpVn4m9f+Xtt1mLqzyoqEbQztn3IrLmBuelAOgqIkMLPj8IoIWIPO7k2FgAfwOIFpEicpiiKI8AeAQAqlWr1sS+kFtFce3aNYSGhmLUqFF48803AcBmCgoMDERycjLWqhQGgNFoRF6BeKkoCuLi4nD06FGYTCbk5eXhnnvuwU8//QQANqexXq9Hz569sHv3DwAs2LcvBsHBXrh06RC6d++O5cv/gtkcBcCIe+/9B4sXKxg7lo4hgKripk2U0ObOBd58k0XaoqJIcFVbttVKwvDAA4DZLAAEcXHDcOjQTJjNetx2G5mGxQJ8+SWZyrlzlH727KENWYWXF233gwaRmPfowYXUsydVZFU7UAmJwUDnZ4MGJKRr19Lp2r8/w13VyZyUBNx/P+8lJ4cL8LXXHE0aAO9t/HhmSNsTIhGGtM6bR+nXXjoGuKj8/Wk+SUggsVKzTUuS8uzh6aklxh06VNSBZzLxOrm55StDoCi8J6u18soYFIZeT2LXsqVjEp+9LVstqfDzz3w/OTm839RUR0ZaHDp2ZDiuWjZkzx7N11MeqIlVKkGMjS29NpKTQwZ34gS1wDNn6NCvIjkXdetSE7v7bj7rvXs131ppoQootWuXnMyXmamZHlu0KH/JlIoygiV2H90BNAewVUQ63eC8sjCCZ0Am8ESJg0HlawQLFixASkoK/vrrL7Rp0wYA8Prrr+PZZ59FkyZNbKUm7MYKDw8PW1RQYmIipkyZgt69eyM0NBRXrlyxMQoAiIxkRdG33/4Lo0e3KcgFeA/AKPTs2RMXLlzA/v1JuHTpUyQmfovg4P7IzOQCzcujSnvqFCWU335jVuGiRZwcGzdSwj1+nLV8Nm3ioqxWTZUScxAYCCxb5o7332ckEcBjP/lEuycRMo/vviODOXBAO7ZmTX4XEMBJHxRE/8M771DCb92axLo4E46bG6Mcqleno81qdS7pqY7mxERKpX//TYd3aCgl3N69aXfW6zneb76haSo9nX02aMAx16tX/LtOS6OpxVkpgfx8fp+TQ6m2pJo7YWGOKntUFKXEzz4jQ+vcmQQyIIDEYedOalipqRy70Uhmk59fNN6/OISGkqldvUoTgrs7CXHz5lrUEcCx//03Nbnc3KIO/6qAXs/31rQp/xb2OwAcg7OoHRGtPlRiIuf6/PlsO3c6Mgb1mZe2zIfq7C6cR2C1Upo/d45CUXJy6bOq9Xpqb2r13P9LqFAeQeEGIAbAglIc1wrAb3afnwPwXDHH/gOgdWmuX9l5BCNHjhQPDw/JtQtcb9y4sQDcN8A+Q1ht6taRnp6ekp2dLX/88YcAKJJ5DHALSy8vL+nR44SYTGapU+ekAFvFzc1N6tatK0ajpyhKKwFiZd++PHFzE0lI0GLJmzZljLqnp0jbtoyPdncX+ftvxp9PnMi4fTU22dtbRFGsYjT+IK1aDZPYWO03o5FZwllZjs/gxRf5+9Sp2nerVzM/QT23Th2Rl18WadlSuw7APIURI/i/mhNwyy2OsfQAN8pJStIynNV4/q5dRbZtY8bkU0/xu5o1RcaMEXnjDZGUFN47IFKvHmve9+jBz7Vq8e/gwSXHepcX2dm83rffMst3zRrnez2ruHBBZNw4bbzFtaAg5ggEBFQszr08zcOD1w8K4vtiPknZm07HHJGBA7W50Ls3Nzk6epSZy6+/zt+bNuUziYsTue8+PqNhwzif7ffGcHYNX1/HLO7KbjqdyG23MXY/L6/y59B/CahIZrETrqKAmcV1bnCcAXQWdwZwGnQW9xeRPYWOSwSwDEB1KcVgKlsjaNSoEQIDA7GiIE03LS0NQUFBMJlMNqnfGcLCwnD+/HksX74cc+bMweeff17kGM2MZALz8H4B0BXAIgBDC47qCGAlkpOnY/r0kSioaQdvb0r2e/dSArVYGMOeksKYZbOZUr0qUTZtyiihjz8GDIZcmM3h2LlzDf76qx4ee8wxQqdrV0rYd93FiIWBA2mrnzXLUWo7doxhlHv2cAznzjH+f8wYRgP9/bcmcT7wADBqFE0Mqh1661ZqK8WZP6pVo7bQs6dWuG7+fN7Dn3/yvFq1qIn4+gIvv6xl79avz0gTd3c+q+7dtdpHzpyFNxMXL1JjcWYqyM/nvam1j5KS6F+Jjub9XrxIk8aFC/SFqEX1dLqivg+g5Nh49TeV7DmDycRrq76QCxccx20fhllcP+oxxb1nRWEr/Hvh6KiYGJpc6tShuTMjQzOJHDmiXVtRyhYeKuJ4bZOJDubQUGp9akScv79W46pDB+a1FPZdlFRDqjjUqcOcHvs8BKD4GkgnTzoWxrOvf1SR6KiKmobeB6VbANABaAjgmIg8UIoLdwfwLhg+OltEpiiKMhnkTOpGN5PAJLVSRcdWJiNQy0hMnDgREydOBABMnz4dTz75JCIiInDWicHTYDDAbDbj119/Rd++fdG7d2+sWLHCYQOaBg0aYMeOHbjrrruwePFijBy5Du+91xpxcS/i2LHJ6Nt3JQYOzMEDDwzClSsXAATir79OYMECL7zzjpaiXrMmF0BmJsMu33iDPgF14ej1ZAzTppGQdu0KrFplhdmsQ2LiSnzySUd06cLfTpxgiYjr10lsT53S9iIIC2P56fr1OfFq1NAmXHo6bfpLlpBgbdhA38ETTzB8zt7EpEJRik7kmBgysu+/5/8iWjEttUicGm4YHk6C+NNP9AWoTKEwjEZGi3h5MQQxLY2L+e67/ztMoTicPs3olLlzNaZgD72eZpEGDegj6tyZTHXbNjLgffvImJ0tX0XhM05MJCN1d9f2CPDy4jsxm3ndtWv5bKOjNSKs2uazs/ke7K+hvjdnJraYGJrJvL01U19aGhnMxYuODMbeZBUczKi3IUMY/OCMuWVna0whNbXsxDg4WCOoUVHaNXJzuS7eektjTM7kP/t9DhRFu6dLl9guX+ZcCw4mkwkOZgsIoDP64EH20bIln/fevY5VURWFhF5dK2qSoL3fzmRiKfehQ4uOrzSoaImJgXbtfgBtbnROVbbKNA398ssvAkBWrFghIiIWi0Xi4+MFBWYfFDLzAJCaNWuKh4eH5OXlyYABA8TX19du60lIVFSU1K5dWwBIu3btJDIyUtq0sYq//yUB+gsg8s8/vH6vXh8KAPH3f1GsVqrrqtnk2Wc19XX8eJpq7E0qbduKHDum3ctbb/H7Zs1misHwtqimmuhofv/ww9qxFgtVd5PJ8Ri1ubvzmuq2kWYz1XnVJKSWt/D01Majmgd69hQ5d674Z75kCVP/9Xqaj9zcRAYNciwS99xz2vEnT9IkBNAUMWaMptJv3Kgdl5PDexo4UCtU5+nJYnDOWpMmIgMG0HyxZAm346wK81JxsFppjlCL/QUEsKRBbKxWeExtqjlNbVFRNGeMGCHy5JNF2yOPaGU2jEaa0r780nmZinPnRD78kMXNGjbku7e/VkyMyO23s3zHZ5+xnIdaqM1iYVG8QYNKNocZDOw3LIzz9sknRebO5dalH33EEg2q6ScoiO87OVmkfn1uX3ozsHkzr6nOs6efFnnvPZGZM0XeflvkiSe4B3hYmOO9eXtzm9WBA0Xuvpvv70aFB93cWHbk2WdFvvmG9KCwuVZFejoLP37+Oef+33+X/x5RwT2LvQDo7T7rAXje6LyqapXJCJ555hkxGAySmZkpIiK//vqrU+IPaDWGEhISpH379iIisnTp0iLHLVmyRNzc3MTLy0vc3Nykd+9XCybAKElO/l08PVklU0SkSZM8AWbKhAnp8vXX2kSZPl2bULfcwuM7ddIIXLdujnv7Xr9OW2vLllcFgDz99Gs2whwaytonhSfa88+z/z17tD7+/pv1bvr04bmjRzte5/vvSSzsJ7W/PxdHVJTIAw9wQVerRt9Bcbhyhf4A+0XVrRurjqak8PP8+ST0ERFcbEuW0Gbfpg2Jm7s7mYczpqMyhZEjaYsu3IYOJfGJiHC8F09Pjj02tmjr3Fl7VhVBYQYQG8v6OPa1lfLzWY/oxx/pl3n6aZFZs0g4S1tzyGIh0X7qKUem0LIlK7tOmyaybJnIiROO79hsZh2ghQvpMyqOQYSHF31GISFkWur78fLiu1Obh4fm+7JvNyKcikLBQW0GA+d7w4assjtzpqNQVNxzP3lS5LffSNjV6rZ164rceSeZ2eDBjpV2nY1DUTjHdTrHMTnztajHl3RvHh5c18HBFJCqVaOP8LHHyHi//JIM4667uI6/+65M080BJTGC0piG/gbQRQp2JivYqWy5iLQug1ZSaahM01CbNm2Qn5+P+Ph4vPbaaxg+fDjWr1+PNPsymHZwd3dHfn4+nn32WbzyyivIz8+Hl5cX8gv0VF9fX2zcuBFJSUmoXbs2Dh48CDe3r5Gffw/69n0aR49+BJNJhzVraP9V7eJbtrBuUE4OwzQnTKAZxtub6vDhwzSd1KhBlXHrVibOqHj1VYZa1q8/FOfOLUetWkexebMe/v60+U6fDowcqR2fkUH7fIcOzEouDBHa+99/Hxg9mmqzqkr//DNr2FssjHxR1WijkWpu//6MXjp4kDkNb77pPN4cYB9ffcWoIxFtUx03N/arxvE/8ggTrv78k6atyEiaHk6e5LH16zPTs1evorZji0VTs+1j1IOCaAaJi+M1Dx50LCFh39zdaXrKyODWnE8/XbqkHquVPhN7G/C2bfw/NpbveeDAqjdfWa18JwsWaEmH9qUafHz4TEvyN4jQHJObS9u2xcKksbi44mszFQezmTkwaWn8azY7Pm8RmjIvXKDJ5do1vlfVZJqfr43HHjpd8e/FbHY0L6p5LBaL87wH+wx6tW8/P87l4q6hJkdeu6bV9VKrzF67VvpNb5yVdomNZX7HsGE0E5YHFfURbBeRhjf67mahshhBVlYW/P390a1bNyxevBhNmzbFli1b0L59+4KN5YuiefPm2LRpE3799Vd069YN169fh58axA9g2LBhCAoKwtSpUwt8CQFQlFNISUnDN9+EwMeHBPnNN5l1+/jjTHLKy2MiE8Awt969mTn51VfchaxzZzpfr13jYrCvRZKezsUYF3cW27ZFokWLg9i4sRbef5+OWBEu9Cee0HboevddJqVs2ECbpTM4YwaTJ9NJDLCfEydYkmLjRmYze3hw/AkJnLTffacVFrMPt7T3QQAMi1U3rm/ShD6M4gq3qf0AJBRqiofFQoIdHs6/KqHJyXFcVGpZBrO56G/q74BjJnJgIMNS09NJyJs3Zxa0sxDC/fvp11iyhO/MPj8iOpr3n5JycxhASbh40dFBWdbkqCtXtFLisbFa6exmzUi4Ll4surtaMfJVscjIKBrC6+dHW/q2bVqZCV9fJlmmpmpMymzm/2azxjj0eq2pTE+n43xRc0NUZpefz+/c3TmvjcaSGWV+Pu/RauX879OHY6tbVztP3WnMXihYs4bXiIvj72pCnsFQNLTYYCDNeOedsj1HFSUxgtIkK2cqitJYRLYVdNYEQPYNzvnPY+PGjcjPz7cR8i1btkBvR50K1xMCWBNo8+bNaNWqFUQEXbt2dfi9RYsWGDFiBABuZl+//vvYudOIl14KwY4dnJgtWvDYjz/m35o16XB1c6NjMCODkq+XVy5atz6FNWvi8eefdKTNnk1HqD1mzFBrnAxGWNgH2LixFl5+mRPMaiVBmjSJheJeeIEE7fhxRhkVxwR4/9QkANFtSjcAACAASURBVGYznj/Pap4A8PrrdCAnJ7PPVatIwO+8k0QhPZ1MoH9/SkZ//aVtpQlwgSUlMSdiwABmsb79Nj/v3OkoOcXGcixq4lh8PPMFVCK6bh2d5armZJ9gFhhISdfHh011YgJkFAcOkJno9TzWYHDugM3JYSauqqVs20Yt5NlnyQBTU/lu5s/Xru/nx/fZrRtzQAqXlfi3ERJCLbN9+/L3cfUqHaFz53KuvPUWHbF5eUWroKrVY8sCk4lOZLW0wty5fNenTpHAnjzJ5EY3N77nkBB+Zy9EuLnRQW4yafNAnQsVicDJy+NaTU9ny8jgGIKDqSmrVVdLQloamU9Wllagr3p1zsODBznXBw9mdNOvv1Lgiooq/5hLQmkYwZMA5imKcgasMxQOoG/VDOfmYe3atVAUBWazGWFhYbh8+TKsViu2Fez5V5gJ6HQ6XL58GcnJyTh16hRefvllbNiwwfa7yWTCvHnzkJ2dXcBE9Dh3riduu41ET93bvkULToDdu6kGz5rFySpCyX/ECBLwzMzpuPXWmYiO3oKwsEDbNor2JWjT04G33hKEh2/FpUs+MJsfw8CBvMYLL1CC79KFTU3U+fBDSh1btrC0wZw5xSfHqMwgN1eLDhoxguGrikLJZMgQag2jRpHp3HknpZtOnRhCmZTE3zt00KI+9uxhnZhBg6idhIWR+QFcFNWrM/P588/ZdDr2AWiazbx5fE7btzN6Rd14pk4dMsZz52j+qVZNu5+8PLb0dJpKAgOBqVMpZalJUGfPktHNnEkpr1EjRnEcP87FmpurRXq88gpbYaiZzRs3MsJnzhxNQkxO5jjz88lA7CVmX19qC506/Xubx5QFAQHUbAYO1JjCzz+TCdqXgL6R2am0aNqUz3DqVBLe8HAy9CNH+H7OnCmaiaxGUFksZPz25h5vb0rjXl5s3t4k4iUxCPW92QcUqmWv7RP7SoPgYJqCdTqupbg4ClWhoTRTvvgiw06Dg/ldbm7Zy3eUFqXdvN4NrIYGAAdEpJKrgJQelWUa6tKlCy5dugQvLy9cuHABhw4dgp+fXxH/gLoHcYsWLbBv3z7069cPP/74o9MidB4eHsjMzISHhweCgx/DyZNvYckSvuwHH6SEcPo07cwvvcTwvv37aXOeNo0TfPx49le3bj8cOPAT8vM74LXXfsULL+hhMjlm8Kq+AaAZatRYAL2+GrZt44Ixm8ls7DMmRSil5uYy9PPll0no/vij+IV69CizZNXyDE89xbGqdswePUjUd+6k1LZiBZlBfDwn8YQJlNQbNiThDw4m4f7nH5qE7BdmrVpkAsuX04Q2Zw6JuslEH0GNGppJrV49ahtnztCf8uCDDD1Vcy7mzdMyfQtDp6Okbs8ACuPsWYbrqgyhY0eOIzOTUv+JEyWXh7CXRLOztZLVXl5a5Vj7pefpyfdisfBctcJqUBC1opdeosRbHuTlMfN54UKNWapmusoi0v8G8vIoOe/dSxPlihVkQp06UdNJTuZzfe89Chr79jnOB9XnUNhEqDKHwECtgGB2NoWU7Gye5+2taRceHhV/hpcvU3Dw9OSaPHzYcY8FFSkpnNvlQYVMQ4qijADwrYjsLvgcoCjKfSLyYfmG8+8jPz8fGzZswEMPPYQ5c+YgPz8fzZo1Q0xMDH4s5D1VN6Jv3bo1Nm7ciJiYmCJMQD0uMzMTiqIUaAWjEB+v7RuwcSMldUUhgVIUElfVDqnTAZ99Zoai5EGnu4yVKz/ALbd0woEDw7Bu3ffIz78f3bpp10tPB954wwK9/nc0axaOTZti8NxzJJQHDlCVLJw2/9tvJKhffEEpTq+nJP/bb8xBKIy1a7U9BRITqVmo9smJE7mwOnXiAmzenK1pU2oiL7xA00mdOpTetm933HTbx0fb6lKVcmrWpMbSuzcXb3Awx5aSQola1Rp8fXkfXl50EHt7UyLdsIGLv0YNoF8/tvIiIoL3Om4cGcLq1VysamE+T08e4+dHIqKaCbKySFjy84vWlVeTpxSFpi17mzXA7/Lz2f/Jk2wqw501iwmAI0eyrIe9w9JsZo0gVbs4eJAE6/x59nHmDPt1c2N/9v4PNzc+z8BASs6BgY5EzcND2/4zObn48siVAftqq2oMvTM5VWUA9nH4Oh1NT3v2UABatoz38s8/PKZjRwo/9kxQde/l51OQWbFCy9E4dqzoRk4GA+eoWozOYuE7Lmn/gLIgPp7vccMGTUAKD6c5uGZNmmbVLWkrG+V1Fv9rm9VUhkawceNGtGzZEl988QUGDRoEAJg9ezaeeeYZXLQ3btrhxRdfxOTJk9GpUyf8qVIkOzj6FBoD2Ip33iHxu3KFkt3UqSRytWrxpR8+TOKakwMcP27FyZM6ALno1+86hg8PQfv2QIsWD2Pjxh4AbsPPP3vgjjt4hSlTrHj+eR08PNpj0qT5eOaZEPz8MwnmrbdS+iuMTp20/XPVCIekJBLUf/5xXOCzZ2v11q9do438o48YeVLY6efmxolbnIRsv2GN9rycL3L1ezUTOiiI/Z8757xvnY6LxV56MplIvOrVIyN2Vne/LFi8mAzz2DE6QydNokZxIylw/37g008ZmaX6Dry8NOekycT34CxLluZBahLp6UWflacnTRHqMfbP3sNDK4in0/He1b0JFAW2araqhJuf75jY5ObGZjBo0rAKvZ4E1N9f++vvT2ZcWqk4P59zSI0aUpu9c1Sn43idPRtF4TtPTqY22L49fQbu7pzHo0drPjKARLRVK+fju3pVq/CpPmM3N54TGclnlJpKZ7qbG9erfSG/mjWLmvHS0hydwkV3Biwe589TaGrThhn8LVs6Zoir918eVNRZrFcURSmIQ0XBPgP/0XzN0mHNGhZODQsLs32XnZ1dhAm4ubkhPz8f0dHROHz4MAICApwygfvuuw979uzBzp07AQC+vhNgsWibxW/axL8tWmimH1Vaf+opcnxqHpsBtMDgwSGYNIlmji++eB9JSQYA7yMqqhuARFy/DkydmgtgBWbMGIiFC0NQrRolfauVdvfC2LyZJpxp0zRHq9FI5tSvHx2wgwaRKT33HPto0YJj79+fYyysqtaqRQdh9+4kEN9+S03hyBEuDr2e/dkzAVUCVqVqPz8ykbw8Ei9VYlbb5cva5vCFGY2XF4mHGk2RlMS+TpzgAvz9d/op3N1JuJ1txpKVpW3qsncv+1IXea1adGI//zxNar/8UjwDEOEitt9VLSqKhGPkSN7X/PlkCjt3OkqyNWrwmq1aUfupWbNo/4cOkTAsWaI9jwsXtH0V1EgYET6DmBht4xyVwathmXv2aFnd6lyMjCTBz8zkM8nL43menpqWoIb4ZmeT2Nmb9ewZSHHlH9QInsJCgZsb56K/P/+q/RSHvDwy2f37KZiYTIzUiY3lO8/PZxDC0KFkDPPmadFlheHtTS124MDiibsI14+6B8iyZY5Mo3ZtnqtWYbWvcmswlL6gnf39/fgjBZDYWL7HmBj21b8/iy9WNkqjEbwJIBZAQZwLhgE4ISJjKn84N0ZlaAR33nknDh48iIkTJ+L+++8HAHTs2BHr1q1zqByqYsSIEZg7dy4uXbpUxIkMcBvKHj16FJSZCIFefwbDhhnwwQf8ffx4hoyePk1ziMWimQcWLqQED+SiVq3dOHeuCd57j0zkvfe4aEaPBtzcbkGNGpewadMmvPBCNt57Lwzt2o3Bzz+/iZAQBd26sS/VLFMYvXtzkZw86UgIrVZKHWfPkpAPH05i9vjjjI7ZsYOEQQS47TYym8WLuZ/ryZPso2ZNSqebN3PCjh/P8athmkuX0un7xx+aj0PVEoxGRg2ptY/sonGRn8+tLBcsIGMaOZIEzD4s8c8/i5aiDgxkVE+DBszPWLOGRPjsWS7K227T0vwLS4JWq0bgVOIXE0O/h7NwT9WcsXev4w5V6uY9Kry9tW0VfXy0WPPLl3me+hegL6BWLRIY/0L79V26RB/KhQscl9XKc+1rEJVESL28qGUFBfE5BQVpW2OqyMsjIzt4kO/YPl7f05PnqI7RnBytZWeTmasanT1Dtz9XvW5QEN93cYzD3Z0EXt3ZzX5jmYwM7bmrpqTUVErSEyaQgB46pM2VG+0FXBbk52tVYO3fIcD3kZGhzSmDoai5rTTIy9OeqwjPN5koDLz8cvnGXdE8Ah24F4CaxrATQLiIjCjfcCqGijICq9WKoKAgpKSkIDo6GpMmTbI5ifV6vW2LSXsMGDAAX331ldO9iI1GI06dOoXQ0FB4eXkhM3MUgCnYu1eLxmnalItg4EBKKUlJnMQpKUBW1lX8+msAoqO/hsXyAJo0UbBuHY9ZvZoq74EDwMiRq/DBB11w++298dtvH0Gv34yTJxtgzZpQ9O5NB9OlS1y8qgRiNjMK4c8/6Vh+7jlqAIWxfDmJsaJQgvz0U9pZx47l74pCO/kYO9YvQnvlrFlkbp6eNJ+oDKAwsrMpjf/5J+21u3ZxvDExJB4XLmhMQY2sAUiUFy3iM2jVimGqzsw8585R+tu9m/etEnWTiVL90KGs06TG+Ht7F939KT6e56xfz3s7dIjfWyzOHXeAJo3a91OnDk0XV6442rxVraO40tNqiW6zWWNGxSVJqbuO2RNb+2JsqtZgHzNfXqhahsok1X0UShFnAoBjUBlDWVA4CczX17GOj9pUBm2xaBvw2BeHU7WVqnaKe3sXHV9gYMV8KuoOaPv2cQ2MH08NtTyocBlqAI0AvAngOICVAB4vzXlV0SpaYmLHjh0CQL788kvp37+/uLu7S1BQkEO5afvaQWppicLfq02v18ucOXMEgJhM3mIwnJPbbtOud/Ei08wnT2Z5ZYDleAGRTz7ZK4qSJUCOLFp0UQAtnf/AAZZnVlPRDx0SefvttwV4TgCRt95aLSIi/ftrJZ9feYXlCX7/nfVmgoMd092PHi36PDZu1NLq3dxYXuC++7TzPD1FVq1y/iytVtZgAVi6obg0/6wslnRQFJEvvuB3mZlM9VfLTDRpwjLG1apxHIWbfaq+muZvMBSty6PTMVVfrWekfh8dzfo2ZnPJ82PbNh7r6ckSD/8Wjh9nGYiWLVmywdkzKa4VLtkcGcny5aNGsZzFX3+JXL1adWM/f15k5UqRGTNYKqF9e87FstyDfTMY+C51uuJLNqhzwseHJRsKl7JQy0JUZbMvgVHee73Rc/jww/K/F5SnxISiKLUB3FfQLgH4AcAYEYktHz+qHFRUI5gxYwaeeOIJHD16FH369MHevXttsf/OtAEASE5OxoEDB2AuMG6qvgMV3bt3x7JlyyDSByJzbCGjAPDDD7TBz5xJ5ytT17NhMKTDbD4FoBE6dbqCtm2DMHkyp+20aTQHqZm91aurGZaCwMArCAy8hiNH4pGXx/ji4GCq8o0aUWrIzKSUVKcOHaZz5lC66tqVFT3d3SlpvPACdweLjKQ6PWKEFu4IUPLetImO1+IgwrGqfokWLWjmSUmhep6dTZPPihU0Dw0c6Hh+VhaT615/nTb2Tp04TmfSW0CAtl9zgTvGVpkzPZ3nnz9P7eD8eefZsgYDTUZqeQ+AkmNGhpZk5u5Of0lcnHaMtze1tOTkspdUuNlQdx4rXN64cLXQyEjHzXWcPXN3dy1qKDy8eP/I2bO8xoEDxe9uFhKimXnsd0orK+zLhqj3t307tQCjUSvXXZpd1qoKahZ5cjKjy8qijRgMNA0mJ1PbLkvJ7ZJQLtOQoihWAGsBPCQihwq+OyIiNSpnWOVDRRlB3759sX79ehw/fhxBQUG4fv26LUTUHmoUUNu2bZGZmYndu3c7+A/UctTVq1fHxYsXkZmZiZiY7VCU+jh8WFMHH3qIxLdjR2DhQoGPTyrS0moAyIHBYITZbMQvvzDUcu9eEtI1axg22acPF267diSu58/TPti1Kxfopk3Fmyzs4eFBQv/88xozmDWLyVmDB/O3sWP5vQpvbxLHOnVIwJs3L9qvxaLV0jl6lIR0yRL6FgCacdLTuUDVkNXiUJghFIfx4/kMUlPJEOyZgjOYTGQugYE0MZV1O0Fn8Pbm4o6IIAGtV69sWcMqAa5offmyorQMojgEBDhuI2m/D3JZQyjj4oqa5srKIM6do1N13jwtSsjfv2i/yclkQhU1DWVk0D+mPoeYGK1P1YRTeP+CwrkLZYW6naV6H927ayVWyoryMoJ7APQD0AbcOOZ7ALNEpHr5hlE5qAgjEBFERkaiU6dOmD59OkKcZOio+wyrmD17Nh566CEHJ3FiYiL279+PyMhIDBkyBK+88goMBm8YDNcxdKhiy4IVIUdPTrZg+XIFIjoAawC0Q1iYBf376/HOO3TINmhASWDPHsYyl0Q09XpKDLm5nHyqIvPZZ2QehaFKSZ99Rlt5u3bMLA4PZ2SSXYI0AC7S1FRK8UOH0sn9yCOUvO2zYffvd5S6DAZGyTRtygilDRu4QNRN4UuTEGWxOF84ZjN9FJ99xtyGr7/WiEZWVtGIoowMhsB+8w3H6Wya+/vTUd64sbahuZsbjz9wQKu5f/CgY+x9ZaGwf6F1a76b0hS0q0xYrcUzguvXizpld+1ihExQkPNtJIvbqvL0aeeb1Ns/2+rVHX029s8iK4uax7FjLLx48CD7jYjgnGvWrPgEuZo1qT3aM96DB7UaXyUhJ4fzedkyR0HC3Z3XjoykQOBss3sRjjs9nY53tR5SaeHuzpaXx35eeYWCW3lQrvBREVkIYKGiKF4A7gZLTYQqivIRgJ9EZHn5hvPv4dChQzh37hzatWuHgwcPOvymmnsMhVbhtGnTHJhASEgI7r33Xrz66qto37493ArCM6pVewBHjigOSV/79zPKJS9vM0RagG6FdjAYgB079HjiCRJdNUnrqac40YcOpfkhK4sEMDWVUn2fPlrUjMFA9dPfnxEMbdtSui9J6nnoIS76Rx7hcUeOsAH8rNfTWfvLLzQbnTypmWM+/lirj6SWUOjUiWOIjqaJas8eFspbtozHRUSQsC1aRI1iyRI6v0uCXu8YHWKPTz8lgRgzhtFAixdTKrNfgBkZTEp7802ahjw9SVhycqi1GAxkJGodpt9/JzMcPFgL27Sv7ArwHTiLOhHhO16yhO3AAT7HVq0YZdS4MRm2/f2oUrk9QVy/nuY7gMyyZ09qgO3b3xymoNMV/8y9vUnoEhM59t27tTyS0FCGDzdrVrrrJCay9ezJzyIk6KtXc16fOkVmsXMnNeLCYabF4exZ7R2UBD8/zsOaNXmN9etL7/B2BnVOHT1auuPVaro1anDdBwRwjYSEODIoq5XHZmSQWanzBKi60iNl2qpSUZQAAL0B9P1/7Z13fBRl/sc/z6aRaiB0QiD0JuBRBJViOYVTsaCgB/wAFTwRe0NRQawIeHCKZ0XRAxEV0RMULCh6WEARJIFAgNAhoUpC+n5/f3z2ycxudpNNWQLs83695pXs7OzszOzM9/t86yMilWyGWjWqYhHo0X1KSgpWr15dUkwGWK4gz2Zz1nSTJC0tDVdccQW2bNmCV155BU8//TR27dqFs86ag7y8UTh8WJUIppkznbjnHgeAbXA4msPppLPv9tvZeyg5mW6Fzz/njfDrrxTodevy5oqJoVBZupRKoU4dTgD/wgscbZ/nagTucPDG9sdkfOkluoTsKEXh/sknTLts145mt56VqUMH96ZzvtCte7t04Tls2MDPXX453UXHj3OGMl0UV1k+/5zNyKKieMznnltaAQwYQGXWq5flY01PZ9rru+9aVlRUlJWid+653K9udGdHxwjKasmQkmK5q1JTrfXNmrmPnD1TQgH+vuvWsYnemjW09uLiePwXXMCU1x49eC75+RwcbNvmbgk5ncy+2rPHfyGqiYri733WWTy//HwK5tRUCsxNm7hdUhLv2bAwZqQdO0bFesMNVmZO06a8VrqFgx0RnucHH7CJXHp62ccVEWGl0rZpY/2vs81WrrQUelVcMKGhVlsP/Rt//TUton79WBjqOUCw41kQZz/fggIq/++/57J9u38zrOlZy9q3pxX0xx88jkB0H63wnMU1TVUUwahRo7BkyRJkZmbisccew9NPP+32vreOo/Z1DRo0wOrVq5Hk6mT27LPP4uGHH0ZcXBz+/PMX9OrVAD/+yKdcRNCiRSoyMqIBNAdgCcrffrNG0W3bciR5/fVc/+efbCynUzVffJE5/UuWMAC9fDnrDh58kKMxEfYof+WV8s9/61YKIm+Nqx56iIFjgA+3Upbfe+1auoViYhhn2LePD/DWrVbVZXl0785z//13pqLed1/VfLapqRx179lDxfLtt0zXHDCARW1ldVbdt4/nZA806rTT8tAN1ezuEHvPHhEK0O++47XZsYPLzp2lc/Irg6+K7FMNXf3brBn/RkYy337DBsa1HA4OGPr04TX0FhAND+doWb8nwq6mGzfS6vzjD9+/WZMmHG0fPFi6ziQ+nm7FAwfK/8110oXunlpeUzpvZGVZ/bgADuAGDaJS3bGDz5Je7MVouqDvxAlr4PLMM0wDrwxVrSw+Y1i5ciX69OkDpRQ2b95c0lBO/42Pj8cRlw9A1xTYFUNsbCwef/xxAAwWv/rqqwgJCUG/fqPx3/+2RWjoB6DBBEye/CwyMu5CTExBiV9RT+bRtavlPklL49/UVAqQFSso4M86iwJZu5qWLuVN0bcvHwjdEqlWLY6Cy8PpZHWwpxKoV4836tSpFJCzZ7sXdWklEBtLYZtsixCJsB31e+9RiRw9SiGfnMxiuMaNOfoZP56j3OhoZjY98ADPd/Jk94BbRUhKAoYP54Ohr0VcHC2Dt99mIL1tW99VndHRHGFrt4bTyQfxu+94rNr/3LAhlVirVrx2e/fynBYutBrJARwNR0RYvewDQXi49wlZqgvdm19bBHYhWa+eNVrWzfAOHaLgSkujQLNbJzqTyMu03wC47dq1XCpLRARdLJ060d3StCnXbdhAt6F9vBgRQeu6YUMr48h+fnpyniZNaM2GhfG3zsigQl+3rmoKOCKC99qNN7pbFo0b87g0J05w0JCRwQHKihXuFdy+alCqStAogt27d2P79u24w+UXSUlJKckWCg8PR15eHhy2YYk3S8npdOLtt98GADRs2BAZrqFGbCwjtH/88Tzy8wfhzTffxJQpywE8guzsKCjFBykzk10ylWIVLmD5gFNSmGqqlYRuPduyJW/Azz+nQI6I4LZbt/Jzd93lXx+dkSMtP6Nm2DC2e/7hByqJd97hA/Tww7Qytm3zrQQAjrzfe4/CWLfHvugixjJGjaKAvuYazmg2YgRdS7/9RoGtW0xHRXG/zZvzYU5O5j46d/auIDxdQJddRsuguNgKQC5cWH2VpPv3s7VyeYSGWoVT/hAeztFycrLlM05I8J3CmZTkXqi3YwcFRU4OhXFGBn8ve3VzRSkraJyVxWXdusrvv7rJz7dG0p44HLyHrrqKg6+YGFpkKSmllRxAt2VamjUwC8Sxrl5tPfeVpSo9s8oiaBTB965mI3379oWIIN129+iagEO27lCeKaUtWrRAWloa6tSpg8aNG2P37t3o1KkTNmzYgD17OqNRoxzs27cGY8eOxbvvvouWLT/E1q0CQEHEcp/ojpg6W0H3pn/mGQrQTz6xsiPGjeM2mzdzFKorff/zH/4ND6fPuyxEqCz0Z8LC+H29elEJhITQB7ppE5XQ0aMU6rp6MS6OysFTCbzzDtM4b7qJqa+av/6VWU9XXkklMmMGTfGmTenb3bzZfSR94oR7MEwTEkLhp7N6WrSgEHr5ZV7LgQOpiNq3p4Bq1sxSqiIU4Onp/vvK9W9kb/OtOXaMQuToUQrgjAy+1vvu14/ZHBdcwNe7drGCWk+Uo5c9e9xHzVlZHHUur2LaRXQ03ReDBlmZO1XJ068KO3da/vbylGJREa1grbSLingf/v477wcdmouOpqJs1ox/GzWiWycjw/o99O9WqxZdTlFRvNc82zEwi8+aLKhpU/fjFOGA7eBBWgfe4jmV5dAhxjS++85yEzkc/B77+e3bx+y41q15X9mz7dq0qb7jsRM0MYK33noL06dPx7p165CZmYkmHlP9eIsP2HnuuefQr18/9O7du6SAbNCgQVi58hfk5u7G6NGCjz9OxL59+9CnT19s2PAtjhzh8K5zZ/7wSUnuM1jpm7dvX464leJI+v33GcDUbSr01JLbt/NGqVOHD8+dd1qziInwfbug2buXo/tVq/g6NpbfGRbGm9JzdLFhA1Ps6tThzahbHYSHM1g5ZAh98CkpfN2nD60Xb5kMespNPUtTaChdNSI8r65d6Sbau5fCY8cO/3LZmzTh544epaDXXUnDwkq3evDlGrLXP9gnhvGmBOzoCUj0vmvXprB56y0qi/r1+X179ri3iGjVyj1X/uhRS/n5250yLIxCKynJWpo1o7Bo1Mh/S6RhQ98ZQjVBfj7voYULGfQ9fpz337XX0pLs2tW/+ZQPHKALp1Mn9wlijh5lTCEkhNc+UCPqirJ3LxWCPXssPd16fq+7ji7O6lToJljswfLly3HZZZe5rfOsFvYkOzsb06dPxxNPPIGIiAjccMMNWLVqFWrXHoqff56CJUuA7dtn47PPPkPfvovwyCORJYG9v/yFLhHd62fnTj7EAB/gAwfoCioqYipjdjYF7iefcJvLLrP6jSxeTHcLwJupUSP+P24c20T7QheIORyscNYN8Tz58kuOtps04ag2K4sP6YcfWk3mlGLw7+9/57l16ECLwTOIVlhIP2379laOPsBJViZPdheSOuDqcPA409Lo59+0qXyfuJ5spV49KhR/0/kACm8d9G3RwveDd/QoBU1aGv96tsXWfX6Ki6mshw+nMGvfvvzuk5mZFAS+3DpamGmBoX+HyqJHxZ79kU6mgsjL46j32WepOLXwv/56Fl+eDjO0VTf5+by/dDp4dVUUa4wi8ODuu+/GLD2U/owbsgAAIABJREFUdqGUQmhoqFdl0KxZM2RkZOC8887D7t27sWvXLqxYsQIXXnghzj9/Ndas6Y7Dhzli/OMPVtTq3fTqRYHmdFIZnHMOBe0XX/CHHjLEyiH/5hu6UwC6js4/nz7ghAQK+hkzKHB37ODDojtir1rFbb2RkMBRYEqKpZDWr2cKoC/WrqVQtnXphtNJF8bw4Tymdu3o+ihvFA3QvaSFvRZAmZkUqPbRkOcoOjKSx1q/PpWfCEdRmzbRtB82jMpn7Voqwfx8Kqd77+W+fLmG8vKs1te6LXNqKq9rZYiL40i0XTsK82+/pfCOjKQCbNvWyqFv29Y9GG+ncWPvKZee6CIvz4ndy0PE8pPrgkB78oBWEPbfyZuCryxxcfw93niDCmDvXgq8CRP4e3q2fj56tOYypMLDTy3LqTowWUMefO+lObmIICEhAfu9zIByzTXX4MiRI/j5558RGxuLvn37lkxpuXNnB1x4IZVAdjZHNLrFsghLwn/6iaPNrl2ZTaMzhpxOFnlpPvqII8uePS3BvmIFH9aBA+ky0sJKB2eLi60CHY3DQSE5cyYnjb/jDr5evZoZCmUpAYDKyhOnk5lBOTk8pl69rFTJskapeXkc5aSkMOg6Z471Xr9+tAz69+c56uKZDRtYb7BuHa/HgQNMj3U4GDxv2ZKWy/79tGyuu47XY9o0vp4/nwrh0UcpeAEKFT3R+vLllqLWk9icfz4wZgyVTkXIybHmYv74Y/cgdW4uz6EiAdb4eCqV/v35O+lZweyjw7AwuhvPOcd7a2x/KSqyXGT2at9vvgnM3Lg6hlNURIt48mSrHuTrr93ddKmp7rGkmqBRo9KWU7t23iuIASvj6nQkoBaBUmoAgFkAQsD2FM952WYIgMlg2e06Efl7WfusqkUgIoiOji5pJ21vPZ2QkOAWMNakp6dj7dq1uP56poZ+8MEH+OWXXzBz5qcoLNyEWbPor7/9dgqss86iQGjZkiOqr75iWmVEBAO3gDUv7fbtHHGJ0D10+DDdP1ddxe1uv52+wk2bKNRyczlS17nYw4e7F3pdcAEDucnJFLxXXcUg4h130Noor+ePLx57jIGruXM56UdlOXjQaqMxaxZjEXaFcPQohcPy5aw1mDKFI1/P/jg6vRPgw9e6NR9W3R7jq68ozM47j9d61SoK/6QkKg6dv96iRfWNeLWv2rMNMsDfbf9+a6pLb5/dvJlK098At1I8X7t7pzqauhUVMQMpNZUWkzcKC2nV6XPat49/Dx4sexRfuzafA18zztWvb51HixYnv92G5sQJS8GnpvoXv2rThgPBIUOoxE81pVDlNtSVWUDhvxVAC3BGs3UAOnhs0xrAWgC1Xa/rl7ffqrah3rhxo8CjjTQAqVWrltt6vcTHx4uIyC233CIhISHSpEkTKSwslN69e0ty8nQBRDZvZgvmsDCRoUOt1rdvvsnWsboNNSDSsaP1/sSJ1nH98gvXNWokUlzMdU6nSHKyyKWXWq2rAZF33uH7H35otdgFRK680vrsb7+JREezvXN2NttVn3UW2z9XlGXLeA433VSFC++FEydEZs3iOQMiPXuKNG3K6/jmm2V/Ni9PZM4ckZiY0i2JA7HExIj06CEyapTI88+LLFnC31xf7+oiL0/k00/ZClyfW2SkSPfuIqNHizz9tMhzz3GZNEnkhhtEzj6brapPxnXwtoSEiLRrJzJ4MO9pfXyey+LFbGn+8stsk96tm0hcXM0d9+m43Hhj5e8tlNGGOpD6tieAdBHZBgBKqQVgzyJb8T3GAJgtIkcAQEQyA3g8AIC5c+e6vdbWgLcOpAAwcOBAiAg+++wzFBcXY9y4cSgqKsKvv/6KxMQ30bIlR6P/+Ae3dxUdIyrK8om2aQM8/jizIOzGjH1krsvGJ0yw3AA6bTQ/3yrMufxyWgGpqSxO4bHz76RJ/Ozu3axCrlOHmRi5uQz23nqrb7PWF3v38vs6dEBJM73qIjKSltSYMUyNffll3u6tWnFknZ7ufdpGgKPK0aMZK/nPf6xRdFERrarMTGbyNGjA0e3q1Xzv7LOZpVXRVtKHD/OaL1tGq0qjp+QMBCLcf34+7xt97+h6BX2f6EliHA5LZJSFfdYw/XnPeXG9be/5OR0gV8pKkV2yxPe52N1NsbEc9V93HV0w+jfT9QpZWdU3KXxZhIfzXqhXj9ZIvXpc9PzOFcU+Y523pIXQUOs74uMr/h0DBlT8mPwhYK4hpdR1AAaIyC2u1yMAnCsi423bLAawGexwGgJgsoh84WVfY8FZ0pCUlNRtRyWjekVFRahduzayvfQi9uw6CrDQbOPGjcjPz0eHDh0QGhqKvXv3Ii0tDX36XILw8GyMHRuK+++nMrjlFhZ+ZWSwsdu2bXRRaGH24otWpXDXru5VlTExNLf//NMqHHrqKbpkdO5/ZCSFY0gIP6/N6+ho+uy/+opxij596E753/8o+F54gW6W8oLEpa8Xu4muXm1l/wSCV15h9XHr1qyz+OILuo4A+sGvv56LL6XgD5mZrNiePZtxi3HjGPOojAvFPvOYZ8puoCgq4n21aRPvAW/upehoa1YsX1k3f/5J983hw+7HnZxMN2J4ON0gBw8yrXXXLt5L+v7Twe/K9MnXU1MWFfHe1ddwyxbv6bYnwzV05IjlcrQrnpiYqmcuifB3ErHm6vbnmoWFWa5Oe4yiovMaeHIqB4tDQfdQfwCJAFYqpc4WEbexgIi8BuA1gDGCyn7ZE0884VUJOBwO9O/fH0uXLnVb/+KLL6JFixZ4ztWE56qrrkK9evUwZ84cAP1QUBCKgQOZAQGwuEqncI4fz+yhsDA+uDNnMlAaHs6bQ1sQACtwc3L4IGoloNs+KEW/amYmhVjt2vSlHzjAm6pOHT60Dz7Ih+mGG5i5tGQJhb4I8Npr/gWJS18vZunMnRsYJVBUxPqIl15iUP2992hFTZpE3/SHH7I52SOPcGnThoFUuz+8TRvvU2N6Ur++Nd3mk0/yWi5dyt+kX7+KHXedOgwu+8rUCjT5+YyhrFpltW3u0IHH5S+FhbQuV6xg7cpbb7Hp4dKlpbNlcnPdc/3XreOIviI5+SK8h70J/MGDrd+0rLYggUSEyknHBDwb+vmD00kr1D4H9eHDlAGtWnHx55rl5jJW9NFH7LiriY+nHKlMjK88AmkR9AZH+Je5Xj8MACLyrG2bVwD8LCJvuV5/DWCCiPgsxK5ssPjll1/G7bff7vW9qVOn4sknn3RTEiEhIcjLy0NoaCg6dOiAjRs3YsGCBSgqKsK0adOwY8c9yMsbibVrmcFxyy0U5u+8w+ZUL71EV1DjxhyF/fYbb3Q9e9KRI1ZTty5dOFpPSeE2hYXsb7N+vZXy2bkzKy5vvpkPraZ5c46y1q61ZjT7978tRfPpp1QwFQ0SL19OM3T0aOZ7VzdHjjCo9tVXtFamTvXtYtFK4YcfShfehITwAfNMeyxPQXz7La/Hzp1Uks2b0xXnyx1hn6FMf5ful+8ZWNSj3ED1BKoOsrM5mEhIoIDRr3WPfV8jV92GIje3fBeUJyEh1twYYWHlj469zQfdtq1/iv9ksW0bBysffcTn0/6bayW9d69l/ffqZc3gp93IvtDK035fDRtmVbBXlBqpI1BKhYJun4sB7AGwGsDfRSTFts0AADeKyEilVF0wcNxVRHzWWlZWEYwYMQLz5s2Dt/OdMmVKSTM5Tbdu3TB+/HgsW7YMCxYscHsvPDwccXF70b17Apo1o2DesIHCOi+PLp2vvqKwCQkBbruNykG3YmjXjmYxQNdCixbMINJxgJdfZrYQwAczP583nI43hIbyhhs0iIJ+3jx+7803U6hOn87PpqQwa6ZZM+Dnn/3LUQd443btylH0L79UPK5QHllZ9NNv3Uq30E03VezzeXnufdr1g+KpIJKTfVcWZ2S4ty0OCaHS9VXCr2MEdq9keDhjELt3W0JRV1C3bev/9T7Z5OVxZB8by2JF7W7IyKCVUbdu4Iq68vM5atbL0aNlTynpdFJJ6evrcPB58WU1JCaWLpSrbDVxURHvKbsg3rqVAy99D+lOAT170lLX3+mZuZWebrUo10qha1fKDPvgolkzqzBRN8ezf/9jj9GCqgw14hoSkSKl1HgAy0D//xwRSVFKTQGj15+63rtUKZUKoBjAA2Upgaowbdo0LFy40G1uAYBuoalTp5bafvDgwRg9ejSiXb9mz549cffdd6Nz584IDW2Ddu3CcO65rBQeM4ams76hR45k2qN2A40bx947zZvzxtGVwQC3A2ieAyzQmjyZlsSBA9zn6NH87G23Wb2JmjWjS6hZM1oe7dpR6OtT0fMAREUxjdRfoVRQwCB0Tg5v2upWArm5tFAyMmh19O9f8X3UqsUHqHNn9/WeCmLLFu+pmEpRAOoH8PBhWlOrV9P11rmz94rbwkK6Rb76igoyNZWf7dKFbrfzz2dMpUWLUy91UCPC0ahS7I3v6fJ7/32OOvft8+4m8tzX3r3ugsrXnMUiVJj2tFHdIykx0XeDwU2b3IsWleJ9r11TcXFcoqOtSX907Y0mKYmDGhHef7m5PMbcXArcWrX4fOglLIxWj2cKsL4Wnt5lpXgfrFjBpSxCQ3mvHD5sCXr7dzgclBv5+e4WV3g4j23t2sorgjKPq/p3aSEiSwEs9Vj3uO1/AXCvawkojz/+OAoKChAREYF8210SFxeHo178AQ1cZbWxsbHIycnBF198gdquJia6PYOekeqhh+jKATi5yU8/UaDWqkX3yu7dHEkkJnIbnYd/6JBVA6DXTZvGEXPdurxJIyPp6snMZEWmHvFOmEDFMGsWYwy7dnG7kBDexIMGcT8rV5ZvgmpEmFm0ciWPq7rjAk4nFd6PP9LVUxklUBa+FIQ/9O/P2MEXX9C95ilIYmLc3T1K0eJo25brf/+dE94AFFCeldS6n31NK4j33+f9MnWq99936FD+HTaMcZulSylkPQW+/l/PVgbQzdS+ve+MLM/4jmfDN18cP24Vmdm/2z75T61aVtV2z54U9CdOcECTk1O6FkApnldICN2UWVnWe2Fh3gdOMTE87oED+XwVFLgfS0Xmw9ayAOA9lZ3N5fhxHntUFL9PLzporiejqm5qOlh80mjUqBGUUqUsAs+pKTW6wnj//v1ITk4uUQIAzeqkJPoFx4yhYNM30vjxzNIB+IPecQeDyfXqUSFERFjuh8WLrdF9+/Ychc2YwRHDH39wmyee4Gduu42jW6UorL/4gsHBm27izaFvUKeTSmX1ala6duvm/zV65hnGEiZNYmVudfPYYww4Pv98YEY1VSE6mllEzz3nbpZr4ZOdTavOPjev3Vo6dKi0oFy61D2eoxVEdXa0rAgFBYyznHUWK3l1ixJvdOzIbfWAxG5ZhYVROMXF0XKNjubriAjen9o9o5eGDaumAGNjOcA691z39cePu/dg2riRwl6kdJprQgI/360b25xfeKHlXrJbNvo33LPHij1p5eUtGF/ZieRPNYKm19ChQ4fw8ccfY8yYMYiNjcVxl70ZFRWF3Nxct9hBVFQUrr76aixevBgnTpzAxIkT8dRTTwGwZgrTwdz0dAri3butkVNCAvfTvDkzdi66iJ/57DNu+7//8f1LL2WrBD072K23Wi0Yioropti/nyb8JZfwQROxXCqPP85A58CBVjD4oYcoaF94gRk5/rJgAV1Cw4cz4F3dI9c5cxjDGDuWcYGaHhmfLDwVRGpq9U8uYnd56MXbY52Xx+Xss/1zFerc/ogIbh8VZblOfKGVqL2BXu3aVlPAQKK7yqallQ7aFhe7V0nXqkVlXtE0WIeDz7VWEO3bW0kfgOUCsw8IfDUTjIriMeh96eSDQGGazrn45JNPcPXVV7spAqB0C+rmzZsjMjISaWlpcDqdWLt2Lbp27YojR2jexsTwhhszhr7mq67iDTJ6NAXzLbdwP7NmcdSfmsqbJT2dgvrZZzmaqV2bN+i6dXy4OnXiqOPQId5Q775LxdGli9U59PbbOeqZN4839pAh1vy1c+dS0I4bx6wlf4XtqlVUVj17UjFVJCtDZ/Rs386YxMUXlxYUX39NF9mFF1KRBmNnyerA3o/Js32xPS0zOdl7fYRSbMhXlRYh/mDPdrEfq92NFCg8G+fZ52bwtCD0yL8iFBbyWbO7DvUczX/+WbpHUr16vi2iY8dKJx+0bUuPga8eUjfdxEFhZaiRFhOBWqrSYuLee+8VABIeHi6A1V7Cc+nbt684HA4B2GKi2NVHYORIltNfeSVL+nfsYEsEXc/5/fcinTvz/6gotiEARO6+29rmo494LP/5D1/36MHXgwa5twkYOFDk8GGRtm3ZQiIhQSQigi0GHA6W9F9xhbWPESN4bAMHihQW+n9N0tNF6tYVad1a5OBB/z6zY4fIjBkivXpZx1urFv/WqcNWFJ9/LlJQIJKSwtYWHTuKHD3q/3EZRIqKRObPF7n2Wt4HISHW9XY4RNq0EbnmGrZ1mD9fZN06kdzcmj7qM5+iIpEtW9gy4+mnRYYNE/nLX0T69xe5/Xa20Pj2W5HMzPL3lZ0tsnq1yNtvizz4oMjll/PZbt3a+zJ/fuWPG2W0mKhxwV7RpbKKYN06kYYN73ET+JGRkW6vlVICQIYMGVKy7kZXc4/PPuPV6tOHfx94QOSDD/h/dLRIy5YU3Epx3fjxIhdeKNKwocg991j9gHbu5PH06MHXy5aJrFxpPeBaGfz8s8hFF1kPv8NBIa+3a9SIPWiUEmnShAppwACRY8f8vyaHDlHA1KnDfknl8emn7sK/a1c+CJs3UwB98gkfithYSyk0aMAlI6MSP1qQohVAu3a8js2aUeA/+qgR+IbKYxSBiLz0kgjwfwJEl7IAtALQiuGGG24oeW/+/Ply+LBI48Yi9erxio0eLZKfbzVLA0SefJKNtfTrd97h35kzRTp1okJo0ICN5E6coABPSODovXFjbhsaKtKqFRuM3XIL1zVtKhIfz/e0Mhk9miMSpUQefrhSl0Py8zmCCQ+nIiqPr7/mMbRtawl/X9iVQtu2VGqG8vFUAJ06cbBR3Y3tDMGJUQQuQkLiBWgsgKOUEgAg0dFUEhdeeKEAEIfDIUeOHJGRI62R/ujRfDBffZWvdffEHTusDqHnn29ZA5s3c139+nTliIg89hjX3X8/O25q5TFpkrUeEBkyhH+VspTAbbdRYPzjHxTi+/ZV/Do4nXRzAXRRlUdqKpVRhw7GvRMoFi0yCsAQWIwiEJH9+/e7hHuoAFr495X4+PhSFkJSUpIAkF69epW4hOxKIDubbg+Ao/qLLxbZuNHabupUyxp47TVLmD/xBIVw/fp8PWuW9ZnBgymcdevoxESRfv0s3zsg8tRT+lwYLxgzplKXQp58kvt74onytz1wgK2w69cX2b69ct9n8E1mpsj11/P36NjRKABD4DCKQERef/11L4HhY6JUWKn1Ooj83HP/KukJ/3//Zz2gem6ByEj+ffddBmu1Yujfn9bAiRMiV19tuZSWLmUQCRA55xxrfVycSFoahf4ll3Dd449bCgAQ+ec/rXOZOJGKZNOmil+H+fO5vxEjqJTKIjdXpHdvHtdPP1X8uwxls3AhA/Xh4SLPPFOxIL/BUFGMIhCRG2+80Yuwv6aUEggLsxRD27ZHBHCf8GXtWj64SnEEFxvLAK0O8mq3zsyZ9MPHxDCjQClm5Zx3Ht+/9VZLyM+bJ/Kvf/H/xERONHLOOdb79glsjh+nm+aaayp+DX74gZZE376cAKUsioutSXY+/LDi32Xwjd0K6N5d5I8/avqIDMGAUQQi0rdv31KC3r6EhkZJWFiYJCQkCBAhISFPCCDSpYulBI4dYwpXbCwFe2SkyM03W6mgUVF052hr4JtvuL55c5ELLhDZsIGvHQ4rQJycTJ9/p05WKuodd1hK4Jxz3M/jn//k+h9/rNj5VzRN9JFHpMTNZag6+fkU+K++aqwAQ81QliIImhYT999/P1auXAmHjzJCpzMR0dEHkJMzBMB2FBdPROfOnJBFz/w0dix7BkVFccKU335j7xzdjmHYMPYPnzmTFZiff85KwYwMtpqYPp2FJR06sFspwOrgn3/m65gYoEcPFoNpPvnE+n/DBrZ/6NeP7Wz95fBhFns5nSzo0pXPvnjrLauZ3gMP+P89gWTrVvbL90ZcHK9JVbp9Op1syxERwQK+ylY+FxSwwM+zmMreAK97d17jTp0qf7wGQ7XiS0Ocqkv1xgj04hDgIXE4vhNgkQDHpEWLHDl+3Pr8K69whPyXv3BO3XPPZe3Anj1cHxrKrJpGjWgNiHCU36oV3//f/7gNYAWa69XjSHHkSO5TWwvaGrjjDuv79+0TSUri/nUtgj/k5VUsTXTfPlo6F1/MgrBA4HRyTmV/Cm62bLEK+ewxE88lJobzuS5aZF3/8iguprvsrrtYi6H31bKlyIQJIr/+6juOkp9PC+/995ntdd11Iu3bW7+x/i1btxa56ipaWPPm0bVYVOTvlTIYqg8Y15DIp58ul759h/tQBOMEyBfgmAC7Bdglu3ZZEmDtWvrWzz2XV+y22/j3ySeZJgpQ4Cslsnw5P7Nzp5S4frp0EbnvPisFVS/TprEITccc7O9de63lx8/JYQFaVJTImjX+n3NWFuMB/qaJiojcey+F7pYt/n9PRThwgBlSWlBefDGVrKdSsCuAyEge1++/s1LZc1m2jBlUCQnuSuH990W+/LL08tln7sI/IoJB/XnzRN54Q+TSSy3Fo5XC/PkVF/j+KiSD4WRgFIGIjBy5U4B3SymB6Og5rgd6owC/C3BckpOtSKyOCzRuzOBwYqKVtbNtm7sAf+wx6/vsaaMPPUThFB9vBZVjYpiTr/P57UunTtZItLiYSkEplrT7S0qKSIsWFHLz5vn3GW0NjBzp//f4i9MpsmABhXV4OFNXJ05kmwS7Upg9u7QC8LdWorCQgt6uFHwtduHvrRr74MHSSsEIfMPpjFEEIvLII88LEOmhCJ51CYbpAqwUoEiAy2XSpEkiQuE1dCgFge4X9NJLDPZdcglbR2hh37+/u8l/9dUitWvz/YsvLi2I7riDmT/2dVqp2APBDzzAdfb00fJYupQpqQ0bViztM1DWgN0K6NGDLhWN08mWCXalUFEF4I3CQpFffmH/J8/lhx8q1orj4EEeoxH4htMZowhEZMqUF0SpWi4FECJANwFE6tefK2Fh/3IJ4/ECOCQ9PV1ErLjAI4+wcVr//lZvno0bOarUPv+9e63v0mmjiYl05wAcRdpdCfHxVlxAL/Xq0ZWj0dXL48aVn/Mvwm1eeIH7P+cckV27/L8+gbAGPK2AZ58tO0vG6eR19Sd2YDAYKoZRBCIyeXKuAI1s1sAKARa4/orEx7/jWt9Zjh93luTcDxjAYjIdIA4LE/nuO8v1A1hxAY1OG9Uj/JkzrdGuXnr2tFJIAVYtA/Rfi9DvXZFuovn5Vn+iwYNZ/VwRqtMacDp5TXTNhKcVYDAYTj5GEYjI9dfvEKCFAC0FGCbAYZcQ3iPAY9KgQWOXIpgp06ZZOfe6lfTZZ/Pvu+/Sb69H+pddVvq77r3XEvB33mkFjvVy//0ic+dar0eN4v47duS+V61irULnziJ//ln2eRUWcl86O+nRRyveoqC6rAFPBdC0qci//21y5Q2GUwGjCETknnumCvBGiQUAFIrD8aQAHQRwChAlACQkZJ+EhdHH/s03FNC6sdyECfQt27uM5uS4f09BgbV9TAyFoG5GBzC2kJ9v9RCKjxf5+GP+//bblhJo1Upk927f5+OpALp2pdKqDFW1BnwpgPKqlw0Gw8nDKAIRqVVrl80C+M7lurlTxo59QO69N81lDYSLUsVlZpvYl7/+1f07CgqsOQNCQuiq8QwI//ij+7pFixh7SEyky6k8JeBNASxe7F8MwRvaGhg1qmKfczqZzmkP8hoFYDCcuhhFICK33fa9APcIkCjAmwJkCJAvjRrlSWhoiksRtC8R0H36WLniMTFWg7mICCudcPVqa/8FBUzztAv9v/3N+j8igvtctMha160bs3p0FlF5SmDnTha0VYcC0FTEGrAL/9atpSTwffHFTLU0CsBgOHUxikBE6tef5RL2y1yCuEAAkaQkpzRoMN713nbp0KFYoqPdBXpcHAPGTz7J2IBSzNHXQtiuBM4+m9vYM4K0G+j118Vt35s3s0ApJoZLWUrgp584sU1sLAulqqoARPy3BpxOTjSjlZC9EOzAgaofh8FgCDxGEYhIUtI1AsS4rILFAqQIUOwSbGcJECrAOjcFEBFB4Z2dbWX1AKws1bn+diUwYwaVgGc7hDp1mCXUvbuVSTRqFNssKMXUyrKUwLx5PJbk5OrNvinPGtAKQHdCbdmS87Ea4W8wnH7UmCIAMABAGoB0ABO8vD8KQBaA313LLeXts7KKID7+HwIkizUpDQSIFeA827rv3CaCAege0sJbKY7I69alMrj2WmtWqQkTmPLpGUdo144j6BtvtNaFh9MaSEjgPpOTvSuB4mK6YQDWF2RlVerUS5GdLTJ9Oi0Vb9aANwXw9tsm+8dgOJ2pEUUAIATAVgAtAIQDWAegg8c2owC8VJH9VlYRxMZ+JcBOAf4U4CcBXhXgdgH6uBTECgEKSwK9ngJd968ZN469hq68Ukq5kDwXHWPQ9QLaXXTFFVarid69vSuB7GzL0rjlFmYaVRWtAOrX534vucS9EE5EZP16a/pMowAMhjOHshSB957M1UNPAOkisk1ECgAsAHBVAL+vTOLjlwJo7np1LhyO/wMwE8BKAKkAIgEo1K4NFBe7f7ZzZ6CwEFi4EMjLA+66CwgLA3JygGnTgO++A1q3Lv2dRUVsZ5yYCFxwAfehFPDZZ2xXPG4csGoV0KSJ9Zlt24CpU4Fu3YDFi4F//hN47TUgPLzy556TA8yYAbRoAdx/P8/n+++BL78MLUtvAAAPnUlEQVQEGjXiNoWFwFNP8Xu3bwfmzAE2bQJGjmQrbYPBcAbjS0NUdQFwHYA3bK9HwGP0D1oE+wCsB/AhgKY+9jUWwBoAa5KSkiqlDdu2XSDAewIkCHCTANcKECfAtwKkukbwTomKslpB2y2D2Fi6g+xB4KlTOe+wpzspLExKprh84w2mVOr3OnemNXDZZVbh19atrE3QwViAo/LPP6/UqZbgdIq88467BfD996W3W7/e+u6hQ6vPBWUwGE4dUEOuIX8UQQKACNf/twL4prz9VtY1dN99RwXo6ooFRAgAadLkeZf//xIBbi0RwkqJDB8usmMHewvFxjL3Pz5eSnz8umjM1xIXRx97jx7WusREBoWbNGE/nS1bLDeMFv7Tp4tkZFTqFN3Yu5fuK0CkVy/vCqCggJlQYWFUFmZKSoPhzKWmFEFvAMtsrx8G8HAZ24cAOFbefiurCObPL5DQ0Nq2QPGDNsEdJ8DgUsK8bl0K0bAwplmedx6Dv7qmwG41NGhABREd7V1JKCUyaBC3//57KoEmTRgwri7hL2JZAfHxtFReeMH7RCh797KOARC54QZjBRgMZzo1pQhCAWwDkAwrWNzRY5tGtv+vAfBTefutrCIYPvwFmxI4X9hWwukKHkcKcGeJYNRdRQGmg8bGWsK8LCvAV7A4Lo7z0wLswGlXAuvWVep0vGK3As47TyQtzfd27dpRaRkrwGAIDspSBAELA4pIkVJqPIBlrtH+HBFJUUpNcR3QpwDuVEoNAlAE4DAYMwgIRUW/uP5zAPgcwH1g6CEBQC6AZiVz4ubnM6jrcAAnTtjPietDQxlcrV2bwdUff2RA1k5CAnDoENCwITB3LjBoEDBgAHDttUD//gw6f/MNA7fVwZdfAkOGcL8vvADceScQElJ6u337gIsuAnbt4pzKffpUz/cbDIbTGF8a4lRdKmsRtGs3ymUN/E0uusgpvXvnuPoKLXGt/7BCo/2yFh08btaMM2bFx7Px3E8/BcYSyMriXAYdO/q2AkTcLQF/5i82GAxnDqgJi+BUY+9e5l86HGPxzTcKQC0AMwBMBJAIwH1oHBXFFM/ISKaG5uQA6elWaqlSFPveyMuj1dCtGy2AhATg7beBwYOr3xIAgPHjgaNHga+/Btq08b6NsQQMBoMvAllHcErRrl1nAA3RocMAREXtA4ueH8Tll1+JAwfWYcaM+mjVytr+xAkK/ePHgd9+A9LS3OsLRICICP7ftCn/hoXRndSkCdCjB7BoET+fmwsMHRoYJfDRR8D77wOTJgFnn+19G6MEDAZDWSjxNaw9RenevbusWbOmwp/LzweSkopw+PAyFBWNApCDKVNm4dFHb4FSqmS7oiJgzBj69UVYyNWqFdCyJX3uR4+y6GvPHioGhwNwOvlebCzQpQvw6KPA9dcDZ50F3HMPhf/mzRTY1akEDh4EOnSgIpo5E1i61LuV8vHHPF6jBAyG4EUp9auIdPf6pi+f0am6VDZGkJKSK+Hhd7riAV1k2rTUMrefMcPy+YeEsBjr4485gXlREXP+depomzbWTGKrVzMmkJxcfSmhvhg6lJlJw4czoykkhBlPnkujRiYmYDAEOygjRhA0FkHPnhOxevUzAO5E8+ZTsX17LZ/bFhdzZJ+fT5fKO+/QrQMAtWoBycnAxo3W6/x8un7OPpstJ2rXBlasAJo1q8QJ+slHHwHXXWdlJ40bx9YUMTGB+06DwXD6UpZFEDQxgt69HwLwBYBZyMiohYkTgd27vW87dy6QkgI89xzw6qvA1q0U9KGhVAhaCQB8LQIsWABMnAjUr28pAaeTbqT//hd4/XXg22+BrKyqn8vOncCIEfw/Npaup9mzjRIwGAyVI2iyhhIS4hAVdRmGDQPeeAN45hkuvXsDV1/NUTzATKGJEznq37MHuPJKYPlyrk9MZOO29evpm1+0iIL4xAlmBH3/PTBwIPDYY1QkGzcyUOxJ3bpAx47cR7t2zEzyl4ICYMIEKwD9xhtGARgMhqoRNK4hEaZ/tm4NjB3LdM777mMAdd06359r2pQumOuvB849l8Hh4mKr4Exz4gQVypdfMmtIC/qOHbk0bAhs2UIFkZrKvykpwJ9/VvwaAMBNNwFvvlm5zxoMhuCjLNdQ0FgESlmtou+7jyPp0FDg99/prikooK/9vPOA889nG2alKMAdHg40bxW7UVHAsmVUCNHR3o8hORm49FLrtQi/u7Cw/OPPz2dm0OzZQNeuwCuv+HfeBoPBUB5Bowj27QP++AP461+Btm05ep89G3joIaBePW7z/PP0+c+a5T5HgL8o5VsJ+Nq+fv3yt1uzBhg1ihbE6NFsIREWVvHjMxgMBm8ETbB49mzgsss42l++HHjgAeDIEVoGAAPC//43cPPN9NufCuTnM17RqxfrF5YsoaUSH1/TR2YwGM4kgiZGkJ/PuMDTT7PCtndvVv0eO0YlMGIEs3vS061Zu2qS1as5+rdbAUYBGAyGymLSR8F2ELfeyoDtK68wdXTDBiqFIUNY9Xv//TWvBNavZ3C6Z09jBRgMhpND0CgCjV0hvPwyA8aLFzMF8/77a+64tALo0oWZRzoF9W9/q7ljMhgMwUHQKQJNRARw222MCwBAdjYLwU423hTA9u3AlCnsVWQwGAyBJmgVgeamm9isrXt34MYbUTI5TaApSwHUqXNyjsFgMBgAowjgcLAa+L//ZcXvlVcybhAojAIwGAynGkGvCDQNGzIwm5MDXHEFM4qqE6MADAbDqYpRBDY6dQI++IBB2qFDOTdBVTEKwGAwnOoYReDBpZcym+jzz4G77vI9HWV5GAVgMBhOF4KmxURFGDuW6aXTp7P6eNIktqXwh/XrKew/+giIiwMefxy4+26ru6nBYDCcahhF4IOpUzlN5cyZLDb7+985BaU3hZCVxZbUH3zACeTj4qg87rrLKACDwXDqY1xDPnA42I5i+3Z2K120iG2lR4zgRPZZWZy05pJLGGj+xz84YcyUKUBGBjB5slECBoPh9CBoeg1VlcxMuopmz7amrXQ62dp6yBDOV9C5MzuKGgwGw6lGWb2GjCKoIJmZVAZOJ4PBRvgbDIbTgRqbmEYpNQDALAAhAN4Qked8bDcYwIcAeohIzUl5P6hfH3jiiZo+CoPBYKg+AhYjUEqFAJgNYCCADgBuVEp18LJdLIC7APwcqGMxGAwGg28CGSzuCSBdRLaJSAGABQCu8rLdkwCmAsgL4LEYDAaDwQeBVARNANi79ux2rStBKfUXAE1FZElZO1JKjVVKrVFKrcnKyqr+IzUYDIYgpsbSR5VSDgAvALivvG1F5DUR6S4i3evpCYYNBoPBUC0EUhHsAdDU9jrRtU4TC6ATgG+VUhkAegH4VCnlNaptMBgMhsAQSEWwGkBrpVSyUiocwA0APtVvisgxEakrIs1FpDmAnwAMOtWzhgwGg+FMI2CKQESKAIwHsAzARgALRSRFKTVFKTUoUN9rMBgMhooR0DoCEVkKYKnHusd9bNs/kMdiMBgMBu+cdpXFSqksADsq+fG6AA5W4+GcLgTreQPBe+7mvIMLf867mYh4zbY57RRBVVBKrfFVYn0mE6znDQTvuZvzDi6qet6m+6jBYDAEOUYRGAwGQ5ATbIrgtZo+gBoiWM8bCN5zN+cdXFTpvIMqRmAwGAyG0gSbRWAwGAwGD4wiMBgMhiAnaBSBUmqAUipNKZWulJpQ08cTKJRSc5RSmUqpDbZ1dZRSXyqltrj+nnGzKSulmiqlViilUpVSKUqpu1zrz+hzV0rVUkr9opRa5zrvJ1zrk5VSP7vu9/ddbV7OOJRSIUqptUqpz1yvz/jzVkplKKX+UEr9rpRa41pXpfs8KBSBv5PknCG8DWCAx7oJAL4WkdYAvna9PtMoAnCfiHQAGxje7vqNz/RzzwdwkYh0AdAVwAClVC9wjo9/ikgrAEcA3FyDxxhI7gJb2GiC5bwvFJGuttqBKt3nQaEI4P8kOac9IrISwGGP1VcBmOv6fy6Aq0/qQZ0ERGSfiPzm+v84KBya4Aw/dyHZrpdhrkUAXARO/wqcgecNAEqpRACXA3jD9VohCM7bB1W6z4NFEZQ7Sc4ZTgMR2ef6fz+ABjV5MIFGKdUcwDng9Kdn/Lm73CO/A8gE8CWArQCOuho/Amfu/T4TwIMAnK7XCQiO8xYAy5VSvyqlxrrWVek+D2jTOcOph4iIUuqMzRlWSsUA+AjA3SLyJweJ5Ew9dxEpBtBVKRUP4GMA7Wr4kAKOUuoKAJki8qtSqn9NH89J5gIR2aOUqg/gS6XUJvublbnPg8UiKG+SnDOdA0qpRgDg+ptZw8cTEJRSYaASmCcii1yrg+LcAUBEjgJYAaA3gHillB7onYn3+/kABrkmtVoAuoRm4cw/b4jIHtffTFDx90QV7/NgUQRlTpITBHwKYKTr/5EAPqnBYwkILv/wmwA2isgLtrfO6HNXStVzWQJQSkUC+CsYH1kB4DrXZmfceYvIwyKS6JrU6gYA34jIMJzh562UilZKxer/AVwKYAOqeJ8HTWWxUupvoE8xBMAcEXm6hg8pICil3gPQH2xLewDAJACLASwEkAS28B4iIp4B5dMapdQFAL4H8Acsn/EjYJzgjD13pVRnMDgYAg7sForIFKVUC3CkXAfAWgDDRSS/5o40cLhcQ/eLyBVn+nm7zu9j18tQAPNF5GmlVAKqcJ8HjSIwGAwGg3eCxTVkMBgMBh8YRWAwGAxBjlEEBoPBEOQYRWAwGAxBjlEEBoPBEOQYRWAweKCUKnZ1dtRLtTWqU0o1t3eGNRhOBUyLCYOhNLki0rWmD8JgOFkYi8Bg8BNXH/jnXb3gf1FKtXKtb66U+kYptV4p9bVSKsm1voFS6mPXXAHrlFLnuXYVopR63TV/wHJXRbDBUGMYRWAwlCbSwzU01PbeMRE5G8BLYKU6ALwIYK6IdAYwD8C/XOv/BeA711wBfwGQ4lrfGsBsEekI4CiAwQE+H4OhTExlscHggVIqW0RivKzPACeB2eZqcLdfRBKUUgcBNBKRQtf6fSJSVymVBSDR3uLA1SL7S9cEIlBKPQQgTESeCvyZGQzeMRaBwVAxxMf/FcHe+6YYJlZnqGGMIjAYKsZQ298fXf+vAjtgAsAwsPkdwCkDbwNKJo8562QdpMFQEcxIxGAoTaRrxi/NFyKiU0hrK6XWg6P6G13r7gDwllLqAQBZAEa71t8F4DWl1M3gyP82APtgMJximBiBweAnrhhBdxE5WNPHYjBUJ8Y1ZDAYDEGOsQgMBoMhyDEWgcFgMAQ5RhEYDAZDkGMUgcFgMAQ5RhEYDAZDkGMUgcFgMAQ5/w/jeZY55dGz6wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGMPwsDqT2ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCjtEji1AXdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNEh8pXvAXdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from platform import python_version\n",
        "\n",
        "print(python_version())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VU1KwlnT2i8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}