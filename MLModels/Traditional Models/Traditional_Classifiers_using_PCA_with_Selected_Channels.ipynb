{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "colab_type": "code",
    "id": "ZiaK5_gNh1vH",
    "outputId": "41a29fea-03fc-4bfc-8ec0-d15bd9ce9050"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using homepath \\Users\\marit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marit\\Anaconda3\\lib\\site-packages\\numba\\decorators.py:146: RuntimeWarning: Caching is not available when the 'parallel' target is in use. Caching is now being disabled to allow execution to continue.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "raw_data_dir = ''\n",
    "acc_key = 'acc'\n",
    "plot_examples = False # notebook file size will increase by 30 to 60MB if set to True; size is <1MB otherwise\n",
    "\n",
    "if  'COLAB_GPU' in os.environ :\n",
    "    print('Using Google Colab. Setting up environment')\n",
    "    raw_data_dir = '/content/drive/My Drive/Colab Notebooks/' \n",
    "    #raw_data_dir = 'Raw/'\n",
    "\n",
    "    !pip install mne==0.19.2\n",
    "    !pip install pyedflib==0.1.15\n",
    "    !pip install chart_studio==1.0.0\n",
    "\n",
    "\n",
    "    print('\\n \\n To load files from Google Drive, account validation is required.')\n",
    "    #mount to drive -- files should be located in the /Colab Notebooks directory\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    \n",
    "    if not os.path.exists('/content/tmp/eeg_sz/ReadData'):\n",
    "      os.makedirs('/content/tmp/eeg_sz/ReadData')\n",
    "      os.makedirs('/content/tmp/eeg_sz/utils')\n",
    "    # download project utilities and data reader \n",
    "    !wget -O/content/tmp/eeg_sz/ReadData/RawDataReader.py https://raw.githubusercontent.com/WinAIML/schizophrenia/master/ReadData/RawDataReader.py\n",
    "    !wget -O/content/tmp/eeg_sz/utils/ModelBuilder.py -P/utils https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ModelBuilder.py\n",
    "    !wget -O/content/tmp/eeg_sz/utils/ChartBuilder.py -P/utils https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ChartBuilder.py\n",
    "    sys.path.append('/content/tmp/eeg_sz/')\n",
    "\n",
    "elif 'KAGGLE_URL_BASE' in os.environ:\n",
    "    acc_key = 'accuracy'\n",
    "    print('Using Kaggle kernel. Setting up environment')\n",
    "    !pip install mne==0.19.2\n",
    "    !pip install pyedflib==0.1.15\n",
    "    !pip install chart_studio==1.0.0\n",
    "    !svn checkout https://github.com/WinAIML/schizophrenia/trunk/Data/Raw\n",
    "    raw_data_dir = 'Raw/'\n",
    "    \n",
    "    # download project utilities and data reader \n",
    "    !svn checkout https://github.com/WinAIML/schizophrenia/trunk/ReadData\n",
    "    !svn checkout https://github.com/WinAIML/schizophrenia/trunk/MLModels/utils Utils\n",
    "\n",
    "\n",
    "else:\n",
    "    # assuming that a local run will be launched only from a github project; \n",
    "    # add the utils and ReadData directories to the temporary path\n",
    "    if 'HOMEPATH' in os.environ:\n",
    "        print('Using homepath ' + os.environ['HOMEPATH'])\n",
    "    raw_data_dir = '../../Data/Raw/'\n",
    "    \n",
    "    from pathlib import Path\n",
    "    import sys\n",
    "    sys.path.append(os.path.realpath('..'))\n",
    "    path = Path(os.getcwd())\n",
    "    sys.path.append(str(path.parent.parent))\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, MaxPooling1D, MaxPooling2D, AveragePooling2D, AveragePooling1D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "from importlib import reload  #reload(chart_builder)\n",
    "\n",
    "\n",
    "#################\n",
    "# import project utilities and the raw data reader\n",
    "# Kaggle environment does not accept 'utils' as a file, so it must be accessed seperately\n",
    "\n",
    "import ReadData.RawDataReader as data_reader\n",
    "if 'KAGGLE_URL_BASE' in os.environ:\n",
    "    import Utils.ModelBuilder as model_builder\n",
    "    import Utils.ChartBuilder as chart_builder\n",
    "else:\n",
    "    import utils.ModelBuilder as model_builder\n",
    "    import utils.ChartBuilder as chart_builder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxtrV9-nh1xR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random \n",
    "import math\n",
    "\n",
    "#svm imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BhSgQiKh1xa"
   },
   "outputs": [],
   "source": [
    "ignore_list = [] #['s12', 's14']  #list of patient files that should be skipped\n",
    "resolution_hz =  250 #EEG values per second\n",
    "#seconds of data to include in one slice\n",
    "time_window = resolution_hz * 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V37IOjv2h1xh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum duration:  740\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "#returns file duration in seconds\n",
    "def get_edf_file_duration(file_name):\n",
    "    f = pyedflib.EdfReader(file_name)\n",
    "    duration = f.file_duration\n",
    "    f.close()\n",
    "    return  duration\n",
    "\n",
    "# get the minimum length of the files\n",
    "def get_minimum_duration(group_directory_name, patient_group_file_prefix):\n",
    "    file_durations = []\n",
    "    for i in range (1, 15): # reading 14 files\n",
    "        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n",
    "        file_name = raw_data_dir +'{}/{}.edf'.format(group_directory_name, patient_id)\n",
    "        file_durations.append(get_edf_file_duration(file_name))\n",
    "\n",
    "    return(min(file_durations))\n",
    "\n",
    "\n",
    "minimum_duration = min(get_minimum_duration(\"Healthy Controls\", \"h\"), get_minimum_duration('SZ Patients', 's'))\n",
    "print('Minimum duration: ', minimum_duration)\n",
    "all_channels = ['Fp2', 'F8', 'T4', 'T6', 'O2', 'Fp1', 'F7', 'T3', 'T5', 'O1', 'F4',\n",
    "                'C4' , 'P4', 'F3', 'C3', 'P3', 'Fz' , 'Cz', 'Pz']\n",
    "\n",
    "excluded_channels = ['F8', 'T3', 'T5', 'T6', 'O1', 'F3', 'Fp1', 'Fp2', 'P4']\n",
    "\n",
    "\n",
    "def get_raw_eeg_mne(file_name, resolution_hz, tmin=None, tmax=None, exclude=[]):\n",
    "    raw = mne.io.read_raw_edf(file_name, preload=True, exclude=exclude).load_data()\n",
    "    raw.set_montage(\"standard_1020\") #set montage to 10-20\n",
    "    #print('tmin: ', tmin)\n",
    "    #print('tmax: ', tmax)\n",
    "    tmin = tmin if tmin else 1\n",
    "    tmax = tmax if tmax else (get_edf_file_duration(file_name)-1) #get_edf_file_duration rounds values up\n",
    "    raw.crop(tmin=tmin, tmax=tmax)\n",
    "    raw.resample(resolution_hz, npad=\"auto\") #set sampling frequency (dataset is set to 250Hz)\n",
    "    \n",
    "    return raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUshW_wth1xn"
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "mne.set_log_level(\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiuwFN-6h1xr"
   },
   "outputs": [],
   "source": [
    "\n",
    "# get a list of randomly selected sets of numbers based on a range\n",
    "# the proportion of values selected for each set is determined by the ratio_array\n",
    "import itertools\n",
    "def get_mixed_indexes_for_ml_train_test(length, ratios_array):\n",
    "    input_indexes = range(0, length)\n",
    "    output_indexes = []\n",
    "    for ratio in ratios_array:\n",
    "        input_indexes = [i for i in input_indexes if i not in list(itertools.chain(*output_indexes))]\n",
    "        selection = random.sample(input_indexes, k=math.floor(ratio * length))\n",
    "        output_indexes.append(selection)\n",
    "    return output_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpHKSpi-h1xv"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# modified based on https://stackoverflow.com/a/48704557/2466781\n",
    "def chunk(seq, size):\n",
    "    sl = len(seq) - (len(seq)%size) #exclude values that will be out of range\n",
    "    r = [np.asarray(seq[pos:pos + size]) for pos in range(0, sl, size)]\n",
    "    \"\"\"print('r begin')\n",
    "    print(r)\n",
    "    print('r end')\"\"\"\n",
    "    return r\n",
    "\n",
    "def chunk_list(nested_list, size):\n",
    "    v = []\n",
    "    for d in nested_list:\n",
    "        df = pd.DataFrame(np.asarray(d))\n",
    "        c = chunk(df, size)\n",
    "        for e in c:\n",
    "            v.append(e)\n",
    "    return v\n",
    "\n",
    "# modified version of process_patient_group in older notebooks\n",
    "# Uses the raw EDF files and converts to dataframe, dropping the first 150 and last 30 seconds of the shortest  file\n",
    "# All other files are trimmed similarly to produce the same size\n",
    "# Adapted from page 1 of https://buildmedia.readthedocs.org/media/pdf/pyedflib/latest/pyedflib.pdf\n",
    "def process_patient_group(group_directory_name, patient_group_file_prefix, \n",
    "                          minimum_original_duration,\n",
    "                          resolution_hz,\n",
    "                          plot_channels = False,\n",
    "                          excluded_channels = []):\n",
    "    meta_df = pd.DataFrame()\n",
    "    meta = []\n",
    "    patient_id_list = []\n",
    "\n",
    "    for i in range (1, 15): # reading 14 files\n",
    "        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n",
    "        patient_id_list.append(patient_id)\n",
    "        \n",
    "        file_name = raw_data_dir + '{}/{}.edf'.format(group_directory_name, patient_id)\n",
    "        data = get_raw_eeg_mne(file_name, resolution_hz, exclude=excluded_channels, tmin=120, tmax=minimum_duration-120)\n",
    "        df = data.to_data_frame()\n",
    "        ## based on visual inspection, drop the first 120 seconds\n",
    "        if patient_id not in ignore_list:\n",
    "            meta.append(np.asarray(df))\n",
    "            \n",
    "                    \n",
    "    return np.asarray(meta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRNBze7lh1x0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 125001, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14, 125001, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "hc_data = process_patient_group('Healthy Controls', 'h', minimum_duration, resolution_hz, excluded_channels=excluded_channels)\n",
    "display(np.asarray(hc_data).shape)\n",
    "\n",
    "sz_data = process_patient_group('SZ Patients', 's', minimum_duration, resolution_hz, excluded_channels=excluded_channels)\n",
    "display(np.asarray(sz_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iopTTb5ih1x4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored files: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def plot_examples(file_name, excluded_channels, resolution_hz):\n",
    "    patient_id = file_name.split(\"\\\\\")[-1][:-4]\n",
    "    print('Raw Data')\n",
    "    raw = get_raw_eeg_mne(file_name, resolution_hz)\n",
    "    #events = mne.find_events(raw, stim_channel=raw.ch_names, initial_event=True, consecutive=True)\n",
    "    raw.plot()\n",
    "    df = raw.to_data_frame()\n",
    "    print('Shape: ', df.shape)\n",
    "\n",
    "    print('Cleaned Data ')\n",
    "    print('Excluding channels {}; '.format(\", \".join(excluded_channels)))\n",
    "    print('Removing first 120s of data; and last 120s of shortest sample. Limiting all other samples to range of shortest sample')\n",
    "    cleaned = get_raw_eeg_mne(file_name, resolution_hz, tmin=120, tmax=minimum_duration-120, exclude=excluded_channels)\n",
    "    cleaned.crop()\n",
    "    cleaned.plot()\n",
    "    print('Shape: ', cleaned.to_data_frame().shape)\n",
    "\n",
    "from plotly.graph_objs import Layout, Scatter, Figure, Marker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly    \n",
    "import chart_studio.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "import cufflinks as cf\n",
    "#import plotly.graph_objs.layout.scene.Annotation\n",
    "cf.go_offline()\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "#cl_layout = go.Layout(width=950, height=800)\n",
    "\n",
    "\n",
    "def plot_eeg_plotly(raw, excluded_channels, resolution_hz):\n",
    "    n_channels = len(all_channels) - len(excluded_channels)\n",
    "    picks = range(n_channels)\n",
    "    start, stop = raw.time_as_index([0, -1])\n",
    "    \n",
    "    ####################################\n",
    "    #stop = 500 #dbg\n",
    "\n",
    "    data, times = raw[picks[:n_channels], start:stop]\n",
    "    ch_names = [raw.info['ch_names'][p] for p in picks[:n_channels]]\n",
    "    \n",
    "    step = 1. / n_channels\n",
    "    kwargs = dict(domain=[1 - step, 1], showticklabels=False, zeroline=False, showgrid=False)\n",
    "    mc = 'rgb(27,61,120)'\n",
    "    # create objects for layout and traces\n",
    "    layout = Layout(yaxis=go.layout.YAxis(kwargs), showlegend=False)\n",
    "    layout.update({'yaxis%d' % (0 + 1): go.layout.YAxis(kwargs), 'showlegend': False})\n",
    "    traces = [Scatter(x=times, y=data.T[:, 0], marker_color=mc)]\n",
    "    #display(raw.to_data_frame().head(stop))\n",
    "    \n",
    "\n",
    "    # loop over the channels\n",
    "    for ii in range(1, n_channels):\n",
    "            kwargs.update(domain=[1 - (ii + 1) * step, 1 - ii * step])\n",
    "            layout.update({'yaxis%d' % (ii + 1): go.layout.YAxis(kwargs), 'showlegend': False})\n",
    "            traces.append(Scatter(x=times, y=data.T[:, ii], marker_color = mc, yaxis='y%d' % (ii + 1)))\n",
    "\n",
    "    # add channel names using Annotations\n",
    "    annotations = [go.layout.Annotation(x=-0.06, y=0, xref='paper', yref='y%d' % (ii + 1),\n",
    "                                          text=ch_name, showarrow=False)\n",
    "                              for ii, ch_name in enumerate(ch_names)]\n",
    "    layout.update(annotations=annotations)\n",
    "    traces.reverse() #set the fist trace to the bottom of the plot sine it is the only one with xaxis\n",
    "\n",
    "    # set the size of the figure and plot it\n",
    "    layout.update(autosize=False, width=900, height=400)\n",
    "    fig = Figure(data=traces, layout=layout)\n",
    "    fig.update_xaxes(ticks=\"outside\", tickwidth=2, tickcolor='black', ticklen=10, side='top')\n",
    "\n",
    "    iplot(fig, filename='shared xaxis')\n",
    "    \n",
    "    \n",
    "#adapted from https://plot.ly/python/v3/ipython-notebooks/mne-tutorial/\n",
    "def plot_examples_plotly(file_name, excluded_channels, resolution_hz):\n",
    "    patient_id = file_name.split(\"\\\\\")[-1][:-4]\n",
    "    ### print('\\nRaw Data')\n",
    "    ### raw = get_raw_eeg_mne(file_name)\n",
    "    ### plot_eeg_plotly(raw, [])\n",
    "    \n",
    "    print('\\nCleaned Data')\n",
    "    print('Excluding channels {}; '.format(\", \".join(excluded_channels)))\n",
    "    print('Removing first 120s of data; and last 120s of shortest sample. Limiting all other samples to range of shortest sample')\n",
    "\n",
    "    cleaned = get_raw_eeg_mne(file_name, resolution_hz, tmin=120, tmax=minimum_duration-120, exclude=excluded_channels)\n",
    "    cleaned.crop()\n",
    "    plot_eeg_plotly(cleaned, excluded_channels, resolution_hz)\n",
    "\n",
    "# plot a random patient\n",
    "sz_patient_list = list(range(1, 15, 1))\n",
    "sz_patient_list.remove(12) #drop value from list of exclusions\n",
    "sz_patient_list.remove(14) #drop value from list of exclusions\n",
    "rand_patient_id =  random.choice(sz_patient_list)\n",
    "rand_patient_file =  raw_data_dir + 'SZ Patients/{}.edf'.format(\"{}{:02d}\").format('s', rand_patient_id)\n",
    "\n",
    "rand_control_id = random.randrange(1, 15, 1)\n",
    "rand_control_file = raw_data_dir + 'Healthy Controls/{}{:02d}.edf'.format('h', rand_control_id)\n",
    "\n",
    "\n",
    "\"\"\"print('Example of Input Data From Random Patient')\n",
    "print('Sz patient #{:02d}'.format(rand_patient_id))\n",
    "plot_examples_plotly(rand_patient_file, excluded_channels, resolution_hz)\"\"\"\n",
    "\n",
    "#print(\"Example of Input Data From Random Control\")\n",
    "#print('Control subject #{:02d}'.format(rand_control_id))\n",
    "#plot_examples_plotly(rand_control_file, excluded_channels, resolution_hz)\n",
    "\n",
    "print('Ignored files: ')\n",
    "print(\",\".join(ignore_list))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bs_ZLGCZh1yJ"
   },
   "outputs": [],
   "source": [
    "#drop the second dimension\n",
    "hc_data_all = np.asarray(hc_data)\n",
    "sz_data_all = np.asarray(sz_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "WKi98Pk6h1yQ",
    "outputId": "00682816-eb50-478d-97bd-8a43dfef2ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of denoised data (extracted components) :\n",
      "(14, 10, 125001)\n",
      "(14, 10, 125001)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.decomposition as decomposition\n",
    "\n",
    "def select_denoised_data(patient_data):\n",
    "    all_features = []\n",
    "    \n",
    "    for entry in patient_data:\n",
    "        pca_denoise = decomposition.PCA(n_components=np.asarray(patient_data).shape[2])\n",
    "        pca_denoise.fit(entry.transpose())\n",
    "        denoised_data = pca_denoise.components_[:14] #select top v components, where v is based on chart of explained variance\n",
    "        all_features.append(np.asarray(denoised_data)) \n",
    "        \n",
    "\n",
    "    return all_features\n",
    "    \n",
    "\n",
    "sample_size = minimum_duration #use entire window\n",
    "#send all channels and all patient data; s07 is still skipped\n",
    "hc_data_all_denoised_selected = select_denoised_data(hc_data_all)\n",
    "sz_data_all_denoised_selected = select_denoised_data(sz_data_all)\n",
    "\n",
    "print('Shape of denoised data (extracted components) :')\n",
    "print(np.asarray(hc_data_all_denoised_selected).shape)\n",
    "print(np.asarray(sz_data_all_denoised_selected).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOWRun_Nh1yW"
   },
   "outputs": [],
   "source": [
    "# flatten the feature vectors so that input can be used in scikit learn \n",
    "def flatten_features(data):\n",
    "    flattened_data = []\n",
    "    for entry in data: \n",
    "        # shift axes so that data shape is time * channels * features. Then flatten data\n",
    "        flattened_data.append(np.moveaxis(entry, 0, -1).flatten())\n",
    "    return np.asarray(flattened_data, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "4VbhzxK1h1yc",
    "outputId": "71a4a9ac-5197-4145-8132-d6069388eab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  (28, 10, 125001)\n",
      "Flattened input size:  (28, 1250010)\n"
     ]
    }
   ],
   "source": [
    "# load extracted features\n",
    "\n",
    "X =  np.concatenate((hc_data_all_denoised_selected, sz_data_all_denoised_selected), axis=0)\n",
    "X_original = X.copy()\n",
    "print('Input size: ', X.shape)\n",
    "y = ([0] * len(hc_data_all_denoised_selected)) +( [1] * len(sz_data_all_denoised_selected))\n",
    "sample_size = 2\n",
    "\n",
    "X = flatten_features(X)\n",
    "print('Flattened input size: ', X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paC5wQ8eh1yf"
   },
   "outputs": [],
   "source": [
    "# get a list of randomly selected sets of numbers based on a range\n",
    "# the proportion of values selected for each set is determined by the ratio_array\n",
    "import itertools\n",
    "def get_mixed_indexes_for_ml_train_test(length, ratios_array):\n",
    "    input_indexes = range(0, length)\n",
    "    output_indexes = []\n",
    "    for ratio in ratios_array:\n",
    "        input_indexes = [i for i in input_indexes if i not in list(itertools.chain(*output_indexes))]\n",
    "        selection = random.sample(input_indexes, k=math.floor(ratio * length))\n",
    "        output_indexes.append(selection)\n",
    "    return output_indexes\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xyccwpbgh1yj",
    "outputId": "47fcdaa5-828b-403c-fab5-bebb000f1e75",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 22 samples; testing on 5 samples\n"
     ]
    }
   ],
   "source": [
    "train_idxs, test_idxs = get_mixed_indexes_for_ml_train_test(len(X), [.80, 0.20])\n",
    "\n",
    "X_train      = X[train_idxs][0:,]\n",
    "Y_train      = np.asarray(y)[train_idxs]\n",
    "X_test       = X[test_idxs][0:,]\n",
    "Y_test       = np.asarray(y)[test_idxs]\n",
    "\n",
    "print('Training on {} samples; testing on {} samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "J56n1BcKh1y5",
    "outputId": "e1e2c6ef-39d0-4743-f7e8-9efc76de5ad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessing various classifiers. Using k-fold value of  14 \n",
      "\n",
      "SVM mean cross-validation accuracy (k-fold=14)  using scaled data :  43%\n",
      "Gaussian Naive Bayes mean cross-validation accuracy (k-fold=14) :  54%\n",
      "K Nearest Neighbors mean cross-validation accuracy (k-fold=14) :  50%\n",
      "Nearest Centroid mean cross-validation accuracy (k-fold=14) :  29%\n",
      "Decision Tree mean cross-validation accuracy (k-fold=14) :  93%\n",
      "Adaboost mean cross-validation accuracy (k-fold=14) :  86%\n",
      "Gradient Boosting Classifier mean cross-validation accuracy (k-fold=14) :  86%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Standardize the cross-validation implementation and\n",
    "# the display of results for traditional models\n",
    "#\n",
    "# clf: the scikitlearn classifier to be used\n",
    "# model_name: name of the model for display\n",
    "# X: flattened data\n",
    "# y: labels\n",
    "# k_fold the number of folds (must be <= the number of participants in each group)\n",
    "# scale_data: whether or not to use the StandardScaler to normalize the dataset; this is most helpful for SVM\n",
    "#       but does not seem to have a significant impact on most other classifiers but seems to be problematic for\n",
    "#       decision trees\n",
    "def run_traditional_model(clf, model_name, X, y, k_fold=12, scale_data=False):\n",
    "      \n",
    "    if scale_data:\n",
    "        scaler = StandardScaler()\n",
    "        clf = Pipeline(steps=[('s', scaler), ('m', clf)]) \n",
    "    scaling_note = ' using scaled data ' if scale_data else ''\n",
    "        \n",
    "    scores = cross_val_score(clf, X, y, cv=k_fold)\n",
    "    print('%s %3.f%%' % ('{} mean cross-validation accuracy (k-fold={}) {}:'\n",
    "                         .format(model_name, k_fold, scaling_note), scores.mean() * 100.))\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "k_fold=min(len(hc_data_all_denoised_selected), len(sz_data_all_denoised_selected))\n",
    "print('Assessing various classifiers. Using k-fold value of ',k_fold,'\\n')\n",
    "\n",
    "model_name = 'SVM'\n",
    "clf = SVC(gamma='scale', kernel='rbf', degree=3)## default values \n",
    "svm_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold, scale_data=True)\n",
    "\n",
    "model_name = 'Gaussian Naive Bayes'\n",
    "clf = GaussianNB()\n",
    "gnb_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'K Nearest Neighbors'\n",
    "n_neighbors = 2\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform') #weights={'uniform', 'distance'}\n",
    "knn_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'Nearest Centroid'\n",
    "clf = neighbors.NearestCentroid()\n",
    "nc_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'Decision Tree'\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "decision_tree_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'Adaboost'\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "adaboost_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'Gradient Boosting Classifier'\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0)\n",
    "gbc_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkdi-Z1Qh1y-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iEFmhK0h1zA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing environment settings\n",
      "\n",
      "Python version:  3.7.1\n",
      "\n",
      "Installed modules:\n",
      "\n",
      "absl-py==0.7.1\n",
      "alabaster==0.7.12\n",
      "altgraph==0.16.1\n",
      "anaconda-client==1.7.2\n",
      "anaconda-navigator==1.9.6\n",
      "anaconda-project==0.8.2\n",
      "asn1crypto==0.24.0\n",
      "astor==0.8.0\n",
      "astroid==2.1.0\n",
      "astropy==3.1\n",
      "atomicwrites==1.2.1\n",
      "attrs==18.2.0\n",
      "Babel==2.6.0\n",
      "backcall==0.1.0\n",
      "backports.os==0.1.1\n",
      "backports.shutil-get-terminal-size==1.0.0\n",
      "beautifulsoup4==4.6.0\n",
      "bitarray==0.8.3\n",
      "bkcharts==0.2\n",
      "blaze==0.11.3\n",
      "bleach==3.0.2\n",
      "blis==0.2.4\n",
      "bokeh==1.0.2\n",
      "boto==2.49.0\n",
      "boto3==1.9.169\n",
      "botocore==1.12.169\n",
      "Bottleneck==1.2.1\n",
      "cachetools==3.1.1\n",
      "certifi==2018.11.29\n",
      "cffi==1.11.5\n",
      "chardet==3.0.4\n",
      "Click==7.0\n",
      "cloudpickle==0.6.1\n",
      "clyent==1.2.2\n",
      "colorama==0.4.1\n",
      "colorlover==0.3.0\n",
      "comtypes==1.1.7\n",
      "conda==4.8.2\n",
      "conda-build==3.17.6\n",
      "conda-package-handling==1.3.11\n",
      "conda-verify==3.1.1\n",
      "contextlib2==0.5.5\n",
      "cryptography==2.4.2\n",
      "cufflinks==0.15\n",
      "cycler==0.10.0\n",
      "cymem==2.0.2\n",
      "Cython==0.29.2\n",
      "cytoolz==0.9.0.1\n",
      "dask==1.0.0\n",
      "datashape==0.5.4\n",
      "decorator==4.3.0\n",
      "defusedxml==0.5.0\n",
      "distributed==1.25.1\n",
      "docutils==0.14\n",
      "EasyProcess==0.2.10\n",
      "entrypoints==0.2.3\n",
      "et-xmlfile==1.0.1\n",
      "fastcache==1.0.2\n",
      "filelock==3.0.10\n",
      "Flask==1.0.2\n",
      "Flask-Cors==3.0.7\n",
      "future==0.17.1\n",
      "gast==0.2.2\n",
      "gdown==3.10.1\n",
      "genderdecoder==0.3\n",
      "gensim==3.7.3\n",
      "gevent==1.3.7\n",
      "glob2==0.6\n",
      "google-auth==1.8.2\n",
      "google-auth-oauthlib==0.4.1\n",
      "google-pasta==0.1.8\n",
      "graphviz==0.13.2\n",
      "greenlet==0.4.15\n",
      "grpcio==1.21.1\n",
      "h5py==2.10.0\n",
      "heapdict==1.0.0\n",
      "html2text==2018.1.9\n",
      "html5lib==1.0.1\n",
      "idna==2.8\n",
      "imageio==2.4.1\n",
      "imagesize==1.1.0\n",
      "importlib-metadata==0.6\n",
      "inflection==0.3.1\n",
      "ipykernel==5.1.0\n",
      "ipython==7.2.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.4.2\n",
      "isort==4.3.4\n",
      "itsdangerous==1.1.0\n",
      "jdcal==1.4\n",
      "jedi==0.13.2\n",
      "Jinja2==2.10\n",
      "jmespath==0.9.4\n",
      "joblib==0.14.1\n",
      "jsonschema==2.6.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==5.2.4\n",
      "jupyter-console==6.0.0\n",
      "jupyter-core==4.4.0\n",
      "jupyterlab==0.35.3\n",
      "jupyterlab-server==0.2.0\n",
      "Keras==2.2.4\n",
      "Keras-Applications==1.0.8\n",
      "keras-contrib==2.0.8\n",
      "Keras-Preprocessing==1.0.9\n",
      "keyring==17.0.0\n",
      "kiwisolver==1.0.1\n",
      "lazy-object-proxy==1.3.1\n",
      "libarchive-c==2.8\n",
      "llvmlite==0.26.0\n",
      "locket==0.2.0\n",
      "lxml==4.2.5\n",
      "Markdown==3.0.1\n",
      "MarkupSafe==1.1.0\n",
      "matplotlib==3.2.1\n",
      "mccabe==0.6.1\n",
      "menuinst==1.4.14\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.0.6\n",
      "mkl-random==1.0.2\n",
      "mlxtend==0.17.0\n",
      "mne==0.19.2\n",
      "mock==3.0.5\n",
      "more-itertools==4.3.0\n",
      "mpmath==1.1.0\n",
      "msgpack==0.5.6\n",
      "multipledispatch==0.6.0\n",
      "murmurhash==1.0.2\n",
      "navigator-updater==0.2.1\n",
      "nbconvert==5.4.0\n",
      "nbformat==4.4.0\n",
      "ndg-httpsclient==0.5.1\n",
      "networkx==2.2\n",
      "nltk==3.4.1\n",
      "nose==1.3.7\n",
      "notebook==5.7.4\n",
      "numba==0.41.0\n",
      "numexpr==2.6.8\n",
      "numpy==1.16.5\n",
      "numpydoc==0.8.0\n",
      "oauthlib==3.1.0\n",
      "odo==0.5.1\n",
      "olefile==0.46\n",
      "openpyxl==2.5.12\n",
      "opt-einsum==3.1.0\n",
      "packaging==18.0\n",
      "pandas==0.25.3\n",
      "pandocfilters==1.4.2\n",
      "parso==0.3.1\n",
      "partd==0.3.9\n",
      "path.py==11.5.0\n",
      "pathlib2==2.3.3\n",
      "patool==1.12\n",
      "patsy==0.5.1\n",
      "pefile==2019.4.18\n",
      "pep8==1.7.1\n",
      "pickleshare==0.7.5\n",
      "Pillow==7.0.0\n",
      "pkginfo==1.4.2\n",
      "plac==0.9.6\n",
      "plotly==3.10.0\n",
      "pluggy==0.8.0\n",
      "ply==3.11\n",
      "preshed==2.0.1\n",
      "prometheus-client==0.5.0\n",
      "prompt-toolkit==2.0.7\n",
      "protobuf==3.7.1\n",
      "psutil==5.4.8\n",
      "pupygrib==0.5.0\n",
      "py==1.7.0\n",
      "pyargus==1.0.post3\n",
      "pyasn1==0.4.7\n",
      "pyasn1-modules==0.2.7\n",
      "pycodestyle==2.4.0\n",
      "pycosat==0.6.3\n",
      "pycparser==2.19\n",
      "pycrypto==2.6.1\n",
      "pycurl==7.43.0.2\n",
      "pydot==1.4.1\n",
      "pyEDFlib==0.1.17\n",
      "pyflakes==2.0.0\n",
      "Pygments==2.3.1\n",
      "PyInstaller==4.0.dev0+1eadfa55f2\n",
      "pylint==2.2.2\n",
      "pymssql==2.1.4\n",
      "PyMySQL==0.9.3\n",
      "pyodbc==4.0.25\n",
      "pyOpenSSL==18.0.0\n",
      "pyparsing==2.3.0\n",
      "Pyphen==0.9.5\n",
      "pyproj==2.4.2.post1\n",
      "pyriemann==0.2.5\n",
      "PySocks==1.6.8\n",
      "pytest==4.0.2\n",
      "pytest-arraydiff==0.3\n",
      "pytest-astropy==0.5.0\n",
      "pytest-doctestplus==0.2.0\n",
      "pytest-openfiles==0.3.1\n",
      "pytest-remotedata==0.3.1\n",
      "python-dateutil==2.7.5\n",
      "pytz==2018.7\n",
      "pyunpack==0.1.2\n",
      "PyWavelets==1.0.1\n",
      "pywin32==223\n",
      "pywin32-ctypes==0.2.0\n",
      "pywinpty==0.5.5\n",
      "PyYAML==3.13\n",
      "pyzmq==17.1.2\n",
      "QtAwesome==0.5.3\n",
      "qtconsole==4.4.3\n",
      "QtPy==1.5.2\n",
      "Quandl==3.4.8\n",
      "rarfile==3.1\n",
      "repoze.lru==0.7\n",
      "requests==2.21.0\n",
      "requests-oauthlib==1.3.0\n",
      "retrying==1.3.3\n",
      "rope==0.11.0\n",
      "rsa==4.0\n",
      "ruamel-yaml==0.15.46\n",
      "s3transfer==0.2.1\n",
      "scikit-image==0.14.1\n",
      "scikit-learn==0.22.1\n",
      "scipy==1.4.1\n",
      "seaborn==0.9.0\n",
      "selenium==3.141.0\n",
      "Send2Trash==1.5.0\n",
      "simplegeneric==0.8.1\n",
      "singledispatch==3.4.0.3\n",
      "six==1.12.0\n",
      "smart-open==1.8.4\n",
      "snapshot-phantomjs==0.0.3\n",
      "snowballstemmer==1.2.1\n",
      "sortedcollections==1.0.1\n",
      "sortedcontainers==2.1.0\n",
      "spacy==2.1.4\n",
      "Sphinx==1.8.2\n",
      "sphinxcontrib-websupport==1.1.0\n",
      "spyder==3.3.2\n",
      "spyder-kernels==0.3.0\n",
      "SQLAlchemy==1.2.15\n",
      "srsly==0.0.5\n",
      "statsmodels==0.9.0\n",
      "style==1.1.0\n",
      "sympy==1.3\n",
      "tables==3.4.4\n",
      "tblib==1.3.2\n",
      "tensorboard==1.13.1\n",
      "tensorflow==1.13.1\n",
      "tensorflow-estimator==1.13.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.8.1\n",
      "testpath==0.4.2\n",
      "textblob==0.15.3\n",
      "textstat==0.5.6\n",
      "thinc==7.0.4\n",
      "toolz==0.9.0\n",
      "tornado==5.1.1\n",
      "tqdm==4.28.1\n",
      "traitlets==4.3.2\n",
      "unicodecsv==0.14.1\n",
      "unrar==0.4\n",
      "update==0.0.1\n",
      "urllib3==1.24.1\n",
      "wasabi==0.2.2\n",
      "wcwidth==0.1.7\n",
      "webencodings==0.5.1\n",
      "Werkzeug==0.14.1\n",
      "widgetsnbextension==3.4.2\n",
      "win-inet-pton==1.0.1\n",
      "win-unicode-console==0.5\n",
      "wincertstore==0.2\n",
      "wrapt==1.11.2\n",
      "xlrd==1.2.0\n",
      "XlsxWriter==1.1.2\n",
      "xlwings==0.15.1\n",
      "xlwt==1.3.0\n",
      "zict==0.1.3\n"
     ]
    }
   ],
   "source": [
    "## End of implementation code  \n",
    "\n",
    "print('Printing environment settings')\n",
    "\n",
    "from platform import python_version\n",
    "print('\\nPython version: ', python_version())\n",
    "print('\\nInstalled modules:\\n')\n",
    "\n",
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPrnrajCh1zD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T4', 'O2', 'F7', 'F4', 'C4', 'C3', 'P3', 'Fz', 'Cz', 'Pz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_channels = ['Fp2', 'F8', 'T4', 'T6', 'O2', 'Fp1', 'F7', 'T3', 'T5', 'O1', 'F4',\n",
    "                'C4' , 'P4', 'F3', 'C3', 'P3', 'Fz' , 'Cz', 'Pz']\n",
    "\n",
    "excluded_channels = ['F8', 'T3', 'T5', 'T6', 'O1', 'F3', 'Fp1', 'Fp2', 'P4']\n",
    "\n",
    "selected_channels = [ch for ch in all_channels if ch not in excluded_channels]\n",
    "selected_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Traditional Classifiers using PCA with Limited Channels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
