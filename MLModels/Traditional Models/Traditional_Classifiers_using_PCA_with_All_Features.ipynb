{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "colab_type": "code",
    "id": "ZiaK5_gNh1vH",
    "outputId": "ec3a8ab8-2de6-4d79-ee05-6661fa795f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Google Colab. Setting up environment\n",
      "Requirement already satisfied: mne==0.19.2 in /usr/local/lib/python3.6/dist-packages (0.19.2)\n",
      "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne==0.19.2) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne==0.19.2) (1.18.3)\n",
      "Requirement already satisfied: pyedflib==0.1.15 in /usr/local/lib/python3.6/dist-packages (0.1.15)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from pyedflib==0.1.15) (1.18.3)\n",
      "Requirement already satisfied: chart_studio==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from chart_studio==1.0.0) (4.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from chart_studio==1.0.0) (1.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from chart_studio==1.0.0) (2.23.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from chart_studio==1.0.0) (1.3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio==1.0.0) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio==1.0.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio==1.0.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio==1.0.0) (2.9)\n",
      "\n",
      " \n",
      " To load files from Google Drive, account validation is required.\n",
      "Mounted at /content/drive\n",
      "--2020-05-01 13:09:18--  https://raw.githubusercontent.com/WinAIML/schizophrenia/master/ReadData/RawDataReader.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14735 (14K) [text/plain]\n",
      "Saving to: ‘/content/tmp/eeg_sz/ReadData/RawDataReader.py’\n",
      "\n",
      "/content/tmp/eeg_sz 100%[===================>]  14.39K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2020-05-01 13:09:19 (2.01 MB/s) - ‘/content/tmp/eeg_sz/ReadData/RawDataReader.py’ saved [14735/14735]\n",
      "\n",
      "--2020-05-01 13:09:20--  https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ModelBuilder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4926 (4.8K) [text/plain]\n",
      "Saving to: ‘/content/tmp/eeg_sz/utils/ModelBuilder.py’\n",
      "\n",
      "t/tmp/eeg_sz/utils/ 100%[===================>]   4.81K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-05-01 13:09:21 (68.9 MB/s) - ‘/content/tmp/eeg_sz/utils/ModelBuilder.py’ saved [4926/4926]\n",
      "\n",
      "--2020-05-01 13:09:22--  https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ChartBuilder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9996 (9.8K) [text/plain]\n",
      "Saving to: ‘/content/tmp/eeg_sz/utils/ChartBuilder.py’\n",
      "\n",
      "t/tmp/eeg_sz/utils/ 100%[===================>]   9.76K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-05-01 13:09:22 (117 MB/s) - ‘/content/tmp/eeg_sz/utils/ChartBuilder.py’ saved [9996/9996]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "raw_data_dir = ''\n",
    "acc_key = 'acc'\n",
    "plot_examples = False # notebook file size will increase by 30 to 60MB if set to True; size is <1MB otherwise\n",
    "\n",
    "if  'COLAB_GPU' in os.environ :\n",
    "    print('Using Google Colab. Setting up environment')\n",
    "    raw_data_dir = '/content/drive/My Drive/Colab Notebooks/' \n",
    "    #raw_data_dir = 'Raw/'\n",
    "\n",
    "    !pip install mne==0.19.2\n",
    "    !pip install pyedflib==0.1.15\n",
    "    !pip install chart_studio==1.0.0\n",
    "\n",
    "\n",
    "    print('\\n \\n To load files from Google Drive, account validation is required.')\n",
    "    #mount to drive -- files should be located in the /Colab Notebooks directory\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    \n",
    "    if not os.path.exists('/content/tmp/eeg_sz/ReadData'):\n",
    "      os.makedirs('/content/tmp/eeg_sz/ReadData')\n",
    "      os.makedirs('/content/tmp/eeg_sz/utils')\n",
    "    # download project utilities and data reader \n",
    "    !wget -O/content/tmp/eeg_sz/ReadData/RawDataReader.py https://raw.githubusercontent.com/WinAIML/schizophrenia/master/ReadData/RawDataReader.py\n",
    "    !wget -O/content/tmp/eeg_sz/utils/ModelBuilder.py -P/utils https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ModelBuilder.py\n",
    "    !wget -O/content/tmp/eeg_sz/utils/ChartBuilder.py -P/utils https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ChartBuilder.py\n",
    "    sys.path.append('/content/tmp/eeg_sz/')\n",
    "\n",
    "elif 'KAGGLE_URL_BASE' in os.environ:\n",
    "    acc_key = 'accuracy'\n",
    "    print('Using Kaggle kernel. Setting up environment')\n",
    "    !pip install mne==0.19.2\n",
    "    !pip install pyedflib==0.1.15\n",
    "    !pip install chart_studio==1.0.0\n",
    "    !svn checkout https://github.com/WinAIML/schizophrenia/trunk/Data/Raw\n",
    "    raw_data_dir = 'Raw/'\n",
    "    \n",
    "    # download project utilities and data reader \n",
    "    !svn checkout https://github.com/WinAIML/schizophrenia/trunk/ReadData\n",
    "    !svn checkout https://github.com/WinAIML/schizophrenia/trunk/MLModels/utils Utils\n",
    "\n",
    "\n",
    "else:\n",
    "    # assuming that a local run will be launched only from a github project; \n",
    "    # add the utils and ReadData directories to the temporary path\n",
    "    if 'HOMEPATH' in os.environ:\n",
    "        print('Using homepath ' + os.environ['HOMEPATH'])\n",
    "    raw_data_dir = '../../Data/Raw/'\n",
    "    \n",
    "    from pathlib import Path\n",
    "    import sys\n",
    "    sys.path.append(os.path.realpath('..'))\n",
    "    path = Path(os.getcwd())\n",
    "    sys.path.append(str(path.parent.parent))\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, MaxPooling1D, MaxPooling2D, AveragePooling2D, AveragePooling1D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "from importlib import reload  #reload(chart_builder)\n",
    "\n",
    "\n",
    "#################\n",
    "# import project utilities and the raw data reader\n",
    "# Kaggle environment does not accept 'utils' as a file, so it must be accessed seperately\n",
    "\n",
    "import ReadData.RawDataReader as data_reader\n",
    "if 'KAGGLE_URL_BASE' in os.environ:\n",
    "    import Utils.ModelBuilder as model_builder\n",
    "    import Utils.ChartBuilder as chart_builder\n",
    "else:\n",
    "    import utils.ModelBuilder as model_builder\n",
    "    import utils.ChartBuilder as chart_builder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IaWpLhDl3CG4",
    "outputId": "77f8a5f3-aea2-4abd-a191-91ab87b1d277"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"if not os.path.exists('/content/tmp/eeg_sz/ReadData'):\n",
    "  os.makedirs('/content/tmp/eeg_sz/ReadData')\n",
    "  os.makedirs('/content/tmp/eeg_sz/utils')\n",
    "# download project utilities and data reader \n",
    "!wget -O/content/tmp/eeg_sz/ReadData/RawDataReader.py https://raw.githubusercontent.com/WinAIML/schizophrenia/master/ReadData/RawDataReader.py\n",
    "!wget -O/content/tmp/eeg_sz/utils/ModelBuilder.py -P/utils https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ModelBuilder.py\n",
    "!wget -O/content/tmp/eeg_sz/utils/ChartBuilder.py -P/utils https://raw.githubusercontent.com/WinAIML/schizophrenia/master/MLModels/utils/ChartBuilder.py\n",
    "sys.path.append('/content/tmp/eeg_sz')\n",
    "\n",
    "print(os.getcwd())\n",
    "sys.path.append('/content/tmp/eeg_sz/')\n",
    "import ReadData.RawDataReader as data_reader\n",
    "#print(sys.path)\n",
    "\"\"\"\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxtrV9-nh1xR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random \n",
    "import math\n",
    "\n",
    "#svm imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BhSgQiKh1xa"
   },
   "outputs": [],
   "source": [
    "# to main file\n",
    "ignore_list = ['s12', 's14']  #list of patient files that should be skipped\n",
    "ignore_list = []\n",
    "resolution_hz =  250 #EEG values per second\n",
    "#seconds of data to include in one slice\n",
    "time_window = resolution_hz * 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "V37IOjv2h1xh",
    "outputId": "bdc8fcbd-97f6-4f3c-89f2-cf4427d621df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum duration:  740\n"
     ]
    }
   ],
   "source": [
    "# to main file\n",
    "import pyedflib\n",
    "#returns file duration in seconds\n",
    "def get_edf_file_duration(file_name):\n",
    "    f = pyedflib.EdfReader(file_name)\n",
    "    duration = f.file_duration\n",
    "    f.close()\n",
    "    return  duration\n",
    "\n",
    "# get the minimum length of the files\n",
    "def get_minimum_duration(group_directory_name, patient_group_file_prefix):\n",
    "    file_durations = []\n",
    "    for i in range (1, 15): # reading 14 files\n",
    "        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n",
    "        file_name = raw_data_dir +'{}/{}.edf'.format(group_directory_name, patient_id)\n",
    "        file_durations.append(get_edf_file_duration(file_name))\n",
    "\n",
    "    return(min(file_durations))\n",
    "\n",
    "\n",
    "minimum_duration = min(get_minimum_duration(\"Healthy Controls\", \"h\"), get_minimum_duration('SZ Patients', 's'))\n",
    "print('Minimum duration: ', minimum_duration)\n",
    "all_channels = ['Fp2', 'F8', 'T4', 'T6', 'O2', 'Fp1', 'F7', 'T3', 'T5', 'O1', 'F4',\n",
    "                'C4', 'P4', 'F3', 'C3', 'P3', 'Fz', 'Cz', 'Pz']\n",
    "\n",
    "excluded_channels = []\n",
    "\n",
    "def get_raw_eeg_mne(file_name, resolution_hz, tmin=None, tmax=None, exclude=[]):\n",
    "    raw = mne.io.read_raw_edf(file_name, preload=True, exclude=exclude).load_data()\n",
    "    raw.set_montage(\"standard_1020\") #set montage to 10-20\n",
    "    #print('tmin: ', tmin)\n",
    "    #print('tmax: ', tmax)\n",
    "    tmin = tmin if tmin else 1\n",
    "    tmax = tmax if tmax else (get_edf_file_duration(file_name)-1) #get_edf_file_duration rounds values up\n",
    "    raw.crop(tmin=tmin, tmax=tmax)\n",
    "    raw.resample(resolution_hz, npad=\"auto\") #set sampling frequency (dataset is set to 250Hz)\n",
    "    \n",
    "    return raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUshW_wth1xn"
   },
   "outputs": [],
   "source": [
    "# tmf\n",
    "import mne\n",
    "mne.set_log_level(\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiuwFN-6h1xr"
   },
   "outputs": [],
   "source": [
    "#to main file\n",
    "\n",
    "# get a list of randomly selected sets of numbers based on a range\n",
    "# the proportion of values selected for each set is determined by the ratio_array\n",
    "import itertools\n",
    "def get_mixed_indexes_for_ml_train_test(length, ratios_array):\n",
    "    input_indexes = range(0, length)\n",
    "    output_indexes = []\n",
    "    for ratio in ratios_array:\n",
    "        input_indexes = [i for i in input_indexes if i not in list(itertools.chain(*output_indexes))]\n",
    "        selection = random.sample(input_indexes, k=math.floor(ratio * length))\n",
    "        output_indexes.append(selection)\n",
    "    return output_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpHKSpi-h1xv"
   },
   "outputs": [],
   "source": [
    "# to main file \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# modified based on https://stackoverflow.com/a/48704557/2466781\n",
    "def chunk(seq, size):\n",
    "    sl = len(seq) - (len(seq)%size) #exclude values that will be out of range\n",
    "    r = [np.asarray(seq[pos:pos + size]) for pos in range(0, sl, size)]\n",
    "    \"\"\"print('r begin')\n",
    "    print(r)\n",
    "    print('r end')\"\"\"\n",
    "    return r\n",
    "\n",
    "def chunk_list(nested_list, size):\n",
    "    v = []\n",
    "    for d in nested_list:\n",
    "        df = pd.DataFrame(np.asarray(d))\n",
    "        c = chunk(df, size)\n",
    "        for e in c:\n",
    "            v.append(e)\n",
    "    return v\n",
    "\n",
    "# modified version of process_patient_group in older notebooks\n",
    "# Uses the raw EDF files and converts to dataframe, dropping the first 150 and last 30 seconds of the shortest  file\n",
    "# All other files are trimmed similarly to produce the same size\n",
    "# Adapted from page 1 of https://buildmedia.readthedocs.org/media/pdf/pyedflib/latest/pyedflib.pdf\n",
    "def process_patient_group(group_directory_name, patient_group_file_prefix, \n",
    "                          minimum_original_duration,\n",
    "                          resolution_hz,\n",
    "                          plot_channels = False,\n",
    "                          excluded_channels = []):\n",
    "    meta_df = pd.DataFrame()\n",
    "    meta = []\n",
    "    patient_id_list = []\n",
    "\n",
    "    for i in range (1, 15): # reading 14 files\n",
    "        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n",
    "        patient_id_list.append(patient_id)\n",
    "        \n",
    "        file_name = raw_data_dir + '{}/{}.edf'.format(group_directory_name, patient_id)\n",
    "        data = get_raw_eeg_mne(file_name, resolution_hz, exclude=excluded_channels, tmin=120, tmax=minimum_duration-120)\n",
    "        df = data.to_data_frame()\n",
    "        ## based on visual inspection, drop the first 120 seconds\n",
    "        if patient_id not in ignore_list:\n",
    "            meta.append(np.asarray(df))\n",
    "            \n",
    "            \n",
    "    #batches = chunk(meta_df, time_window)\n",
    "\n",
    "    #for batch in batches:\n",
    "    #   #display(np.asarray(batch.values).shape)\n",
    "    #    meta.append([np.asarray(batch.values)])\n",
    "           \n",
    "                    \n",
    "    return np.asarray(meta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "HRNBze7lh1x0",
    "outputId": "369908b9-519d-4c8a-f424-c3efe41a217d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 125001, 19)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14, 125001, 19)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "hc_data = process_patient_group('Healthy Controls', 'h', minimum_duration, resolution_hz, excluded_channels=excluded_channels)\n",
    "display(np.asarray(hc_data).shape)\n",
    "\n",
    "sz_data = process_patient_group('SZ Patients', 's', minimum_duration, resolution_hz, excluded_channels=excluded_channels)\n",
    "display(np.asarray(sz_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "iopTTb5ih1x4",
    "outputId": "450b8027-40fd-4c73-d69c-08165fb6c64b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_examples(file_name, excluded_channels, resolution_hz):\n",
    "    patient_id = file_name.split(\"\\\\\")[-1][:-4]\n",
    "    print('Raw Data')\n",
    "    raw = get_raw_eeg_mne(file_name, resolution_hz)\n",
    "    #events = mne.find_events(raw, stim_channel=raw.ch_names, initial_event=True, consecutive=True)\n",
    "    raw.plot()\n",
    "    df = raw.to_data_frame()\n",
    "    print('Shape: ', df.shape)\n",
    "\n",
    "    print('Cleaned Data ')\n",
    "    print('Excluding channels {}; '.format(\", \".join(excluded_channels)))\n",
    "    print('Removing first 120s of data; and last 120s of shortest sample. Limiting all other samples to range of shortest sample')\n",
    "    cleaned = get_raw_eeg_mne(file_name, resolution_hz, tmin=120, tmax=minimum_duration-120, exclude=excluded_channels)\n",
    "    cleaned.crop()\n",
    "    cleaned.plot()\n",
    "    print('Shape: ', cleaned.to_data_frame().shape)\n",
    "\n",
    "from plotly.graph_objs import Layout, Scatter, Figure, Marker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly    \n",
    "import chart_studio.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "import cufflinks as cf\n",
    "#import plotly.graph_objs.layout.scene.Annotation\n",
    "cf.go_offline()\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "#cl_layout = go.Layout(width=950, height=800)\n",
    "\n",
    "\n",
    "def plot_eeg_plotly(raw, excluded_channels, resolution_hz):\n",
    "    n_channels = len(all_channels) - len(excluded_channels)\n",
    "    picks = range(n_channels)\n",
    "    start, stop = raw.time_as_index([0, -1])\n",
    "    \n",
    "    ####################################\n",
    "    #stop = 500 #dbg\n",
    "\n",
    "    data, times = raw[picks[:n_channels], start:stop]\n",
    "    ch_names = [raw.info['ch_names'][p] for p in picks[:n_channels]]\n",
    "    \n",
    "    step = 1. / n_channels\n",
    "    kwargs = dict(domain=[1 - step, 1], showticklabels=False, zeroline=False, showgrid=False)\n",
    "    mc = 'rgb(27,61,120)'\n",
    "    # create objects for layout and traces\n",
    "    layout = Layout(yaxis=go.layout.YAxis(kwargs), showlegend=False)\n",
    "    layout.update({'yaxis%d' % (0 + 1): go.layout.YAxis(kwargs), 'showlegend': False})\n",
    "    traces = [Scatter(x=times, y=data.T[:, 0], marker_color=mc)]\n",
    "    #display(raw.to_data_frame().head(stop))\n",
    "    \n",
    "\n",
    "    # loop over the channels\n",
    "    for ii in range(1, n_channels):\n",
    "            kwargs.update(domain=[1 - (ii + 1) * step, 1 - ii * step])\n",
    "            layout.update({'yaxis%d' % (ii + 1): go.layout.YAxis(kwargs), 'showlegend': False})\n",
    "            traces.append(Scatter(x=times, y=data.T[:, ii], marker_color = mc, yaxis='y%d' % (ii + 1)))\n",
    "\n",
    "    # add channel names using Annotations\n",
    "    annotations = [go.layout.Annotation(x=-0.06, y=0, xref='paper', yref='y%d' % (ii + 1),\n",
    "                                          text=ch_name, showarrow=False)\n",
    "                              for ii, ch_name in enumerate(ch_names)]\n",
    "    layout.update(annotations=annotations)\n",
    "    traces.reverse() #set the fist trace to the bottom of the plot sine it is the only one with xaxis\n",
    "\n",
    "    # set the size of the figure and plot it\n",
    "    layout.update(autosize=False, width=900, height=400)\n",
    "    fig = Figure(data=traces, layout=layout)\n",
    "    fig.update_xaxes(ticks=\"outside\", tickwidth=2, tickcolor='black', ticklen=10, side='top')\n",
    "\n",
    "    iplot(fig, filename='shared xaxis')\n",
    "    \n",
    "    \n",
    "#adapted from https://plot.ly/python/v3/ipython-notebooks/mne-tutorial/\n",
    "def plot_examples_plotly(file_name, excluded_channels, resolution_hz):\n",
    "    patient_id = file_name.split(\"\\\\\")[-1][:-4]\n",
    "    ### print('\\nRaw Data')\n",
    "    ### raw = get_raw_eeg_mne(file_name)\n",
    "    ### plot_eeg_plotly(raw, [])\n",
    "    \n",
    "    print('\\nCleaned Data')\n",
    "    print('Excluding channels {}; '.format(\", \".join(excluded_channels)))\n",
    "    print('Removing first 120s of data; and last 120s of shortest sample. Limiting all other samples to range of shortest sample')\n",
    "\n",
    "    cleaned = get_raw_eeg_mne(file_name, resolution_hz, tmin=120, tmax=minimum_duration-120, exclude=excluded_channels)\n",
    "    cleaned.crop()\n",
    "    plot_eeg_plotly(cleaned, excluded_channels, resolution_hz)\n",
    "\n",
    "# plot a random patient\n",
    "sz_patient_list = list(range(1, 15, 1))\n",
    "sz_patient_list.remove(12) #drop value from list of exclusions\n",
    "sz_patient_list.remove(14) #drop value from list of exclusions\n",
    "rand_patient_id =  random.choice(sz_patient_list)\n",
    "rand_patient_file =  raw_data_dir + 'SZ Patients/{}.edf'.format(\"{}{:02d}\").format('s', rand_patient_id)\n",
    "\n",
    "rand_control_id = random.randrange(1, 15, 1)\n",
    "rand_control_file = raw_data_dir + 'Healthy Controls/{}{:02d}.edf'.format('h', rand_control_id)\n",
    "\n",
    "\n",
    "print('Example of Input Data From Random Patient')\n",
    "print('Sz patient #{:02d}'.format(rand_patient_id))\n",
    "plot_examples_plotly(rand_patient_file, excluded_channels, resolution_hz)\n",
    "\n",
    "#print(\"Example of Input Data From Random Control\")\n",
    "#print('Control subject #{:02d}'.format(rand_control_id))\n",
    "#plot_examples_plotly(rand_control_file, excluded_channels, resolution_hz)\n",
    "\n",
    "print('Ignored files: ')\n",
    "print(\",\".join(ignore_list))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bs_ZLGCZh1yJ"
   },
   "outputs": [],
   "source": [
    "#drop the second dimension\n",
    "hc_data_all = np.asarray(hc_data)\n",
    "sz_data_all = np.asarray(sz_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "WKi98Pk6h1yQ",
    "outputId": "275ac50a-3390-4714-b2ec-7acdc1f197c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of denoised data (extracted components) :\n",
      "(14, 14, 125001)\n",
      "(14, 14, 125001)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.decomposition as decomposition\n",
    "\n",
    "def select_denoised_data(patient_data):\n",
    "    all_features = []\n",
    "  \n",
    "    \n",
    "    for entry in patient_data:\n",
    "        pca_denoise = decomposition.PCA(n_components=19)\n",
    "        pca_denoise.fit(entry.transpose())\n",
    "        denoised_data = pca_denoise.components_[:14] #select top v components, where v is based on chart of explained variance\n",
    "        all_features.append(np.asarray(denoised_data)) \n",
    "        \n",
    "\n",
    "    return all_features\n",
    "    \n",
    "\n",
    "sample_size = minimum_duration #use entire window\n",
    "#send all channels and all patient data; s07 is still skipped\n",
    "hc_data_all_denoised_selected = select_denoised_data(hc_data_all)\n",
    "sz_data_all_denoised_selected = select_denoised_data(sz_data_all)\n",
    "\n",
    "print('Shape of denoised data (extracted components) :')\n",
    "print(np.asarray(hc_data_all_denoised_selected).shape)\n",
    "print(np.asarray(sz_data_all_denoised_selected).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOWRun_Nh1yW"
   },
   "outputs": [],
   "source": [
    "# flatten the feature vectors so that input can be used in scikit learn \n",
    "def flatten_features(data):\n",
    "    flattened_data = []\n",
    "    for entry in data: \n",
    "        # shift axes so that data shape is time * channels * features. Then flatten data\n",
    "        flattened_data.append(np.moveaxis(entry, 0, -1).flatten())\n",
    "    return np.asarray(flattened_data, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "4VbhzxK1h1yc",
    "outputId": "902bbaeb-8c15-4c38-bf1c-e111dc65c592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  (28, 14, 125001)\n",
      "Flattened input size:  (28, 1750014)\n"
     ]
    }
   ],
   "source": [
    "# load extracted features\n",
    "\n",
    "X =  np.concatenate((hc_data_all_denoised_selected, sz_data_all_denoised_selected), axis=0)\n",
    "X_original = X.copy()\n",
    "print('Input size: ', X.shape)\n",
    "y = ([0] * len(hc_data_all_denoised_selected)) +( [1] * len(sz_data_all_denoised_selected))\n",
    "sample_size = 2\n",
    "\n",
    "X = flatten_features(X)\n",
    "print('Flattened input size: ', X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paC5wQ8eh1yf"
   },
   "outputs": [],
   "source": [
    "# get a list of randomly selected sets of numbers based on a range\n",
    "# the proportion of values selected for each set is determined by the ratio_array\n",
    "import itertools\n",
    "def get_mixed_indexes_for_ml_train_test(length, ratios_array):\n",
    "    input_indexes = range(0, length)\n",
    "    output_indexes = []\n",
    "    for ratio in ratios_array:\n",
    "        input_indexes = [i for i in input_indexes if i not in list(itertools.chain(*output_indexes))]\n",
    "        selection = random.sample(input_indexes, k=math.floor(ratio * length))\n",
    "        output_indexes.append(selection)\n",
    "    return output_indexes\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xyccwpbgh1yj",
    "outputId": "fb2cc989-8e1f-4b4d-a4c3-ba496d2a2a7e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 22 samples; testing on 5 samples\n"
     ]
    }
   ],
   "source": [
    "train_idxs, test_idxs = get_mixed_indexes_for_ml_train_test(len(X), [.80, 0.20])\n",
    "\n",
    "X_train      = X[train_idxs][0:,]\n",
    "Y_train      = np.asarray(y)[train_idxs]\n",
    "X_test       = X[test_idxs][0:,]\n",
    "Y_test       = np.asarray(y)[test_idxs]\n",
    "\n",
    "print('Training on {} samples; testing on {} samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "J56n1BcKh1y5",
    "outputId": "06e52288-ec33-46b4-a5a3-5d3ad262b664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessing various classifiers. Using k-fold value of  14 \n",
      "\n",
      "SVM mean cross-validation accuracy (k-fold=14)  using scaled data :  46%\n",
      "Gaussian Naive Bayes mean cross-validation accuracy (k-fold=14) :  50%\n",
      "K Nearest Neighbors mean cross-validation accuracy (k-fold=14) :  50%\n",
      "Nearest Centroid mean cross-validation accuracy (k-fold=14) :  50%\n",
      "Decision Tree mean cross-validation accuracy (k-fold=14) :  39%\n",
      "Adaboost mean cross-validation accuracy (k-fold=14) :  43%\n",
      "Gradient Boosting Classifier mean cross-validation accuracy (k-fold=14) :  36%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Standardize the cross-validation implementation and\n",
    "# the display of results for traditional models\n",
    "#\n",
    "# clf: the scikitlearn classifier to be used\n",
    "# model_name: name of the model for display\n",
    "# X: flattened data\n",
    "# y: labels\n",
    "# k_fold the number of folds (must be <= the number of participants in each group)\n",
    "# scale_data: whether or not to use the StandardScaler to normalize the dataset; this is most helpful for SVM\n",
    "#       but does not seem to have a significant impact on most other classifiers but seems to be problematic for\n",
    "#       decision trees\n",
    "def run_traditional_model(clf, model_name, X, y, k_fold=12, scale_data=False):\n",
    "      \n",
    "    if scale_data:\n",
    "        scaler = StandardScaler()\n",
    "        clf = Pipeline(steps=[('s', scaler), ('m', clf)]) \n",
    "    scaling_note = ' using scaled data ' if scale_data else ''\n",
    "        \n",
    "    scores = cross_val_score(clf, X, y, cv=k_fold)\n",
    "    print('%s %3.f%%' % ('{} mean cross-validation accuracy (k-fold={}) {}:'\n",
    "                         .format(model_name, k_fold, scaling_note), scores.mean() * 100.))\n",
    "    return scores\n",
    "\n",
    "\n",
    "k_fold=min(len(hc_data_all_denoised_selected), len(sz_data_all_denoised_selected))\n",
    "print('Assessing various classifiers. Using k-fold value of ',k_fold,'\\n')\n",
    "\n",
    "model_name = 'SVM'\n",
    "clf = SVC(gamma='scale', kernel='rbf', degree=3)## default values \n",
    "svm_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold, scale_data=True)\n",
    "\n",
    "\n",
    "model_name = 'Gaussian Naive Bayes'\n",
    "clf = GaussianNB()\n",
    "gnb_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'K Nearest Neighbors'\n",
    "n_neighbors = 2\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform') #weights={'uniform', 'distance'}\n",
    "knn_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'Nearest Centroid'\n",
    "clf = neighbors.NearestCentroid()\n",
    "nc_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'Decision Tree'\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "decision_tree_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'Adaboost'\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "adaboost_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n",
    "model_name = 'Gradient Boosting Classifier'\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0)\n",
    "gbc_scores = run_traditional_model(clf, model_name, X, y, k_fold=k_fold)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkdi-Z1Qh1y-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4iEFmhK0h1zA",
    "outputId": "214fb53b-1f8c-4002-ad7a-d5bc39b64cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing environment settings\n",
      "\n",
      "Python version:  3.6.9\n",
      "\n",
      "Installed modules:\n",
      "\n",
      "absl-py==0.9.0\n",
      "alabaster==0.7.12\n",
      "albumentations==0.1.12\n",
      "altair==4.1.0\n",
      "asgiref==3.2.7\n",
      "astor==0.8.1\n",
      "astropy==4.0.1.post1\n",
      "astunparse==1.6.3\n",
      "atari-py==0.2.6\n",
      "atomicwrites==1.3.0\n",
      "attrs==19.3.0\n",
      "audioread==2.1.8\n",
      "autograd==1.3\n",
      "Babel==2.8.0\n",
      "backcall==0.1.0\n",
      "beautifulsoup4==4.6.3\n",
      "bleach==3.1.4\n",
      "blis==0.4.1\n",
      "bokeh==1.4.0\n",
      "boto==2.49.0\n",
      "boto3==1.12.47\n",
      "botocore==1.15.47\n",
      "Bottleneck==1.3.2\n",
      "branca==0.4.0\n",
      "bs4==0.0.1\n",
      "CacheControl==0.12.6\n",
      "cachetools==3.1.1\n",
      "catalogue==1.0.0\n",
      "certifi==2020.4.5.1\n",
      "cffi==1.14.0\n",
      "chainer==6.5.0\n",
      "chardet==3.0.4\n",
      "chart-studio==1.0.0\n",
      "click==7.1.2\n",
      "cloudpickle==1.3.0\n",
      "cmake==3.12.0\n",
      "cmdstanpy==0.4.0\n",
      "colorlover==0.3.0\n",
      "community==1.0.0b1\n",
      "contextlib2==0.5.5\n",
      "convertdate==2.2.0\n",
      "coverage==3.7.1\n",
      "coveralls==0.5\n",
      "crcmod==1.7\n",
      "cufflinks==0.17.3\n",
      "cvxopt==1.2.5\n",
      "cvxpy==1.0.31\n",
      "cycler==0.10.0\n",
      "cymem==2.0.3\n",
      "Cython==0.29.17\n",
      "daft==0.0.4\n",
      "dask==2.12.0\n",
      "dataclasses==0.7\n",
      "datascience==0.10.6\n",
      "decorator==4.4.2\n",
      "defusedxml==0.6.0\n",
      "descartes==1.1.0\n",
      "dill==0.3.1.1\n",
      "distributed==1.25.3\n",
      "Django==3.0.5\n",
      "dlib==19.18.0\n",
      "docopt==0.6.2\n",
      "docutils==0.15.2\n",
      "dopamine-rl==1.0.5\n",
      "earthengine-api==0.1.219\n",
      "easydict==1.9\n",
      "ecos==2.0.7.post1\n",
      "editdistance==0.5.3\n",
      "en-core-web-sm==2.2.5\n",
      "entrypoints==0.3\n",
      "ephem==3.7.7.1\n",
      "et-xmlfile==1.0.1\n",
      "fa2==0.3.5\n",
      "fancyimpute==0.4.3\n",
      "fastai==1.0.60\n",
      "fastdtw==0.3.4\n",
      "fastprogress==0.2.3\n",
      "fastrlock==0.4\n",
      "fbprophet==0.6\n",
      "feather-format==0.4.1\n",
      "featuretools==0.4.1\n",
      "filelock==3.0.12\n",
      "firebase-admin==4.1.0\n",
      "fix-yahoo-finance==0.0.22\n",
      "Flask==1.1.2\n",
      "folium==0.8.3\n",
      "fsspec==0.7.3\n",
      "future==0.16.0\n",
      "gast==0.3.3\n",
      "GDAL==2.2.2\n",
      "gdown==3.6.4\n",
      "gensim==3.6.0\n",
      "geographiclib==1.50\n",
      "geopy==1.17.0\n",
      "gin-config==0.3.0\n",
      "glob2==0.7\n",
      "google==2.0.3\n",
      "google-api-core==1.16.0\n",
      "google-api-python-client==1.7.12\n",
      "google-auth==1.7.2\n",
      "google-auth-httplib2==0.0.3\n",
      "google-auth-oauthlib==0.4.1\n",
      "google-cloud-bigquery==1.21.0\n",
      "google-cloud-core==1.0.3\n",
      "google-cloud-datastore==1.8.0\n",
      "google-cloud-firestore==1.6.2\n",
      "google-cloud-language==1.2.0\n",
      "google-cloud-storage==1.18.1\n",
      "google-cloud-translate==1.5.0\n",
      "google-colab==1.0.0\n",
      "google-pasta==0.2.0\n",
      "google-resumable-media==0.4.1\n",
      "googleapis-common-protos==1.51.0\n",
      "googledrivedownloader==0.4\n",
      "graphviz==0.10.1\n",
      "grpcio==1.28.1\n",
      "gspread==3.0.1\n",
      "gspread-dataframe==3.0.6\n",
      "gym==0.17.1\n",
      "h5py==2.10.0\n",
      "HeapDict==1.0.1\n",
      "holidays==0.9.12\n",
      "html5lib==1.0.1\n",
      "httpimport==0.5.18\n",
      "httplib2==0.17.3\n",
      "httplib2shim==0.0.3\n",
      "humanize==0.5.1\n",
      "hyperopt==0.1.2\n",
      "ideep4py==2.0.0.post3\n",
      "idna==2.9\n",
      "image==1.5.31\n",
      "imageio==2.4.1\n",
      "imagesize==1.2.0\n",
      "imbalanced-learn==0.4.3\n",
      "imblearn==0.0\n",
      "imgaug==0.2.9\n",
      "importlib-metadata==1.6.0\n",
      "imutils==0.5.3\n",
      "inflect==2.1.0\n",
      "intel-openmp==2020.0.133\n",
      "intervaltree==2.1.0\n",
      "ipykernel==4.10.1\n",
      "ipython==5.5.0\n",
      "ipython-genutils==0.2.0\n",
      "ipython-sql==0.3.9\n",
      "ipywidgets==7.5.1\n",
      "itsdangerous==1.1.0\n",
      "jax==0.1.64\n",
      "jaxlib==0.1.45\n",
      "jdcal==1.4.1\n",
      "jedi==0.17.0\n",
      "jieba==0.42.1\n",
      "Jinja2==2.11.2\n",
      "jmespath==0.9.5\n",
      "joblib==0.14.1\n",
      "jpeg4py==0.1.4\n",
      "jsonschema==2.6.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==5.3.4\n",
      "jupyter-console==5.2.0\n",
      "jupyter-core==4.6.3\n",
      "kaggle==1.5.6\n",
      "kapre==0.1.3.1\n",
      "Keras==2.3.1\n",
      "Keras-Applications==1.0.8\n",
      "Keras-Preprocessing==1.1.0\n",
      "keras-vis==0.4.1\n",
      "kiwisolver==1.2.0\n",
      "knnimpute==0.1.0\n",
      "librosa==0.6.3\n",
      "lightgbm==2.2.3\n",
      "llvmlite==0.31.0\n",
      "lmdb==0.98\n",
      "lucid==0.3.8\n",
      "LunarCalendar==0.0.9\n",
      "lxml==4.2.6\n",
      "Markdown==3.2.1\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib==3.2.1\n",
      "matplotlib-venn==0.11.5\n",
      "missingno==0.4.2\n",
      "mistune==0.8.4\n",
      "mizani==0.6.0\n",
      "mkl==2019.0\n",
      "mlxtend==0.14.0\n",
      "mne==0.19.2\n",
      "more-itertools==8.2.0\n",
      "moviepy==0.2.3.5\n",
      "mpmath==1.1.0\n",
      "msgpack==1.0.0\n",
      "multiprocess==0.70.9\n",
      "multitasking==0.0.9\n",
      "murmurhash==1.0.2\n",
      "music21==5.5.0\n",
      "natsort==5.5.0\n",
      "nbconvert==5.6.1\n",
      "nbformat==5.0.6\n",
      "networkx==2.4\n",
      "nibabel==3.0.2\n",
      "nltk==3.2.5\n",
      "notebook==5.2.2\n",
      "np-utils==0.5.12.1\n",
      "numba==0.48.0\n",
      "numexpr==2.7.1\n",
      "numpy==1.18.3\n",
      "nvidia-ml-py3==7.352.0\n",
      "oauth2client==4.1.3\n",
      "oauthlib==3.1.0\n",
      "okgrade==0.4.3\n",
      "opencv-contrib-python==4.1.2.30\n",
      "opencv-python==4.1.2.30\n",
      "openpyxl==2.5.9\n",
      "opt-einsum==3.2.1\n",
      "osqp==0.6.1\n",
      "packaging==20.3\n",
      "palettable==3.3.0\n",
      "pandas==1.0.3\n",
      "pandas-datareader==0.8.1\n",
      "pandas-gbq==0.11.0\n",
      "pandas-profiling==1.4.1\n",
      "pandocfilters==1.4.2\n",
      "parso==0.7.0\n",
      "pathlib==1.0.1\n",
      "patsy==0.5.1\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==7.0.0\n",
      "pip-tools==4.5.1\n",
      "plac==1.1.3\n",
      "plotly==4.4.1\n",
      "plotnine==0.6.0\n",
      "pluggy==0.7.1\n",
      "portpicker==1.3.1\n",
      "prefetch-generator==1.0.1\n",
      "preshed==3.0.2\n",
      "prettytable==0.7.2\n",
      "progressbar2==3.38.0\n",
      "prometheus-client==0.7.1\n",
      "promise==2.3\n",
      "prompt-toolkit==1.0.18\n",
      "protobuf==3.10.0\n",
      "psutil==5.4.8\n",
      "psycopg2==2.7.6.1\n",
      "ptvsd==5.0.0a12\n",
      "ptyprocess==0.6.0\n",
      "py==1.8.1\n",
      "pyarrow==0.14.1\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycocotools==2.0.0\n",
      "pycparser==2.20\n",
      "pydata-google-auth==1.1.0\n",
      "pydot==1.3.0\n",
      "pydot-ng==2.0.0\n",
      "pydotplus==2.0.2\n",
      "PyDrive==1.3.1\n",
      "pyEDFlib==0.1.15\n",
      "pyemd==0.5.1\n",
      "pyglet==1.5.0\n",
      "Pygments==2.1.3\n",
      "pygobject==3.26.1\n",
      "pymc3==3.7\n",
      "PyMeeus==0.3.7\n",
      "pymongo==3.10.1\n",
      "pymystem3==0.2.0\n",
      "PyOpenGL==3.1.5\n",
      "pyparsing==2.4.7\n",
      "pyrsistent==0.16.0\n",
      "pysndfile==1.3.8\n",
      "PySocks==1.7.1\n",
      "pystan==2.19.1.1\n",
      "pytest==3.6.4\n",
      "python-apt==1.6.5+ubuntu0.2\n",
      "python-chess==0.23.11\n",
      "python-dateutil==2.8.1\n",
      "python-louvain==0.14\n",
      "python-slugify==4.0.0\n",
      "python-utils==2.4.0\n",
      "pytz==2018.9\n",
      "PyWavelets==1.1.1\n",
      "PyYAML==3.13\n",
      "pyzmq==19.0.0\n",
      "qtconsole==4.7.3\n",
      "QtPy==1.9.0\n",
      "regex==2019.12.20\n",
      "requests==2.23.0\n",
      "requests-oauthlib==1.3.0\n",
      "resampy==0.2.2\n",
      "retrying==1.3.3\n",
      "rpy2==3.2.7\n",
      "rsa==4.0\n",
      "s3fs==0.4.2\n",
      "s3transfer==0.3.3\n",
      "scikit-image==0.16.2\n",
      "scikit-learn==0.22.2.post1\n",
      "scipy==1.4.1\n",
      "screen-resolution-extra==0.0.0\n",
      "scs==2.1.2\n",
      "seaborn==0.10.1\n",
      "Send2Trash==1.5.0\n",
      "setuptools-git==1.2\n",
      "Shapely==1.7.0\n",
      "simplegeneric==0.8.1\n",
      "six==1.12.0\n",
      "sklearn==0.0\n",
      "sklearn-pandas==1.8.0\n",
      "smart-open==1.11.1\n",
      "snowballstemmer==2.0.0\n",
      "sortedcontainers==2.1.0\n",
      "spacy==2.2.4\n",
      "Sphinx==1.8.5\n",
      "sphinxcontrib-websupport==1.2.1\n",
      "SQLAlchemy==1.3.16\n",
      "sqlparse==0.3.1\n",
      "srsly==1.0.2\n",
      "statsmodels==0.10.2\n",
      "sympy==1.1.1\n",
      "tables==3.4.4\n",
      "tabulate==0.8.7\n",
      "tbb==2020.0.133\n",
      "tblib==1.6.0\n",
      "tensorboard==2.2.1\n",
      "tensorboard-plugin-wit==1.6.0.post3\n",
      "tensorboardcolab==0.0.22\n",
      "tensorflow==2.2.0rc3\n",
      "tensorflow-addons==0.8.3\n",
      "tensorflow-datasets==2.1.0\n",
      "tensorflow-estimator==2.2.0\n",
      "tensorflow-gcs-config==2.1.8\n",
      "tensorflow-hub==0.8.0\n",
      "tensorflow-metadata==0.21.2\n",
      "tensorflow-privacy==0.2.2\n",
      "tensorflow-probability==0.10.0rc0\n",
      "termcolor==1.1.0\n",
      "terminado==0.8.3\n",
      "testpath==0.4.4\n",
      "text-unidecode==1.3\n",
      "textblob==0.15.3\n",
      "textgenrnn==1.4.1\n",
      "Theano==1.0.4\n",
      "thinc==7.4.0\n",
      "toolz==0.10.0\n",
      "torch==1.5.0+cu101\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.3.1\n",
      "torchvision==0.6.0+cu101\n",
      "tornado==4.5.3\n",
      "tqdm==4.38.0\n",
      "traitlets==4.3.3\n",
      "tweepy==3.6.0\n",
      "typeguard==2.7.1\n",
      "typing==3.6.6\n",
      "typing-extensions==3.6.6\n",
      "tzlocal==1.5.1\n",
      "umap-learn==0.4.1\n",
      "uritemplate==3.0.1\n",
      "urllib3==1.24.3\n",
      "vega-datasets==0.8.0\n",
      "wasabi==0.6.0\n",
      "wcwidth==0.1.9\n",
      "webencodings==0.5.1\n",
      "Werkzeug==1.0.1\n",
      "widgetsnbextension==3.5.1\n",
      "wordcloud==1.5.0\n",
      "wrapt==1.12.1\n",
      "xarray==0.15.1\n",
      "xgboost==0.90\n",
      "xkit==0.0.0\n",
      "xlrd==1.1.0\n",
      "xlwt==1.3.0\n",
      "yellowbrick==0.9.1\n",
      "zict==2.0.0\n",
      "zipp==3.1.0\n"
     ]
    }
   ],
   "source": [
    "## End of implementation code  \n",
    "\n",
    "print('Printing environment settings')\n",
    "\n",
    "from platform import python_version\n",
    "print('\\nPython version: ', python_version())\n",
    "print('\\nInstalled modules:\\n')\n",
    "\n",
    "!pip freeze"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Traditional Classifiers using PCA with All Features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
