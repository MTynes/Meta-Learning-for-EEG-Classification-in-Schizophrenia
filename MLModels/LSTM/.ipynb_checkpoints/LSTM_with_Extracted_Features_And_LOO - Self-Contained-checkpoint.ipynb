{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "X_ZRvtEVHxY2",
    "outputId": "40cceb00-fedc-4bdb-bb3c-0aa2515fcc52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using homepath \\Users\\marit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "raw_data_dir = ''\n",
    "\n",
    "if  'COLAB_GPU' in os.environ:\n",
    "    print('Using Google Colab. Setting up environment')\n",
    "    raw_data_dir = '/content/drive/My Drive/Colab Notebooks/' \n",
    "    !pip install mne\n",
    "    !pip install pyedflib\n",
    "\n",
    "    print('\\n \\n To load files from Google Drive, account validation is required.')\n",
    "    #mount to drive -- files should be located in the Colab notebooks directory\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "else:\n",
    "    if 'HOMEPATH' in os.environ:\n",
    "        print('Using homepath ' + os.environ['HOMEPATH'])\n",
    "    #declare local data directory here\n",
    "    raw_data_dir = '../../Data/Raw/' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "2ibl3Xz6AXWV",
    "outputId": "7e2498a0-8e16-4591-9dcb-7289287f7316"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marit\\Anaconda3\\lib\\site-packages\\numba\\decorators.py:146: RuntimeWarning: Caching is not available when the 'parallel' target is in use. Caching is now being disabled to allow execution to continue.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import pandas as pd\n",
    "import pyedflib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "use_gpu = tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import random \n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mjbWjSEJl0C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving raw data....\n",
      "Minimum file duration: 740 seconds\n",
      "Healthy Controls:\n",
      "(14, 500, 17)\n",
      "Sz Patients:\n",
      "(13, 500, 17)\n"
     ]
    }
   ],
   "source": [
    "#### Get all raw data\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# edf libraries\n",
    "import pyedflib\n",
    "import mne\n",
    "\n",
    "#pca dependencies\n",
    "from sklearn import decomposition\n",
    "\n",
    "ignore_list = ['s12']#['s07']  #list of patient files that should be skipped\n",
    "sample_size = 20\n",
    "\n",
    "import pyedflib\n",
    "mne.set_log_level(\"WARNING\")\n",
    "\n",
    "# get the minimum length of the files\n",
    "def get_minimum_duration(group_directory_name, patient_group_file_prefix):\n",
    "    file_durations = []\n",
    "    for i in range (1, 15): # reading 14 files\n",
    "        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n",
    "        file_name = raw_data_dir + '{}/{}.edf'.format(group_directory_name, patient_id)\n",
    "        f = pyedflib.EdfReader(file_name)\n",
    "        file_durations.append(f.file_duration)\n",
    "        f.close()\n",
    "    return(min(file_durations))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def process_patient_group_all_data(group_directory_name, patient_group_file_prefix, \n",
    "                          minimum_original_duration, \n",
    "                          channels = ['Fp2', 'F8', 'T4', 'T6', 'O2', 'Fp1',\n",
    "                                      'F7',  'T3', 'T5', 'O1', 'F4', 'C4', \n",
    "                                      'P4', 'F3', 'C3', 'P3', 'Fz', 'Cz', 'Pz']):\n",
    "    meta = []\n",
    "    patient_id_list = []\n",
    "    for i in range (1, 15): # reading 14 files\n",
    "        patient_df = []\n",
    "        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n",
    "        patient_id_list.append(patient_id)\n",
    "        \n",
    "        file_name = raw_data_dir + '{}/{}.edf'.format(group_directory_name, patient_id)\n",
    "        data = mne.io.read_raw_edf(file_name)\n",
    "        df = data.to_data_frame()\n",
    "        df = df[channels]\n",
    "        ## drop the first 120 seconds and last 120 seconds\n",
    "        df2 = df[120: (minimum_original_duration-120)]\n",
    "        if patient_id not in ignore_list:\n",
    "            meta.append(np.asarray(df2))\n",
    "           \n",
    "                    \n",
    "    return meta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "all_channels = ['Fp2', 'F8', 'T4', 'T6', 'O2', 'Fp1', 'F7', 'T3', 'T5', 'O1', 'F4',\n",
    "                'C4', 'P4', 'F3', 'C3', 'P3', 'Fz', 'Cz', 'Pz']\n",
    "#target_channels = ['T4', 'T6', 'O2', 'T3', 'T5', 'O1',\n",
    "#                   'C4', 'P4', 'C3', 'P3', 'Cz', 'Pz']\n",
    "\n",
    "target_channels = ['Fp2', 'F8', 'T4', 'T6', 'Fp1', 'F7', 'T3', 'T5', 'F4',\n",
    "                'C4', 'P4', 'F3', 'C3', 'P3', 'Fz', 'Cz', 'Pz']\n",
    "\n",
    "minimum_duration = min(get_minimum_duration(\"Healthy Controls\", \"h\"), get_minimum_duration('SZ Patients', 's'))\n",
    "print('Retrieving raw data....')\n",
    "print('Minimum file duration: {} seconds'.format( minimum_duration))\n",
    "print(\"Healthy Controls:\")\n",
    "hc_data_all = np.asarray(process_patient_group_all_data('Healthy Controls', 'h', minimum_duration, channels=target_channels), dtype=np.float32)\n",
    "print(np.asarray(hc_data_all).shape)\n",
    "\n",
    "\n",
    "print('Sz Patients:')\n",
    "sz_data_all = np.asarray(process_patient_group_all_data('SZ Patients', 's', minimum_duration, channels=target_channels), dtype=np.float32)\n",
    "print(np.asarray(sz_data_all).shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 500, 17)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'transpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-f01963b715e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0msample_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimum_duration\u001b[0m \u001b[1;31m#use entire window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#send all channels and all patient data; s07 is still skipped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mhc_data_all_denoised_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_denoised_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhc_data_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0msz_data_all_denoised_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_denoised_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msz_data_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-f01963b715e8>\u001b[0m in \u001b[0;36mselect_denoised_data\u001b[1;34m(patient_data)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mpca_denoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_entries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpca_denoise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_entries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdenoised_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_denoise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mall_entries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdenoised_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "def select_denoised_data(patient_data):\n",
    "    all_features = []\n",
    "    all_entries = []\n",
    "    for entry in patient_data:\n",
    "        all_entries.append(entry)\n",
    "        \n",
    "    \n",
    "    pca_denoise = decomposition.PCA(n_components=12)\n",
    "    print(np.asarray(all_entries).shape)\n",
    "    pca_denoise.fit(all_entries.transpose())\n",
    "    denoised_data = pca_denoise.components_\n",
    "    all_entries.append(np.asarray(denoised_data)) \n",
    "        \n",
    "    return all_features\n",
    "    \n",
    "\n",
    "sample_size = minimum_duration #use entire window\n",
    "#send all channels and all patient data; s07 is still skipped\n",
    "hc_data_all_denoised_selected = select_denoised_data(hc_data_all)\n",
    "sz_data_all_denoised_selected = select_denoised_data(sz_data_all)\n",
    "\n",
    "print('Shape of denoised data (extracted components) :')\n",
    "print(np.asarray(hc_data_all_denoised_selected).shape)\n",
    "print(np.asarray(sz_data_all_denoised_selected).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-P1L5LqkAXXa"
   },
   "outputs": [],
   "source": [
    "#setup the network\n",
    "from tensorflow.keras import layers\n",
    "#https://www.tensorflow.org/guide/keras/rnn\n",
    "\n",
    "def LSTM(samples, time_steps, nb_features, chans, nb_classes):\n",
    "\n",
    "    model=tf.keras.Sequential()\n",
    "    \n",
    "    model.add(layers.LSTM(256,\n",
    "                          input_shape=(chans, time_steps)\n",
    "            #input_shape=(chans* nb_features, time_steps),\n",
    "            ))\n",
    "\n",
    "    model.add(Dense(32,kernel_initializer='he_uniform',activation='relu'))\n",
    "\n",
    "    model.add(Dense(nb_classes,activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "MHAeuZnVAXZc",
    "outputId": "0cbfc7ba-68f4-4d71-bcb9-2986341e423e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  (27, 500, 17)\n"
     ]
    }
   ],
   "source": [
    "#X =  np.concatenate((hc_data_all_denoised_selected, sz_data_all_denoised_selected), axis=0)\n",
    "X =  np.concatenate((hc_data_all, sz_data_all), axis=0)\n",
    "print('Input size: ', X.shape)\n",
    "y = ([0] * len(hc_data_all)) +( [1] * len(sz_data_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "bOd_LccVvXcc",
    "outputId": "d074690f-c3e8-4abb-bd88-a40af89de4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Input Data From Random Patient\n",
      "sz patient  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 460.8x338.4 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Input Data From Random Control\n",
      "control subject  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 460.8x338.4 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored files: \n",
      "s12\n"
     ]
    }
   ],
   "source": [
    "def plot_all_channels(file_name):\n",
    "    patient_id = file_name.split(\"\\\\\")[-1][:-4]\n",
    "    #display(\"### Patient ID: \" +  patient_id)\n",
    "    raw = mne.io.read_raw_edf(file_name, preload=True, exclude=['O1', 'O2'])\n",
    "    raw.crop(tmin=120, tmax=minimum_duration-120)\n",
    "    #raw.set_montage(\"standard_1020\")\n",
    "    events = mne.find_events(raw, stim_channel=raw.ch_names, initial_event=True, consecutive=True)\n",
    "    raw.plot()\n",
    "\n",
    "# plot a random patient\n",
    "sz_patient_list = list(range(1, len(sz_data_all)+1, 1))\n",
    "sz_patient_list.remove(12) #drop value from list of exclusions\n",
    "rand_patient_id =  random.choice(sz_patient_list)\n",
    "rand_patient_file=  raw_data_dir + 'SZ Patients/{}.edf'.format(\"{}{:02d}\").format('s', rand_patient_id)\n",
    "\n",
    "rand_control_id = random.randrange(1, len(hc_data_all)+ 1, 1)\n",
    "rand_control_file = raw_data_dir + 'Healthy Controls/{}{:02d}.edf'.format('h', rand_control_id)\n",
    "\n",
    "print('Example of Input Data From Random Patient')\n",
    "print('sz patient ', rand_patient_id)\n",
    "plot_all_channels(rand_patient_file)\n",
    "\n",
    "print(\"Example of Input Data From Random Control\")\n",
    "print('control subject ', rand_control_id)\n",
    "plot_all_channels(rand_control_file)\n",
    "\n",
    "print('Ignored files: ')\n",
    "print(\",\".join(ignore_list))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2C7VyiTAXbC"
   },
   "outputs": [],
   "source": [
    "#### Create the /tmp directory if it doesn't already exist\n",
    "import os\n",
    "if not os.path.exists('tmp'):\n",
    "    os.makedirs('tmp')\n",
    "\n",
    "# set a valid path for the system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/LSTM_LOO_checkpoint.h5', verbose=1,\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marit\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn wrapper to implement LOO\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "#from tensorflow.keras.models import * \n",
    "#from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "time_steps = 500 #sample_size #seconds of data to include in one slice\n",
    "kernels, chans, samples = 1, len(target_channels), time_steps\n",
    "X_full  = X.reshape(X.shape[0], chans, time_steps)\n",
    "y_full  = np_utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "\n",
    "def buildmodel():\n",
    "    \"\"\"model= Sequential([\n",
    "        Dense(10, activation=\"relu\"),\n",
    "        Dense(5, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\"\"\"\n",
    "    \n",
    "    model = LSTM(samples=samples, time_steps=time_steps, chans=chans, nb_features=1, nb_classes=2, )\n",
    "    model.summary()\n",
    "\n",
    "    #import tensorflow \n",
    "    import tensorflow.keras.optimizers\n",
    "    opt_adam = tensorflow.keras.optimizers.Adam(lr=0.000001, \n",
    "                                    beta_1=0.99,\n",
    "                                    beta_2=0.999,\n",
    "                                    epsilon=1e-07)\n",
    "    sgd = tensorflow.keras.optimizers.SGD(lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "    def rmse (y_true, y_pred):\n",
    "\n",
    "        return K.sqrt(K.mean(K.square(y_pred -y_true)))\n",
    "\n",
    "\n",
    "    # compile the model and set the optimizers\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt_adam, \n",
    "                  metrics=[#'mse', 'mae', \n",
    "                      'accuracy', rmse\n",
    "                     ])\n",
    "    return(model)\n",
    "\n",
    "estimator= KerasRegressor(build_fn=buildmodel, epochs=100, batch_size=16, verbose=0)\n",
    "kfold= KFold(n_splits=X.shape[0]) #set n_splits to n to implement LOO https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html\n",
    "results= cross_val_score(estimator, X_full, y_full, cv=kfold, n_jobs=2)  # n_jobs - number of CPUs\n",
    "results.mean()  # Mean MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "_luI4i6LAXbn",
    "outputId": "dc6d2348-ad11-4b78-8d5b-e4aa9623ad14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.20539, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 8s - loss: 0.8287 - acc: 0.5385 - rmse: 0.5439 - val_loss: 1.2054 - val_acc: 0.0000e+00 - val_rmse: 0.7004\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.8262 - acc: 0.5385 - rmse: 0.5430 - val_loss: 1.2055 - val_acc: 0.0000e+00 - val_rmse: 0.7005\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.8237 - acc: 0.5385 - rmse: 0.5422 - val_loss: 1.2056 - val_acc: 0.0000e+00 - val_rmse: 0.7005\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.8212 - acc: 0.5385 - rmse: 0.5414 - val_loss: 1.2058 - val_acc: 0.0000e+00 - val_rmse: 0.7005\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.8188 - acc: 0.5385 - rmse: 0.5406 - val_loss: 1.2059 - val_acc: 0.0000e+00 - val_rmse: 0.7006\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.8165 - acc: 0.5385 - rmse: 0.5398 - val_loss: 1.2060 - val_acc: 0.0000e+00 - val_rmse: 0.7006\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.8143 - acc: 0.5385 - rmse: 0.5391 - val_loss: 1.2062 - val_acc: 0.0000e+00 - val_rmse: 0.7007\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.8120 - acc: 0.5385 - rmse: 0.5383 - val_loss: 1.2063 - val_acc: 0.0000e+00 - val_rmse: 0.7007\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.8098 - acc: 0.5385 - rmse: 0.5376 - val_loss: 1.2064 - val_acc: 0.0000e+00 - val_rmse: 0.7007\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.8076 - acc: 0.5385 - rmse: 0.5368 - val_loss: 1.2066 - val_acc: 0.0000e+00 - val_rmse: 0.7008\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.8054 - acc: 0.5385 - rmse: 0.5361 - val_loss: 1.2067 - val_acc: 0.0000e+00 - val_rmse: 0.7008\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.8032 - acc: 0.5385 - rmse: 0.5354 - val_loss: 1.2068 - val_acc: 0.0000e+00 - val_rmse: 0.7009\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.8011 - acc: 0.5385 - rmse: 0.5347 - val_loss: 1.2069 - val_acc: 0.0000e+00 - val_rmse: 0.7009\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.7989 - acc: 0.5385 - rmse: 0.5339 - val_loss: 1.2071 - val_acc: 0.0000e+00 - val_rmse: 0.7009\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.7968 - acc: 0.5385 - rmse: 0.5332 - val_loss: 1.2072 - val_acc: 0.0000e+00 - val_rmse: 0.7010\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7947 - acc: 0.5385 - rmse: 0.5325 - val_loss: 1.2073 - val_acc: 0.0000e+00 - val_rmse: 0.7010\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7926 - acc: 0.5385 - rmse: 0.5318 - val_loss: 1.2075 - val_acc: 0.0000e+00 - val_rmse: 0.7010\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7905 - acc: 0.5385 - rmse: 0.5311 - val_loss: 1.2076 - val_acc: 0.0000e+00 - val_rmse: 0.7011\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7885 - acc: 0.5385 - rmse: 0.5304 - val_loss: 1.2077 - val_acc: 0.0000e+00 - val_rmse: 0.7011\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7864 - acc: 0.5385 - rmse: 0.5297 - val_loss: 1.2078 - val_acc: 0.0000e+00 - val_rmse: 0.7012\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7844 - acc: 0.5385 - rmse: 0.5290 - val_loss: 1.2080 - val_acc: 0.0000e+00 - val_rmse: 0.7012\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7824 - acc: 0.5385 - rmse: 0.5283 - val_loss: 1.2081 - val_acc: 0.0000e+00 - val_rmse: 0.7012\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7804 - acc: 0.5385 - rmse: 0.5277 - val_loss: 1.2082 - val_acc: 0.0000e+00 - val_rmse: 0.7013\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7784 - acc: 0.5769 - rmse: 0.5270 - val_loss: 1.2084 - val_acc: 0.0000e+00 - val_rmse: 0.7013\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7764 - acc: 0.5769 - rmse: 0.5263 - val_loss: 1.2086 - val_acc: 0.0000e+00 - val_rmse: 0.7014\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7744 - acc: 0.5769 - rmse: 0.5256 - val_loss: 1.2087 - val_acc: 0.0000e+00 - val_rmse: 0.7014\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7724 - acc: 0.5769 - rmse: 0.5249 - val_loss: 1.2089 - val_acc: 0.0000e+00 - val_rmse: 0.7015\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7705 - acc: 0.5769 - rmse: 0.5243 - val_loss: 1.2091 - val_acc: 0.0000e+00 - val_rmse: 0.7015\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7685 - acc: 0.5769 - rmse: 0.5236 - val_loss: 1.2092 - val_acc: 0.0000e+00 - val_rmse: 0.7016\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.7666 - acc: 0.5769 - rmse: 0.5229 - val_loss: 1.2094 - val_acc: 0.0000e+00 - val_rmse: 0.7016\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.7647 - acc: 0.5769 - rmse: 0.5223 - val_loss: 1.2095 - val_acc: 0.0000e+00 - val_rmse: 0.7017\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7628 - acc: 0.5769 - rmse: 0.5216 - val_loss: 1.2097 - val_acc: 0.0000e+00 - val_rmse: 0.7017\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7609 - acc: 0.5769 - rmse: 0.5209 - val_loss: 1.2099 - val_acc: 0.0000e+00 - val_rmse: 0.7018\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7590 - acc: 0.5769 - rmse: 0.5203 - val_loss: 1.2100 - val_acc: 0.0000e+00 - val_rmse: 0.7018\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7571 - acc: 0.5769 - rmse: 0.5196 - val_loss: 1.2102 - val_acc: 0.0000e+00 - val_rmse: 0.7019\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7552 - acc: 0.5769 - rmse: 0.5189 - val_loss: 1.2104 - val_acc: 0.0000e+00 - val_rmse: 0.7019\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7533 - acc: 0.5769 - rmse: 0.5183 - val_loss: 1.2105 - val_acc: 0.0000e+00 - val_rmse: 0.7020\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7514 - acc: 0.5769 - rmse: 0.5176 - val_loss: 1.2107 - val_acc: 0.0000e+00 - val_rmse: 0.7020\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7495 - acc: 0.5769 - rmse: 0.5169 - val_loss: 1.2109 - val_acc: 0.0000e+00 - val_rmse: 0.7021\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7476 - acc: 0.5769 - rmse: 0.5163 - val_loss: 1.2110 - val_acc: 0.0000e+00 - val_rmse: 0.7021\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7457 - acc: 0.5769 - rmse: 0.5156 - val_loss: 1.2112 - val_acc: 0.0000e+00 - val_rmse: 0.7022\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7438 - acc: 0.5769 - rmse: 0.5149 - val_loss: 1.2114 - val_acc: 0.0000e+00 - val_rmse: 0.7022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7420 - acc: 0.5769 - rmse: 0.5143 - val_loss: 1.2115 - val_acc: 0.0000e+00 - val_rmse: 0.7023\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7401 - acc: 0.5769 - rmse: 0.5136 - val_loss: 1.2117 - val_acc: 0.0000e+00 - val_rmse: 0.7023\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7382 - acc: 0.5769 - rmse: 0.5129 - val_loss: 1.2119 - val_acc: 0.0000e+00 - val_rmse: 0.7024\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7364 - acc: 0.5769 - rmse: 0.5123 - val_loss: 1.2120 - val_acc: 0.0000e+00 - val_rmse: 0.7024\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7346 - acc: 0.5769 - rmse: 0.5116 - val_loss: 1.2122 - val_acc: 0.0000e+00 - val_rmse: 0.7025\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7328 - acc: 0.5769 - rmse: 0.5110 - val_loss: 1.2124 - val_acc: 0.0000e+00 - val_rmse: 0.7025\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7310 - acc: 0.5769 - rmse: 0.5103 - val_loss: 1.2125 - val_acc: 0.0000e+00 - val_rmse: 0.7026\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7292 - acc: 0.5769 - rmse: 0.5097 - val_loss: 1.2127 - val_acc: 0.0000e+00 - val_rmse: 0.7026\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7274 - acc: 0.5769 - rmse: 0.5090 - val_loss: 1.2128 - val_acc: 0.0000e+00 - val_rmse: 0.7026\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7256 - acc: 0.5769 - rmse: 0.5084 - val_loss: 1.2130 - val_acc: 0.0000e+00 - val_rmse: 0.7027\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7238 - acc: 0.5769 - rmse: 0.5077 - val_loss: 1.2132 - val_acc: 0.0000e+00 - val_rmse: 0.7027\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.20539\n",
      " - 1s - loss: 0.7220 - acc: 0.5769 - rmse: 0.5071 - val_loss: 1.2133 - val_acc: 0.0000e+00 - val_rmse: 0.7028\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7203 - acc: 0.5769 - rmse: 0.5064 - val_loss: 1.2135 - val_acc: 0.0000e+00 - val_rmse: 0.7028\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7185 - acc: 0.5769 - rmse: 0.5058 - val_loss: 1.2136 - val_acc: 0.0000e+00 - val_rmse: 0.7029\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7167 - acc: 0.5769 - rmse: 0.5051 - val_loss: 1.2138 - val_acc: 0.0000e+00 - val_rmse: 0.7029\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7150 - acc: 0.5769 - rmse: 0.5045 - val_loss: 1.2139 - val_acc: 0.0000e+00 - val_rmse: 0.7030\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7132 - acc: 0.5769 - rmse: 0.5039 - val_loss: 1.2141 - val_acc: 0.0000e+00 - val_rmse: 0.7030\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7115 - acc: 0.5769 - rmse: 0.5032 - val_loss: 1.2143 - val_acc: 0.0000e+00 - val_rmse: 0.7031\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7097 - acc: 0.5769 - rmse: 0.5026 - val_loss: 1.2144 - val_acc: 0.0000e+00 - val_rmse: 0.7031\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7080 - acc: 0.5769 - rmse: 0.5019 - val_loss: 1.2146 - val_acc: 0.0000e+00 - val_rmse: 0.7032\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7063 - acc: 0.5769 - rmse: 0.5013 - val_loss: 1.2147 - val_acc: 0.0000e+00 - val_rmse: 0.7032\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7045 - acc: 0.5769 - rmse: 0.5006 - val_loss: 1.2149 - val_acc: 0.0000e+00 - val_rmse: 0.7033\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7028 - acc: 0.5769 - rmse: 0.5000 - val_loss: 1.2151 - val_acc: 0.0000e+00 - val_rmse: 0.7033\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.7011 - acc: 0.5769 - rmse: 0.4993 - val_loss: 1.2152 - val_acc: 0.0000e+00 - val_rmse: 0.7034\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6993 - acc: 0.5769 - rmse: 0.4987 - val_loss: 1.2154 - val_acc: 0.0000e+00 - val_rmse: 0.7034\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6976 - acc: 0.5769 - rmse: 0.4980 - val_loss: 1.2155 - val_acc: 0.0000e+00 - val_rmse: 0.7035\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6959 - acc: 0.5769 - rmse: 0.4974 - val_loss: 1.2157 - val_acc: 0.0000e+00 - val_rmse: 0.7035\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6942 - acc: 0.5769 - rmse: 0.4967 - val_loss: 1.2159 - val_acc: 0.0000e+00 - val_rmse: 0.7035\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6925 - acc: 0.5769 - rmse: 0.4961 - val_loss: 1.2160 - val_acc: 0.0000e+00 - val_rmse: 0.7036\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6908 - acc: 0.5769 - rmse: 0.4955 - val_loss: 1.2162 - val_acc: 0.0000e+00 - val_rmse: 0.7036\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6891 - acc: 0.5769 - rmse: 0.4948 - val_loss: 1.2163 - val_acc: 0.0000e+00 - val_rmse: 0.7037\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6875 - acc: 0.5769 - rmse: 0.4942 - val_loss: 1.2165 - val_acc: 0.0000e+00 - val_rmse: 0.7037\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6858 - acc: 0.5769 - rmse: 0.4935 - val_loss: 1.2167 - val_acc: 0.0000e+00 - val_rmse: 0.7038\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6841 - acc: 0.5769 - rmse: 0.4929 - val_loss: 1.2168 - val_acc: 0.0000e+00 - val_rmse: 0.7038\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6824 - acc: 0.5769 - rmse: 0.4923 - val_loss: 1.2170 - val_acc: 0.0000e+00 - val_rmse: 0.7039\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6808 - acc: 0.5769 - rmse: 0.4916 - val_loss: 1.2171 - val_acc: 0.0000e+00 - val_rmse: 0.7039\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6791 - acc: 0.5769 - rmse: 0.4910 - val_loss: 1.2173 - val_acc: 0.0000e+00 - val_rmse: 0.7040\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6775 - acc: 0.5769 - rmse: 0.4904 - val_loss: 1.2174 - val_acc: 0.0000e+00 - val_rmse: 0.7040\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6758 - acc: 0.5769 - rmse: 0.4897 - val_loss: 1.2176 - val_acc: 0.0000e+00 - val_rmse: 0.7041\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6742 - acc: 0.5769 - rmse: 0.4891 - val_loss: 1.2178 - val_acc: 0.0000e+00 - val_rmse: 0.7041\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6726 - acc: 0.5769 - rmse: 0.4885 - val_loss: 1.2179 - val_acc: 0.0000e+00 - val_rmse: 0.7042\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6709 - acc: 0.5769 - rmse: 0.4878 - val_loss: 1.2181 - val_acc: 0.0000e+00 - val_rmse: 0.7042\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6693 - acc: 0.5769 - rmse: 0.4872 - val_loss: 1.2182 - val_acc: 0.0000e+00 - val_rmse: 0.7042\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6677 - acc: 0.5769 - rmse: 0.4865 - val_loss: 1.2184 - val_acc: 0.0000e+00 - val_rmse: 0.7043\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6660 - acc: 0.5769 - rmse: 0.4859 - val_loss: 1.2185 - val_acc: 0.0000e+00 - val_rmse: 0.7043\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6644 - acc: 0.5769 - rmse: 0.4853 - val_loss: 1.2187 - val_acc: 0.0000e+00 - val_rmse: 0.7044\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6628 - acc: 0.5769 - rmse: 0.4846 - val_loss: 1.2188 - val_acc: 0.0000e+00 - val_rmse: 0.7044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6612 - acc: 0.5769 - rmse: 0.4840 - val_loss: 1.2190 - val_acc: 0.0000e+00 - val_rmse: 0.7045\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6595 - acc: 0.5769 - rmse: 0.4833 - val_loss: 1.2191 - val_acc: 0.0000e+00 - val_rmse: 0.7045\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6579 - acc: 0.5769 - rmse: 0.4827 - val_loss: 1.2193 - val_acc: 0.0000e+00 - val_rmse: 0.7046\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6563 - acc: 0.5769 - rmse: 0.4821 - val_loss: 1.2194 - val_acc: 0.0000e+00 - val_rmse: 0.7046\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6547 - acc: 0.5769 - rmse: 0.4814 - val_loss: 1.2196 - val_acc: 0.0000e+00 - val_rmse: 0.7047\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6531 - acc: 0.5769 - rmse: 0.4808 - val_loss: 1.2198 - val_acc: 0.0000e+00 - val_rmse: 0.7047\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6515 - acc: 0.5769 - rmse: 0.4801 - val_loss: 1.2199 - val_acc: 0.0000e+00 - val_rmse: 0.7047\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6499 - acc: 0.5769 - rmse: 0.4795 - val_loss: 1.2201 - val_acc: 0.0000e+00 - val_rmse: 0.7048\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6483 - acc: 0.5769 - rmse: 0.4789 - val_loss: 1.2202 - val_acc: 0.0000e+00 - val_rmse: 0.7048\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6467 - acc: 0.5769 - rmse: 0.4782 - val_loss: 1.2204 - val_acc: 0.0000e+00 - val_rmse: 0.7049\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.20539\n",
      " - 0s - loss: 0.6452 - acc: 0.5769 - rmse: 0.4776 - val_loss: 1.2205 - val_acc: 0.0000e+00 - val_rmse: 0.7049\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.20539 to 0.88328, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 6s - loss: 0.6976 - acc: 0.4615 - rmse: 0.5024 - val_loss: 0.8833 - val_acc: 0.0000e+00 - val_rmse: 0.5866\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.88328 to 0.88312, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6951 - acc: 0.5000 - rmse: 0.5013 - val_loss: 0.8831 - val_acc: 0.0000e+00 - val_rmse: 0.5865\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.88312 to 0.88295, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6926 - acc: 0.5000 - rmse: 0.5001 - val_loss: 0.8829 - val_acc: 0.0000e+00 - val_rmse: 0.5864\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.88295 to 0.88278, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6901 - acc: 0.5000 - rmse: 0.4990 - val_loss: 0.8828 - val_acc: 0.0000e+00 - val_rmse: 0.5864\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.88278 to 0.88261, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6876 - acc: 0.5000 - rmse: 0.4978 - val_loss: 0.8826 - val_acc: 0.0000e+00 - val_rmse: 0.5863\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.88261 to 0.88245, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6851 - acc: 0.5000 - rmse: 0.4967 - val_loss: 0.8824 - val_acc: 0.0000e+00 - val_rmse: 0.5862\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.88245 to 0.88228, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6827 - acc: 0.5000 - rmse: 0.4956 - val_loss: 0.8823 - val_acc: 0.0000e+00 - val_rmse: 0.5862\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.88228 to 0.88211, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6802 - acc: 0.5000 - rmse: 0.4944 - val_loss: 0.8821 - val_acc: 0.0000e+00 - val_rmse: 0.5861\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.88211 to 0.88195, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6778 - acc: 0.5000 - rmse: 0.4933 - val_loss: 0.8819 - val_acc: 0.0000e+00 - val_rmse: 0.5860\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.88195 to 0.88178, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6755 - acc: 0.5000 - rmse: 0.4922 - val_loss: 0.8818 - val_acc: 0.0000e+00 - val_rmse: 0.5860\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.88178 to 0.88162, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6732 - acc: 0.5000 - rmse: 0.4911 - val_loss: 0.8816 - val_acc: 0.0000e+00 - val_rmse: 0.5859\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.88162 to 0.88145, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6709 - acc: 0.5000 - rmse: 0.4901 - val_loss: 0.8815 - val_acc: 0.0000e+00 - val_rmse: 0.5858\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.88145 to 0.88129, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6687 - acc: 0.5385 - rmse: 0.4890 - val_loss: 0.8813 - val_acc: 0.0000e+00 - val_rmse: 0.5858\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.88129 to 0.88112, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6664 - acc: 0.5385 - rmse: 0.4879 - val_loss: 0.8811 - val_acc: 0.0000e+00 - val_rmse: 0.5857\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.88112 to 0.88096, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6641 - acc: 0.5385 - rmse: 0.4868 - val_loss: 0.8810 - val_acc: 0.0000e+00 - val_rmse: 0.5856\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.88096 to 0.88080, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6619 - acc: 0.5385 - rmse: 0.4858 - val_loss: 0.8808 - val_acc: 0.0000e+00 - val_rmse: 0.5855\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.88080 to 0.88064, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6597 - acc: 0.5385 - rmse: 0.4847 - val_loss: 0.8806 - val_acc: 0.0000e+00 - val_rmse: 0.5855\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.88064 to 0.88048, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6576 - acc: 0.5385 - rmse: 0.4837 - val_loss: 0.8805 - val_acc: 0.0000e+00 - val_rmse: 0.5854\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.88048 to 0.88032, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6554 - acc: 0.5385 - rmse: 0.4826 - val_loss: 0.8803 - val_acc: 0.0000e+00 - val_rmse: 0.5853\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.88032 to 0.88015, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6533 - acc: 0.5385 - rmse: 0.4816 - val_loss: 0.8802 - val_acc: 0.0000e+00 - val_rmse: 0.5853\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.88015 to 0.87999, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6511 - acc: 0.5385 - rmse: 0.4806 - val_loss: 0.8800 - val_acc: 0.0000e+00 - val_rmse: 0.5852\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.87999 to 0.87983, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6490 - acc: 0.5385 - rmse: 0.4795 - val_loss: 0.8798 - val_acc: 0.0000e+00 - val_rmse: 0.5851\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.87983 to 0.87967, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6468 - acc: 0.5385 - rmse: 0.4785 - val_loss: 0.8797 - val_acc: 0.0000e+00 - val_rmse: 0.5851\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.87967 to 0.87951, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6447 - acc: 0.5385 - rmse: 0.4774 - val_loss: 0.8795 - val_acc: 0.0000e+00 - val_rmse: 0.5850\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.87951 to 0.87934, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6426 - acc: 0.5385 - rmse: 0.4764 - val_loss: 0.8793 - val_acc: 0.0000e+00 - val_rmse: 0.5849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.87934 to 0.87918, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6405 - acc: 0.5385 - rmse: 0.4754 - val_loss: 0.8792 - val_acc: 0.0000e+00 - val_rmse: 0.5849\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.87918 to 0.87902, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6384 - acc: 0.5385 - rmse: 0.4743 - val_loss: 0.8790 - val_acc: 0.0000e+00 - val_rmse: 0.5848\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.87902 to 0.87886, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6363 - acc: 0.5769 - rmse: 0.4733 - val_loss: 0.8789 - val_acc: 0.0000e+00 - val_rmse: 0.5847\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.87886 to 0.87870, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6343 - acc: 0.6154 - rmse: 0.4723 - val_loss: 0.8787 - val_acc: 0.0000e+00 - val_rmse: 0.5847\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.87870 to 0.87854, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6322 - acc: 0.6154 - rmse: 0.4713 - val_loss: 0.8785 - val_acc: 0.0000e+00 - val_rmse: 0.5846\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.87854 to 0.87838, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6302 - acc: 0.6154 - rmse: 0.4703 - val_loss: 0.8784 - val_acc: 0.0000e+00 - val_rmse: 0.5845\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.87838 to 0.87822, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6282 - acc: 0.6154 - rmse: 0.4693 - val_loss: 0.8782 - val_acc: 0.0000e+00 - val_rmse: 0.5845\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.87822 to 0.87806, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6261 - acc: 0.6154 - rmse: 0.4683 - val_loss: 0.8781 - val_acc: 0.0000e+00 - val_rmse: 0.5844\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.87806 to 0.87790, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6241 - acc: 0.6154 - rmse: 0.4672 - val_loss: 0.8779 - val_acc: 0.0000e+00 - val_rmse: 0.5843\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.87790 to 0.87774, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6221 - acc: 0.6154 - rmse: 0.4662 - val_loss: 0.8777 - val_acc: 0.0000e+00 - val_rmse: 0.5843\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.87774 to 0.87759, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6201 - acc: 0.6154 - rmse: 0.4652 - val_loss: 0.8776 - val_acc: 0.0000e+00 - val_rmse: 0.5842\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.87759 to 0.87743, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6181 - acc: 0.6538 - rmse: 0.4642 - val_loss: 0.8774 - val_acc: 0.0000e+00 - val_rmse: 0.5841\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.87743 to 0.87727, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6162 - acc: 0.6538 - rmse: 0.4632 - val_loss: 0.8773 - val_acc: 0.0000e+00 - val_rmse: 0.5841\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.87727 to 0.87711, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6142 - acc: 0.6538 - rmse: 0.4622 - val_loss: 0.8771 - val_acc: 0.0000e+00 - val_rmse: 0.5840\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.87711 to 0.87695, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6122 - acc: 0.6538 - rmse: 0.4612 - val_loss: 0.8770 - val_acc: 0.0000e+00 - val_rmse: 0.5840\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.87695 to 0.87679, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6102 - acc: 0.6538 - rmse: 0.4602 - val_loss: 0.8768 - val_acc: 0.0000e+00 - val_rmse: 0.5839\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.87679 to 0.87664, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6083 - acc: 0.6538 - rmse: 0.4592 - val_loss: 0.8766 - val_acc: 0.0000e+00 - val_rmse: 0.5838\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.87664 to 0.87648, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6063 - acc: 0.6538 - rmse: 0.4582 - val_loss: 0.8765 - val_acc: 0.0000e+00 - val_rmse: 0.5838\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.87648 to 0.87632, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6043 - acc: 0.6538 - rmse: 0.4572 - val_loss: 0.8763 - val_acc: 0.0000e+00 - val_rmse: 0.5837\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.87632 to 0.87615, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6024 - acc: 0.6538 - rmse: 0.4562 - val_loss: 0.8762 - val_acc: 0.0000e+00 - val_rmse: 0.5836\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.87615 to 0.87599, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6005 - acc: 0.6538 - rmse: 0.4552 - val_loss: 0.8760 - val_acc: 0.0000e+00 - val_rmse: 0.5836\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.87599 to 0.87583, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5986 - acc: 0.6538 - rmse: 0.4543 - val_loss: 0.8758 - val_acc: 0.0000e+00 - val_rmse: 0.5835\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.87583 to 0.87567, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5967 - acc: 0.6538 - rmse: 0.4533 - val_loss: 0.8757 - val_acc: 0.0000e+00 - val_rmse: 0.5834\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.87567 to 0.87551, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5948 - acc: 0.6538 - rmse: 0.4523 - val_loss: 0.8755 - val_acc: 0.0000e+00 - val_rmse: 0.5833\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.87551 to 0.87535, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5930 - acc: 0.6538 - rmse: 0.4513 - val_loss: 0.8753 - val_acc: 0.0000e+00 - val_rmse: 0.5833\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.87535 to 0.87519, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5911 - acc: 0.6538 - rmse: 0.4504 - val_loss: 0.8752 - val_acc: 0.0000e+00 - val_rmse: 0.5832\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.87519 to 0.87503, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5892 - acc: 0.6538 - rmse: 0.4494 - val_loss: 0.8750 - val_acc: 0.0000e+00 - val_rmse: 0.5831\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.87503 to 0.87487, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5874 - acc: 0.6538 - rmse: 0.4484 - val_loss: 0.8749 - val_acc: 0.0000e+00 - val_rmse: 0.5831\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.87487 to 0.87471, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5855 - acc: 0.6538 - rmse: 0.4475 - val_loss: 0.8747 - val_acc: 0.0000e+00 - val_rmse: 0.5830\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.87471 to 0.87455, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5837 - acc: 0.6538 - rmse: 0.4465 - val_loss: 0.8745 - val_acc: 0.0000e+00 - val_rmse: 0.5829\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.87455 to 0.87439, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5819 - acc: 0.6538 - rmse: 0.4455 - val_loss: 0.8744 - val_acc: 0.0000e+00 - val_rmse: 0.5829\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.87439 to 0.87423, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5801 - acc: 0.6538 - rmse: 0.4446 - val_loss: 0.8742 - val_acc: 0.0000e+00 - val_rmse: 0.5828\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.87423 to 0.87407, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5782 - acc: 0.6538 - rmse: 0.4436 - val_loss: 0.8741 - val_acc: 0.0000e+00 - val_rmse: 0.5828\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.87407 to 0.87391, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5764 - acc: 0.6538 - rmse: 0.4426 - val_loss: 0.8739 - val_acc: 0.0000e+00 - val_rmse: 0.5827\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.87391 to 0.87376, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5746 - acc: 0.6538 - rmse: 0.4417 - val_loss: 0.8738 - val_acc: 0.0000e+00 - val_rmse: 0.5826\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.87376 to 0.87360, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5728 - acc: 0.6538 - rmse: 0.4407 - val_loss: 0.8736 - val_acc: 0.0000e+00 - val_rmse: 0.5826\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.87360 to 0.87344, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5710 - acc: 0.6538 - rmse: 0.4398 - val_loss: 0.8734 - val_acc: 0.0000e+00 - val_rmse: 0.5825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.87344 to 0.87328, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5693 - acc: 0.6923 - rmse: 0.4388 - val_loss: 0.8733 - val_acc: 0.0000e+00 - val_rmse: 0.5824\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.87328 to 0.87313, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5675 - acc: 0.6923 - rmse: 0.4379 - val_loss: 0.8731 - val_acc: 0.0000e+00 - val_rmse: 0.5824\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.87313 to 0.87297, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5657 - acc: 0.6923 - rmse: 0.4369 - val_loss: 0.8730 - val_acc: 0.0000e+00 - val_rmse: 0.5823\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.87297 to 0.87282, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5640 - acc: 0.7308 - rmse: 0.4360 - val_loss: 0.8728 - val_acc: 0.0000e+00 - val_rmse: 0.5822\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.87282 to 0.87266, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5622 - acc: 0.7308 - rmse: 0.4350 - val_loss: 0.8727 - val_acc: 0.0000e+00 - val_rmse: 0.5822\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.87266 to 0.87250, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5605 - acc: 0.7308 - rmse: 0.4341 - val_loss: 0.8725 - val_acc: 0.0000e+00 - val_rmse: 0.5821\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.87250 to 0.87235, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5587 - acc: 0.7308 - rmse: 0.4332 - val_loss: 0.8723 - val_acc: 0.0000e+00 - val_rmse: 0.5820\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.87235 to 0.87219, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5570 - acc: 0.7308 - rmse: 0.4322 - val_loss: 0.8722 - val_acc: 0.0000e+00 - val_rmse: 0.5820\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.87219 to 0.87204, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5553 - acc: 0.7308 - rmse: 0.4313 - val_loss: 0.8720 - val_acc: 0.0000e+00 - val_rmse: 0.5819\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.87204 to 0.87188, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5536 - acc: 0.7308 - rmse: 0.4303 - val_loss: 0.8719 - val_acc: 0.0000e+00 - val_rmse: 0.5818\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.87188 to 0.87173, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5519 - acc: 0.7308 - rmse: 0.4294 - val_loss: 0.8717 - val_acc: 0.0000e+00 - val_rmse: 0.5818\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.87173 to 0.87158, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5501 - acc: 0.7308 - rmse: 0.4285 - val_loss: 0.8716 - val_acc: 0.0000e+00 - val_rmse: 0.5817\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.87158 to 0.87142, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5484 - acc: 0.7692 - rmse: 0.4275 - val_loss: 0.8714 - val_acc: 0.0000e+00 - val_rmse: 0.5816\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.87142 to 0.87127, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5467 - acc: 0.8077 - rmse: 0.4266 - val_loss: 0.8713 - val_acc: 0.0000e+00 - val_rmse: 0.5816\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.87127 to 0.87112, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5451 - acc: 0.8077 - rmse: 0.4257 - val_loss: 0.8711 - val_acc: 0.0000e+00 - val_rmse: 0.5815\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.87112 to 0.87096, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5434 - acc: 0.8077 - rmse: 0.4248 - val_loss: 0.8710 - val_acc: 0.0000e+00 - val_rmse: 0.5815\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.87096 to 0.87081, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5417 - acc: 0.8077 - rmse: 0.4238 - val_loss: 0.8708 - val_acc: 0.0000e+00 - val_rmse: 0.5814\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.87081 to 0.87066, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5400 - acc: 0.8077 - rmse: 0.4229 - val_loss: 0.8707 - val_acc: 0.0000e+00 - val_rmse: 0.5813\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.87066 to 0.87051, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5383 - acc: 0.8077 - rmse: 0.4220 - val_loss: 0.8705 - val_acc: 0.0000e+00 - val_rmse: 0.5813\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.87051 to 0.87036, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5367 - acc: 0.8077 - rmse: 0.4210 - val_loss: 0.8704 - val_acc: 0.0000e+00 - val_rmse: 0.5812\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.87036 to 0.87021, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5350 - acc: 0.8077 - rmse: 0.4201 - val_loss: 0.8702 - val_acc: 0.0000e+00 - val_rmse: 0.5811\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.87021 to 0.87007, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5334 - acc: 0.8077 - rmse: 0.4192 - val_loss: 0.8701 - val_acc: 0.0000e+00 - val_rmse: 0.5811\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.87007 to 0.86992, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5317 - acc: 0.8077 - rmse: 0.4183 - val_loss: 0.8699 - val_acc: 0.0000e+00 - val_rmse: 0.5810\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.86992 to 0.86977, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5301 - acc: 0.8077 - rmse: 0.4174 - val_loss: 0.8698 - val_acc: 0.0000e+00 - val_rmse: 0.5810\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.86977 to 0.86963, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5285 - acc: 0.8077 - rmse: 0.4165 - val_loss: 0.8696 - val_acc: 0.0000e+00 - val_rmse: 0.5809\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.86963 to 0.86948, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5268 - acc: 0.8077 - rmse: 0.4155 - val_loss: 0.8695 - val_acc: 0.0000e+00 - val_rmse: 0.5808\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.86948 to 0.86934, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5252 - acc: 0.8077 - rmse: 0.4146 - val_loss: 0.8693 - val_acc: 0.0000e+00 - val_rmse: 0.5808\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.86934 to 0.86920, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5236 - acc: 0.8077 - rmse: 0.4137 - val_loss: 0.8692 - val_acc: 0.0000e+00 - val_rmse: 0.5807\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.86920 to 0.86906, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5220 - acc: 0.8077 - rmse: 0.4128 - val_loss: 0.8691 - val_acc: 0.0000e+00 - val_rmse: 0.5807\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.86906 to 0.86891, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5204 - acc: 0.8077 - rmse: 0.4119 - val_loss: 0.8689 - val_acc: 0.0000e+00 - val_rmse: 0.5806\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.86891 to 0.86877, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5188 - acc: 0.8077 - rmse: 0.4110 - val_loss: 0.8688 - val_acc: 0.0000e+00 - val_rmse: 0.5805\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.86877 to 0.86863, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5172 - acc: 0.8077 - rmse: 0.4101 - val_loss: 0.8686 - val_acc: 0.0000e+00 - val_rmse: 0.5805\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.86863 to 0.86849, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5156 - acc: 0.8077 - rmse: 0.4092 - val_loss: 0.8685 - val_acc: 0.0000e+00 - val_rmse: 0.5804\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.86849 to 0.86835, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5140 - acc: 0.8077 - rmse: 0.4083 - val_loss: 0.8684 - val_acc: 0.0000e+00 - val_rmse: 0.5804\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.86835 to 0.86821, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5125 - acc: 0.8077 - rmse: 0.4074 - val_loss: 0.8682 - val_acc: 0.0000e+00 - val_rmse: 0.5803\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.86821 to 0.86808, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5109 - acc: 0.8077 - rmse: 0.4065 - val_loss: 0.8681 - val_acc: 0.0000e+00 - val_rmse: 0.5802\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.86808 to 0.86794, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5093 - acc: 0.8077 - rmse: 0.4056 - val_loss: 0.8679 - val_acc: 0.0000e+00 - val_rmse: 0.5802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.86794 to 0.86780, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5078 - acc: 0.8077 - rmse: 0.4047 - val_loss: 0.8678 - val_acc: 0.0000e+00 - val_rmse: 0.5801\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.86780 to 0.40000, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 6s - loss: 0.7385 - acc: 0.5000 - rmse: 0.5200 - val_loss: 0.4000 - val_acc: 1.0000 - val_rmse: 0.3297\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7361 - acc: 0.5000 - rmse: 0.5190 - val_loss: 0.4001 - val_acc: 1.0000 - val_rmse: 0.3297\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7337 - acc: 0.5000 - rmse: 0.5179 - val_loss: 0.4002 - val_acc: 1.0000 - val_rmse: 0.3298\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7314 - acc: 0.5000 - rmse: 0.5169 - val_loss: 0.4003 - val_acc: 1.0000 - val_rmse: 0.3299\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7290 - acc: 0.5000 - rmse: 0.5159 - val_loss: 0.4004 - val_acc: 1.0000 - val_rmse: 0.3299\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7267 - acc: 0.5000 - rmse: 0.5148 - val_loss: 0.4005 - val_acc: 1.0000 - val_rmse: 0.3300\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7244 - acc: 0.5000 - rmse: 0.5138 - val_loss: 0.4006 - val_acc: 1.0000 - val_rmse: 0.3301\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7221 - acc: 0.5000 - rmse: 0.5128 - val_loss: 0.4007 - val_acc: 1.0000 - val_rmse: 0.3301\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7198 - acc: 0.5385 - rmse: 0.5117 - val_loss: 0.4008 - val_acc: 1.0000 - val_rmse: 0.3302\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7174 - acc: 0.5385 - rmse: 0.5107 - val_loss: 0.4009 - val_acc: 1.0000 - val_rmse: 0.3303\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7151 - acc: 0.5385 - rmse: 0.5097 - val_loss: 0.4009 - val_acc: 1.0000 - val_rmse: 0.3303\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7129 - acc: 0.5385 - rmse: 0.5086 - val_loss: 0.4010 - val_acc: 1.0000 - val_rmse: 0.3304\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7106 - acc: 0.5385 - rmse: 0.5076 - val_loss: 0.4011 - val_acc: 1.0000 - val_rmse: 0.3304\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7083 - acc: 0.6154 - rmse: 0.5066 - val_loss: 0.4012 - val_acc: 1.0000 - val_rmse: 0.3305\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7060 - acc: 0.6154 - rmse: 0.5055 - val_loss: 0.4013 - val_acc: 1.0000 - val_rmse: 0.3306\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7038 - acc: 0.6154 - rmse: 0.5045 - val_loss: 0.4014 - val_acc: 1.0000 - val_rmse: 0.3306\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.7015 - acc: 0.6154 - rmse: 0.5035 - val_loss: 0.4015 - val_acc: 1.0000 - val_rmse: 0.3307\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6993 - acc: 0.6154 - rmse: 0.5024 - val_loss: 0.4016 - val_acc: 1.0000 - val_rmse: 0.3308\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6970 - acc: 0.6154 - rmse: 0.5014 - val_loss: 0.4017 - val_acc: 1.0000 - val_rmse: 0.3308\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6948 - acc: 0.6154 - rmse: 0.5004 - val_loss: 0.4018 - val_acc: 1.0000 - val_rmse: 0.3309\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6926 - acc: 0.6154 - rmse: 0.4994 - val_loss: 0.4019 - val_acc: 1.0000 - val_rmse: 0.3310\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6903 - acc: 0.6154 - rmse: 0.4983 - val_loss: 0.4020 - val_acc: 1.0000 - val_rmse: 0.3310\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6882 - acc: 0.6154 - rmse: 0.4973 - val_loss: 0.4021 - val_acc: 1.0000 - val_rmse: 0.3311\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6861 - acc: 0.6154 - rmse: 0.4963 - val_loss: 0.4022 - val_acc: 1.0000 - val_rmse: 0.3312\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6839 - acc: 0.6154 - rmse: 0.4953 - val_loss: 0.4024 - val_acc: 1.0000 - val_rmse: 0.3313\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6818 - acc: 0.6154 - rmse: 0.4944 - val_loss: 0.4025 - val_acc: 1.0000 - val_rmse: 0.3313\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6797 - acc: 0.6154 - rmse: 0.4934 - val_loss: 0.4026 - val_acc: 1.0000 - val_rmse: 0.3314\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6776 - acc: 0.6154 - rmse: 0.4924 - val_loss: 0.4027 - val_acc: 1.0000 - val_rmse: 0.3315\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6755 - acc: 0.6154 - rmse: 0.4914 - val_loss: 0.4028 - val_acc: 1.0000 - val_rmse: 0.3315\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6735 - acc: 0.6154 - rmse: 0.4904 - val_loss: 0.4029 - val_acc: 1.0000 - val_rmse: 0.3316\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6714 - acc: 0.6154 - rmse: 0.4894 - val_loss: 0.4030 - val_acc: 1.0000 - val_rmse: 0.3317\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6693 - acc: 0.6154 - rmse: 0.4884 - val_loss: 0.4031 - val_acc: 1.0000 - val_rmse: 0.3317\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6672 - acc: 0.6154 - rmse: 0.4874 - val_loss: 0.4032 - val_acc: 1.0000 - val_rmse: 0.3318\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6651 - acc: 0.6538 - rmse: 0.4865 - val_loss: 0.4033 - val_acc: 1.0000 - val_rmse: 0.3319\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6631 - acc: 0.6538 - rmse: 0.4855 - val_loss: 0.4034 - val_acc: 1.0000 - val_rmse: 0.3319\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6610 - acc: 0.6538 - rmse: 0.4845 - val_loss: 0.4034 - val_acc: 1.0000 - val_rmse: 0.3320\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6589 - acc: 0.6538 - rmse: 0.4835 - val_loss: 0.4035 - val_acc: 1.0000 - val_rmse: 0.3320\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6569 - acc: 0.6538 - rmse: 0.4825 - val_loss: 0.4036 - val_acc: 1.0000 - val_rmse: 0.3321\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6548 - acc: 0.6538 - rmse: 0.4815 - val_loss: 0.4037 - val_acc: 1.0000 - val_rmse: 0.3322\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6528 - acc: 0.6923 - rmse: 0.4805 - val_loss: 0.4038 - val_acc: 1.0000 - val_rmse: 0.3322\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6508 - acc: 0.6923 - rmse: 0.4795 - val_loss: 0.4039 - val_acc: 1.0000 - val_rmse: 0.3323\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6487 - acc: 0.6923 - rmse: 0.4785 - val_loss: 0.4040 - val_acc: 1.0000 - val_rmse: 0.3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6467 - acc: 0.6923 - rmse: 0.4776 - val_loss: 0.4040 - val_acc: 1.0000 - val_rmse: 0.3324\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6447 - acc: 0.6923 - rmse: 0.4766 - val_loss: 0.4041 - val_acc: 1.0000 - val_rmse: 0.3324\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6427 - acc: 0.6923 - rmse: 0.4756 - val_loss: 0.4042 - val_acc: 1.0000 - val_rmse: 0.3325\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6407 - acc: 0.6923 - rmse: 0.4746 - val_loss: 0.4043 - val_acc: 1.0000 - val_rmse: 0.3326\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6387 - acc: 0.6923 - rmse: 0.4736 - val_loss: 0.4044 - val_acc: 1.0000 - val_rmse: 0.3326\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6368 - acc: 0.6923 - rmse: 0.4727 - val_loss: 0.4045 - val_acc: 1.0000 - val_rmse: 0.3327\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6348 - acc: 0.6923 - rmse: 0.4717 - val_loss: 0.4046 - val_acc: 1.0000 - val_rmse: 0.3327\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6328 - acc: 0.6923 - rmse: 0.4707 - val_loss: 0.4047 - val_acc: 1.0000 - val_rmse: 0.3328\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6309 - acc: 0.6923 - rmse: 0.4698 - val_loss: 0.4047 - val_acc: 1.0000 - val_rmse: 0.3329\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6289 - acc: 0.6923 - rmse: 0.4688 - val_loss: 0.4048 - val_acc: 1.0000 - val_rmse: 0.3329\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6270 - acc: 0.6923 - rmse: 0.4678 - val_loss: 0.4049 - val_acc: 1.0000 - val_rmse: 0.3330\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6251 - acc: 0.6923 - rmse: 0.4669 - val_loss: 0.4050 - val_acc: 1.0000 - val_rmse: 0.3330\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6231 - acc: 0.6923 - rmse: 0.4659 - val_loss: 0.4051 - val_acc: 1.0000 - val_rmse: 0.3331\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6212 - acc: 0.6923 - rmse: 0.4649 - val_loss: 0.4052 - val_acc: 1.0000 - val_rmse: 0.3331\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6193 - acc: 0.6923 - rmse: 0.4640 - val_loss: 0.4053 - val_acc: 1.0000 - val_rmse: 0.3332\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6174 - acc: 0.6923 - rmse: 0.4630 - val_loss: 0.4053 - val_acc: 1.0000 - val_rmse: 0.3333\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6155 - acc: 0.6923 - rmse: 0.4620 - val_loss: 0.4054 - val_acc: 1.0000 - val_rmse: 0.3333\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6136 - acc: 0.6923 - rmse: 0.4611 - val_loss: 0.4055 - val_acc: 1.0000 - val_rmse: 0.3334\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6117 - acc: 0.6923 - rmse: 0.4601 - val_loss: 0.4056 - val_acc: 1.0000 - val_rmse: 0.3334\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6098 - acc: 0.6923 - rmse: 0.4591 - val_loss: 0.4057 - val_acc: 1.0000 - val_rmse: 0.3335\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6079 - acc: 0.6923 - rmse: 0.4582 - val_loss: 0.4058 - val_acc: 1.0000 - val_rmse: 0.3335\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6060 - acc: 0.6923 - rmse: 0.4572 - val_loss: 0.4059 - val_acc: 1.0000 - val_rmse: 0.3336\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6041 - acc: 0.6923 - rmse: 0.4562 - val_loss: 0.4060 - val_acc: 1.0000 - val_rmse: 0.3337\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6023 - acc: 0.6923 - rmse: 0.4553 - val_loss: 0.4060 - val_acc: 1.0000 - val_rmse: 0.3337\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.6004 - acc: 0.6923 - rmse: 0.4543 - val_loss: 0.4061 - val_acc: 1.0000 - val_rmse: 0.3338\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5985 - acc: 0.6923 - rmse: 0.4533 - val_loss: 0.4062 - val_acc: 1.0000 - val_rmse: 0.3338\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5967 - acc: 0.6923 - rmse: 0.4524 - val_loss: 0.4063 - val_acc: 1.0000 - val_rmse: 0.3339\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5948 - acc: 0.6923 - rmse: 0.4514 - val_loss: 0.4064 - val_acc: 1.0000 - val_rmse: 0.3340\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5930 - acc: 0.6923 - rmse: 0.4505 - val_loss: 0.4065 - val_acc: 1.0000 - val_rmse: 0.3340\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5912 - acc: 0.6923 - rmse: 0.4495 - val_loss: 0.4066 - val_acc: 1.0000 - val_rmse: 0.3341\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5893 - acc: 0.6923 - rmse: 0.4485 - val_loss: 0.4066 - val_acc: 1.0000 - val_rmse: 0.3341\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5875 - acc: 0.6923 - rmse: 0.4476 - val_loss: 0.4067 - val_acc: 1.0000 - val_rmse: 0.3342\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5857 - acc: 0.6923 - rmse: 0.4466 - val_loss: 0.4068 - val_acc: 1.0000 - val_rmse: 0.3342\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5839 - acc: 0.6923 - rmse: 0.4457 - val_loss: 0.4069 - val_acc: 1.0000 - val_rmse: 0.3343\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5820 - acc: 0.6923 - rmse: 0.4447 - val_loss: 0.4070 - val_acc: 1.0000 - val_rmse: 0.3344\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5802 - acc: 0.6923 - rmse: 0.4438 - val_loss: 0.4071 - val_acc: 1.0000 - val_rmse: 0.3344\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5784 - acc: 0.6923 - rmse: 0.4428 - val_loss: 0.4072 - val_acc: 1.0000 - val_rmse: 0.3345\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5766 - acc: 0.6923 - rmse: 0.4418 - val_loss: 0.4072 - val_acc: 1.0000 - val_rmse: 0.3345\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5748 - acc: 0.6923 - rmse: 0.4409 - val_loss: 0.4073 - val_acc: 1.0000 - val_rmse: 0.3346\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5730 - acc: 0.6923 - rmse: 0.4399 - val_loss: 0.4074 - val_acc: 1.0000 - val_rmse: 0.3346\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5713 - acc: 0.6923 - rmse: 0.4390 - val_loss: 0.4075 - val_acc: 1.0000 - val_rmse: 0.3347\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5695 - acc: 0.6923 - rmse: 0.4380 - val_loss: 0.4076 - val_acc: 1.0000 - val_rmse: 0.3347\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5677 - acc: 0.6923 - rmse: 0.4371 - val_loss: 0.4076 - val_acc: 1.0000 - val_rmse: 0.3348\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5660 - acc: 0.6923 - rmse: 0.4361 - val_loss: 0.4077 - val_acc: 1.0000 - val_rmse: 0.3348\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5642 - acc: 0.6923 - rmse: 0.4352 - val_loss: 0.4078 - val_acc: 1.0000 - val_rmse: 0.3349\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5624 - acc: 0.6923 - rmse: 0.4342 - val_loss: 0.4079 - val_acc: 1.0000 - val_rmse: 0.3349\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5607 - acc: 0.6923 - rmse: 0.4333 - val_loss: 0.4079 - val_acc: 1.0000 - val_rmse: 0.3350\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5589 - acc: 0.6923 - rmse: 0.4323 - val_loss: 0.4080 - val_acc: 1.0000 - val_rmse: 0.3350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5572 - acc: 0.6923 - rmse: 0.4314 - val_loss: 0.4081 - val_acc: 1.0000 - val_rmse: 0.3351\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5555 - acc: 0.6923 - rmse: 0.4305 - val_loss: 0.4082 - val_acc: 1.0000 - val_rmse: 0.3351\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5539 - acc: 0.6923 - rmse: 0.4296 - val_loss: 0.4082 - val_acc: 1.0000 - val_rmse: 0.3352\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5522 - acc: 0.6923 - rmse: 0.4287 - val_loss: 0.4083 - val_acc: 1.0000 - val_rmse: 0.3352\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5506 - acc: 0.6923 - rmse: 0.4278 - val_loss: 0.4084 - val_acc: 1.0000 - val_rmse: 0.3353\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5490 - acc: 0.6923 - rmse: 0.4269 - val_loss: 0.4084 - val_acc: 1.0000 - val_rmse: 0.3353\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5473 - acc: 0.6923 - rmse: 0.4260 - val_loss: 0.4085 - val_acc: 1.0000 - val_rmse: 0.3354\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5457 - acc: 0.6923 - rmse: 0.4251 - val_loss: 0.4086 - val_acc: 1.0000 - val_rmse: 0.3354\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5441 - acc: 0.7308 - rmse: 0.4242 - val_loss: 0.4086 - val_acc: 1.0000 - val_rmse: 0.3355\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.40000\n",
      " - 0s - loss: 0.5424 - acc: 0.7308 - rmse: 0.4233 - val_loss: 0.4087 - val_acc: 1.0000 - val_rmse: 0.3355\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40000 to 0.38537, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 7s - loss: 0.7815 - acc: 0.6154 - rmse: 0.5352 - val_loss: 0.3854 - val_acc: 1.0000 - val_rmse: 0.3198\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38537 to 0.38533, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7790 - acc: 0.6154 - rmse: 0.5342 - val_loss: 0.3853 - val_acc: 1.0000 - val_rmse: 0.3198\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38533 to 0.38528, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7766 - acc: 0.6154 - rmse: 0.5332 - val_loss: 0.3853 - val_acc: 1.0000 - val_rmse: 0.3197\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38528 to 0.38524, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7741 - acc: 0.6154 - rmse: 0.5323 - val_loss: 0.3852 - val_acc: 1.0000 - val_rmse: 0.3197\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.38524 to 0.38519, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7716 - acc: 0.6154 - rmse: 0.5313 - val_loss: 0.3852 - val_acc: 1.0000 - val_rmse: 0.3197\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38519 to 0.38515, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7691 - acc: 0.6154 - rmse: 0.5303 - val_loss: 0.3851 - val_acc: 1.0000 - val_rmse: 0.3197\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38515 to 0.38510, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7667 - acc: 0.6154 - rmse: 0.5293 - val_loss: 0.3851 - val_acc: 1.0000 - val_rmse: 0.3196\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.38510 to 0.38506, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7642 - acc: 0.6154 - rmse: 0.5283 - val_loss: 0.3851 - val_acc: 1.0000 - val_rmse: 0.3196\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38506 to 0.38502, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7617 - acc: 0.6154 - rmse: 0.5274 - val_loss: 0.3850 - val_acc: 1.0000 - val_rmse: 0.3196\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38502 to 0.38497, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7593 - acc: 0.6154 - rmse: 0.5264 - val_loss: 0.3850 - val_acc: 1.0000 - val_rmse: 0.3195\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.38497 to 0.38493, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7568 - acc: 0.6154 - rmse: 0.5254 - val_loss: 0.3849 - val_acc: 1.0000 - val_rmse: 0.3195\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.38493 to 0.38488, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7544 - acc: 0.6154 - rmse: 0.5244 - val_loss: 0.3849 - val_acc: 1.0000 - val_rmse: 0.3195\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.38488 to 0.38484, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7521 - acc: 0.6154 - rmse: 0.5235 - val_loss: 0.3848 - val_acc: 1.0000 - val_rmse: 0.3194\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.38484 to 0.38479, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7497 - acc: 0.6154 - rmse: 0.5225 - val_loss: 0.3848 - val_acc: 1.0000 - val_rmse: 0.3194\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.38479 to 0.38475, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7473 - acc: 0.6154 - rmse: 0.5215 - val_loss: 0.3847 - val_acc: 1.0000 - val_rmse: 0.3194\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.38475 to 0.38470, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7449 - acc: 0.6154 - rmse: 0.5206 - val_loss: 0.3847 - val_acc: 1.0000 - val_rmse: 0.3193\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.38470 to 0.38466, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7425 - acc: 0.6154 - rmse: 0.5196 - val_loss: 0.3847 - val_acc: 1.0000 - val_rmse: 0.3193\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.38466 to 0.38461, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7401 - acc: 0.6154 - rmse: 0.5186 - val_loss: 0.3846 - val_acc: 1.0000 - val_rmse: 0.3193\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.38461 to 0.38456, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7378 - acc: 0.6154 - rmse: 0.5177 - val_loss: 0.3846 - val_acc: 1.0000 - val_rmse: 0.3193\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.38456 to 0.38452, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7354 - acc: 0.6154 - rmse: 0.5167 - val_loss: 0.3845 - val_acc: 1.0000 - val_rmse: 0.3192\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.38452 to 0.38447, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7330 - acc: 0.6154 - rmse: 0.5157 - val_loss: 0.3845 - val_acc: 1.0000 - val_rmse: 0.3192\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.38447 to 0.38443, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7307 - acc: 0.6154 - rmse: 0.5147 - val_loss: 0.3844 - val_acc: 1.0000 - val_rmse: 0.3192\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.38443 to 0.38438, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7283 - acc: 0.6154 - rmse: 0.5138 - val_loss: 0.3844 - val_acc: 1.0000 - val_rmse: 0.3191\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.38438 to 0.38434, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7259 - acc: 0.6154 - rmse: 0.5128 - val_loss: 0.3843 - val_acc: 1.0000 - val_rmse: 0.3191\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.38434 to 0.38430, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7236 - acc: 0.6154 - rmse: 0.5118 - val_loss: 0.3843 - val_acc: 1.0000 - val_rmse: 0.3191\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.38430 to 0.38426, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7214 - acc: 0.6154 - rmse: 0.5109 - val_loss: 0.3843 - val_acc: 1.0000 - val_rmse: 0.3190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.38426 to 0.38421, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7192 - acc: 0.6154 - rmse: 0.5099 - val_loss: 0.3842 - val_acc: 1.0000 - val_rmse: 0.3190\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.38421 to 0.38417, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7169 - acc: 0.6154 - rmse: 0.5090 - val_loss: 0.3842 - val_acc: 1.0000 - val_rmse: 0.3190\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.38417 to 0.38413, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7147 - acc: 0.6154 - rmse: 0.5081 - val_loss: 0.3841 - val_acc: 1.0000 - val_rmse: 0.3190\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.38413 to 0.38409, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7126 - acc: 0.6154 - rmse: 0.5072 - val_loss: 0.3841 - val_acc: 1.0000 - val_rmse: 0.3189\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.38409 to 0.38404, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7104 - acc: 0.6154 - rmse: 0.5063 - val_loss: 0.3840 - val_acc: 1.0000 - val_rmse: 0.3189\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.38404 to 0.38400, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7082 - acc: 0.6154 - rmse: 0.5053 - val_loss: 0.3840 - val_acc: 1.0000 - val_rmse: 0.3189\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.38400 to 0.38396, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7060 - acc: 0.6154 - rmse: 0.5044 - val_loss: 0.3840 - val_acc: 1.0000 - val_rmse: 0.3188\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.38396 to 0.38392, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7039 - acc: 0.6154 - rmse: 0.5035 - val_loss: 0.3839 - val_acc: 1.0000 - val_rmse: 0.3188\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.38392 to 0.38387, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.7017 - acc: 0.6154 - rmse: 0.5026 - val_loss: 0.3839 - val_acc: 1.0000 - val_rmse: 0.3188\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.38387 to 0.38383, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6996 - acc: 0.6154 - rmse: 0.5016 - val_loss: 0.3838 - val_acc: 1.0000 - val_rmse: 0.3188\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.38383 to 0.38379, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6974 - acc: 0.6154 - rmse: 0.5007 - val_loss: 0.3838 - val_acc: 1.0000 - val_rmse: 0.3187\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.38379 to 0.38375, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6953 - acc: 0.6154 - rmse: 0.4998 - val_loss: 0.3837 - val_acc: 1.0000 - val_rmse: 0.3187\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.38375 to 0.38370, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6931 - acc: 0.6154 - rmse: 0.4989 - val_loss: 0.3837 - val_acc: 1.0000 - val_rmse: 0.3187\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.38370 to 0.38366, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6910 - acc: 0.6154 - rmse: 0.4979 - val_loss: 0.3837 - val_acc: 1.0000 - val_rmse: 0.3186\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.38366 to 0.38362, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6889 - acc: 0.6154 - rmse: 0.4970 - val_loss: 0.3836 - val_acc: 1.0000 - val_rmse: 0.3186\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.38362 to 0.38358, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6868 - acc: 0.6154 - rmse: 0.4961 - val_loss: 0.3836 - val_acc: 1.0000 - val_rmse: 0.3186\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.38358 to 0.38354, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6847 - acc: 0.6154 - rmse: 0.4952 - val_loss: 0.3835 - val_acc: 1.0000 - val_rmse: 0.3186\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.38354 to 0.38350, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6827 - acc: 0.6154 - rmse: 0.4943 - val_loss: 0.3835 - val_acc: 1.0000 - val_rmse: 0.3185\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.38350 to 0.38346, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6806 - acc: 0.6154 - rmse: 0.4934 - val_loss: 0.3835 - val_acc: 1.0000 - val_rmse: 0.3185\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.38346 to 0.38342, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6786 - acc: 0.6154 - rmse: 0.4925 - val_loss: 0.3834 - val_acc: 1.0000 - val_rmse: 0.3185\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.38342 to 0.38338, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6765 - acc: 0.6154 - rmse: 0.4916 - val_loss: 0.3834 - val_acc: 1.0000 - val_rmse: 0.3184\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.38338 to 0.38335, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6745 - acc: 0.6154 - rmse: 0.4907 - val_loss: 0.3833 - val_acc: 1.0000 - val_rmse: 0.3184\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.38335 to 0.38331, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6725 - acc: 0.6154 - rmse: 0.4898 - val_loss: 0.3833 - val_acc: 1.0000 - val_rmse: 0.3184\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.38331 to 0.38327, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6705 - acc: 0.6154 - rmse: 0.4889 - val_loss: 0.3833 - val_acc: 1.0000 - val_rmse: 0.3184\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.38327 to 0.38323, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6684 - acc: 0.6154 - rmse: 0.4880 - val_loss: 0.3832 - val_acc: 1.0000 - val_rmse: 0.3183\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.38323 to 0.38320, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6665 - acc: 0.6154 - rmse: 0.4871 - val_loss: 0.3832 - val_acc: 1.0000 - val_rmse: 0.3183\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.38320 to 0.38316, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6645 - acc: 0.6154 - rmse: 0.4862 - val_loss: 0.3832 - val_acc: 1.0000 - val_rmse: 0.3183\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.38316 to 0.38312, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6625 - acc: 0.6154 - rmse: 0.4853 - val_loss: 0.3831 - val_acc: 1.0000 - val_rmse: 0.3183\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.38312 to 0.38309, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6605 - acc: 0.6154 - rmse: 0.4844 - val_loss: 0.3831 - val_acc: 1.0000 - val_rmse: 0.3182\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.38309 to 0.38305, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6586 - acc: 0.6154 - rmse: 0.4836 - val_loss: 0.3831 - val_acc: 1.0000 - val_rmse: 0.3182\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.38305 to 0.38302, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6566 - acc: 0.6154 - rmse: 0.4827 - val_loss: 0.3830 - val_acc: 1.0000 - val_rmse: 0.3182\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.38302 to 0.38298, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6547 - acc: 0.6538 - rmse: 0.4818 - val_loss: 0.3830 - val_acc: 1.0000 - val_rmse: 0.3182\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.38298 to 0.38295, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6527 - acc: 0.6538 - rmse: 0.4809 - val_loss: 0.3829 - val_acc: 1.0000 - val_rmse: 0.3182\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.38295 to 0.38291, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6508 - acc: 0.6538 - rmse: 0.4800 - val_loss: 0.3829 - val_acc: 1.0000 - val_rmse: 0.3181\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.38291 to 0.38288, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6488 - acc: 0.6538 - rmse: 0.4791 - val_loss: 0.3829 - val_acc: 1.0000 - val_rmse: 0.3181\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.38288 to 0.38285, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6469 - acc: 0.6538 - rmse: 0.4782 - val_loss: 0.3828 - val_acc: 1.0000 - val_rmse: 0.3181\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.38285 to 0.38281, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6450 - acc: 0.6538 - rmse: 0.4774 - val_loss: 0.3828 - val_acc: 1.0000 - val_rmse: 0.3181\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.38281 to 0.38278, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6431 - acc: 0.6538 - rmse: 0.4765 - val_loss: 0.3828 - val_acc: 1.0000 - val_rmse: 0.3180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.38278 to 0.38275, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6412 - acc: 0.6538 - rmse: 0.4756 - val_loss: 0.3827 - val_acc: 1.0000 - val_rmse: 0.3180\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.38275 to 0.38272, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6393 - acc: 0.6538 - rmse: 0.4747 - val_loss: 0.3827 - val_acc: 1.0000 - val_rmse: 0.3180\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.38272 to 0.38268, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6374 - acc: 0.6538 - rmse: 0.4738 - val_loss: 0.3827 - val_acc: 1.0000 - val_rmse: 0.3180\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.38268 to 0.38265, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6355 - acc: 0.6538 - rmse: 0.4730 - val_loss: 0.3827 - val_acc: 1.0000 - val_rmse: 0.3179\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.38265 to 0.38262, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6336 - acc: 0.6538 - rmse: 0.4721 - val_loss: 0.3826 - val_acc: 1.0000 - val_rmse: 0.3179\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.38262 to 0.38258, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6317 - acc: 0.6538 - rmse: 0.4712 - val_loss: 0.3826 - val_acc: 1.0000 - val_rmse: 0.3179\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.38258 to 0.38255, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6299 - acc: 0.6538 - rmse: 0.4703 - val_loss: 0.3826 - val_acc: 1.0000 - val_rmse: 0.3179\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.38255 to 0.38252, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6280 - acc: 0.6538 - rmse: 0.4695 - val_loss: 0.3825 - val_acc: 1.0000 - val_rmse: 0.3179\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.38252 to 0.38248, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6261 - acc: 0.6538 - rmse: 0.4686 - val_loss: 0.3825 - val_acc: 1.0000 - val_rmse: 0.3178\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.38248 to 0.38245, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6243 - acc: 0.6538 - rmse: 0.4677 - val_loss: 0.3824 - val_acc: 1.0000 - val_rmse: 0.3178\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.38245 to 0.38242, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6224 - acc: 0.6538 - rmse: 0.4668 - val_loss: 0.3824 - val_acc: 1.0000 - val_rmse: 0.3178\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.38242 to 0.38238, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6205 - acc: 0.6538 - rmse: 0.4660 - val_loss: 0.3824 - val_acc: 1.0000 - val_rmse: 0.3178\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.38238 to 0.38235, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6187 - acc: 0.6538 - rmse: 0.4651 - val_loss: 0.3823 - val_acc: 1.0000 - val_rmse: 0.3177\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.38235 to 0.38232, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6169 - acc: 0.6538 - rmse: 0.4642 - val_loss: 0.3823 - val_acc: 1.0000 - val_rmse: 0.3177\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.38232 to 0.38228, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6150 - acc: 0.6538 - rmse: 0.4633 - val_loss: 0.3823 - val_acc: 1.0000 - val_rmse: 0.3177\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.38228 to 0.38225, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6132 - acc: 0.6538 - rmse: 0.4625 - val_loss: 0.3822 - val_acc: 1.0000 - val_rmse: 0.3177\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.38225 to 0.38222, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6114 - acc: 0.6538 - rmse: 0.4616 - val_loss: 0.3822 - val_acc: 1.0000 - val_rmse: 0.3177\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.38222 to 0.38218, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6096 - acc: 0.6538 - rmse: 0.4607 - val_loss: 0.3822 - val_acc: 1.0000 - val_rmse: 0.3176\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.38218 to 0.38215, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6078 - acc: 0.6538 - rmse: 0.4599 - val_loss: 0.3821 - val_acc: 1.0000 - val_rmse: 0.3176\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.38215 to 0.38211, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6060 - acc: 0.6538 - rmse: 0.4590 - val_loss: 0.3821 - val_acc: 1.0000 - val_rmse: 0.3176\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.38211 to 0.38208, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6042 - acc: 0.6538 - rmse: 0.4582 - val_loss: 0.3821 - val_acc: 1.0000 - val_rmse: 0.3176\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.38208 to 0.38205, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.6025 - acc: 0.6538 - rmse: 0.4573 - val_loss: 0.3820 - val_acc: 1.0000 - val_rmse: 0.3175\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.38205 to 0.38201, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6008 - acc: 0.6923 - rmse: 0.4565 - val_loss: 0.3820 - val_acc: 1.0000 - val_rmse: 0.3175\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.38201 to 0.38198, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5991 - acc: 0.6923 - rmse: 0.4557 - val_loss: 0.3820 - val_acc: 1.0000 - val_rmse: 0.3175\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.38198 to 0.38194, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5975 - acc: 0.6923 - rmse: 0.4549 - val_loss: 0.3819 - val_acc: 1.0000 - val_rmse: 0.3175\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.38194 to 0.38191, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5958 - acc: 0.6923 - rmse: 0.4541 - val_loss: 0.3819 - val_acc: 1.0000 - val_rmse: 0.3174\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.38191 to 0.38188, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5942 - acc: 0.6923 - rmse: 0.4533 - val_loss: 0.3819 - val_acc: 1.0000 - val_rmse: 0.3174\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.38188 to 0.38184, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5925 - acc: 0.6923 - rmse: 0.4525 - val_loss: 0.3818 - val_acc: 1.0000 - val_rmse: 0.3174\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.38184 to 0.38181, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5909 - acc: 0.6923 - rmse: 0.4517 - val_loss: 0.3818 - val_acc: 1.0000 - val_rmse: 0.3174\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.38181 to 0.38178, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5892 - acc: 0.6923 - rmse: 0.4509 - val_loss: 0.3818 - val_acc: 1.0000 - val_rmse: 0.3174\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.38178 to 0.38174, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5876 - acc: 0.6923 - rmse: 0.4501 - val_loss: 0.3817 - val_acc: 1.0000 - val_rmse: 0.3173\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.38174 to 0.38171, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5860 - acc: 0.6923 - rmse: 0.4493 - val_loss: 0.3817 - val_acc: 1.0000 - val_rmse: 0.3173\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.38171 to 0.38168, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5844 - acc: 0.6923 - rmse: 0.4485 - val_loss: 0.3817 - val_acc: 1.0000 - val_rmse: 0.3173\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.38168 to 0.38165, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5829 - acc: 0.6923 - rmse: 0.4477 - val_loss: 0.3816 - val_acc: 1.0000 - val_rmse: 0.3173\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.38165 to 0.38162, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5813 - acc: 0.6923 - rmse: 0.4470 - val_loss: 0.3816 - val_acc: 1.0000 - val_rmse: 0.3172\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.38162 to 0.38158, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 0s - loss: 0.5797 - acc: 0.6923 - rmse: 0.4462 - val_loss: 0.3816 - val_acc: 1.0000 - val_rmse: 0.3172\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 2s - loss: 0.7382 - acc: 0.5769 - rmse: 0.5186 - val_loss: 0.8122 - val_acc: 0.0000e+00 - val_rmse: 0.5561\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7357 - acc: 0.5769 - rmse: 0.5175 - val_loss: 0.8122 - val_acc: 0.0000e+00 - val_rmse: 0.5561\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7331 - acc: 0.5769 - rmse: 0.5164 - val_loss: 0.8121 - val_acc: 0.0000e+00 - val_rmse: 0.5561\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7306 - acc: 0.5769 - rmse: 0.5152 - val_loss: 0.8120 - val_acc: 0.0000e+00 - val_rmse: 0.5560\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7280 - acc: 0.5769 - rmse: 0.5141 - val_loss: 0.8119 - val_acc: 0.0000e+00 - val_rmse: 0.5560\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7256 - acc: 0.5769 - rmse: 0.5131 - val_loss: 0.8119 - val_acc: 0.0000e+00 - val_rmse: 0.5560\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7231 - acc: 0.5769 - rmse: 0.5120 - val_loss: 0.8118 - val_acc: 0.0000e+00 - val_rmse: 0.5559\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7207 - acc: 0.5769 - rmse: 0.5109 - val_loss: 0.8117 - val_acc: 0.0000e+00 - val_rmse: 0.5559\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7183 - acc: 0.6154 - rmse: 0.5099 - val_loss: 0.8116 - val_acc: 0.0000e+00 - val_rmse: 0.5559\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7159 - acc: 0.6154 - rmse: 0.5088 - val_loss: 0.8116 - val_acc: 0.0000e+00 - val_rmse: 0.5558\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7135 - acc: 0.6154 - rmse: 0.5078 - val_loss: 0.8115 - val_acc: 0.0000e+00 - val_rmse: 0.5558\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7112 - acc: 0.6154 - rmse: 0.5067 - val_loss: 0.8114 - val_acc: 0.0000e+00 - val_rmse: 0.5558\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7089 - acc: 0.6154 - rmse: 0.5057 - val_loss: 0.8113 - val_acc: 0.0000e+00 - val_rmse: 0.5557\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7065 - acc: 0.6154 - rmse: 0.5047 - val_loss: 0.8113 - val_acc: 0.0000e+00 - val_rmse: 0.5557\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7042 - acc: 0.6154 - rmse: 0.5036 - val_loss: 0.8112 - val_acc: 0.0000e+00 - val_rmse: 0.5557\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7019 - acc: 0.6154 - rmse: 0.5026 - val_loss: 0.8111 - val_acc: 0.0000e+00 - val_rmse: 0.5556\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6996 - acc: 0.6154 - rmse: 0.5015 - val_loss: 0.8110 - val_acc: 0.0000e+00 - val_rmse: 0.5556\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6973 - acc: 0.6154 - rmse: 0.5005 - val_loss: 0.8110 - val_acc: 0.0000e+00 - val_rmse: 0.5556\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6950 - acc: 0.6538 - rmse: 0.4995 - val_loss: 0.8109 - val_acc: 0.0000e+00 - val_rmse: 0.5555\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6928 - acc: 0.6538 - rmse: 0.4985 - val_loss: 0.8108 - val_acc: 0.0000e+00 - val_rmse: 0.5555\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6905 - acc: 0.6538 - rmse: 0.4975 - val_loss: 0.8107 - val_acc: 0.0000e+00 - val_rmse: 0.5555\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6883 - acc: 0.6538 - rmse: 0.4964 - val_loss: 0.8107 - val_acc: 0.0000e+00 - val_rmse: 0.5554\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6860 - acc: 0.6538 - rmse: 0.4954 - val_loss: 0.8106 - val_acc: 0.0000e+00 - val_rmse: 0.5554\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6838 - acc: 0.6923 - rmse: 0.4944 - val_loss: 0.8105 - val_acc: 0.0000e+00 - val_rmse: 0.5554\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6816 - acc: 0.6923 - rmse: 0.4934 - val_loss: 0.8104 - val_acc: 0.0000e+00 - val_rmse: 0.5553\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6793 - acc: 0.6923 - rmse: 0.4923 - val_loss: 0.8104 - val_acc: 0.0000e+00 - val_rmse: 0.5553\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6771 - acc: 0.6923 - rmse: 0.4913 - val_loss: 0.8103 - val_acc: 0.0000e+00 - val_rmse: 0.5553\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6749 - acc: 0.6923 - rmse: 0.4903 - val_loss: 0.8102 - val_acc: 0.0000e+00 - val_rmse: 0.5552\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6727 - acc: 0.6923 - rmse: 0.4893 - val_loss: 0.8101 - val_acc: 0.0000e+00 - val_rmse: 0.5552\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6705 - acc: 0.6923 - rmse: 0.4883 - val_loss: 0.8101 - val_acc: 0.0000e+00 - val_rmse: 0.5552\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6684 - acc: 0.6923 - rmse: 0.4873 - val_loss: 0.8100 - val_acc: 0.0000e+00 - val_rmse: 0.5551\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6662 - acc: 0.6923 - rmse: 0.4862 - val_loss: 0.8099 - val_acc: 0.0000e+00 - val_rmse: 0.5551\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6641 - acc: 0.6923 - rmse: 0.4852 - val_loss: 0.8098 - val_acc: 0.0000e+00 - val_rmse: 0.5551\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6619 - acc: 0.6923 - rmse: 0.4842 - val_loss: 0.8098 - val_acc: 0.0000e+00 - val_rmse: 0.5550\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6598 - acc: 0.6923 - rmse: 0.4833 - val_loss: 0.8097 - val_acc: 0.0000e+00 - val_rmse: 0.5550\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6577 - acc: 0.6923 - rmse: 0.4823 - val_loss: 0.8096 - val_acc: 0.0000e+00 - val_rmse: 0.5550\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6557 - acc: 0.6923 - rmse: 0.4813 - val_loss: 0.8095 - val_acc: 0.0000e+00 - val_rmse: 0.5549\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6537 - acc: 0.6923 - rmse: 0.4803 - val_loss: 0.8095 - val_acc: 0.0000e+00 - val_rmse: 0.5549\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6517 - acc: 0.6923 - rmse: 0.4794 - val_loss: 0.8094 - val_acc: 0.0000e+00 - val_rmse: 0.5549\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6497 - acc: 0.6923 - rmse: 0.4784 - val_loss: 0.8093 - val_acc: 0.0000e+00 - val_rmse: 0.5548\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6477 - acc: 0.6923 - rmse: 0.4775 - val_loss: 0.8092 - val_acc: 0.0000e+00 - val_rmse: 0.5548\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6457 - acc: 0.6923 - rmse: 0.4765 - val_loss: 0.8091 - val_acc: 0.0000e+00 - val_rmse: 0.5548\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6437 - acc: 0.6923 - rmse: 0.4756 - val_loss: 0.8091 - val_acc: 0.0000e+00 - val_rmse: 0.5547\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6417 - acc: 0.6923 - rmse: 0.4746 - val_loss: 0.8090 - val_acc: 0.0000e+00 - val_rmse: 0.5547\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6397 - acc: 0.6923 - rmse: 0.4737 - val_loss: 0.8089 - val_acc: 0.0000e+00 - val_rmse: 0.5547\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6378 - acc: 0.6923 - rmse: 0.4727 - val_loss: 0.8089 - val_acc: 0.0000e+00 - val_rmse: 0.5546\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6358 - acc: 0.6923 - rmse: 0.4718 - val_loss: 0.8088 - val_acc: 0.0000e+00 - val_rmse: 0.5546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6338 - acc: 0.6923 - rmse: 0.4708 - val_loss: 0.8087 - val_acc: 0.0000e+00 - val_rmse: 0.5546\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6319 - acc: 0.6923 - rmse: 0.4699 - val_loss: 0.8086 - val_acc: 0.0000e+00 - val_rmse: 0.5545\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6299 - acc: 0.6923 - rmse: 0.4689 - val_loss: 0.8086 - val_acc: 0.0000e+00 - val_rmse: 0.5545\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6280 - acc: 0.6923 - rmse: 0.4680 - val_loss: 0.8085 - val_acc: 0.0000e+00 - val_rmse: 0.5545\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6260 - acc: 0.6923 - rmse: 0.4670 - val_loss: 0.8084 - val_acc: 0.0000e+00 - val_rmse: 0.5544\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6241 - acc: 0.6923 - rmse: 0.4661 - val_loss: 0.8083 - val_acc: 0.0000e+00 - val_rmse: 0.5544\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6222 - acc: 0.6923 - rmse: 0.4651 - val_loss: 0.8083 - val_acc: 0.0000e+00 - val_rmse: 0.5544\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6202 - acc: 0.6923 - rmse: 0.4642 - val_loss: 0.8082 - val_acc: 0.0000e+00 - val_rmse: 0.5543\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6183 - acc: 0.6923 - rmse: 0.4632 - val_loss: 0.8081 - val_acc: 0.0000e+00 - val_rmse: 0.5543\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6164 - acc: 0.6923 - rmse: 0.4623 - val_loss: 0.8081 - val_acc: 0.0000e+00 - val_rmse: 0.5543\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6145 - acc: 0.6923 - rmse: 0.4613 - val_loss: 0.8080 - val_acc: 0.0000e+00 - val_rmse: 0.5543\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6126 - acc: 0.6923 - rmse: 0.4604 - val_loss: 0.8079 - val_acc: 0.0000e+00 - val_rmse: 0.5542\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6107 - acc: 0.6923 - rmse: 0.4594 - val_loss: 0.8079 - val_acc: 0.0000e+00 - val_rmse: 0.5542\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6089 - acc: 0.6923 - rmse: 0.4585 - val_loss: 0.8078 - val_acc: 0.0000e+00 - val_rmse: 0.5542\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6071 - acc: 0.6923 - rmse: 0.4576 - val_loss: 0.8077 - val_acc: 0.0000e+00 - val_rmse: 0.5541\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6052 - acc: 0.6923 - rmse: 0.4567 - val_loss: 0.8077 - val_acc: 0.0000e+00 - val_rmse: 0.5541\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6034 - acc: 0.6923 - rmse: 0.4557 - val_loss: 0.8076 - val_acc: 0.0000e+00 - val_rmse: 0.5541\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6016 - acc: 0.6923 - rmse: 0.4548 - val_loss: 0.8076 - val_acc: 0.0000e+00 - val_rmse: 0.5541\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5998 - acc: 0.6923 - rmse: 0.4539 - val_loss: 0.8075 - val_acc: 0.0000e+00 - val_rmse: 0.5540\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5980 - acc: 0.6923 - rmse: 0.4530 - val_loss: 0.8074 - val_acc: 0.0000e+00 - val_rmse: 0.5540\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5963 - acc: 0.6923 - rmse: 0.4521 - val_loss: 0.8074 - val_acc: 0.0000e+00 - val_rmse: 0.5540\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5946 - acc: 0.6923 - rmse: 0.4513 - val_loss: 0.8073 - val_acc: 0.0000e+00 - val_rmse: 0.5539\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5930 - acc: 0.6923 - rmse: 0.4504 - val_loss: 0.8073 - val_acc: 0.0000e+00 - val_rmse: 0.5539\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5913 - acc: 0.6923 - rmse: 0.4496 - val_loss: 0.8072 - val_acc: 0.0000e+00 - val_rmse: 0.5539\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5896 - acc: 0.6923 - rmse: 0.4487 - val_loss: 0.8071 - val_acc: 0.0000e+00 - val_rmse: 0.5539\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5880 - acc: 0.6923 - rmse: 0.4479 - val_loss: 0.8071 - val_acc: 0.0000e+00 - val_rmse: 0.5538\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5863 - acc: 0.6923 - rmse: 0.4470 - val_loss: 0.8070 - val_acc: 0.0000e+00 - val_rmse: 0.5538\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5847 - acc: 0.6923 - rmse: 0.4462 - val_loss: 0.8070 - val_acc: 0.0000e+00 - val_rmse: 0.5538\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5830 - acc: 0.6923 - rmse: 0.4453 - val_loss: 0.8069 - val_acc: 0.0000e+00 - val_rmse: 0.5538\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5814 - acc: 0.6923 - rmse: 0.4445 - val_loss: 0.8069 - val_acc: 0.0000e+00 - val_rmse: 0.5537\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5798 - acc: 0.6923 - rmse: 0.4436 - val_loss: 0.8068 - val_acc: 0.0000e+00 - val_rmse: 0.5537\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5781 - acc: 0.7308 - rmse: 0.4428 - val_loss: 0.8068 - val_acc: 0.0000e+00 - val_rmse: 0.5537\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5765 - acc: 0.7308 - rmse: 0.4419 - val_loss: 0.8067 - val_acc: 0.0000e+00 - val_rmse: 0.5537\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5749 - acc: 0.7308 - rmse: 0.4411 - val_loss: 0.8066 - val_acc: 0.0000e+00 - val_rmse: 0.5536\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5733 - acc: 0.7308 - rmse: 0.4402 - val_loss: 0.8066 - val_acc: 0.0000e+00 - val_rmse: 0.5536\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5716 - acc: 0.7308 - rmse: 0.4394 - val_loss: 0.8065 - val_acc: 0.0000e+00 - val_rmse: 0.5536\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5700 - acc: 0.7308 - rmse: 0.4385 - val_loss: 0.8065 - val_acc: 0.0000e+00 - val_rmse: 0.5536\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5684 - acc: 0.7308 - rmse: 0.4377 - val_loss: 0.8064 - val_acc: 0.0000e+00 - val_rmse: 0.5535\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5668 - acc: 0.7308 - rmse: 0.4368 - val_loss: 0.8064 - val_acc: 0.0000e+00 - val_rmse: 0.5535\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5652 - acc: 0.7308 - rmse: 0.4360 - val_loss: 0.8063 - val_acc: 0.0000e+00 - val_rmse: 0.5535\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5636 - acc: 0.7308 - rmse: 0.4351 - val_loss: 0.8063 - val_acc: 0.0000e+00 - val_rmse: 0.5535\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5620 - acc: 0.7308 - rmse: 0.4343 - val_loss: 0.8062 - val_acc: 0.0000e+00 - val_rmse: 0.5535\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5604 - acc: 0.7308 - rmse: 0.4334 - val_loss: 0.8062 - val_acc: 0.0000e+00 - val_rmse: 0.5534\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5588 - acc: 0.7308 - rmse: 0.4326 - val_loss: 0.8061 - val_acc: 0.0000e+00 - val_rmse: 0.5534\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5573 - acc: 0.7308 - rmse: 0.4317 - val_loss: 0.8061 - val_acc: 0.0000e+00 - val_rmse: 0.5534\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5557 - acc: 0.7308 - rmse: 0.4309 - val_loss: 0.8060 - val_acc: 0.0000e+00 - val_rmse: 0.5534\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5541 - acc: 0.7308 - rmse: 0.4301 - val_loss: 0.8060 - val_acc: 0.0000e+00 - val_rmse: 0.5533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5526 - acc: 0.7308 - rmse: 0.4292 - val_loss: 0.8059 - val_acc: 0.0000e+00 - val_rmse: 0.5533\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5510 - acc: 0.7308 - rmse: 0.4284 - val_loss: 0.8059 - val_acc: 0.0000e+00 - val_rmse: 0.5533\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5494 - acc: 0.7308 - rmse: 0.4275 - val_loss: 0.8058 - val_acc: 0.0000e+00 - val_rmse: 0.5533\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5479 - acc: 0.7308 - rmse: 0.4267 - val_loss: 0.8058 - val_acc: 0.0000e+00 - val_rmse: 0.5532\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5463 - acc: 0.7308 - rmse: 0.4259 - val_loss: 0.8057 - val_acc: 0.0000e+00 - val_rmse: 0.5532\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5448 - acc: 0.7308 - rmse: 0.4250 - val_loss: 0.8057 - val_acc: 0.0000e+00 - val_rmse: 0.5532\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 3s - loss: 0.7853 - acc: 0.3462 - rmse: 0.5424 - val_loss: 1.1723 - val_acc: 0.0000e+00 - val_rmse: 0.6903\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7828 - acc: 0.3462 - rmse: 0.5414 - val_loss: 1.1722 - val_acc: 0.0000e+00 - val_rmse: 0.6903\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7802 - acc: 0.3462 - rmse: 0.5403 - val_loss: 1.1721 - val_acc: 0.0000e+00 - val_rmse: 0.6903\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7776 - acc: 0.3846 - rmse: 0.5391 - val_loss: 1.1721 - val_acc: 0.0000e+00 - val_rmse: 0.6903\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7751 - acc: 0.3846 - rmse: 0.5380 - val_loss: 1.1720 - val_acc: 0.0000e+00 - val_rmse: 0.6903\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7725 - acc: 0.3846 - rmse: 0.5369 - val_loss: 1.1720 - val_acc: 0.0000e+00 - val_rmse: 0.6902\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7699 - acc: 0.3846 - rmse: 0.5358 - val_loss: 1.1719 - val_acc: 0.0000e+00 - val_rmse: 0.6902\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7674 - acc: 0.3846 - rmse: 0.5347 - val_loss: 1.1718 - val_acc: 0.0000e+00 - val_rmse: 0.6902\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7650 - acc: 0.3846 - rmse: 0.5337 - val_loss: 1.1718 - val_acc: 0.0000e+00 - val_rmse: 0.6902\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7625 - acc: 0.3846 - rmse: 0.5326 - val_loss: 1.1717 - val_acc: 0.0000e+00 - val_rmse: 0.6902\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7602 - acc: 0.3846 - rmse: 0.5316 - val_loss: 1.1717 - val_acc: 0.0000e+00 - val_rmse: 0.6902\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7578 - acc: 0.3846 - rmse: 0.5306 - val_loss: 1.1716 - val_acc: 0.0000e+00 - val_rmse: 0.6901\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7555 - acc: 0.3846 - rmse: 0.5295 - val_loss: 1.1716 - val_acc: 0.0000e+00 - val_rmse: 0.6901\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7532 - acc: 0.3846 - rmse: 0.5285 - val_loss: 1.1715 - val_acc: 0.0000e+00 - val_rmse: 0.6901\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7509 - acc: 0.3846 - rmse: 0.5275 - val_loss: 1.1715 - val_acc: 0.0000e+00 - val_rmse: 0.6901\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7487 - acc: 0.3846 - rmse: 0.5265 - val_loss: 1.1714 - val_acc: 0.0000e+00 - val_rmse: 0.6901\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7464 - acc: 0.3846 - rmse: 0.5256 - val_loss: 1.1713 - val_acc: 0.0000e+00 - val_rmse: 0.6901\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7442 - acc: 0.3846 - rmse: 0.5246 - val_loss: 1.1713 - val_acc: 0.0000e+00 - val_rmse: 0.6900\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7420 - acc: 0.3846 - rmse: 0.5236 - val_loss: 1.1712 - val_acc: 0.0000e+00 - val_rmse: 0.6900\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7397 - acc: 0.3846 - rmse: 0.5226 - val_loss: 1.1712 - val_acc: 0.0000e+00 - val_rmse: 0.6900\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7375 - acc: 0.3846 - rmse: 0.5216 - val_loss: 1.1711 - val_acc: 0.0000e+00 - val_rmse: 0.6900\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7354 - acc: 0.3846 - rmse: 0.5206 - val_loss: 1.1711 - val_acc: 0.0000e+00 - val_rmse: 0.6900\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7332 - acc: 0.3846 - rmse: 0.5197 - val_loss: 1.1710 - val_acc: 0.0000e+00 - val_rmse: 0.6900\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7310 - acc: 0.3846 - rmse: 0.5187 - val_loss: 1.1710 - val_acc: 0.0000e+00 - val_rmse: 0.6899\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7288 - acc: 0.3846 - rmse: 0.5177 - val_loss: 1.1709 - val_acc: 0.0000e+00 - val_rmse: 0.6899\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7267 - acc: 0.3846 - rmse: 0.5167 - val_loss: 1.1709 - val_acc: 0.0000e+00 - val_rmse: 0.6899\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7245 - acc: 0.3846 - rmse: 0.5158 - val_loss: 1.1709 - val_acc: 0.0000e+00 - val_rmse: 0.6899\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7224 - acc: 0.3846 - rmse: 0.5148 - val_loss: 1.1708 - val_acc: 0.0000e+00 - val_rmse: 0.6899\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7203 - acc: 0.3846 - rmse: 0.5138 - val_loss: 1.1708 - val_acc: 0.0000e+00 - val_rmse: 0.6899\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7182 - acc: 0.4231 - rmse: 0.5129 - val_loss: 1.1707 - val_acc: 0.0000e+00 - val_rmse: 0.6899\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7160 - acc: 0.4231 - rmse: 0.5119 - val_loss: 1.1707 - val_acc: 0.0000e+00 - val_rmse: 0.6898\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7139 - acc: 0.4231 - rmse: 0.5109 - val_loss: 1.1706 - val_acc: 0.0000e+00 - val_rmse: 0.6898\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7118 - acc: 0.4231 - rmse: 0.5100 - val_loss: 1.1706 - val_acc: 0.0000e+00 - val_rmse: 0.6898\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7097 - acc: 0.4231 - rmse: 0.5090 - val_loss: 1.1706 - val_acc: 0.0000e+00 - val_rmse: 0.6898\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7076 - acc: 0.4615 - rmse: 0.5081 - val_loss: 1.1705 - val_acc: 0.0000e+00 - val_rmse: 0.6898\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7055 - acc: 0.4615 - rmse: 0.5071 - val_loss: 1.1705 - val_acc: 0.0000e+00 - val_rmse: 0.6898\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7034 - acc: 0.4615 - rmse: 0.5061 - val_loss: 1.1705 - val_acc: 0.0000e+00 - val_rmse: 0.6898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7013 - acc: 0.4615 - rmse: 0.5052 - val_loss: 1.1704 - val_acc: 0.0000e+00 - val_rmse: 0.6898\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6993 - acc: 0.4615 - rmse: 0.5042 - val_loss: 1.1704 - val_acc: 0.0000e+00 - val_rmse: 0.6898\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6972 - acc: 0.4615 - rmse: 0.5032 - val_loss: 1.1704 - val_acc: 0.0000e+00 - val_rmse: 0.6897\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6951 - acc: 0.4615 - rmse: 0.5023 - val_loss: 1.1703 - val_acc: 0.0000e+00 - val_rmse: 0.6897\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6931 - acc: 0.4615 - rmse: 0.5013 - val_loss: 1.1703 - val_acc: 0.0000e+00 - val_rmse: 0.6897\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6911 - acc: 0.5000 - rmse: 0.5004 - val_loss: 1.1703 - val_acc: 0.0000e+00 - val_rmse: 0.6897\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6890 - acc: 0.5000 - rmse: 0.4994 - val_loss: 1.1702 - val_acc: 0.0000e+00 - val_rmse: 0.6897\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6870 - acc: 0.5000 - rmse: 0.4985 - val_loss: 1.1702 - val_acc: 0.0000e+00 - val_rmse: 0.6897\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6850 - acc: 0.5000 - rmse: 0.4975 - val_loss: 1.1701 - val_acc: 0.0000e+00 - val_rmse: 0.6897\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6831 - acc: 0.5000 - rmse: 0.4966 - val_loss: 1.1701 - val_acc: 0.0000e+00 - val_rmse: 0.6897\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6811 - acc: 0.5000 - rmse: 0.4957 - val_loss: 1.1701 - val_acc: 0.0000e+00 - val_rmse: 0.6897\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6791 - acc: 0.5000 - rmse: 0.4947 - val_loss: 1.1700 - val_acc: 0.0000e+00 - val_rmse: 0.6896\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6772 - acc: 0.5000 - rmse: 0.4938 - val_loss: 1.1700 - val_acc: 0.0000e+00 - val_rmse: 0.6896\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6753 - acc: 0.5000 - rmse: 0.4929 - val_loss: 1.1700 - val_acc: 0.0000e+00 - val_rmse: 0.6896\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6733 - acc: 0.5000 - rmse: 0.4920 - val_loss: 1.1699 - val_acc: 0.0000e+00 - val_rmse: 0.6896\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6714 - acc: 0.5385 - rmse: 0.4911 - val_loss: 1.1699 - val_acc: 0.0000e+00 - val_rmse: 0.6896\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6695 - acc: 0.5385 - rmse: 0.4902 - val_loss: 1.1698 - val_acc: 0.0000e+00 - val_rmse: 0.6896\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6676 - acc: 0.5385 - rmse: 0.4892 - val_loss: 1.1698 - val_acc: 0.0000e+00 - val_rmse: 0.6896\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6657 - acc: 0.5385 - rmse: 0.4883 - val_loss: 1.1698 - val_acc: 0.0000e+00 - val_rmse: 0.6896\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6638 - acc: 0.5385 - rmse: 0.4874 - val_loss: 1.1697 - val_acc: 0.0000e+00 - val_rmse: 0.6895\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6619 - acc: 0.5385 - rmse: 0.4865 - val_loss: 1.1697 - val_acc: 0.0000e+00 - val_rmse: 0.6895\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6600 - acc: 0.5385 - rmse: 0.4856 - val_loss: 1.1696 - val_acc: 0.0000e+00 - val_rmse: 0.6895\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6581 - acc: 0.5385 - rmse: 0.4847 - val_loss: 1.1696 - val_acc: 0.0000e+00 - val_rmse: 0.6895\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6562 - acc: 0.5769 - rmse: 0.4837 - val_loss: 1.1696 - val_acc: 0.0000e+00 - val_rmse: 0.6895\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6544 - acc: 0.6154 - rmse: 0.4829 - val_loss: 1.1695 - val_acc: 0.0000e+00 - val_rmse: 0.6895\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6526 - acc: 0.6154 - rmse: 0.4820 - val_loss: 1.1695 - val_acc: 0.0000e+00 - val_rmse: 0.6895\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6507 - acc: 0.6154 - rmse: 0.4811 - val_loss: 1.1694 - val_acc: 0.0000e+00 - val_rmse: 0.6895\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6489 - acc: 0.6154 - rmse: 0.4802 - val_loss: 1.1694 - val_acc: 0.0000e+00 - val_rmse: 0.6894\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6471 - acc: 0.6154 - rmse: 0.4793 - val_loss: 1.1693 - val_acc: 0.0000e+00 - val_rmse: 0.6894\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6453 - acc: 0.6154 - rmse: 0.4784 - val_loss: 1.1693 - val_acc: 0.0000e+00 - val_rmse: 0.6894\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6435 - acc: 0.6154 - rmse: 0.4775 - val_loss: 1.1692 - val_acc: 0.0000e+00 - val_rmse: 0.6894\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6417 - acc: 0.6154 - rmse: 0.4766 - val_loss: 1.1692 - val_acc: 0.0000e+00 - val_rmse: 0.6894\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6399 - acc: 0.6154 - rmse: 0.4757 - val_loss: 1.1692 - val_acc: 0.0000e+00 - val_rmse: 0.6894\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6381 - acc: 0.6154 - rmse: 0.4749 - val_loss: 1.1691 - val_acc: 0.0000e+00 - val_rmse: 0.6894\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6364 - acc: 0.6154 - rmse: 0.4740 - val_loss: 1.1691 - val_acc: 0.0000e+00 - val_rmse: 0.6893\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6346 - acc: 0.6154 - rmse: 0.4731 - val_loss: 1.1690 - val_acc: 0.0000e+00 - val_rmse: 0.6893\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6328 - acc: 0.6154 - rmse: 0.4722 - val_loss: 1.1690 - val_acc: 0.0000e+00 - val_rmse: 0.6893\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6311 - acc: 0.6154 - rmse: 0.4714 - val_loss: 1.1689 - val_acc: 0.0000e+00 - val_rmse: 0.6893\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6294 - acc: 0.6154 - rmse: 0.4705 - val_loss: 1.1689 - val_acc: 0.0000e+00 - val_rmse: 0.6893\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6276 - acc: 0.6154 - rmse: 0.4696 - val_loss: 1.1688 - val_acc: 0.0000e+00 - val_rmse: 0.6893\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6259 - acc: 0.6538 - rmse: 0.4688 - val_loss: 1.1688 - val_acc: 0.0000e+00 - val_rmse: 0.6892\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6242 - acc: 0.6923 - rmse: 0.4679 - val_loss: 1.1687 - val_acc: 0.0000e+00 - val_rmse: 0.6892\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6224 - acc: 0.6923 - rmse: 0.4670 - val_loss: 1.1686 - val_acc: 0.0000e+00 - val_rmse: 0.6892\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6207 - acc: 0.6923 - rmse: 0.4662 - val_loss: 1.1686 - val_acc: 0.0000e+00 - val_rmse: 0.6892\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6190 - acc: 0.6923 - rmse: 0.4653 - val_loss: 1.1685 - val_acc: 0.0000e+00 - val_rmse: 0.6892\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6173 - acc: 0.6923 - rmse: 0.4644 - val_loss: 1.1685 - val_acc: 0.0000e+00 - val_rmse: 0.6892\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6156 - acc: 0.6923 - rmse: 0.4636 - val_loss: 1.1684 - val_acc: 0.0000e+00 - val_rmse: 0.6891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6139 - acc: 0.7308 - rmse: 0.4627 - val_loss: 1.1684 - val_acc: 0.0000e+00 - val_rmse: 0.6891\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6122 - acc: 0.7308 - rmse: 0.4618 - val_loss: 1.1683 - val_acc: 0.0000e+00 - val_rmse: 0.6891\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6105 - acc: 0.7308 - rmse: 0.4610 - val_loss: 1.1682 - val_acc: 0.0000e+00 - val_rmse: 0.6891\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6089 - acc: 0.7308 - rmse: 0.4601 - val_loss: 1.1682 - val_acc: 0.0000e+00 - val_rmse: 0.6891\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6072 - acc: 0.7308 - rmse: 0.4593 - val_loss: 1.1681 - val_acc: 0.0000e+00 - val_rmse: 0.6890\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6055 - acc: 0.7308 - rmse: 0.4584 - val_loss: 1.1680 - val_acc: 0.0000e+00 - val_rmse: 0.6890\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6038 - acc: 0.7308 - rmse: 0.4575 - val_loss: 1.1680 - val_acc: 0.0000e+00 - val_rmse: 0.6890\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6022 - acc: 0.7308 - rmse: 0.4567 - val_loss: 1.1679 - val_acc: 0.0000e+00 - val_rmse: 0.6890\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6005 - acc: 0.7308 - rmse: 0.4558 - val_loss: 1.1679 - val_acc: 0.0000e+00 - val_rmse: 0.6890\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5988 - acc: 0.7308 - rmse: 0.4550 - val_loss: 1.1678 - val_acc: 0.0000e+00 - val_rmse: 0.6890\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5972 - acc: 0.7308 - rmse: 0.4541 - val_loss: 1.1677 - val_acc: 0.0000e+00 - val_rmse: 0.6889\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5955 - acc: 0.7308 - rmse: 0.4532 - val_loss: 1.1677 - val_acc: 0.0000e+00 - val_rmse: 0.6889\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5939 - acc: 0.7308 - rmse: 0.4524 - val_loss: 1.1676 - val_acc: 0.0000e+00 - val_rmse: 0.6889\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5923 - acc: 0.7308 - rmse: 0.4515 - val_loss: 1.1676 - val_acc: 0.0000e+00 - val_rmse: 0.6889\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5906 - acc: 0.7308 - rmse: 0.4507 - val_loss: 1.1675 - val_acc: 0.0000e+00 - val_rmse: 0.6889\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5890 - acc: 0.7308 - rmse: 0.4499 - val_loss: 1.1674 - val_acc: 0.0000e+00 - val_rmse: 0.6888\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 3s - loss: 0.7658 - acc: 0.5000 - rmse: 0.5268 - val_loss: 0.5111 - val_acc: 1.0000 - val_rmse: 0.4002\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7634 - acc: 0.5000 - rmse: 0.5258 - val_loss: 0.5111 - val_acc: 1.0000 - val_rmse: 0.4001\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7611 - acc: 0.5000 - rmse: 0.5249 - val_loss: 0.5110 - val_acc: 1.0000 - val_rmse: 0.4001\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7587 - acc: 0.5000 - rmse: 0.5239 - val_loss: 0.5110 - val_acc: 1.0000 - val_rmse: 0.4001\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7564 - acc: 0.5385 - rmse: 0.5229 - val_loss: 0.5110 - val_acc: 1.0000 - val_rmse: 0.4001\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7541 - acc: 0.5385 - rmse: 0.5219 - val_loss: 0.5110 - val_acc: 1.0000 - val_rmse: 0.4001\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7517 - acc: 0.5385 - rmse: 0.5209 - val_loss: 0.5109 - val_acc: 1.0000 - val_rmse: 0.4001\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7493 - acc: 0.5385 - rmse: 0.5199 - val_loss: 0.5109 - val_acc: 1.0000 - val_rmse: 0.4000\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7470 - acc: 0.5385 - rmse: 0.5189 - val_loss: 0.5109 - val_acc: 1.0000 - val_rmse: 0.4000\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7446 - acc: 0.5385 - rmse: 0.5179 - val_loss: 0.5108 - val_acc: 1.0000 - val_rmse: 0.4000\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7423 - acc: 0.5385 - rmse: 0.5169 - val_loss: 0.5108 - val_acc: 1.0000 - val_rmse: 0.4000\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7400 - acc: 0.5385 - rmse: 0.5160 - val_loss: 0.5108 - val_acc: 1.0000 - val_rmse: 0.4000\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7379 - acc: 0.5385 - rmse: 0.5151 - val_loss: 0.5107 - val_acc: 1.0000 - val_rmse: 0.4000\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7358 - acc: 0.5385 - rmse: 0.5142 - val_loss: 0.5107 - val_acc: 1.0000 - val_rmse: 0.3999\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7337 - acc: 0.5385 - rmse: 0.5133 - val_loss: 0.5107 - val_acc: 1.0000 - val_rmse: 0.3999\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7316 - acc: 0.5385 - rmse: 0.5124 - val_loss: 0.5107 - val_acc: 1.0000 - val_rmse: 0.3999\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7294 - acc: 0.5385 - rmse: 0.5114 - val_loss: 0.5106 - val_acc: 1.0000 - val_rmse: 0.3999\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7273 - acc: 0.5385 - rmse: 0.5105 - val_loss: 0.5106 - val_acc: 1.0000 - val_rmse: 0.3999\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7251 - acc: 0.5385 - rmse: 0.5096 - val_loss: 0.5106 - val_acc: 1.0000 - val_rmse: 0.3998\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7230 - acc: 0.5385 - rmse: 0.5086 - val_loss: 0.5105 - val_acc: 1.0000 - val_rmse: 0.3998\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7209 - acc: 0.5385 - rmse: 0.5077 - val_loss: 0.5105 - val_acc: 1.0000 - val_rmse: 0.3998\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7187 - acc: 0.5385 - rmse: 0.5068 - val_loss: 0.5105 - val_acc: 1.0000 - val_rmse: 0.3998\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7166 - acc: 0.5769 - rmse: 0.5058 - val_loss: 0.5105 - val_acc: 1.0000 - val_rmse: 0.3998\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7145 - acc: 0.5769 - rmse: 0.5049 - val_loss: 0.5104 - val_acc: 1.0000 - val_rmse: 0.3998\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7123 - acc: 0.5769 - rmse: 0.5040 - val_loss: 0.5104 - val_acc: 1.0000 - val_rmse: 0.3997\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7102 - acc: 0.5769 - rmse: 0.5030 - val_loss: 0.5104 - val_acc: 1.0000 - val_rmse: 0.3997\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7081 - acc: 0.5769 - rmse: 0.5021 - val_loss: 0.5103 - val_acc: 1.0000 - val_rmse: 0.3997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7060 - acc: 0.6154 - rmse: 0.5012 - val_loss: 0.5103 - val_acc: 1.0000 - val_rmse: 0.3997\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7040 - acc: 0.6154 - rmse: 0.5003 - val_loss: 0.5103 - val_acc: 1.0000 - val_rmse: 0.3997\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7019 - acc: 0.6154 - rmse: 0.4993 - val_loss: 0.5103 - val_acc: 1.0000 - val_rmse: 0.3997\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6999 - acc: 0.6154 - rmse: 0.4984 - val_loss: 0.5102 - val_acc: 1.0000 - val_rmse: 0.3996\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6978 - acc: 0.6154 - rmse: 0.4975 - val_loss: 0.5102 - val_acc: 1.0000 - val_rmse: 0.3996\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6958 - acc: 0.6154 - rmse: 0.4966 - val_loss: 0.5102 - val_acc: 1.0000 - val_rmse: 0.3996\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6937 - acc: 0.6538 - rmse: 0.4957 - val_loss: 0.5102 - val_acc: 1.0000 - val_rmse: 0.3996\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6917 - acc: 0.6538 - rmse: 0.4948 - val_loss: 0.5101 - val_acc: 1.0000 - val_rmse: 0.3996\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6897 - acc: 0.6538 - rmse: 0.4939 - val_loss: 0.5101 - val_acc: 1.0000 - val_rmse: 0.3996\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6877 - acc: 0.6538 - rmse: 0.4930 - val_loss: 0.5101 - val_acc: 1.0000 - val_rmse: 0.3995\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6857 - acc: 0.6538 - rmse: 0.4920 - val_loss: 0.5100 - val_acc: 1.0000 - val_rmse: 0.3995\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6837 - acc: 0.6538 - rmse: 0.4911 - val_loss: 0.5100 - val_acc: 1.0000 - val_rmse: 0.3995\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6817 - acc: 0.6538 - rmse: 0.4902 - val_loss: 0.5100 - val_acc: 1.0000 - val_rmse: 0.3995\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6798 - acc: 0.6538 - rmse: 0.4893 - val_loss: 0.5099 - val_acc: 1.0000 - val_rmse: 0.3995\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6778 - acc: 0.6538 - rmse: 0.4884 - val_loss: 0.5099 - val_acc: 1.0000 - val_rmse: 0.3995\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6758 - acc: 0.6538 - rmse: 0.4875 - val_loss: 0.5099 - val_acc: 1.0000 - val_rmse: 0.3994\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6739 - acc: 0.6538 - rmse: 0.4866 - val_loss: 0.5099 - val_acc: 1.0000 - val_rmse: 0.3994\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6719 - acc: 0.6538 - rmse: 0.4857 - val_loss: 0.5098 - val_acc: 1.0000 - val_rmse: 0.3994\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6700 - acc: 0.6538 - rmse: 0.4849 - val_loss: 0.5098 - val_acc: 1.0000 - val_rmse: 0.3994\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6682 - acc: 0.6538 - rmse: 0.4840 - val_loss: 0.5098 - val_acc: 1.0000 - val_rmse: 0.3994\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6663 - acc: 0.6538 - rmse: 0.4831 - val_loss: 0.5097 - val_acc: 1.0000 - val_rmse: 0.3993\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6645 - acc: 0.6538 - rmse: 0.4823 - val_loss: 0.5097 - val_acc: 1.0000 - val_rmse: 0.3993\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6626 - acc: 0.6538 - rmse: 0.4814 - val_loss: 0.5097 - val_acc: 1.0000 - val_rmse: 0.3993\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6608 - acc: 0.6538 - rmse: 0.4806 - val_loss: 0.5096 - val_acc: 1.0000 - val_rmse: 0.3993\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6590 - acc: 0.6538 - rmse: 0.4797 - val_loss: 0.5096 - val_acc: 1.0000 - val_rmse: 0.3993\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6572 - acc: 0.6538 - rmse: 0.4789 - val_loss: 0.5096 - val_acc: 1.0000 - val_rmse: 0.3992\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6554 - acc: 0.6538 - rmse: 0.4780 - val_loss: 0.5095 - val_acc: 1.0000 - val_rmse: 0.3992\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6536 - acc: 0.6538 - rmse: 0.4772 - val_loss: 0.5095 - val_acc: 1.0000 - val_rmse: 0.3992\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6518 - acc: 0.6538 - rmse: 0.4763 - val_loss: 0.5095 - val_acc: 1.0000 - val_rmse: 0.3992\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6500 - acc: 0.6538 - rmse: 0.4755 - val_loss: 0.5094 - val_acc: 1.0000 - val_rmse: 0.3992\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6482 - acc: 0.6538 - rmse: 0.4747 - val_loss: 0.5094 - val_acc: 1.0000 - val_rmse: 0.3992\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6464 - acc: 0.6538 - rmse: 0.4738 - val_loss: 0.5094 - val_acc: 1.0000 - val_rmse: 0.3991\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6446 - acc: 0.6538 - rmse: 0.4730 - val_loss: 0.5093 - val_acc: 1.0000 - val_rmse: 0.3991\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6429 - acc: 0.6538 - rmse: 0.4721 - val_loss: 0.5093 - val_acc: 1.0000 - val_rmse: 0.3991\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6411 - acc: 0.6538 - rmse: 0.4713 - val_loss: 0.5093 - val_acc: 1.0000 - val_rmse: 0.3991\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6393 - acc: 0.6538 - rmse: 0.4704 - val_loss: 0.5092 - val_acc: 1.0000 - val_rmse: 0.3991\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6376 - acc: 0.6538 - rmse: 0.4696 - val_loss: 0.5092 - val_acc: 1.0000 - val_rmse: 0.3990\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6358 - acc: 0.6538 - rmse: 0.4688 - val_loss: 0.5092 - val_acc: 1.0000 - val_rmse: 0.3990\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6341 - acc: 0.6538 - rmse: 0.4679 - val_loss: 0.5091 - val_acc: 1.0000 - val_rmse: 0.3990\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6323 - acc: 0.6538 - rmse: 0.4671 - val_loss: 0.5091 - val_acc: 1.0000 - val_rmse: 0.3990\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6306 - acc: 0.6538 - rmse: 0.4662 - val_loss: 0.5091 - val_acc: 1.0000 - val_rmse: 0.3990\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6288 - acc: 0.6538 - rmse: 0.4654 - val_loss: 0.5091 - val_acc: 1.0000 - val_rmse: 0.3989\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6271 - acc: 0.6538 - rmse: 0.4646 - val_loss: 0.5090 - val_acc: 1.0000 - val_rmse: 0.3989\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6254 - acc: 0.6538 - rmse: 0.4637 - val_loss: 0.5090 - val_acc: 1.0000 - val_rmse: 0.3989\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6236 - acc: 0.6538 - rmse: 0.4629 - val_loss: 0.5090 - val_acc: 1.0000 - val_rmse: 0.3989\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6219 - acc: 0.6923 - rmse: 0.4620 - val_loss: 0.5089 - val_acc: 1.0000 - val_rmse: 0.3989\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6202 - acc: 0.6923 - rmse: 0.4612 - val_loss: 0.5089 - val_acc: 1.0000 - val_rmse: 0.3988\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6185 - acc: 0.6923 - rmse: 0.4604 - val_loss: 0.5089 - val_acc: 1.0000 - val_rmse: 0.3988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6168 - acc: 0.6923 - rmse: 0.4595 - val_loss: 0.5088 - val_acc: 1.0000 - val_rmse: 0.3988\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6151 - acc: 0.6923 - rmse: 0.4587 - val_loss: 0.5088 - val_acc: 1.0000 - val_rmse: 0.3988\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6134 - acc: 0.7308 - rmse: 0.4579 - val_loss: 0.5088 - val_acc: 1.0000 - val_rmse: 0.3988\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6117 - acc: 0.7308 - rmse: 0.4570 - val_loss: 0.5087 - val_acc: 1.0000 - val_rmse: 0.3987\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6100 - acc: 0.7308 - rmse: 0.4562 - val_loss: 0.5087 - val_acc: 1.0000 - val_rmse: 0.3987\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6083 - acc: 0.7308 - rmse: 0.4554 - val_loss: 0.5087 - val_acc: 1.0000 - val_rmse: 0.3987\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6066 - acc: 0.7308 - rmse: 0.4545 - val_loss: 0.5086 - val_acc: 1.0000 - val_rmse: 0.3987\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6049 - acc: 0.7692 - rmse: 0.4537 - val_loss: 0.5086 - val_acc: 1.0000 - val_rmse: 0.3987\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6033 - acc: 0.7692 - rmse: 0.4529 - val_loss: 0.5086 - val_acc: 1.0000 - val_rmse: 0.3986\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6016 - acc: 0.7692 - rmse: 0.4520 - val_loss: 0.5085 - val_acc: 1.0000 - val_rmse: 0.3986\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5999 - acc: 0.7692 - rmse: 0.4512 - val_loss: 0.5085 - val_acc: 1.0000 - val_rmse: 0.3986\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5983 - acc: 0.7692 - rmse: 0.4504 - val_loss: 0.5085 - val_acc: 1.0000 - val_rmse: 0.3986\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5966 - acc: 0.7692 - rmse: 0.4496 - val_loss: 0.5085 - val_acc: 1.0000 - val_rmse: 0.3986\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5950 - acc: 0.7692 - rmse: 0.4487 - val_loss: 0.5084 - val_acc: 1.0000 - val_rmse: 0.3986\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5933 - acc: 0.7692 - rmse: 0.4479 - val_loss: 0.5084 - val_acc: 1.0000 - val_rmse: 0.3985\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5917 - acc: 0.7692 - rmse: 0.4471 - val_loss: 0.5084 - val_acc: 1.0000 - val_rmse: 0.3985\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5901 - acc: 0.7692 - rmse: 0.4463 - val_loss: 0.5083 - val_acc: 1.0000 - val_rmse: 0.3985\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5884 - acc: 0.7692 - rmse: 0.4454 - val_loss: 0.5083 - val_acc: 1.0000 - val_rmse: 0.3985\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5868 - acc: 0.7692 - rmse: 0.4446 - val_loss: 0.5083 - val_acc: 1.0000 - val_rmse: 0.3985\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5852 - acc: 0.7692 - rmse: 0.4438 - val_loss: 0.5082 - val_acc: 1.0000 - val_rmse: 0.3984\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5836 - acc: 0.7692 - rmse: 0.4430 - val_loss: 0.5082 - val_acc: 1.0000 - val_rmse: 0.3984\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5820 - acc: 0.7692 - rmse: 0.4422 - val_loss: 0.5082 - val_acc: 1.0000 - val_rmse: 0.3984\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5804 - acc: 0.7692 - rmse: 0.4413 - val_loss: 0.5081 - val_acc: 1.0000 - val_rmse: 0.3984\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5789 - acc: 0.7692 - rmse: 0.4405 - val_loss: 0.5081 - val_acc: 1.0000 - val_rmse: 0.3984\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5773 - acc: 0.7692 - rmse: 0.4397 - val_loss: 0.5081 - val_acc: 1.0000 - val_rmse: 0.3984\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 3s - loss: 0.6756 - acc: 0.5000 - rmse: 0.4869 - val_loss: 1.3919 - val_acc: 0.0000e+00 - val_rmse: 0.7514\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6731 - acc: 0.5000 - rmse: 0.4859 - val_loss: 1.3918 - val_acc: 0.0000e+00 - val_rmse: 0.7514\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6706 - acc: 0.5000 - rmse: 0.4849 - val_loss: 1.3918 - val_acc: 0.0000e+00 - val_rmse: 0.7514\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6681 - acc: 0.5000 - rmse: 0.4839 - val_loss: 1.3917 - val_acc: 0.0000e+00 - val_rmse: 0.7514\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6656 - acc: 0.5000 - rmse: 0.4829 - val_loss: 1.3917 - val_acc: 0.0000e+00 - val_rmse: 0.7513\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6631 - acc: 0.5000 - rmse: 0.4819 - val_loss: 1.3916 - val_acc: 0.0000e+00 - val_rmse: 0.7513\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6607 - acc: 0.5000 - rmse: 0.4809 - val_loss: 1.3916 - val_acc: 0.0000e+00 - val_rmse: 0.7513\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6582 - acc: 0.5000 - rmse: 0.4799 - val_loss: 1.3915 - val_acc: 0.0000e+00 - val_rmse: 0.7513\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6558 - acc: 0.5000 - rmse: 0.4789 - val_loss: 1.3915 - val_acc: 0.0000e+00 - val_rmse: 0.7513\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6533 - acc: 0.5000 - rmse: 0.4779 - val_loss: 1.3914 - val_acc: 0.0000e+00 - val_rmse: 0.7513\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6509 - acc: 0.5000 - rmse: 0.4769 - val_loss: 1.3914 - val_acc: 0.0000e+00 - val_rmse: 0.7513\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6485 - acc: 0.5385 - rmse: 0.4759 - val_loss: 1.3913 - val_acc: 0.0000e+00 - val_rmse: 0.7513\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6460 - acc: 0.5385 - rmse: 0.4749 - val_loss: 1.3913 - val_acc: 0.0000e+00 - val_rmse: 0.7512\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6436 - acc: 0.5385 - rmse: 0.4739 - val_loss: 1.3912 - val_acc: 0.0000e+00 - val_rmse: 0.7512\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6412 - acc: 0.5769 - rmse: 0.4729 - val_loss: 1.3912 - val_acc: 0.0000e+00 - val_rmse: 0.7512\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6388 - acc: 0.5769 - rmse: 0.4719 - val_loss: 1.3911 - val_acc: 0.0000e+00 - val_rmse: 0.7512\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6364 - acc: 0.5769 - rmse: 0.4709 - val_loss: 1.3911 - val_acc: 0.0000e+00 - val_rmse: 0.7512\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6341 - acc: 0.5769 - rmse: 0.4699 - val_loss: 1.3910 - val_acc: 0.0000e+00 - val_rmse: 0.7512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6317 - acc: 0.5769 - rmse: 0.4689 - val_loss: 1.3910 - val_acc: 0.0000e+00 - val_rmse: 0.7512\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6293 - acc: 0.5769 - rmse: 0.4679 - val_loss: 1.3910 - val_acc: 0.0000e+00 - val_rmse: 0.7512\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6270 - acc: 0.5769 - rmse: 0.4669 - val_loss: 1.3909 - val_acc: 0.0000e+00 - val_rmse: 0.7512\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6246 - acc: 0.5769 - rmse: 0.4659 - val_loss: 1.3909 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6223 - acc: 0.6154 - rmse: 0.4649 - val_loss: 1.3908 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6200 - acc: 0.6154 - rmse: 0.4640 - val_loss: 1.3908 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6177 - acc: 0.6154 - rmse: 0.4630 - val_loss: 1.3907 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6154 - acc: 0.6154 - rmse: 0.4620 - val_loss: 1.3907 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6130 - acc: 0.6154 - rmse: 0.4610 - val_loss: 1.3907 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6107 - acc: 0.6154 - rmse: 0.4600 - val_loss: 1.3906 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6085 - acc: 0.6154 - rmse: 0.4590 - val_loss: 1.3906 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6062 - acc: 0.6154 - rmse: 0.4580 - val_loss: 1.3905 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6039 - acc: 0.6154 - rmse: 0.4570 - val_loss: 1.3905 - val_acc: 0.0000e+00 - val_rmse: 0.7511\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6016 - acc: 0.6154 - rmse: 0.4560 - val_loss: 1.3905 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5994 - acc: 0.6154 - rmse: 0.4549 - val_loss: 1.3904 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5971 - acc: 0.6154 - rmse: 0.4539 - val_loss: 1.3904 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5949 - acc: 0.6154 - rmse: 0.4529 - val_loss: 1.3903 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5926 - acc: 0.6154 - rmse: 0.4519 - val_loss: 1.3903 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5904 - acc: 0.6154 - rmse: 0.4509 - val_loss: 1.3903 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5882 - acc: 0.6154 - rmse: 0.4499 - val_loss: 1.3902 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5860 - acc: 0.6154 - rmse: 0.4489 - val_loss: 1.3902 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5838 - acc: 0.6538 - rmse: 0.4480 - val_loss: 1.3901 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5816 - acc: 0.6538 - rmse: 0.4470 - val_loss: 1.3901 - val_acc: 0.0000e+00 - val_rmse: 0.7510\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5794 - acc: 0.6538 - rmse: 0.4460 - val_loss: 1.3901 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5773 - acc: 0.6923 - rmse: 0.4450 - val_loss: 1.3900 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5752 - acc: 0.6923 - rmse: 0.4440 - val_loss: 1.3900 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5730 - acc: 0.6923 - rmse: 0.4430 - val_loss: 1.3900 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5709 - acc: 0.6923 - rmse: 0.4421 - val_loss: 1.3899 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5688 - acc: 0.6923 - rmse: 0.4411 - val_loss: 1.3899 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5667 - acc: 0.6923 - rmse: 0.4401 - val_loss: 1.3898 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5647 - acc: 0.6923 - rmse: 0.4391 - val_loss: 1.3898 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5626 - acc: 0.6923 - rmse: 0.4382 - val_loss: 1.3898 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5605 - acc: 0.6923 - rmse: 0.4372 - val_loss: 1.3897 - val_acc: 0.0000e+00 - val_rmse: 0.7509\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5585 - acc: 0.7308 - rmse: 0.4362 - val_loss: 1.3897 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5564 - acc: 0.7308 - rmse: 0.4353 - val_loss: 1.3897 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5544 - acc: 0.7308 - rmse: 0.4343 - val_loss: 1.3896 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5524 - acc: 0.7308 - rmse: 0.4333 - val_loss: 1.3896 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5504 - acc: 0.7308 - rmse: 0.4324 - val_loss: 1.3895 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5485 - acc: 0.7308 - rmse: 0.4314 - val_loss: 1.3895 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5466 - acc: 0.7308 - rmse: 0.4305 - val_loss: 1.3895 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5447 - acc: 0.7308 - rmse: 0.4296 - val_loss: 1.3894 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5428 - acc: 0.7308 - rmse: 0.4287 - val_loss: 1.3894 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5410 - acc: 0.7308 - rmse: 0.4277 - val_loss: 1.3893 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5391 - acc: 0.7308 - rmse: 0.4268 - val_loss: 1.3893 - val_acc: 0.0000e+00 - val_rmse: 0.7508\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5373 - acc: 0.7308 - rmse: 0.4259 - val_loss: 1.3893 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5355 - acc: 0.7308 - rmse: 0.4250 - val_loss: 1.3892 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5337 - acc: 0.7308 - rmse: 0.4241 - val_loss: 1.3892 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5319 - acc: 0.7308 - rmse: 0.4232 - val_loss: 1.3891 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5301 - acc: 0.7308 - rmse: 0.4223 - val_loss: 1.3891 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5284 - acc: 0.7308 - rmse: 0.4214 - val_loss: 1.3891 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5267 - acc: 0.7308 - rmse: 0.4206 - val_loss: 1.3890 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5250 - acc: 0.7308 - rmse: 0.4197 - val_loss: 1.3890 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5233 - acc: 0.7308 - rmse: 0.4188 - val_loss: 1.3890 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5215 - acc: 0.7692 - rmse: 0.4179 - val_loss: 1.3889 - val_acc: 0.0000e+00 - val_rmse: 0.7507\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5198 - acc: 0.8077 - rmse: 0.4170 - val_loss: 1.3889 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5181 - acc: 0.8077 - rmse: 0.4161 - val_loss: 1.3888 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5164 - acc: 0.8077 - rmse: 0.4153 - val_loss: 1.3888 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5147 - acc: 0.8077 - rmse: 0.4144 - val_loss: 1.3888 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5130 - acc: 0.8077 - rmse: 0.4135 - val_loss: 1.3887 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5114 - acc: 0.8077 - rmse: 0.4126 - val_loss: 1.3887 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5097 - acc: 0.8077 - rmse: 0.4118 - val_loss: 1.3886 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5081 - acc: 0.8077 - rmse: 0.4109 - val_loss: 1.3886 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5064 - acc: 0.8077 - rmse: 0.4100 - val_loss: 1.3886 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5048 - acc: 0.8077 - rmse: 0.4092 - val_loss: 1.3885 - val_acc: 0.0000e+00 - val_rmse: 0.7506\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5031 - acc: 0.8077 - rmse: 0.4083 - val_loss: 1.3885 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5015 - acc: 0.8077 - rmse: 0.4074 - val_loss: 1.3885 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4999 - acc: 0.8077 - rmse: 0.4066 - val_loss: 1.3884 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4983 - acc: 0.8077 - rmse: 0.4057 - val_loss: 1.3884 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4966 - acc: 0.8077 - rmse: 0.4049 - val_loss: 1.3883 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4950 - acc: 0.8077 - rmse: 0.4040 - val_loss: 1.3883 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4934 - acc: 0.8077 - rmse: 0.4031 - val_loss: 1.3883 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4919 - acc: 0.8077 - rmse: 0.4023 - val_loss: 1.3882 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4903 - acc: 0.8077 - rmse: 0.4015 - val_loss: 1.3882 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4888 - acc: 0.8077 - rmse: 0.4006 - val_loss: 1.3882 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4872 - acc: 0.8077 - rmse: 0.3998 - val_loss: 1.3881 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4857 - acc: 0.8077 - rmse: 0.3990 - val_loss: 1.3881 - val_acc: 0.0000e+00 - val_rmse: 0.7505\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4841 - acc: 0.8077 - rmse: 0.3982 - val_loss: 1.3881 - val_acc: 0.0000e+00 - val_rmse: 0.7504\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4826 - acc: 0.8077 - rmse: 0.3973 - val_loss: 1.3880 - val_acc: 0.0000e+00 - val_rmse: 0.7504\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4811 - acc: 0.8077 - rmse: 0.3965 - val_loss: 1.3880 - val_acc: 0.0000e+00 - val_rmse: 0.7504\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4796 - acc: 0.8077 - rmse: 0.3957 - val_loss: 1.3880 - val_acc: 0.0000e+00 - val_rmse: 0.7504\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4781 - acc: 0.8077 - rmse: 0.3949 - val_loss: 1.3879 - val_acc: 0.0000e+00 - val_rmse: 0.7504\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4766 - acc: 0.8077 - rmse: 0.3941 - val_loss: 1.3879 - val_acc: 0.0000e+00 - val_rmse: 0.7504\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 3s - loss: 0.7108 - acc: 0.6154 - rmse: 0.5008 - val_loss: 1.6280 - val_acc: 0.0000e+00 - val_rmse: 0.8037\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7082 - acc: 0.6154 - rmse: 0.4998 - val_loss: 1.6278 - val_acc: 0.0000e+00 - val_rmse: 0.8036\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7055 - acc: 0.6154 - rmse: 0.4988 - val_loss: 1.6275 - val_acc: 0.0000e+00 - val_rmse: 0.8036\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7029 - acc: 0.6154 - rmse: 0.4978 - val_loss: 1.6272 - val_acc: 0.0000e+00 - val_rmse: 0.8035\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7003 - acc: 0.6154 - rmse: 0.4967 - val_loss: 1.6269 - val_acc: 0.0000e+00 - val_rmse: 0.8035\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6977 - acc: 0.6538 - rmse: 0.4957 - val_loss: 1.6266 - val_acc: 0.0000e+00 - val_rmse: 0.8034\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6951 - acc: 0.6538 - rmse: 0.4947 - val_loss: 1.6263 - val_acc: 0.0000e+00 - val_rmse: 0.8033\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6925 - acc: 0.6538 - rmse: 0.4937 - val_loss: 1.6260 - val_acc: 0.0000e+00 - val_rmse: 0.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6899 - acc: 0.6538 - rmse: 0.4926 - val_loss: 1.6258 - val_acc: 0.0000e+00 - val_rmse: 0.8032\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6873 - acc: 0.6538 - rmse: 0.4916 - val_loss: 1.6255 - val_acc: 0.0000e+00 - val_rmse: 0.8032\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6848 - acc: 0.6538 - rmse: 0.4906 - val_loss: 1.6252 - val_acc: 0.0000e+00 - val_rmse: 0.8031\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6822 - acc: 0.6538 - rmse: 0.4896 - val_loss: 1.6249 - val_acc: 0.0000e+00 - val_rmse: 0.8031\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6796 - acc: 0.6538 - rmse: 0.4885 - val_loss: 1.6246 - val_acc: 0.0000e+00 - val_rmse: 0.8030\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6771 - acc: 0.6538 - rmse: 0.4875 - val_loss: 1.6243 - val_acc: 0.0000e+00 - val_rmse: 0.8029\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6746 - acc: 0.6538 - rmse: 0.4865 - val_loss: 1.6240 - val_acc: 0.0000e+00 - val_rmse: 0.8029\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6720 - acc: 0.6538 - rmse: 0.4855 - val_loss: 1.6237 - val_acc: 0.0000e+00 - val_rmse: 0.8028\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6695 - acc: 0.6538 - rmse: 0.4844 - val_loss: 1.6234 - val_acc: 0.0000e+00 - val_rmse: 0.8028\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6670 - acc: 0.6538 - rmse: 0.4834 - val_loss: 1.6231 - val_acc: 0.0000e+00 - val_rmse: 0.8027\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6645 - acc: 0.6538 - rmse: 0.4824 - val_loss: 1.6228 - val_acc: 0.0000e+00 - val_rmse: 0.8027\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6620 - acc: 0.6538 - rmse: 0.4814 - val_loss: 1.6225 - val_acc: 0.0000e+00 - val_rmse: 0.8026\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6596 - acc: 0.6538 - rmse: 0.4803 - val_loss: 1.6222 - val_acc: 0.0000e+00 - val_rmse: 0.8025\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6571 - acc: 0.6538 - rmse: 0.4793 - val_loss: 1.6219 - val_acc: 0.0000e+00 - val_rmse: 0.8025\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6547 - acc: 0.6538 - rmse: 0.4783 - val_loss: 1.6216 - val_acc: 0.0000e+00 - val_rmse: 0.8024\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6522 - acc: 0.6538 - rmse: 0.4773 - val_loss: 1.6213 - val_acc: 0.0000e+00 - val_rmse: 0.8024\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6498 - acc: 0.6538 - rmse: 0.4763 - val_loss: 1.6210 - val_acc: 0.0000e+00 - val_rmse: 0.8023\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6474 - acc: 0.6538 - rmse: 0.4753 - val_loss: 1.6207 - val_acc: 0.0000e+00 - val_rmse: 0.8022\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6450 - acc: 0.6538 - rmse: 0.4743 - val_loss: 1.6204 - val_acc: 0.0000e+00 - val_rmse: 0.8022\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6426 - acc: 0.6538 - rmse: 0.4733 - val_loss: 1.6201 - val_acc: 0.0000e+00 - val_rmse: 0.8021\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6403 - acc: 0.6538 - rmse: 0.4723 - val_loss: 1.6198 - val_acc: 0.0000e+00 - val_rmse: 0.8021\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6379 - acc: 0.6538 - rmse: 0.4712 - val_loss: 1.6196 - val_acc: 0.0000e+00 - val_rmse: 0.8020\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6355 - acc: 0.6538 - rmse: 0.4702 - val_loss: 1.6193 - val_acc: 0.0000e+00 - val_rmse: 0.8020\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6332 - acc: 0.6538 - rmse: 0.4692 - val_loss: 1.6190 - val_acc: 0.0000e+00 - val_rmse: 0.8019\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6308 - acc: 0.6538 - rmse: 0.4682 - val_loss: 1.6187 - val_acc: 0.0000e+00 - val_rmse: 0.8018\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6285 - acc: 0.6538 - rmse: 0.4672 - val_loss: 1.6185 - val_acc: 0.0000e+00 - val_rmse: 0.8018\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6261 - acc: 0.6538 - rmse: 0.4662 - val_loss: 1.6182 - val_acc: 0.0000e+00 - val_rmse: 0.8017\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6238 - acc: 0.6538 - rmse: 0.4652 - val_loss: 1.6179 - val_acc: 0.0000e+00 - val_rmse: 0.8017\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6215 - acc: 0.6538 - rmse: 0.4642 - val_loss: 1.6176 - val_acc: 0.0000e+00 - val_rmse: 0.8016\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6192 - acc: 0.6538 - rmse: 0.4632 - val_loss: 1.6174 - val_acc: 0.0000e+00 - val_rmse: 0.8016\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6168 - acc: 0.6538 - rmse: 0.4622 - val_loss: 1.6171 - val_acc: 0.0000e+00 - val_rmse: 0.8015\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6146 - acc: 0.6538 - rmse: 0.4612 - val_loss: 1.6168 - val_acc: 0.0000e+00 - val_rmse: 0.8015\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6123 - acc: 0.6923 - rmse: 0.4602 - val_loss: 1.6166 - val_acc: 0.0000e+00 - val_rmse: 0.8014\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6101 - acc: 0.6923 - rmse: 0.4592 - val_loss: 1.6163 - val_acc: 0.0000e+00 - val_rmse: 0.8014\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6079 - acc: 0.6923 - rmse: 0.4582 - val_loss: 1.6160 - val_acc: 0.0000e+00 - val_rmse: 0.8013\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6056 - acc: 0.6923 - rmse: 0.4572 - val_loss: 1.6158 - val_acc: 0.0000e+00 - val_rmse: 0.8013\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6034 - acc: 0.6923 - rmse: 0.4562 - val_loss: 1.6155 - val_acc: 0.0000e+00 - val_rmse: 0.8012\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6012 - acc: 0.6923 - rmse: 0.4553 - val_loss: 1.6152 - val_acc: 0.0000e+00 - val_rmse: 0.8012\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5990 - acc: 0.6923 - rmse: 0.4543 - val_loss: 1.6149 - val_acc: 0.0000e+00 - val_rmse: 0.8011\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5969 - acc: 0.6923 - rmse: 0.4533 - val_loss: 1.6147 - val_acc: 0.0000e+00 - val_rmse: 0.8010\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5947 - acc: 0.6923 - rmse: 0.4523 - val_loss: 1.6144 - val_acc: 0.0000e+00 - val_rmse: 0.8010\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5925 - acc: 0.6923 - rmse: 0.4514 - val_loss: 1.6141 - val_acc: 0.0000e+00 - val_rmse: 0.8009\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5904 - acc: 0.6923 - rmse: 0.4504 - val_loss: 1.6139 - val_acc: 0.0000e+00 - val_rmse: 0.8009\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5882 - acc: 0.6923 - rmse: 0.4494 - val_loss: 1.6136 - val_acc: 0.0000e+00 - val_rmse: 0.8008\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5861 - acc: 0.6923 - rmse: 0.4484 - val_loss: 1.6133 - val_acc: 0.0000e+00 - val_rmse: 0.8008\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5840 - acc: 0.6923 - rmse: 0.4474 - val_loss: 1.6130 - val_acc: 0.0000e+00 - val_rmse: 0.8007\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5818 - acc: 0.6923 - rmse: 0.4465 - val_loss: 1.6128 - val_acc: 0.0000e+00 - val_rmse: 0.8007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5797 - acc: 0.6923 - rmse: 0.4455 - val_loss: 1.6125 - val_acc: 0.0000e+00 - val_rmse: 0.8006\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5776 - acc: 0.6923 - rmse: 0.4445 - val_loss: 1.6122 - val_acc: 0.0000e+00 - val_rmse: 0.8006\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5755 - acc: 0.6923 - rmse: 0.4435 - val_loss: 1.6119 - val_acc: 0.0000e+00 - val_rmse: 0.8005\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5734 - acc: 0.6923 - rmse: 0.4426 - val_loss: 1.6117 - val_acc: 0.0000e+00 - val_rmse: 0.8004\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5713 - acc: 0.6923 - rmse: 0.4416 - val_loss: 1.6114 - val_acc: 0.0000e+00 - val_rmse: 0.8004\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5692 - acc: 0.6923 - rmse: 0.4406 - val_loss: 1.6111 - val_acc: 0.0000e+00 - val_rmse: 0.8003\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5671 - acc: 0.6923 - rmse: 0.4396 - val_loss: 1.6108 - val_acc: 0.0000e+00 - val_rmse: 0.8003\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5651 - acc: 0.6923 - rmse: 0.4387 - val_loss: 1.6106 - val_acc: 0.0000e+00 - val_rmse: 0.8002\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5631 - acc: 0.6923 - rmse: 0.4377 - val_loss: 1.6103 - val_acc: 0.0000e+00 - val_rmse: 0.8002\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5610 - acc: 0.6923 - rmse: 0.4367 - val_loss: 1.6100 - val_acc: 0.0000e+00 - val_rmse: 0.8001\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5590 - acc: 0.6923 - rmse: 0.4358 - val_loss: 1.6097 - val_acc: 0.0000e+00 - val_rmse: 0.8001\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5570 - acc: 0.6923 - rmse: 0.4348 - val_loss: 1.6094 - val_acc: 0.0000e+00 - val_rmse: 0.8000\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5550 - acc: 0.6923 - rmse: 0.4338 - val_loss: 1.6092 - val_acc: 0.0000e+00 - val_rmse: 0.7999\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5530 - acc: 0.6923 - rmse: 0.4329 - val_loss: 1.6089 - val_acc: 0.0000e+00 - val_rmse: 0.7999\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5510 - acc: 0.6923 - rmse: 0.4319 - val_loss: 1.6086 - val_acc: 0.0000e+00 - val_rmse: 0.7998\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5491 - acc: 0.6923 - rmse: 0.4309 - val_loss: 1.6083 - val_acc: 0.0000e+00 - val_rmse: 0.7998\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5471 - acc: 0.6923 - rmse: 0.4300 - val_loss: 1.6081 - val_acc: 0.0000e+00 - val_rmse: 0.7997\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5451 - acc: 0.7308 - rmse: 0.4290 - val_loss: 1.6078 - val_acc: 0.0000e+00 - val_rmse: 0.7997\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5431 - acc: 0.7308 - rmse: 0.4280 - val_loss: 1.6075 - val_acc: 0.0000e+00 - val_rmse: 0.7996\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5412 - acc: 0.7308 - rmse: 0.4271 - val_loss: 1.6072 - val_acc: 0.0000e+00 - val_rmse: 0.7996\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5393 - acc: 0.7308 - rmse: 0.4261 - val_loss: 1.6070 - val_acc: 0.0000e+00 - val_rmse: 0.7995\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5373 - acc: 0.7308 - rmse: 0.4252 - val_loss: 1.6067 - val_acc: 0.0000e+00 - val_rmse: 0.7994\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5355 - acc: 0.7308 - rmse: 0.4242 - val_loss: 1.6064 - val_acc: 0.0000e+00 - val_rmse: 0.7994\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5336 - acc: 0.7308 - rmse: 0.4233 - val_loss: 1.6061 - val_acc: 0.0000e+00 - val_rmse: 0.7993\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5318 - acc: 0.7308 - rmse: 0.4224 - val_loss: 1.6059 - val_acc: 0.0000e+00 - val_rmse: 0.7993\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5299 - acc: 0.7308 - rmse: 0.4215 - val_loss: 1.6056 - val_acc: 0.0000e+00 - val_rmse: 0.7992\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5281 - acc: 0.7308 - rmse: 0.4206 - val_loss: 1.6053 - val_acc: 0.0000e+00 - val_rmse: 0.7992\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5262 - acc: 0.7308 - rmse: 0.4196 - val_loss: 1.6050 - val_acc: 0.0000e+00 - val_rmse: 0.7991\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5244 - acc: 0.7308 - rmse: 0.4187 - val_loss: 1.6048 - val_acc: 0.0000e+00 - val_rmse: 0.7991\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5226 - acc: 0.7308 - rmse: 0.4178 - val_loss: 1.6045 - val_acc: 0.0000e+00 - val_rmse: 0.7990\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5208 - acc: 0.7692 - rmse: 0.4169 - val_loss: 1.6042 - val_acc: 0.0000e+00 - val_rmse: 0.7990\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5190 - acc: 0.7692 - rmse: 0.4160 - val_loss: 1.6039 - val_acc: 0.0000e+00 - val_rmse: 0.7989\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5172 - acc: 0.7692 - rmse: 0.4150 - val_loss: 1.6037 - val_acc: 0.0000e+00 - val_rmse: 0.7988\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5154 - acc: 0.7692 - rmse: 0.4141 - val_loss: 1.6034 - val_acc: 0.0000e+00 - val_rmse: 0.7988\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5136 - acc: 0.7692 - rmse: 0.4132 - val_loss: 1.6031 - val_acc: 0.0000e+00 - val_rmse: 0.7987\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5118 - acc: 0.7692 - rmse: 0.4123 - val_loss: 1.6029 - val_acc: 0.0000e+00 - val_rmse: 0.7987\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5100 - acc: 0.7692 - rmse: 0.4113 - val_loss: 1.6026 - val_acc: 0.0000e+00 - val_rmse: 0.7986\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5082 - acc: 0.7692 - rmse: 0.4104 - val_loss: 1.6023 - val_acc: 0.0000e+00 - val_rmse: 0.7986\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5064 - acc: 0.7692 - rmse: 0.4095 - val_loss: 1.6020 - val_acc: 0.0000e+00 - val_rmse: 0.7985\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5046 - acc: 0.7692 - rmse: 0.4086 - val_loss: 1.6018 - val_acc: 0.0000e+00 - val_rmse: 0.7985\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5029 - acc: 0.7692 - rmse: 0.4076 - val_loss: 1.6015 - val_acc: 0.0000e+00 - val_rmse: 0.7984\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5011 - acc: 0.7692 - rmse: 0.4067 - val_loss: 1.6012 - val_acc: 0.0000e+00 - val_rmse: 0.7983\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4993 - acc: 0.7692 - rmse: 0.4058 - val_loss: 1.6009 - val_acc: 0.0000e+00 - val_rmse: 0.7983\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4976 - acc: 0.7692 - rmse: 0.4049 - val_loss: 1.6006 - val_acc: 0.0000e+00 - val_rmse: 0.7982\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.4958 - acc: 0.7692 - rmse: 0.4039 - val_loss: 1.6004 - val_acc: 0.0000e+00 - val_rmse: 0.7982\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 4s - loss: 0.7569 - acc: 0.4231 - rmse: 0.5300 - val_loss: 0.7926 - val_acc: 0.0000e+00 - val_rmse: 0.5473\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7545 - acc: 0.4231 - rmse: 0.5289 - val_loss: 0.7928 - val_acc: 0.0000e+00 - val_rmse: 0.5474\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7522 - acc: 0.4231 - rmse: 0.5279 - val_loss: 0.7929 - val_acc: 0.0000e+00 - val_rmse: 0.5475\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7498 - acc: 0.4231 - rmse: 0.5269 - val_loss: 0.7930 - val_acc: 0.0000e+00 - val_rmse: 0.5475\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7475 - acc: 0.4231 - rmse: 0.5258 - val_loss: 0.7932 - val_acc: 0.0000e+00 - val_rmse: 0.5476\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7452 - acc: 0.4231 - rmse: 0.5248 - val_loss: 0.7933 - val_acc: 0.0000e+00 - val_rmse: 0.5477\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7428 - acc: 0.4615 - rmse: 0.5237 - val_loss: 0.7934 - val_acc: 0.0000e+00 - val_rmse: 0.5477\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7405 - acc: 0.4615 - rmse: 0.5227 - val_loss: 0.7936 - val_acc: 0.0000e+00 - val_rmse: 0.5478\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7382 - acc: 0.4615 - rmse: 0.5217 - val_loss: 0.7937 - val_acc: 0.0000e+00 - val_rmse: 0.5478\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7359 - acc: 0.4615 - rmse: 0.5206 - val_loss: 0.7938 - val_acc: 0.0000e+00 - val_rmse: 0.5479\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7336 - acc: 0.4615 - rmse: 0.5196 - val_loss: 0.7940 - val_acc: 0.0000e+00 - val_rmse: 0.5480\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7313 - acc: 0.4615 - rmse: 0.5186 - val_loss: 0.7941 - val_acc: 0.0000e+00 - val_rmse: 0.5480\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7290 - acc: 0.4615 - rmse: 0.5175 - val_loss: 0.7943 - val_acc: 0.0000e+00 - val_rmse: 0.5481\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7268 - acc: 0.4615 - rmse: 0.5165 - val_loss: 0.7944 - val_acc: 0.0000e+00 - val_rmse: 0.5481\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7245 - acc: 0.4615 - rmse: 0.5155 - val_loss: 0.7945 - val_acc: 0.0000e+00 - val_rmse: 0.5482\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7222 - acc: 0.5000 - rmse: 0.5144 - val_loss: 0.7947 - val_acc: 0.0000e+00 - val_rmse: 0.5483\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7200 - acc: 0.5000 - rmse: 0.5134 - val_loss: 0.7948 - val_acc: 0.0000e+00 - val_rmse: 0.5483\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7178 - acc: 0.5000 - rmse: 0.5124 - val_loss: 0.7950 - val_acc: 0.0000e+00 - val_rmse: 0.5484\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7155 - acc: 0.5000 - rmse: 0.5114 - val_loss: 0.7951 - val_acc: 0.0000e+00 - val_rmse: 0.5485\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7133 - acc: 0.5000 - rmse: 0.5103 - val_loss: 0.7952 - val_acc: 0.0000e+00 - val_rmse: 0.5485\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7111 - acc: 0.5385 - rmse: 0.5093 - val_loss: 0.7954 - val_acc: 0.0000e+00 - val_rmse: 0.5486\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7089 - acc: 0.5385 - rmse: 0.5083 - val_loss: 0.7955 - val_acc: 0.0000e+00 - val_rmse: 0.5487\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7067 - acc: 0.5385 - rmse: 0.5073 - val_loss: 0.7957 - val_acc: 0.0000e+00 - val_rmse: 0.5487\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7045 - acc: 0.5385 - rmse: 0.5063 - val_loss: 0.7958 - val_acc: 0.0000e+00 - val_rmse: 0.5488\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7023 - acc: 0.5385 - rmse: 0.5053 - val_loss: 0.7959 - val_acc: 0.0000e+00 - val_rmse: 0.5488\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7001 - acc: 0.5385 - rmse: 0.5042 - val_loss: 0.7961 - val_acc: 0.0000e+00 - val_rmse: 0.5489\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6980 - acc: 0.5385 - rmse: 0.5032 - val_loss: 0.7962 - val_acc: 0.0000e+00 - val_rmse: 0.5490\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6958 - acc: 0.5385 - rmse: 0.5022 - val_loss: 0.7963 - val_acc: 0.0000e+00 - val_rmse: 0.5490\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6937 - acc: 0.5385 - rmse: 0.5012 - val_loss: 0.7965 - val_acc: 0.0000e+00 - val_rmse: 0.5491\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6915 - acc: 0.5385 - rmse: 0.5002 - val_loss: 0.7966 - val_acc: 0.0000e+00 - val_rmse: 0.5492\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6894 - acc: 0.5385 - rmse: 0.4992 - val_loss: 0.7968 - val_acc: 0.0000e+00 - val_rmse: 0.5492\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6873 - acc: 0.5385 - rmse: 0.4982 - val_loss: 0.7969 - val_acc: 0.0000e+00 - val_rmse: 0.5493\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6851 - acc: 0.5385 - rmse: 0.4972 - val_loss: 0.7970 - val_acc: 0.0000e+00 - val_rmse: 0.5493\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6830 - acc: 0.5385 - rmse: 0.4962 - val_loss: 0.7972 - val_acc: 0.0000e+00 - val_rmse: 0.5494\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6809 - acc: 0.5385 - rmse: 0.4952 - val_loss: 0.7973 - val_acc: 0.0000e+00 - val_rmse: 0.5495\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6788 - acc: 0.5385 - rmse: 0.4942 - val_loss: 0.7975 - val_acc: 0.0000e+00 - val_rmse: 0.5495\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6768 - acc: 0.5385 - rmse: 0.4932 - val_loss: 0.7976 - val_acc: 0.0000e+00 - val_rmse: 0.5496\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6747 - acc: 0.5385 - rmse: 0.4922 - val_loss: 0.7977 - val_acc: 0.0000e+00 - val_rmse: 0.5496\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6726 - acc: 0.5385 - rmse: 0.4912 - val_loss: 0.7979 - val_acc: 0.0000e+00 - val_rmse: 0.5497\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6705 - acc: 0.5385 - rmse: 0.4902 - val_loss: 0.7980 - val_acc: 0.0000e+00 - val_rmse: 0.5498\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6684 - acc: 0.5385 - rmse: 0.4892 - val_loss: 0.7981 - val_acc: 0.0000e+00 - val_rmse: 0.5498\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6664 - acc: 0.5385 - rmse: 0.4882 - val_loss: 0.7983 - val_acc: 0.0000e+00 - val_rmse: 0.5499\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6643 - acc: 0.5769 - rmse: 0.4872 - val_loss: 0.7984 - val_acc: 0.0000e+00 - val_rmse: 0.5500\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6623 - acc: 0.5769 - rmse: 0.4862 - val_loss: 0.7986 - val_acc: 0.0000e+00 - val_rmse: 0.5500\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6602 - acc: 0.5769 - rmse: 0.4852 - val_loss: 0.7987 - val_acc: 0.0000e+00 - val_rmse: 0.5501\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6582 - acc: 0.5769 - rmse: 0.4842 - val_loss: 0.7988 - val_acc: 0.0000e+00 - val_rmse: 0.5501\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6562 - acc: 0.5769 - rmse: 0.4832 - val_loss: 0.7990 - val_acc: 0.0000e+00 - val_rmse: 0.5502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6541 - acc: 0.5769 - rmse: 0.4823 - val_loss: 0.7991 - val_acc: 0.0000e+00 - val_rmse: 0.5503\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6521 - acc: 0.5769 - rmse: 0.4813 - val_loss: 0.7993 - val_acc: 0.0000e+00 - val_rmse: 0.5503\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6501 - acc: 0.5769 - rmse: 0.4803 - val_loss: 0.7994 - val_acc: 0.0000e+00 - val_rmse: 0.5504\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6481 - acc: 0.5769 - rmse: 0.4793 - val_loss: 0.7995 - val_acc: 0.0000e+00 - val_rmse: 0.5505\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6461 - acc: 0.5769 - rmse: 0.4783 - val_loss: 0.7997 - val_acc: 0.0000e+00 - val_rmse: 0.5505\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6441 - acc: 0.5769 - rmse: 0.4773 - val_loss: 0.7998 - val_acc: 0.0000e+00 - val_rmse: 0.5506\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6421 - acc: 0.5769 - rmse: 0.4763 - val_loss: 0.8000 - val_acc: 0.0000e+00 - val_rmse: 0.5507\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6402 - acc: 0.5769 - rmse: 0.4754 - val_loss: 0.8001 - val_acc: 0.0000e+00 - val_rmse: 0.5507\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6382 - acc: 0.5769 - rmse: 0.4744 - val_loss: 0.8002 - val_acc: 0.0000e+00 - val_rmse: 0.5508\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6363 - acc: 0.5769 - rmse: 0.4734 - val_loss: 0.8004 - val_acc: 0.0000e+00 - val_rmse: 0.5508\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6343 - acc: 0.5769 - rmse: 0.4724 - val_loss: 0.8005 - val_acc: 0.0000e+00 - val_rmse: 0.5509\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6324 - acc: 0.5769 - rmse: 0.4715 - val_loss: 0.8007 - val_acc: 0.0000e+00 - val_rmse: 0.5510\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6304 - acc: 0.5769 - rmse: 0.4705 - val_loss: 0.8008 - val_acc: 0.0000e+00 - val_rmse: 0.5510\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6285 - acc: 0.5769 - rmse: 0.4695 - val_loss: 0.8009 - val_acc: 0.0000e+00 - val_rmse: 0.5511\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6266 - acc: 0.5769 - rmse: 0.4686 - val_loss: 0.8011 - val_acc: 0.0000e+00 - val_rmse: 0.5512\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6246 - acc: 0.5769 - rmse: 0.4676 - val_loss: 0.8012 - val_acc: 0.0000e+00 - val_rmse: 0.5512\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6227 - acc: 0.5769 - rmse: 0.4666 - val_loss: 0.8014 - val_acc: 0.0000e+00 - val_rmse: 0.5513\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6208 - acc: 0.5769 - rmse: 0.4657 - val_loss: 0.8015 - val_acc: 0.0000e+00 - val_rmse: 0.5513\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6189 - acc: 0.5769 - rmse: 0.4647 - val_loss: 0.8016 - val_acc: 0.0000e+00 - val_rmse: 0.5514\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6170 - acc: 0.5769 - rmse: 0.4637 - val_loss: 0.8018 - val_acc: 0.0000e+00 - val_rmse: 0.5515\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6152 - acc: 0.5769 - rmse: 0.4628 - val_loss: 0.8019 - val_acc: 0.0000e+00 - val_rmse: 0.5515\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6133 - acc: 0.5769 - rmse: 0.4618 - val_loss: 0.8021 - val_acc: 0.0000e+00 - val_rmse: 0.5516\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6115 - acc: 0.5769 - rmse: 0.4609 - val_loss: 0.8022 - val_acc: 0.0000e+00 - val_rmse: 0.5517\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6096 - acc: 0.5769 - rmse: 0.4600 - val_loss: 0.8023 - val_acc: 0.0000e+00 - val_rmse: 0.5517\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6078 - acc: 0.5769 - rmse: 0.4590 - val_loss: 0.8025 - val_acc: 0.0000e+00 - val_rmse: 0.5518\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6060 - acc: 0.5769 - rmse: 0.4581 - val_loss: 0.8026 - val_acc: 0.0000e+00 - val_rmse: 0.5518\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6042 - acc: 0.5769 - rmse: 0.4572 - val_loss: 0.8027 - val_acc: 0.0000e+00 - val_rmse: 0.5519\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6024 - acc: 0.5769 - rmse: 0.4563 - val_loss: 0.8029 - val_acc: 0.0000e+00 - val_rmse: 0.5520\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6006 - acc: 0.5769 - rmse: 0.4553 - val_loss: 0.8030 - val_acc: 0.0000e+00 - val_rmse: 0.5520\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5989 - acc: 0.5769 - rmse: 0.4544 - val_loss: 0.8031 - val_acc: 0.0000e+00 - val_rmse: 0.5521\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5971 - acc: 0.5769 - rmse: 0.4535 - val_loss: 0.8033 - val_acc: 0.0000e+00 - val_rmse: 0.5521\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5953 - acc: 0.5769 - rmse: 0.4526 - val_loss: 0.8034 - val_acc: 0.0000e+00 - val_rmse: 0.5522\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5936 - acc: 0.5769 - rmse: 0.4517 - val_loss: 0.8035 - val_acc: 0.0000e+00 - val_rmse: 0.5523\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5919 - acc: 0.6154 - rmse: 0.4508 - val_loss: 0.8037 - val_acc: 0.0000e+00 - val_rmse: 0.5523\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5902 - acc: 0.6538 - rmse: 0.4499 - val_loss: 0.8038 - val_acc: 0.0000e+00 - val_rmse: 0.5524\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5885 - acc: 0.6538 - rmse: 0.4490 - val_loss: 0.8039 - val_acc: 0.0000e+00 - val_rmse: 0.5524\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5868 - acc: 0.6538 - rmse: 0.4482 - val_loss: 0.8040 - val_acc: 0.0000e+00 - val_rmse: 0.5525\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5852 - acc: 0.6538 - rmse: 0.4473 - val_loss: 0.8042 - val_acc: 0.0000e+00 - val_rmse: 0.5525\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5835 - acc: 0.6538 - rmse: 0.4464 - val_loss: 0.8043 - val_acc: 0.0000e+00 - val_rmse: 0.5526\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5818 - acc: 0.6538 - rmse: 0.4455 - val_loss: 0.8044 - val_acc: 0.0000e+00 - val_rmse: 0.5526\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5802 - acc: 0.6538 - rmse: 0.4447 - val_loss: 0.8045 - val_acc: 0.0000e+00 - val_rmse: 0.5527\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5785 - acc: 0.6923 - rmse: 0.4438 - val_loss: 0.8047 - val_acc: 0.0000e+00 - val_rmse: 0.5528\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5769 - acc: 0.6923 - rmse: 0.4429 - val_loss: 0.8048 - val_acc: 0.0000e+00 - val_rmse: 0.5528\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5753 - acc: 0.7308 - rmse: 0.4421 - val_loss: 0.8049 - val_acc: 0.0000e+00 - val_rmse: 0.5529\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5736 - acc: 0.7308 - rmse: 0.4412 - val_loss: 0.8050 - val_acc: 0.0000e+00 - val_rmse: 0.5529\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5720 - acc: 0.7308 - rmse: 0.4404 - val_loss: 0.8051 - val_acc: 0.0000e+00 - val_rmse: 0.5530\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5704 - acc: 0.7308 - rmse: 0.4395 - val_loss: 0.8052 - val_acc: 0.0000e+00 - val_rmse: 0.5530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5688 - acc: 0.7308 - rmse: 0.4387 - val_loss: 0.8053 - val_acc: 0.0000e+00 - val_rmse: 0.5531\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5672 - acc: 0.7308 - rmse: 0.4378 - val_loss: 0.8055 - val_acc: 0.0000e+00 - val_rmse: 0.5531\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5656 - acc: 0.7308 - rmse: 0.4370 - val_loss: 0.8056 - val_acc: 0.0000e+00 - val_rmse: 0.5532\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5640 - acc: 0.7308 - rmse: 0.4361 - val_loss: 0.8057 - val_acc: 0.0000e+00 - val_rmse: 0.5532\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5624 - acc: 0.7308 - rmse: 0.4352 - val_loss: 0.8058 - val_acc: 0.0000e+00 - val_rmse: 0.5533\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5608 - acc: 0.7308 - rmse: 0.4344 - val_loss: 0.8060 - val_acc: 0.0000e+00 - val_rmse: 0.5533\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 3s - loss: 0.8722 - acc: 0.3846 - rmse: 0.5710 - val_loss: 1.4384 - val_acc: 0.0000e+00 - val_rmse: 0.7627\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8690 - acc: 0.3846 - rmse: 0.5698 - val_loss: 1.4386 - val_acc: 0.0000e+00 - val_rmse: 0.7627\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8659 - acc: 0.3846 - rmse: 0.5686 - val_loss: 1.4387 - val_acc: 0.0000e+00 - val_rmse: 0.7628\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8628 - acc: 0.3846 - rmse: 0.5675 - val_loss: 1.4388 - val_acc: 0.0000e+00 - val_rmse: 0.7628\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8597 - acc: 0.3846 - rmse: 0.5663 - val_loss: 1.4390 - val_acc: 0.0000e+00 - val_rmse: 0.7628\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8566 - acc: 0.3846 - rmse: 0.5652 - val_loss: 1.4391 - val_acc: 0.0000e+00 - val_rmse: 0.7629\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8535 - acc: 0.4231 - rmse: 0.5640 - val_loss: 1.4392 - val_acc: 0.0000e+00 - val_rmse: 0.7629\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8505 - acc: 0.4231 - rmse: 0.5629 - val_loss: 1.4394 - val_acc: 0.0000e+00 - val_rmse: 0.7629\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8474 - acc: 0.4231 - rmse: 0.5618 - val_loss: 1.4395 - val_acc: 0.0000e+00 - val_rmse: 0.7630\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8444 - acc: 0.4231 - rmse: 0.5606 - val_loss: 1.4396 - val_acc: 0.0000e+00 - val_rmse: 0.7630\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8414 - acc: 0.4231 - rmse: 0.5595 - val_loss: 1.4397 - val_acc: 0.0000e+00 - val_rmse: 0.7630\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8385 - acc: 0.4231 - rmse: 0.5584 - val_loss: 1.4399 - val_acc: 0.0000e+00 - val_rmse: 0.7630\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8355 - acc: 0.4231 - rmse: 0.5573 - val_loss: 1.4400 - val_acc: 0.0000e+00 - val_rmse: 0.7631\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8326 - acc: 0.4231 - rmse: 0.5561 - val_loss: 1.4401 - val_acc: 0.0000e+00 - val_rmse: 0.7631\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8296 - acc: 0.4231 - rmse: 0.5550 - val_loss: 1.4402 - val_acc: 0.0000e+00 - val_rmse: 0.7631\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8267 - acc: 0.4231 - rmse: 0.5539 - val_loss: 1.4403 - val_acc: 0.0000e+00 - val_rmse: 0.7631\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8238 - acc: 0.4615 - rmse: 0.5528 - val_loss: 1.4404 - val_acc: 0.0000e+00 - val_rmse: 0.7632\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8209 - acc: 0.4615 - rmse: 0.5517 - val_loss: 1.4406 - val_acc: 0.0000e+00 - val_rmse: 0.7632\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8180 - acc: 0.4615 - rmse: 0.5505 - val_loss: 1.4407 - val_acc: 0.0000e+00 - val_rmse: 0.7632\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8151 - acc: 0.4615 - rmse: 0.5494 - val_loss: 1.4408 - val_acc: 0.0000e+00 - val_rmse: 0.7633\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8122 - acc: 0.4615 - rmse: 0.5483 - val_loss: 1.4409 - val_acc: 0.0000e+00 - val_rmse: 0.7633\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8093 - acc: 0.4615 - rmse: 0.5472 - val_loss: 1.4410 - val_acc: 0.0000e+00 - val_rmse: 0.7633\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8065 - acc: 0.4615 - rmse: 0.5460 - val_loss: 1.4411 - val_acc: 0.0000e+00 - val_rmse: 0.7633\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.8036 - acc: 0.4615 - rmse: 0.5449 - val_loss: 1.4412 - val_acc: 0.0000e+00 - val_rmse: 0.7634\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.8008 - acc: 0.4615 - rmse: 0.5438 - val_loss: 1.4413 - val_acc: 0.0000e+00 - val_rmse: 0.7634\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7979 - acc: 0.4615 - rmse: 0.5426 - val_loss: 1.4415 - val_acc: 0.0000e+00 - val_rmse: 0.7634\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7951 - acc: 0.4615 - rmse: 0.5415 - val_loss: 1.4416 - val_acc: 0.0000e+00 - val_rmse: 0.7634\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7923 - acc: 0.4615 - rmse: 0.5404 - val_loss: 1.4417 - val_acc: 0.0000e+00 - val_rmse: 0.7635\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7896 - acc: 0.4615 - rmse: 0.5393 - val_loss: 1.4418 - val_acc: 0.0000e+00 - val_rmse: 0.7635\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7869 - acc: 0.4615 - rmse: 0.5382 - val_loss: 1.4419 - val_acc: 0.0000e+00 - val_rmse: 0.7635\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7841 - acc: 0.4615 - rmse: 0.5371 - val_loss: 1.4420 - val_acc: 0.0000e+00 - val_rmse: 0.7636\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7814 - acc: 0.4615 - rmse: 0.5360 - val_loss: 1.4422 - val_acc: 0.0000e+00 - val_rmse: 0.7636\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7787 - acc: 0.5000 - rmse: 0.5349 - val_loss: 1.4423 - val_acc: 0.0000e+00 - val_rmse: 0.7636\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7761 - acc: 0.5000 - rmse: 0.5338 - val_loss: 1.4424 - val_acc: 0.0000e+00 - val_rmse: 0.7636\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7734 - acc: 0.5000 - rmse: 0.5327 - val_loss: 1.4425 - val_acc: 0.0000e+00 - val_rmse: 0.7637\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7707 - acc: 0.5000 - rmse: 0.5317 - val_loss: 1.4426 - val_acc: 0.0000e+00 - val_rmse: 0.7637\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7680 - acc: 0.5385 - rmse: 0.5306 - val_loss: 1.4428 - val_acc: 0.0000e+00 - val_rmse: 0.7637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7654 - acc: 0.5385 - rmse: 0.5295 - val_loss: 1.4429 - val_acc: 0.0000e+00 - val_rmse: 0.7638\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7627 - acc: 0.5385 - rmse: 0.5284 - val_loss: 1.4430 - val_acc: 0.0000e+00 - val_rmse: 0.7638\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7601 - acc: 0.5385 - rmse: 0.5273 - val_loss: 1.4431 - val_acc: 0.0000e+00 - val_rmse: 0.7638\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7574 - acc: 0.5385 - rmse: 0.5262 - val_loss: 1.4433 - val_acc: 0.0000e+00 - val_rmse: 0.7638\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7548 - acc: 0.5385 - rmse: 0.5251 - val_loss: 1.4434 - val_acc: 0.0000e+00 - val_rmse: 0.7639\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7522 - acc: 0.5385 - rmse: 0.5240 - val_loss: 1.4435 - val_acc: 0.0000e+00 - val_rmse: 0.7639\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7496 - acc: 0.5385 - rmse: 0.5229 - val_loss: 1.4436 - val_acc: 0.0000e+00 - val_rmse: 0.7639\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7470 - acc: 0.5385 - rmse: 0.5218 - val_loss: 1.4437 - val_acc: 0.0000e+00 - val_rmse: 0.7640\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7444 - acc: 0.5385 - rmse: 0.5207 - val_loss: 1.4439 - val_acc: 0.0000e+00 - val_rmse: 0.7640\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7418 - acc: 0.5385 - rmse: 0.5196 - val_loss: 1.4440 - val_acc: 0.0000e+00 - val_rmse: 0.7640\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7393 - acc: 0.5385 - rmse: 0.5185 - val_loss: 1.4441 - val_acc: 0.0000e+00 - val_rmse: 0.7640\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7367 - acc: 0.5385 - rmse: 0.5174 - val_loss: 1.4442 - val_acc: 0.0000e+00 - val_rmse: 0.7641\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7342 - acc: 0.5385 - rmse: 0.5164 - val_loss: 1.4444 - val_acc: 0.0000e+00 - val_rmse: 0.7641\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7317 - acc: 0.5385 - rmse: 0.5153 - val_loss: 1.4445 - val_acc: 0.0000e+00 - val_rmse: 0.7641\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7292 - acc: 0.5385 - rmse: 0.5142 - val_loss: 1.4446 - val_acc: 0.0000e+00 - val_rmse: 0.7642\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7267 - acc: 0.5385 - rmse: 0.5131 - val_loss: 1.4448 - val_acc: 0.0000e+00 - val_rmse: 0.7642\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7242 - acc: 0.5385 - rmse: 0.5120 - val_loss: 1.4449 - val_acc: 0.0000e+00 - val_rmse: 0.7642\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7217 - acc: 0.5385 - rmse: 0.5110 - val_loss: 1.4450 - val_acc: 0.0000e+00 - val_rmse: 0.7643\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7193 - acc: 0.5385 - rmse: 0.5099 - val_loss: 1.4451 - val_acc: 0.0000e+00 - val_rmse: 0.7643\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7168 - acc: 0.5385 - rmse: 0.5088 - val_loss: 1.4453 - val_acc: 0.0000e+00 - val_rmse: 0.7643\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7143 - acc: 0.5385 - rmse: 0.5077 - val_loss: 1.4454 - val_acc: 0.0000e+00 - val_rmse: 0.7643\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7119 - acc: 0.5385 - rmse: 0.5067 - val_loss: 1.4455 - val_acc: 0.0000e+00 - val_rmse: 0.7644\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7094 - acc: 0.5385 - rmse: 0.5056 - val_loss: 1.4457 - val_acc: 0.0000e+00 - val_rmse: 0.7644\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7070 - acc: 0.5385 - rmse: 0.5045 - val_loss: 1.4458 - val_acc: 0.0000e+00 - val_rmse: 0.7644\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7045 - acc: 0.5385 - rmse: 0.5034 - val_loss: 1.4459 - val_acc: 0.0000e+00 - val_rmse: 0.7645\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7021 - acc: 0.5385 - rmse: 0.5023 - val_loss: 1.4460 - val_acc: 0.0000e+00 - val_rmse: 0.7645\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6997 - acc: 0.5385 - rmse: 0.5012 - val_loss: 1.4462 - val_acc: 0.0000e+00 - val_rmse: 0.7645\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6972 - acc: 0.5385 - rmse: 0.5001 - val_loss: 1.4463 - val_acc: 0.0000e+00 - val_rmse: 0.7646\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6948 - acc: 0.5385 - rmse: 0.4990 - val_loss: 1.4464 - val_acc: 0.0000e+00 - val_rmse: 0.7646\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6924 - acc: 0.5385 - rmse: 0.4979 - val_loss: 1.4466 - val_acc: 0.0000e+00 - val_rmse: 0.7646\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6900 - acc: 0.5385 - rmse: 0.4968 - val_loss: 1.4467 - val_acc: 0.0000e+00 - val_rmse: 0.7646\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6875 - acc: 0.5385 - rmse: 0.4957 - val_loss: 1.4468 - val_acc: 0.0000e+00 - val_rmse: 0.7647\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6851 - acc: 0.5385 - rmse: 0.4946 - val_loss: 1.4469 - val_acc: 0.0000e+00 - val_rmse: 0.7647\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6827 - acc: 0.5769 - rmse: 0.4935 - val_loss: 1.4470 - val_acc: 0.0000e+00 - val_rmse: 0.7647\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6803 - acc: 0.5769 - rmse: 0.4925 - val_loss: 1.4472 - val_acc: 0.0000e+00 - val_rmse: 0.7648\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6780 - acc: 0.5769 - rmse: 0.4914 - val_loss: 1.4473 - val_acc: 0.0000e+00 - val_rmse: 0.7648\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6756 - acc: 0.5769 - rmse: 0.4903 - val_loss: 1.4474 - val_acc: 0.0000e+00 - val_rmse: 0.7648\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6732 - acc: 0.5769 - rmse: 0.4892 - val_loss: 1.4475 - val_acc: 0.0000e+00 - val_rmse: 0.7648\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6708 - acc: 0.5769 - rmse: 0.4880 - val_loss: 1.4476 - val_acc: 0.0000e+00 - val_rmse: 0.7649\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6684 - acc: 0.5769 - rmse: 0.4869 - val_loss: 1.4478 - val_acc: 0.0000e+00 - val_rmse: 0.7649\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6661 - acc: 0.5769 - rmse: 0.4858 - val_loss: 1.4479 - val_acc: 0.0000e+00 - val_rmse: 0.7649\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6637 - acc: 0.6154 - rmse: 0.4847 - val_loss: 1.4480 - val_acc: 0.0000e+00 - val_rmse: 0.7650\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6614 - acc: 0.6154 - rmse: 0.4836 - val_loss: 1.4481 - val_acc: 0.0000e+00 - val_rmse: 0.7650\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6590 - acc: 0.6154 - rmse: 0.4825 - val_loss: 1.4483 - val_acc: 0.0000e+00 - val_rmse: 0.7650\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6567 - acc: 0.6538 - rmse: 0.4814 - val_loss: 1.4484 - val_acc: 0.0000e+00 - val_rmse: 0.7650\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6544 - acc: 0.6538 - rmse: 0.4803 - val_loss: 1.4485 - val_acc: 0.0000e+00 - val_rmse: 0.7651\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6520 - acc: 0.6538 - rmse: 0.4792 - val_loss: 1.4486 - val_acc: 0.0000e+00 - val_rmse: 0.7651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6497 - acc: 0.6538 - rmse: 0.4781 - val_loss: 1.4487 - val_acc: 0.0000e+00 - val_rmse: 0.7651\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6474 - acc: 0.6538 - rmse: 0.4770 - val_loss: 1.4489 - val_acc: 0.0000e+00 - val_rmse: 0.7652\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6451 - acc: 0.6923 - rmse: 0.4759 - val_loss: 1.4490 - val_acc: 0.0000e+00 - val_rmse: 0.7652\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6428 - acc: 0.6923 - rmse: 0.4748 - val_loss: 1.4491 - val_acc: 0.0000e+00 - val_rmse: 0.7652\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6405 - acc: 0.6923 - rmse: 0.4737 - val_loss: 1.4492 - val_acc: 0.0000e+00 - val_rmse: 0.7652\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6382 - acc: 0.6923 - rmse: 0.4726 - val_loss: 1.4493 - val_acc: 0.0000e+00 - val_rmse: 0.7653\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6360 - acc: 0.6923 - rmse: 0.4715 - val_loss: 1.4495 - val_acc: 0.0000e+00 - val_rmse: 0.7653\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6337 - acc: 0.6923 - rmse: 0.4704 - val_loss: 1.4496 - val_acc: 0.0000e+00 - val_rmse: 0.7653\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6314 - acc: 0.6923 - rmse: 0.4693 - val_loss: 1.4497 - val_acc: 0.0000e+00 - val_rmse: 0.7654\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6292 - acc: 0.6923 - rmse: 0.4682 - val_loss: 1.4498 - val_acc: 0.0000e+00 - val_rmse: 0.7654\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6270 - acc: 0.6923 - rmse: 0.4671 - val_loss: 1.4499 - val_acc: 0.0000e+00 - val_rmse: 0.7654\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6248 - acc: 0.6923 - rmse: 0.4660 - val_loss: 1.4501 - val_acc: 0.0000e+00 - val_rmse: 0.7654\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6226 - acc: 0.6923 - rmse: 0.4649 - val_loss: 1.4502 - val_acc: 0.0000e+00 - val_rmse: 0.7655\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6204 - acc: 0.6923 - rmse: 0.4638 - val_loss: 1.4503 - val_acc: 0.0000e+00 - val_rmse: 0.7655\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6182 - acc: 0.6923 - rmse: 0.4627 - val_loss: 1.4504 - val_acc: 0.0000e+00 - val_rmse: 0.7655\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6160 - acc: 0.6923 - rmse: 0.4616 - val_loss: 1.4505 - val_acc: 0.0000e+00 - val_rmse: 0.7656\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 3s - loss: 0.6938 - acc: 0.5000 - rmse: 0.5004 - val_loss: 0.5017 - val_acc: 1.0000 - val_rmse: 0.3945\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6912 - acc: 0.5000 - rmse: 0.4992 - val_loss: 0.5020 - val_acc: 1.0000 - val_rmse: 0.3947\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6886 - acc: 0.5000 - rmse: 0.4980 - val_loss: 0.5022 - val_acc: 1.0000 - val_rmse: 0.3948\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6860 - acc: 0.5000 - rmse: 0.4968 - val_loss: 0.5025 - val_acc: 1.0000 - val_rmse: 0.3950\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6835 - acc: 0.5000 - rmse: 0.4956 - val_loss: 0.5028 - val_acc: 1.0000 - val_rmse: 0.3952\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6809 - acc: 0.5385 - rmse: 0.4944 - val_loss: 0.5031 - val_acc: 1.0000 - val_rmse: 0.3953\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6784 - acc: 0.5385 - rmse: 0.4932 - val_loss: 0.5034 - val_acc: 1.0000 - val_rmse: 0.3955\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6759 - acc: 0.5385 - rmse: 0.4920 - val_loss: 0.5036 - val_acc: 1.0000 - val_rmse: 0.3957\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6734 - acc: 0.5385 - rmse: 0.4908 - val_loss: 0.5039 - val_acc: 1.0000 - val_rmse: 0.3958\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6708 - acc: 0.5385 - rmse: 0.4896 - val_loss: 0.5042 - val_acc: 1.0000 - val_rmse: 0.3960\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6683 - acc: 0.5385 - rmse: 0.4884 - val_loss: 0.5045 - val_acc: 1.0000 - val_rmse: 0.3962\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6658 - acc: 0.5385 - rmse: 0.4872 - val_loss: 0.5047 - val_acc: 1.0000 - val_rmse: 0.3963\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6633 - acc: 0.5385 - rmse: 0.4860 - val_loss: 0.5050 - val_acc: 1.0000 - val_rmse: 0.3965\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6608 - acc: 0.5385 - rmse: 0.4848 - val_loss: 0.5053 - val_acc: 1.0000 - val_rmse: 0.3967\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6583 - acc: 0.5385 - rmse: 0.4836 - val_loss: 0.5056 - val_acc: 1.0000 - val_rmse: 0.3968\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6558 - acc: 0.5769 - rmse: 0.4824 - val_loss: 0.5058 - val_acc: 1.0000 - val_rmse: 0.3970\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6534 - acc: 0.5769 - rmse: 0.4812 - val_loss: 0.5061 - val_acc: 1.0000 - val_rmse: 0.3972\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6509 - acc: 0.5769 - rmse: 0.4801 - val_loss: 0.5064 - val_acc: 1.0000 - val_rmse: 0.3973\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6485 - acc: 0.5769 - rmse: 0.4789 - val_loss: 0.5067 - val_acc: 1.0000 - val_rmse: 0.3975\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6461 - acc: 0.5769 - rmse: 0.4777 - val_loss: 0.5069 - val_acc: 1.0000 - val_rmse: 0.3977\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6437 - acc: 0.5769 - rmse: 0.4765 - val_loss: 0.5072 - val_acc: 1.0000 - val_rmse: 0.3978\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6413 - acc: 0.5769 - rmse: 0.4753 - val_loss: 0.5075 - val_acc: 1.0000 - val_rmse: 0.3980\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6389 - acc: 0.5769 - rmse: 0.4741 - val_loss: 0.5078 - val_acc: 1.0000 - val_rmse: 0.3982\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6366 - acc: 0.6154 - rmse: 0.4730 - val_loss: 0.5080 - val_acc: 1.0000 - val_rmse: 0.3983\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6343 - acc: 0.6154 - rmse: 0.4718 - val_loss: 0.5083 - val_acc: 1.0000 - val_rmse: 0.3985\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6319 - acc: 0.6154 - rmse: 0.4707 - val_loss: 0.5086 - val_acc: 1.0000 - val_rmse: 0.3986\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6296 - acc: 0.6154 - rmse: 0.4695 - val_loss: 0.5088 - val_acc: 1.0000 - val_rmse: 0.3988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6273 - acc: 0.6154 - rmse: 0.4683 - val_loss: 0.5091 - val_acc: 1.0000 - val_rmse: 0.3990\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6250 - acc: 0.6154 - rmse: 0.4672 - val_loss: 0.5094 - val_acc: 1.0000 - val_rmse: 0.3991\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6227 - acc: 0.6538 - rmse: 0.4660 - val_loss: 0.5097 - val_acc: 1.0000 - val_rmse: 0.3993\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6205 - acc: 0.6538 - rmse: 0.4649 - val_loss: 0.5099 - val_acc: 1.0000 - val_rmse: 0.3995\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6182 - acc: 0.6538 - rmse: 0.4637 - val_loss: 0.5102 - val_acc: 1.0000 - val_rmse: 0.3996\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6159 - acc: 0.6538 - rmse: 0.4625 - val_loss: 0.5105 - val_acc: 1.0000 - val_rmse: 0.3998\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6137 - acc: 0.6538 - rmse: 0.4614 - val_loss: 0.5107 - val_acc: 1.0000 - val_rmse: 0.3999\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6114 - acc: 0.6538 - rmse: 0.4602 - val_loss: 0.5110 - val_acc: 1.0000 - val_rmse: 0.4001\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6092 - acc: 0.6923 - rmse: 0.4591 - val_loss: 0.5113 - val_acc: 1.0000 - val_rmse: 0.4003\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6070 - acc: 0.6923 - rmse: 0.4579 - val_loss: 0.5115 - val_acc: 1.0000 - val_rmse: 0.4004\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6047 - acc: 0.6923 - rmse: 0.4568 - val_loss: 0.5118 - val_acc: 1.0000 - val_rmse: 0.4006\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6025 - acc: 0.7308 - rmse: 0.4556 - val_loss: 0.5121 - val_acc: 1.0000 - val_rmse: 0.4007\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6003 - acc: 0.7308 - rmse: 0.4545 - val_loss: 0.5123 - val_acc: 1.0000 - val_rmse: 0.4009\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5981 - acc: 0.7308 - rmse: 0.4533 - val_loss: 0.5126 - val_acc: 1.0000 - val_rmse: 0.4011\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5960 - acc: 0.7308 - rmse: 0.4522 - val_loss: 0.5129 - val_acc: 1.0000 - val_rmse: 0.4012\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5938 - acc: 0.7308 - rmse: 0.4510 - val_loss: 0.5131 - val_acc: 1.0000 - val_rmse: 0.4014\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5917 - acc: 0.7308 - rmse: 0.4499 - val_loss: 0.5134 - val_acc: 1.0000 - val_rmse: 0.4015\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5895 - acc: 0.7308 - rmse: 0.4488 - val_loss: 0.5137 - val_acc: 1.0000 - val_rmse: 0.4017\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5874 - acc: 0.7308 - rmse: 0.4476 - val_loss: 0.5139 - val_acc: 1.0000 - val_rmse: 0.4019\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5852 - acc: 0.7308 - rmse: 0.4465 - val_loss: 0.5142 - val_acc: 1.0000 - val_rmse: 0.4020\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5832 - acc: 0.7308 - rmse: 0.4454 - val_loss: 0.5145 - val_acc: 1.0000 - val_rmse: 0.4022\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5811 - acc: 0.7308 - rmse: 0.4443 - val_loss: 0.5147 - val_acc: 1.0000 - val_rmse: 0.4023\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5790 - acc: 0.7308 - rmse: 0.4431 - val_loss: 0.5150 - val_acc: 1.0000 - val_rmse: 0.4025\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5770 - acc: 0.7308 - rmse: 0.4420 - val_loss: 0.5153 - val_acc: 1.0000 - val_rmse: 0.4027\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5749 - acc: 0.7692 - rmse: 0.4409 - val_loss: 0.5156 - val_acc: 1.0000 - val_rmse: 0.4028\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5728 - acc: 0.7692 - rmse: 0.4398 - val_loss: 0.5158 - val_acc: 1.0000 - val_rmse: 0.4030\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5708 - acc: 0.7692 - rmse: 0.4387 - val_loss: 0.5161 - val_acc: 1.0000 - val_rmse: 0.4032\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5688 - acc: 0.7692 - rmse: 0.4376 - val_loss: 0.5164 - val_acc: 1.0000 - val_rmse: 0.4033\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5667 - acc: 0.7692 - rmse: 0.4365 - val_loss: 0.5166 - val_acc: 1.0000 - val_rmse: 0.4035\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5647 - acc: 0.7692 - rmse: 0.4354 - val_loss: 0.5169 - val_acc: 1.0000 - val_rmse: 0.4036\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5627 - acc: 0.7692 - rmse: 0.4343 - val_loss: 0.5172 - val_acc: 1.0000 - val_rmse: 0.4038\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5607 - acc: 0.7692 - rmse: 0.4332 - val_loss: 0.5174 - val_acc: 1.0000 - val_rmse: 0.4040\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5587 - acc: 0.7692 - rmse: 0.4321 - val_loss: 0.5177 - val_acc: 1.0000 - val_rmse: 0.4041\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5567 - acc: 0.7692 - rmse: 0.4310 - val_loss: 0.5180 - val_acc: 1.0000 - val_rmse: 0.4043\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5547 - acc: 0.7692 - rmse: 0.4299 - val_loss: 0.5182 - val_acc: 1.0000 - val_rmse: 0.4044\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5527 - acc: 0.7692 - rmse: 0.4288 - val_loss: 0.5185 - val_acc: 1.0000 - val_rmse: 0.4046\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5508 - acc: 0.7692 - rmse: 0.4277 - val_loss: 0.5188 - val_acc: 1.0000 - val_rmse: 0.4048\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5488 - acc: 0.8077 - rmse: 0.4266 - val_loss: 0.5190 - val_acc: 1.0000 - val_rmse: 0.4049\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5468 - acc: 0.8462 - rmse: 0.4255 - val_loss: 0.5193 - val_acc: 1.0000 - val_rmse: 0.4051\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5449 - acc: 0.8462 - rmse: 0.4244 - val_loss: 0.5196 - val_acc: 1.0000 - val_rmse: 0.4052\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5429 - acc: 0.8462 - rmse: 0.4233 - val_loss: 0.5198 - val_acc: 1.0000 - val_rmse: 0.4054\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5410 - acc: 0.8462 - rmse: 0.4222 - val_loss: 0.5201 - val_acc: 1.0000 - val_rmse: 0.4055\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5390 - acc: 0.8462 - rmse: 0.4211 - val_loss: 0.5204 - val_acc: 1.0000 - val_rmse: 0.4057\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5371 - acc: 0.8462 - rmse: 0.4200 - val_loss: 0.5206 - val_acc: 1.0000 - val_rmse: 0.4058\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5352 - acc: 0.8462 - rmse: 0.4189 - val_loss: 0.5209 - val_acc: 1.0000 - val_rmse: 0.4060\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5333 - acc: 0.8846 - rmse: 0.4178 - val_loss: 0.5211 - val_acc: 1.0000 - val_rmse: 0.4061\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5314 - acc: 0.8846 - rmse: 0.4167 - val_loss: 0.5214 - val_acc: 1.0000 - val_rmse: 0.4063\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5295 - acc: 0.8846 - rmse: 0.4156 - val_loss: 0.5216 - val_acc: 1.0000 - val_rmse: 0.4065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5276 - acc: 0.8846 - rmse: 0.4145 - val_loss: 0.5219 - val_acc: 1.0000 - val_rmse: 0.4066\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5257 - acc: 0.8846 - rmse: 0.4135 - val_loss: 0.5221 - val_acc: 1.0000 - val_rmse: 0.4067\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5238 - acc: 0.8846 - rmse: 0.4124 - val_loss: 0.5224 - val_acc: 1.0000 - val_rmse: 0.4069\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5220 - acc: 0.8846 - rmse: 0.4113 - val_loss: 0.5226 - val_acc: 1.0000 - val_rmse: 0.4070\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5201 - acc: 0.8846 - rmse: 0.4102 - val_loss: 0.5229 - val_acc: 1.0000 - val_rmse: 0.4072\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5183 - acc: 0.8846 - rmse: 0.4092 - val_loss: 0.5231 - val_acc: 1.0000 - val_rmse: 0.4073\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5164 - acc: 0.8846 - rmse: 0.4081 - val_loss: 0.5234 - val_acc: 1.0000 - val_rmse: 0.4075\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5146 - acc: 0.8846 - rmse: 0.4070 - val_loss: 0.5236 - val_acc: 1.0000 - val_rmse: 0.4076\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5128 - acc: 0.8846 - rmse: 0.4060 - val_loss: 0.5239 - val_acc: 1.0000 - val_rmse: 0.4078\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5109 - acc: 0.8846 - rmse: 0.4049 - val_loss: 0.5241 - val_acc: 1.0000 - val_rmse: 0.4079\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5091 - acc: 0.8846 - rmse: 0.4038 - val_loss: 0.5244 - val_acc: 1.0000 - val_rmse: 0.4081\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5074 - acc: 0.8846 - rmse: 0.4028 - val_loss: 0.5246 - val_acc: 1.0000 - val_rmse: 0.4082\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5056 - acc: 0.8846 - rmse: 0.4017 - val_loss: 0.5248 - val_acc: 1.0000 - val_rmse: 0.4084\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5038 - acc: 0.8846 - rmse: 0.4007 - val_loss: 0.5251 - val_acc: 1.0000 - val_rmse: 0.4085\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5020 - acc: 0.8846 - rmse: 0.3996 - val_loss: 0.5253 - val_acc: 1.0000 - val_rmse: 0.4086\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5003 - acc: 0.8846 - rmse: 0.3986 - val_loss: 0.5256 - val_acc: 1.0000 - val_rmse: 0.4088\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4985 - acc: 0.8846 - rmse: 0.3976 - val_loss: 0.5258 - val_acc: 1.0000 - val_rmse: 0.4089\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4968 - acc: 0.8846 - rmse: 0.3965 - val_loss: 0.5260 - val_acc: 1.0000 - val_rmse: 0.4091\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.4950 - acc: 0.8846 - rmse: 0.3955 - val_loss: 0.5263 - val_acc: 1.0000 - val_rmse: 0.4092\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4933 - acc: 0.8846 - rmse: 0.3945 - val_loss: 0.5265 - val_acc: 1.0000 - val_rmse: 0.4093\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.4916 - acc: 0.8846 - rmse: 0.3934 - val_loss: 0.5268 - val_acc: 1.0000 - val_rmse: 0.4095\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4898 - acc: 0.8846 - rmse: 0.3924 - val_loss: 0.5270 - val_acc: 1.0000 - val_rmse: 0.4096\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.4881 - acc: 0.8846 - rmse: 0.3914 - val_loss: 0.5273 - val_acc: 1.0000 - val_rmse: 0.4098\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4864 - acc: 0.8846 - rmse: 0.3903 - val_loss: 0.5275 - val_acc: 1.0000 - val_rmse: 0.4099\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4847 - acc: 0.8846 - rmse: 0.3893 - val_loss: 0.5278 - val_acc: 1.0000 - val_rmse: 0.4101\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 3s - loss: 0.7307 - acc: 0.5000 - rmse: 0.5173 - val_loss: 0.8079 - val_acc: 0.0000e+00 - val_rmse: 0.5542\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7284 - acc: 0.5000 - rmse: 0.5163 - val_loss: 0.8078 - val_acc: 0.0000e+00 - val_rmse: 0.5542\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7262 - acc: 0.5000 - rmse: 0.5153 - val_loss: 0.8076 - val_acc: 0.0000e+00 - val_rmse: 0.5541\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7239 - acc: 0.5000 - rmse: 0.5143 - val_loss: 0.8075 - val_acc: 0.0000e+00 - val_rmse: 0.5540\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7217 - acc: 0.5000 - rmse: 0.5132 - val_loss: 0.8073 - val_acc: 0.0000e+00 - val_rmse: 0.5539\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7194 - acc: 0.5000 - rmse: 0.5122 - val_loss: 0.8071 - val_acc: 0.0000e+00 - val_rmse: 0.5539\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7172 - acc: 0.5000 - rmse: 0.5112 - val_loss: 0.8070 - val_acc: 0.0000e+00 - val_rmse: 0.5538\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7150 - acc: 0.5000 - rmse: 0.5102 - val_loss: 0.8068 - val_acc: 0.0000e+00 - val_rmse: 0.5537\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7129 - acc: 0.5000 - rmse: 0.5092 - val_loss: 0.8066 - val_acc: 0.0000e+00 - val_rmse: 0.5536\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7107 - acc: 0.5000 - rmse: 0.5083 - val_loss: 0.8065 - val_acc: 0.0000e+00 - val_rmse: 0.5536\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7085 - acc: 0.5000 - rmse: 0.5073 - val_loss: 0.8063 - val_acc: 0.0000e+00 - val_rmse: 0.5535\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7063 - acc: 0.5000 - rmse: 0.5063 - val_loss: 0.8062 - val_acc: 0.0000e+00 - val_rmse: 0.5534\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.7042 - acc: 0.5000 - rmse: 0.5053 - val_loss: 0.8060 - val_acc: 0.0000e+00 - val_rmse: 0.5534\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7020 - acc: 0.5000 - rmse: 0.5043 - val_loss: 0.8058 - val_acc: 0.0000e+00 - val_rmse: 0.5533\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6999 - acc: 0.5000 - rmse: 0.5033 - val_loss: 0.8057 - val_acc: 0.0000e+00 - val_rmse: 0.5532\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6977 - acc: 0.5000 - rmse: 0.5023 - val_loss: 0.8055 - val_acc: 0.0000e+00 - val_rmse: 0.5531\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6955 - acc: 0.5000 - rmse: 0.5013 - val_loss: 0.8054 - val_acc: 0.0000e+00 - val_rmse: 0.5531\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6934 - acc: 0.5000 - rmse: 0.5003 - val_loss: 0.8052 - val_acc: 0.0000e+00 - val_rmse: 0.5530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6913 - acc: 0.5000 - rmse: 0.4993 - val_loss: 0.8051 - val_acc: 0.0000e+00 - val_rmse: 0.5529\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6891 - acc: 0.5000 - rmse: 0.4983 - val_loss: 0.8049 - val_acc: 0.0000e+00 - val_rmse: 0.5529\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6870 - acc: 0.5385 - rmse: 0.4973 - val_loss: 0.8047 - val_acc: 0.0000e+00 - val_rmse: 0.5528\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6849 - acc: 0.5385 - rmse: 0.4963 - val_loss: 0.8046 - val_acc: 0.0000e+00 - val_rmse: 0.5527\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6828 - acc: 0.5385 - rmse: 0.4953 - val_loss: 0.8044 - val_acc: 0.0000e+00 - val_rmse: 0.5527\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6807 - acc: 0.5385 - rmse: 0.4943 - val_loss: 0.8043 - val_acc: 0.0000e+00 - val_rmse: 0.5526\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6786 - acc: 0.5385 - rmse: 0.4934 - val_loss: 0.8041 - val_acc: 0.0000e+00 - val_rmse: 0.5525\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6765 - acc: 0.5385 - rmse: 0.4924 - val_loss: 0.8040 - val_acc: 0.0000e+00 - val_rmse: 0.5524\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6744 - acc: 0.5385 - rmse: 0.4914 - val_loss: 0.8038 - val_acc: 0.0000e+00 - val_rmse: 0.5524\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6724 - acc: 0.5385 - rmse: 0.4904 - val_loss: 0.8036 - val_acc: 0.0000e+00 - val_rmse: 0.5523\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6704 - acc: 0.5769 - rmse: 0.4895 - val_loss: 0.8035 - val_acc: 0.0000e+00 - val_rmse: 0.5522\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6684 - acc: 0.5769 - rmse: 0.4885 - val_loss: 0.8033 - val_acc: 0.0000e+00 - val_rmse: 0.5522\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6664 - acc: 0.5769 - rmse: 0.4876 - val_loss: 0.8032 - val_acc: 0.0000e+00 - val_rmse: 0.5521\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6644 - acc: 0.5769 - rmse: 0.4866 - val_loss: 0.8030 - val_acc: 0.0000e+00 - val_rmse: 0.5520\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6624 - acc: 0.5769 - rmse: 0.4857 - val_loss: 0.8028 - val_acc: 0.0000e+00 - val_rmse: 0.5519\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6604 - acc: 0.5769 - rmse: 0.4847 - val_loss: 0.8027 - val_acc: 0.0000e+00 - val_rmse: 0.5519\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6585 - acc: 0.5769 - rmse: 0.4838 - val_loss: 0.8025 - val_acc: 0.0000e+00 - val_rmse: 0.5518\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6566 - acc: 0.5769 - rmse: 0.4829 - val_loss: 0.8024 - val_acc: 0.0000e+00 - val_rmse: 0.5517\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6546 - acc: 0.5769 - rmse: 0.4820 - val_loss: 0.8022 - val_acc: 0.0000e+00 - val_rmse: 0.5517\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6527 - acc: 0.5769 - rmse: 0.4810 - val_loss: 0.8021 - val_acc: 0.0000e+00 - val_rmse: 0.5516\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6508 - acc: 0.6154 - rmse: 0.4801 - val_loss: 0.8019 - val_acc: 0.0000e+00 - val_rmse: 0.5515\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6489 - acc: 0.6154 - rmse: 0.4792 - val_loss: 0.8017 - val_acc: 0.0000e+00 - val_rmse: 0.5515\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6470 - acc: 0.6154 - rmse: 0.4783 - val_loss: 0.8016 - val_acc: 0.0000e+00 - val_rmse: 0.5514\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6451 - acc: 0.6538 - rmse: 0.4774 - val_loss: 0.8014 - val_acc: 0.0000e+00 - val_rmse: 0.5513\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6432 - acc: 0.6538 - rmse: 0.4764 - val_loss: 0.8013 - val_acc: 0.0000e+00 - val_rmse: 0.5512\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6413 - acc: 0.6538 - rmse: 0.4755 - val_loss: 0.8011 - val_acc: 0.0000e+00 - val_rmse: 0.5512\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6395 - acc: 0.6538 - rmse: 0.4746 - val_loss: 0.8010 - val_acc: 0.0000e+00 - val_rmse: 0.5511\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6376 - acc: 0.6538 - rmse: 0.4737 - val_loss: 0.8008 - val_acc: 0.0000e+00 - val_rmse: 0.5510\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6357 - acc: 0.6538 - rmse: 0.4728 - val_loss: 0.8006 - val_acc: 0.0000e+00 - val_rmse: 0.5510\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6338 - acc: 0.6538 - rmse: 0.4719 - val_loss: 0.8005 - val_acc: 0.0000e+00 - val_rmse: 0.5509\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6320 - acc: 0.6538 - rmse: 0.4709 - val_loss: 0.8003 - val_acc: 0.0000e+00 - val_rmse: 0.5508\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6301 - acc: 0.6538 - rmse: 0.4700 - val_loss: 0.8002 - val_acc: 0.0000e+00 - val_rmse: 0.5508\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6283 - acc: 0.6538 - rmse: 0.4691 - val_loss: 0.8000 - val_acc: 0.0000e+00 - val_rmse: 0.5507\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6264 - acc: 0.6538 - rmse: 0.4682 - val_loss: 0.7999 - val_acc: 0.0000e+00 - val_rmse: 0.5506\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6246 - acc: 0.6538 - rmse: 0.4673 - val_loss: 0.7997 - val_acc: 0.0000e+00 - val_rmse: 0.5505\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6228 - acc: 0.6538 - rmse: 0.4664 - val_loss: 0.7996 - val_acc: 0.0000e+00 - val_rmse: 0.5505\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6209 - acc: 0.6538 - rmse: 0.4655 - val_loss: 0.7994 - val_acc: 0.0000e+00 - val_rmse: 0.5504\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6191 - acc: 0.6538 - rmse: 0.4646 - val_loss: 0.7992 - val_acc: 0.0000e+00 - val_rmse: 0.5503\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6173 - acc: 0.6538 - rmse: 0.4637 - val_loss: 0.7991 - val_acc: 0.0000e+00 - val_rmse: 0.5503\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6155 - acc: 0.6538 - rmse: 0.4628 - val_loss: 0.7989 - val_acc: 0.0000e+00 - val_rmse: 0.5502\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6137 - acc: 0.6538 - rmse: 0.4619 - val_loss: 0.7988 - val_acc: 0.0000e+00 - val_rmse: 0.5501\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6119 - acc: 0.6538 - rmse: 0.4610 - val_loss: 0.7986 - val_acc: 0.0000e+00 - val_rmse: 0.5500\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6101 - acc: 0.6538 - rmse: 0.4601 - val_loss: 0.7985 - val_acc: 0.0000e+00 - val_rmse: 0.5500\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6083 - acc: 0.6538 - rmse: 0.4592 - val_loss: 0.7983 - val_acc: 0.0000e+00 - val_rmse: 0.5499\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6065 - acc: 0.6923 - rmse: 0.4583 - val_loss: 0.7981 - val_acc: 0.0000e+00 - val_rmse: 0.5498\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6048 - acc: 0.6923 - rmse: 0.4574 - val_loss: 0.7980 - val_acc: 0.0000e+00 - val_rmse: 0.5498\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6030 - acc: 0.6923 - rmse: 0.4565 - val_loss: 0.7978 - val_acc: 0.0000e+00 - val_rmse: 0.5497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6012 - acc: 0.6923 - rmse: 0.4556 - val_loss: 0.7977 - val_acc: 0.0000e+00 - val_rmse: 0.5496\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5995 - acc: 0.6923 - rmse: 0.4547 - val_loss: 0.7975 - val_acc: 0.0000e+00 - val_rmse: 0.5496\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5977 - acc: 0.6923 - rmse: 0.4538 - val_loss: 0.7974 - val_acc: 0.0000e+00 - val_rmse: 0.5495\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5960 - acc: 0.6923 - rmse: 0.4529 - val_loss: 0.7972 - val_acc: 0.0000e+00 - val_rmse: 0.5494\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5943 - acc: 0.6923 - rmse: 0.4520 - val_loss: 0.7970 - val_acc: 0.0000e+00 - val_rmse: 0.5493\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5925 - acc: 0.6923 - rmse: 0.4511 - val_loss: 0.7969 - val_acc: 0.0000e+00 - val_rmse: 0.5493\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5908 - acc: 0.6923 - rmse: 0.4503 - val_loss: 0.7967 - val_acc: 0.0000e+00 - val_rmse: 0.5492\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5891 - acc: 0.6923 - rmse: 0.4494 - val_loss: 0.7965 - val_acc: 0.0000e+00 - val_rmse: 0.5491\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5874 - acc: 0.6923 - rmse: 0.4485 - val_loss: 0.7963 - val_acc: 0.0000e+00 - val_rmse: 0.5490\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5857 - acc: 0.6923 - rmse: 0.4476 - val_loss: 0.7962 - val_acc: 0.0000e+00 - val_rmse: 0.5489\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5840 - acc: 0.6923 - rmse: 0.4467 - val_loss: 0.7960 - val_acc: 0.0000e+00 - val_rmse: 0.5489\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5823 - acc: 0.6923 - rmse: 0.4459 - val_loss: 0.7958 - val_acc: 0.0000e+00 - val_rmse: 0.5488\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5806 - acc: 0.6923 - rmse: 0.4450 - val_loss: 0.7956 - val_acc: 0.0000e+00 - val_rmse: 0.5487\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5789 - acc: 0.6923 - rmse: 0.4441 - val_loss: 0.7955 - val_acc: 0.0000e+00 - val_rmse: 0.5486\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5772 - acc: 0.7308 - rmse: 0.4432 - val_loss: 0.7953 - val_acc: 0.0000e+00 - val_rmse: 0.5486\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5755 - acc: 0.7308 - rmse: 0.4424 - val_loss: 0.7951 - val_acc: 0.0000e+00 - val_rmse: 0.5485\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5739 - acc: 0.7308 - rmse: 0.4415 - val_loss: 0.7949 - val_acc: 0.0000e+00 - val_rmse: 0.5484\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5722 - acc: 0.7308 - rmse: 0.4406 - val_loss: 0.7948 - val_acc: 0.0000e+00 - val_rmse: 0.5483\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5705 - acc: 0.7308 - rmse: 0.4397 - val_loss: 0.7946 - val_acc: 0.0000e+00 - val_rmse: 0.5482\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5689 - acc: 0.7308 - rmse: 0.4389 - val_loss: 0.7944 - val_acc: 0.0000e+00 - val_rmse: 0.5482\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5672 - acc: 0.7308 - rmse: 0.4380 - val_loss: 0.7943 - val_acc: 0.0000e+00 - val_rmse: 0.5481\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5656 - acc: 0.7308 - rmse: 0.4371 - val_loss: 0.7941 - val_acc: 0.0000e+00 - val_rmse: 0.5480\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5639 - acc: 0.7308 - rmse: 0.4363 - val_loss: 0.7939 - val_acc: 0.0000e+00 - val_rmse: 0.5479\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5623 - acc: 0.7308 - rmse: 0.4354 - val_loss: 0.7938 - val_acc: 0.0000e+00 - val_rmse: 0.5479\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5606 - acc: 0.7308 - rmse: 0.4345 - val_loss: 0.7936 - val_acc: 0.0000e+00 - val_rmse: 0.5478\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5590 - acc: 0.7308 - rmse: 0.4337 - val_loss: 0.7934 - val_acc: 0.0000e+00 - val_rmse: 0.5477\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5574 - acc: 0.7308 - rmse: 0.4328 - val_loss: 0.7933 - val_acc: 0.0000e+00 - val_rmse: 0.5476\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5558 - acc: 0.7308 - rmse: 0.4320 - val_loss: 0.7931 - val_acc: 0.0000e+00 - val_rmse: 0.5476\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5542 - acc: 0.7308 - rmse: 0.4311 - val_loss: 0.7929 - val_acc: 0.0000e+00 - val_rmse: 0.5475\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5526 - acc: 0.7308 - rmse: 0.4303 - val_loss: 0.7928 - val_acc: 0.0000e+00 - val_rmse: 0.5474\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5510 - acc: 0.7308 - rmse: 0.4294 - val_loss: 0.7926 - val_acc: 0.0000e+00 - val_rmse: 0.5473\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5494 - acc: 0.7308 - rmse: 0.4286 - val_loss: 0.7924 - val_acc: 0.0000e+00 - val_rmse: 0.5473\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5478 - acc: 0.7308 - rmse: 0.4277 - val_loss: 0.7923 - val_acc: 0.0000e+00 - val_rmse: 0.5472\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5463 - acc: 0.7308 - rmse: 0.4269 - val_loss: 0.7921 - val_acc: 0.0000e+00 - val_rmse: 0.5471\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5447 - acc: 0.7308 - rmse: 0.4260 - val_loss: 0.7919 - val_acc: 0.0000e+00 - val_rmse: 0.5470\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 4s - loss: 0.6710 - acc: 0.6538 - rmse: 0.4897 - val_loss: 0.6286 - val_acc: 1.0000 - val_rmse: 0.4667\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6689 - acc: 0.6538 - rmse: 0.4887 - val_loss: 0.6285 - val_acc: 1.0000 - val_rmse: 0.4666\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6668 - acc: 0.6538 - rmse: 0.4877 - val_loss: 0.6283 - val_acc: 1.0000 - val_rmse: 0.4665\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6647 - acc: 0.6538 - rmse: 0.4867 - val_loss: 0.6282 - val_acc: 1.0000 - val_rmse: 0.4664\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6626 - acc: 0.6538 - rmse: 0.4856 - val_loss: 0.6280 - val_acc: 1.0000 - val_rmse: 0.4664\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6605 - acc: 0.6538 - rmse: 0.4846 - val_loss: 0.6279 - val_acc: 1.0000 - val_rmse: 0.4663\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6585 - acc: 0.6538 - rmse: 0.4836 - val_loss: 0.6277 - val_acc: 1.0000 - val_rmse: 0.4662\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6564 - acc: 0.6538 - rmse: 0.4826 - val_loss: 0.6276 - val_acc: 1.0000 - val_rmse: 0.4661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6544 - acc: 0.6538 - rmse: 0.4816 - val_loss: 0.6274 - val_acc: 1.0000 - val_rmse: 0.4660\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6523 - acc: 0.6538 - rmse: 0.4806 - val_loss: 0.6273 - val_acc: 1.0000 - val_rmse: 0.4660\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6503 - acc: 0.6538 - rmse: 0.4796 - val_loss: 0.6272 - val_acc: 1.0000 - val_rmse: 0.4659\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6482 - acc: 0.6538 - rmse: 0.4786 - val_loss: 0.6270 - val_acc: 1.0000 - val_rmse: 0.4658\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6462 - acc: 0.6538 - rmse: 0.4776 - val_loss: 0.6269 - val_acc: 1.0000 - val_rmse: 0.4657\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6442 - acc: 0.6538 - rmse: 0.4766 - val_loss: 0.6267 - val_acc: 1.0000 - val_rmse: 0.4657\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6422 - acc: 0.6538 - rmse: 0.4756 - val_loss: 0.6266 - val_acc: 1.0000 - val_rmse: 0.4656\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6402 - acc: 0.6538 - rmse: 0.4746 - val_loss: 0.6265 - val_acc: 1.0000 - val_rmse: 0.4655\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6382 - acc: 0.6538 - rmse: 0.4737 - val_loss: 0.6263 - val_acc: 1.0000 - val_rmse: 0.4655\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6362 - acc: 0.6538 - rmse: 0.4727 - val_loss: 0.6262 - val_acc: 1.0000 - val_rmse: 0.4654\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6342 - acc: 0.6538 - rmse: 0.4717 - val_loss: 0.6261 - val_acc: 1.0000 - val_rmse: 0.4653\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6323 - acc: 0.6538 - rmse: 0.4707 - val_loss: 0.6259 - val_acc: 1.0000 - val_rmse: 0.4652\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6303 - acc: 0.6538 - rmse: 0.4697 - val_loss: 0.6258 - val_acc: 1.0000 - val_rmse: 0.4652\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6284 - acc: 0.6538 - rmse: 0.4688 - val_loss: 0.6257 - val_acc: 1.0000 - val_rmse: 0.4651\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6265 - acc: 0.6538 - rmse: 0.4678 - val_loss: 0.6255 - val_acc: 1.0000 - val_rmse: 0.4650\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6247 - acc: 0.6538 - rmse: 0.4669 - val_loss: 0.6254 - val_acc: 1.0000 - val_rmse: 0.4649\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6228 - acc: 0.6538 - rmse: 0.4659 - val_loss: 0.6253 - val_acc: 1.0000 - val_rmse: 0.4649\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6210 - acc: 0.6538 - rmse: 0.4650 - val_loss: 0.6251 - val_acc: 1.0000 - val_rmse: 0.4648\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6192 - acc: 0.6538 - rmse: 0.4641 - val_loss: 0.6250 - val_acc: 1.0000 - val_rmse: 0.4647\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6174 - acc: 0.6538 - rmse: 0.4631 - val_loss: 0.6249 - val_acc: 1.0000 - val_rmse: 0.4647\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6156 - acc: 0.6538 - rmse: 0.4622 - val_loss: 0.6247 - val_acc: 1.0000 - val_rmse: 0.4646\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6138 - acc: 0.6538 - rmse: 0.4613 - val_loss: 0.6246 - val_acc: 1.0000 - val_rmse: 0.4645\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6120 - acc: 0.6538 - rmse: 0.4604 - val_loss: 0.6245 - val_acc: 1.0000 - val_rmse: 0.4645\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6102 - acc: 0.6538 - rmse: 0.4594 - val_loss: 0.6243 - val_acc: 1.0000 - val_rmse: 0.4644\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6084 - acc: 0.6923 - rmse: 0.4585 - val_loss: 0.6242 - val_acc: 1.0000 - val_rmse: 0.4643\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6066 - acc: 0.6923 - rmse: 0.4576 - val_loss: 0.6241 - val_acc: 1.0000 - val_rmse: 0.4643\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6049 - acc: 0.6923 - rmse: 0.4567 - val_loss: 0.6240 - val_acc: 1.0000 - val_rmse: 0.4642\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6031 - acc: 0.6923 - rmse: 0.4558 - val_loss: 0.6239 - val_acc: 1.0000 - val_rmse: 0.4642\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6014 - acc: 0.6923 - rmse: 0.4549 - val_loss: 0.6238 - val_acc: 1.0000 - val_rmse: 0.4641\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5996 - acc: 0.6923 - rmse: 0.4539 - val_loss: 0.6237 - val_acc: 1.0000 - val_rmse: 0.4640\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5979 - acc: 0.6923 - rmse: 0.4530 - val_loss: 0.6236 - val_acc: 1.0000 - val_rmse: 0.4640\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5961 - acc: 0.6923 - rmse: 0.4521 - val_loss: 0.6235 - val_acc: 1.0000 - val_rmse: 0.4639\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5944 - acc: 0.6923 - rmse: 0.4512 - val_loss: 0.6234 - val_acc: 1.0000 - val_rmse: 0.4639\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5926 - acc: 0.6923 - rmse: 0.4503 - val_loss: 0.6233 - val_acc: 1.0000 - val_rmse: 0.4638\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5909 - acc: 0.6923 - rmse: 0.4494 - val_loss: 0.6232 - val_acc: 1.0000 - val_rmse: 0.4638\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5892 - acc: 0.6923 - rmse: 0.4485 - val_loss: 0.6231 - val_acc: 1.0000 - val_rmse: 0.4637\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5875 - acc: 0.6923 - rmse: 0.4476 - val_loss: 0.6230 - val_acc: 1.0000 - val_rmse: 0.4637\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5858 - acc: 0.6923 - rmse: 0.4467 - val_loss: 0.6229 - val_acc: 1.0000 - val_rmse: 0.4636\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5842 - acc: 0.6923 - rmse: 0.4458 - val_loss: 0.6228 - val_acc: 1.0000 - val_rmse: 0.4636\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5825 - acc: 0.6923 - rmse: 0.4449 - val_loss: 0.6227 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5808 - acc: 0.6923 - rmse: 0.4440 - val_loss: 0.6226 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5792 - acc: 0.7308 - rmse: 0.4431 - val_loss: 0.6225 - val_acc: 1.0000 - val_rmse: 0.4634\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5775 - acc: 0.7308 - rmse: 0.4422 - val_loss: 0.6224 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5758 - acc: 0.7308 - rmse: 0.4413 - val_loss: 0.6223 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5742 - acc: 0.7308 - rmse: 0.4404 - val_loss: 0.6222 - val_acc: 1.0000 - val_rmse: 0.4632\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5726 - acc: 0.7308 - rmse: 0.4396 - val_loss: 0.6221 - val_acc: 1.0000 - val_rmse: 0.4632\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5709 - acc: 0.7308 - rmse: 0.4387 - val_loss: 0.6220 - val_acc: 1.0000 - val_rmse: 0.4631\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5693 - acc: 0.7308 - rmse: 0.4378 - val_loss: 0.6219 - val_acc: 1.0000 - val_rmse: 0.4631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5677 - acc: 0.7308 - rmse: 0.4369 - val_loss: 0.6218 - val_acc: 1.0000 - val_rmse: 0.4630\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5661 - acc: 0.7308 - rmse: 0.4360 - val_loss: 0.6217 - val_acc: 1.0000 - val_rmse: 0.4630\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5644 - acc: 0.7308 - rmse: 0.4352 - val_loss: 0.6216 - val_acc: 1.0000 - val_rmse: 0.4629\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5628 - acc: 0.7692 - rmse: 0.4343 - val_loss: 0.6215 - val_acc: 1.0000 - val_rmse: 0.4629\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5612 - acc: 0.7692 - rmse: 0.4334 - val_loss: 0.6214 - val_acc: 1.0000 - val_rmse: 0.4628\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5597 - acc: 0.8077 - rmse: 0.4325 - val_loss: 0.6213 - val_acc: 1.0000 - val_rmse: 0.4627\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5581 - acc: 0.8077 - rmse: 0.4316 - val_loss: 0.6212 - val_acc: 1.0000 - val_rmse: 0.4627\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5565 - acc: 0.8077 - rmse: 0.4308 - val_loss: 0.6211 - val_acc: 1.0000 - val_rmse: 0.4626\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5549 - acc: 0.8077 - rmse: 0.4299 - val_loss: 0.6210 - val_acc: 1.0000 - val_rmse: 0.4626\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5533 - acc: 0.8077 - rmse: 0.4290 - val_loss: 0.6209 - val_acc: 1.0000 - val_rmse: 0.4625\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5517 - acc: 0.8077 - rmse: 0.4282 - val_loss: 0.6208 - val_acc: 1.0000 - val_rmse: 0.4625\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5502 - acc: 0.8077 - rmse: 0.4273 - val_loss: 0.6207 - val_acc: 1.0000 - val_rmse: 0.4624\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5486 - acc: 0.8077 - rmse: 0.4264 - val_loss: 0.6206 - val_acc: 1.0000 - val_rmse: 0.4624\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5470 - acc: 0.8077 - rmse: 0.4255 - val_loss: 0.6205 - val_acc: 1.0000 - val_rmse: 0.4623\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5455 - acc: 0.8077 - rmse: 0.4247 - val_loss: 0.6204 - val_acc: 1.0000 - val_rmse: 0.4622\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5439 - acc: 0.8077 - rmse: 0.4238 - val_loss: 0.6203 - val_acc: 1.0000 - val_rmse: 0.4622\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5424 - acc: 0.8077 - rmse: 0.4229 - val_loss: 0.6202 - val_acc: 1.0000 - val_rmse: 0.4621\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5409 - acc: 0.8077 - rmse: 0.4221 - val_loss: 0.6201 - val_acc: 1.0000 - val_rmse: 0.4621\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5393 - acc: 0.8077 - rmse: 0.4212 - val_loss: 0.6200 - val_acc: 1.0000 - val_rmse: 0.4620\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5378 - acc: 0.8077 - rmse: 0.4204 - val_loss: 0.6198 - val_acc: 1.0000 - val_rmse: 0.4620\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5363 - acc: 0.8077 - rmse: 0.4195 - val_loss: 0.6197 - val_acc: 1.0000 - val_rmse: 0.4619\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5348 - acc: 0.8077 - rmse: 0.4186 - val_loss: 0.6196 - val_acc: 1.0000 - val_rmse: 0.4619\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5333 - acc: 0.8077 - rmse: 0.4178 - val_loss: 0.6195 - val_acc: 1.0000 - val_rmse: 0.4618\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5318 - acc: 0.8077 - rmse: 0.4170 - val_loss: 0.6194 - val_acc: 1.0000 - val_rmse: 0.4618\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5303 - acc: 0.8077 - rmse: 0.4161 - val_loss: 0.6193 - val_acc: 1.0000 - val_rmse: 0.4617\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5289 - acc: 0.8077 - rmse: 0.4153 - val_loss: 0.6192 - val_acc: 1.0000 - val_rmse: 0.4616\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5274 - acc: 0.8077 - rmse: 0.4144 - val_loss: 0.6191 - val_acc: 1.0000 - val_rmse: 0.4616\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5259 - acc: 0.8077 - rmse: 0.4136 - val_loss: 0.6190 - val_acc: 1.0000 - val_rmse: 0.4615\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5245 - acc: 0.8077 - rmse: 0.4128 - val_loss: 0.6189 - val_acc: 1.0000 - val_rmse: 0.4615\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5230 - acc: 0.8077 - rmse: 0.4119 - val_loss: 0.6188 - val_acc: 1.0000 - val_rmse: 0.4614\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5216 - acc: 0.8077 - rmse: 0.4111 - val_loss: 0.6187 - val_acc: 1.0000 - val_rmse: 0.4614\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5201 - acc: 0.8077 - rmse: 0.4103 - val_loss: 0.6186 - val_acc: 1.0000 - val_rmse: 0.4613\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5187 - acc: 0.8077 - rmse: 0.4094 - val_loss: 0.6185 - val_acc: 1.0000 - val_rmse: 0.4612\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5172 - acc: 0.8077 - rmse: 0.4086 - val_loss: 0.6184 - val_acc: 1.0000 - val_rmse: 0.4612\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5158 - acc: 0.8077 - rmse: 0.4078 - val_loss: 0.6183 - val_acc: 1.0000 - val_rmse: 0.4611\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5144 - acc: 0.8077 - rmse: 0.4069 - val_loss: 0.6182 - val_acc: 1.0000 - val_rmse: 0.4611\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5129 - acc: 0.8077 - rmse: 0.4061 - val_loss: 0.6181 - val_acc: 1.0000 - val_rmse: 0.4610\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5115 - acc: 0.8077 - rmse: 0.4053 - val_loss: 0.6180 - val_acc: 1.0000 - val_rmse: 0.4610\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5101 - acc: 0.8077 - rmse: 0.4045 - val_loss: 0.6179 - val_acc: 1.0000 - val_rmse: 0.4609\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5087 - acc: 0.8077 - rmse: 0.4036 - val_loss: 0.6178 - val_acc: 1.0000 - val_rmse: 0.4609\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5072 - acc: 0.8077 - rmse: 0.4028 - val_loss: 0.6177 - val_acc: 1.0000 - val_rmse: 0.4608\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5058 - acc: 0.8077 - rmse: 0.4020 - val_loss: 0.6176 - val_acc: 1.0000 - val_rmse: 0.4607\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5044 - acc: 0.8077 - rmse: 0.4012 - val_loss: 0.6174 - val_acc: 1.0000 - val_rmse: 0.4607\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5030 - acc: 0.8077 - rmse: 0.4003 - val_loss: 0.6173 - val_acc: 1.0000 - val_rmse: 0.4606\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 4s - loss: 0.6762 - acc: 0.5385 - rmse: 0.4914 - val_loss: 1.2576 - val_acc: 0.0000e+00 - val_rmse: 0.7157\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6742 - acc: 0.5385 - rmse: 0.4904 - val_loss: 1.2578 - val_acc: 0.0000e+00 - val_rmse: 0.7157\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6723 - acc: 0.5385 - rmse: 0.4895 - val_loss: 1.2580 - val_acc: 0.0000e+00 - val_rmse: 0.7158\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6704 - acc: 0.5385 - rmse: 0.4886 - val_loss: 1.2581 - val_acc: 0.0000e+00 - val_rmse: 0.7158\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6685 - acc: 0.5385 - rmse: 0.4877 - val_loss: 1.2583 - val_acc: 0.0000e+00 - val_rmse: 0.7159\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6666 - acc: 0.5769 - rmse: 0.4867 - val_loss: 1.2584 - val_acc: 0.0000e+00 - val_rmse: 0.7159\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6648 - acc: 0.5769 - rmse: 0.4858 - val_loss: 1.2586 - val_acc: 0.0000e+00 - val_rmse: 0.7160\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6629 - acc: 0.5769 - rmse: 0.4849 - val_loss: 1.2588 - val_acc: 0.0000e+00 - val_rmse: 0.7160\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6611 - acc: 0.5769 - rmse: 0.4840 - val_loss: 1.2589 - val_acc: 0.0000e+00 - val_rmse: 0.7160\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6592 - acc: 0.5769 - rmse: 0.4831 - val_loss: 1.2591 - val_acc: 0.0000e+00 - val_rmse: 0.7161\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6574 - acc: 0.5769 - rmse: 0.4822 - val_loss: 1.2592 - val_acc: 0.0000e+00 - val_rmse: 0.7161\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6555 - acc: 0.5769 - rmse: 0.4813 - val_loss: 1.2594 - val_acc: 0.0000e+00 - val_rmse: 0.7162\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6537 - acc: 0.5769 - rmse: 0.4803 - val_loss: 1.2596 - val_acc: 0.0000e+00 - val_rmse: 0.7162\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6518 - acc: 0.5769 - rmse: 0.4794 - val_loss: 1.2597 - val_acc: 0.0000e+00 - val_rmse: 0.7163\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6500 - acc: 0.5769 - rmse: 0.4785 - val_loss: 1.2599 - val_acc: 0.0000e+00 - val_rmse: 0.7163\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6482 - acc: 0.5769 - rmse: 0.4776 - val_loss: 1.2600 - val_acc: 0.0000e+00 - val_rmse: 0.7164\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6464 - acc: 0.5769 - rmse: 0.4767 - val_loss: 1.2602 - val_acc: 0.0000e+00 - val_rmse: 0.7164\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6446 - acc: 0.5769 - rmse: 0.4758 - val_loss: 1.2603 - val_acc: 0.0000e+00 - val_rmse: 0.7164\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6428 - acc: 0.5769 - rmse: 0.4749 - val_loss: 1.2605 - val_acc: 0.0000e+00 - val_rmse: 0.7165\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6410 - acc: 0.5769 - rmse: 0.4740 - val_loss: 1.2606 - val_acc: 0.0000e+00 - val_rmse: 0.7165\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6392 - acc: 0.6154 - rmse: 0.4731 - val_loss: 1.2608 - val_acc: 0.0000e+00 - val_rmse: 0.7166\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6375 - acc: 0.6154 - rmse: 0.4722 - val_loss: 1.2609 - val_acc: 0.0000e+00 - val_rmse: 0.7166\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6357 - acc: 0.6154 - rmse: 0.4713 - val_loss: 1.2610 - val_acc: 0.0000e+00 - val_rmse: 0.7166\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6339 - acc: 0.6154 - rmse: 0.4704 - val_loss: 1.2612 - val_acc: 0.0000e+00 - val_rmse: 0.7167\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6322 - acc: 0.6154 - rmse: 0.4696 - val_loss: 1.2613 - val_acc: 0.0000e+00 - val_rmse: 0.7167\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6305 - acc: 0.6154 - rmse: 0.4687 - val_loss: 1.2615 - val_acc: 0.0000e+00 - val_rmse: 0.7168\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6287 - acc: 0.6154 - rmse: 0.4678 - val_loss: 1.2616 - val_acc: 0.0000e+00 - val_rmse: 0.7168\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6270 - acc: 0.6154 - rmse: 0.4669 - val_loss: 1.2617 - val_acc: 0.0000e+00 - val_rmse: 0.7168\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6253 - acc: 0.6154 - rmse: 0.4661 - val_loss: 1.2619 - val_acc: 0.0000e+00 - val_rmse: 0.7169\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6236 - acc: 0.6154 - rmse: 0.4652 - val_loss: 1.2620 - val_acc: 0.0000e+00 - val_rmse: 0.7169\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6219 - acc: 0.6154 - rmse: 0.4643 - val_loss: 1.2622 - val_acc: 0.0000e+00 - val_rmse: 0.7170\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6202 - acc: 0.6154 - rmse: 0.4634 - val_loss: 1.2623 - val_acc: 0.0000e+00 - val_rmse: 0.7170\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6185 - acc: 0.6154 - rmse: 0.4626 - val_loss: 1.2625 - val_acc: 0.0000e+00 - val_rmse: 0.7170\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6168 - acc: 0.6154 - rmse: 0.4617 - val_loss: 1.2626 - val_acc: 0.0000e+00 - val_rmse: 0.7171\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6151 - acc: 0.6154 - rmse: 0.4608 - val_loss: 1.2628 - val_acc: 0.0000e+00 - val_rmse: 0.7171\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6135 - acc: 0.6538 - rmse: 0.4600 - val_loss: 1.2629 - val_acc: 0.0000e+00 - val_rmse: 0.7172\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6118 - acc: 0.6923 - rmse: 0.4591 - val_loss: 1.2630 - val_acc: 0.0000e+00 - val_rmse: 0.7172\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6101 - acc: 0.6923 - rmse: 0.4582 - val_loss: 1.2632 - val_acc: 0.0000e+00 - val_rmse: 0.7173\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6085 - acc: 0.6923 - rmse: 0.4574 - val_loss: 1.2633 - val_acc: 0.0000e+00 - val_rmse: 0.7173\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6068 - acc: 0.6923 - rmse: 0.4565 - val_loss: 1.2635 - val_acc: 0.0000e+00 - val_rmse: 0.7173\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6051 - acc: 0.6923 - rmse: 0.4556 - val_loss: 1.2636 - val_acc: 0.0000e+00 - val_rmse: 0.7174\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6035 - acc: 0.7308 - rmse: 0.4548 - val_loss: 1.2638 - val_acc: 0.0000e+00 - val_rmse: 0.7174\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6018 - acc: 0.7308 - rmse: 0.4539 - val_loss: 1.2639 - val_acc: 0.0000e+00 - val_rmse: 0.7175\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6002 - acc: 0.7308 - rmse: 0.4531 - val_loss: 1.2641 - val_acc: 0.0000e+00 - val_rmse: 0.7175\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5986 - acc: 0.7308 - rmse: 0.4522 - val_loss: 1.2642 - val_acc: 0.0000e+00 - val_rmse: 0.7175\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5971 - acc: 0.7308 - rmse: 0.4514 - val_loss: 1.2644 - val_acc: 0.0000e+00 - val_rmse: 0.7176\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5955 - acc: 0.7308 - rmse: 0.4506 - val_loss: 1.2645 - val_acc: 0.0000e+00 - val_rmse: 0.7176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5939 - acc: 0.7308 - rmse: 0.4497 - val_loss: 1.2647 - val_acc: 0.0000e+00 - val_rmse: 0.7177\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5924 - acc: 0.7308 - rmse: 0.4489 - val_loss: 1.2648 - val_acc: 0.0000e+00 - val_rmse: 0.7177\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5908 - acc: 0.7308 - rmse: 0.4481 - val_loss: 1.2650 - val_acc: 0.0000e+00 - val_rmse: 0.7178\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5893 - acc: 0.7308 - rmse: 0.4473 - val_loss: 1.2651 - val_acc: 0.0000e+00 - val_rmse: 0.7178\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5877 - acc: 0.7308 - rmse: 0.4465 - val_loss: 1.2653 - val_acc: 0.0000e+00 - val_rmse: 0.7178\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5862 - acc: 0.7308 - rmse: 0.4456 - val_loss: 1.2654 - val_acc: 0.0000e+00 - val_rmse: 0.7179\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5847 - acc: 0.7308 - rmse: 0.4448 - val_loss: 1.2656 - val_acc: 0.0000e+00 - val_rmse: 0.7179\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5832 - acc: 0.7308 - rmse: 0.4440 - val_loss: 1.2657 - val_acc: 0.0000e+00 - val_rmse: 0.7180\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5816 - acc: 0.7308 - rmse: 0.4432 - val_loss: 1.2659 - val_acc: 0.0000e+00 - val_rmse: 0.7180\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5801 - acc: 0.7308 - rmse: 0.4424 - val_loss: 1.2661 - val_acc: 0.0000e+00 - val_rmse: 0.7181\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5786 - acc: 0.7308 - rmse: 0.4416 - val_loss: 1.2662 - val_acc: 0.0000e+00 - val_rmse: 0.7181\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5771 - acc: 0.8077 - rmse: 0.4408 - val_loss: 1.2664 - val_acc: 0.0000e+00 - val_rmse: 0.7182\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5756 - acc: 0.8077 - rmse: 0.4400 - val_loss: 1.2666 - val_acc: 0.0000e+00 - val_rmse: 0.7182\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5741 - acc: 0.8077 - rmse: 0.4392 - val_loss: 1.2667 - val_acc: 0.0000e+00 - val_rmse: 0.7182\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5726 - acc: 0.8077 - rmse: 0.4383 - val_loss: 1.2669 - val_acc: 0.0000e+00 - val_rmse: 0.7183\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5711 - acc: 0.8077 - rmse: 0.4375 - val_loss: 1.2671 - val_acc: 0.0000e+00 - val_rmse: 0.7183\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5697 - acc: 0.8077 - rmse: 0.4368 - val_loss: 1.2672 - val_acc: 0.0000e+00 - val_rmse: 0.7184\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5682 - acc: 0.8077 - rmse: 0.4360 - val_loss: 1.2674 - val_acc: 0.0000e+00 - val_rmse: 0.7184\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5667 - acc: 0.8077 - rmse: 0.4352 - val_loss: 1.2676 - val_acc: 0.0000e+00 - val_rmse: 0.7185\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5653 - acc: 0.8077 - rmse: 0.4344 - val_loss: 1.2678 - val_acc: 0.0000e+00 - val_rmse: 0.7185\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5638 - acc: 0.8077 - rmse: 0.4336 - val_loss: 1.2680 - val_acc: 0.0000e+00 - val_rmse: 0.7186\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5624 - acc: 0.8077 - rmse: 0.4328 - val_loss: 1.2682 - val_acc: 0.0000e+00 - val_rmse: 0.7187\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5610 - acc: 0.8077 - rmse: 0.4320 - val_loss: 1.2683 - val_acc: 0.0000e+00 - val_rmse: 0.7187\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5596 - acc: 0.8077 - rmse: 0.4312 - val_loss: 1.2685 - val_acc: 0.0000e+00 - val_rmse: 0.7188\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5581 - acc: 0.8077 - rmse: 0.4305 - val_loss: 1.2687 - val_acc: 0.0000e+00 - val_rmse: 0.7188\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5567 - acc: 0.8077 - rmse: 0.4297 - val_loss: 1.2689 - val_acc: 0.0000e+00 - val_rmse: 0.7189\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5553 - acc: 0.8077 - rmse: 0.4289 - val_loss: 1.2691 - val_acc: 0.0000e+00 - val_rmse: 0.7189\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5539 - acc: 0.8077 - rmse: 0.4281 - val_loss: 1.2693 - val_acc: 0.0000e+00 - val_rmse: 0.7190\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5525 - acc: 0.8077 - rmse: 0.4274 - val_loss: 1.2695 - val_acc: 0.0000e+00 - val_rmse: 0.7190\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5511 - acc: 0.8077 - rmse: 0.4266 - val_loss: 1.2697 - val_acc: 0.0000e+00 - val_rmse: 0.7191\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5497 - acc: 0.8077 - rmse: 0.4258 - val_loss: 1.2699 - val_acc: 0.0000e+00 - val_rmse: 0.7191\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5483 - acc: 0.8077 - rmse: 0.4250 - val_loss: 1.2701 - val_acc: 0.0000e+00 - val_rmse: 0.7192\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5469 - acc: 0.8077 - rmse: 0.4243 - val_loss: 1.2703 - val_acc: 0.0000e+00 - val_rmse: 0.7192\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5455 - acc: 0.8077 - rmse: 0.4235 - val_loss: 1.2705 - val_acc: 0.0000e+00 - val_rmse: 0.7193\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5441 - acc: 0.8077 - rmse: 0.4227 - val_loss: 1.2707 - val_acc: 0.0000e+00 - val_rmse: 0.7194\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5427 - acc: 0.8077 - rmse: 0.4219 - val_loss: 1.2709 - val_acc: 0.0000e+00 - val_rmse: 0.7194\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5414 - acc: 0.8077 - rmse: 0.4212 - val_loss: 1.2711 - val_acc: 0.0000e+00 - val_rmse: 0.7195\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5400 - acc: 0.8077 - rmse: 0.4204 - val_loss: 1.2713 - val_acc: 0.0000e+00 - val_rmse: 0.7195\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5386 - acc: 0.8077 - rmse: 0.4196 - val_loss: 1.2715 - val_acc: 0.0000e+00 - val_rmse: 0.7196\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5373 - acc: 0.8077 - rmse: 0.4189 - val_loss: 1.2717 - val_acc: 0.0000e+00 - val_rmse: 0.7196\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5359 - acc: 0.8077 - rmse: 0.4181 - val_loss: 1.2719 - val_acc: 0.0000e+00 - val_rmse: 0.7197\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5346 - acc: 0.8077 - rmse: 0.4173 - val_loss: 1.2721 - val_acc: 0.0000e+00 - val_rmse: 0.7198\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5332 - acc: 0.8077 - rmse: 0.4166 - val_loss: 1.2723 - val_acc: 0.0000e+00 - val_rmse: 0.7198\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5319 - acc: 0.8077 - rmse: 0.4158 - val_loss: 1.2726 - val_acc: 0.0000e+00 - val_rmse: 0.7199\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5305 - acc: 0.8077 - rmse: 0.4151 - val_loss: 1.2728 - val_acc: 0.0000e+00 - val_rmse: 0.7199\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5292 - acc: 0.8077 - rmse: 0.4143 - val_loss: 1.2730 - val_acc: 0.0000e+00 - val_rmse: 0.7200\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5279 - acc: 0.8077 - rmse: 0.4136 - val_loss: 1.2732 - val_acc: 0.0000e+00 - val_rmse: 0.7201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5266 - acc: 0.8077 - rmse: 0.4128 - val_loss: 1.2734 - val_acc: 0.0000e+00 - val_rmse: 0.7201\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5253 - acc: 0.8077 - rmse: 0.4121 - val_loss: 1.2736 - val_acc: 0.0000e+00 - val_rmse: 0.7202\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5240 - acc: 0.8077 - rmse: 0.4114 - val_loss: 1.2739 - val_acc: 0.0000e+00 - val_rmse: 0.7203\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5227 - acc: 0.8077 - rmse: 0.4106 - val_loss: 1.2741 - val_acc: 0.0000e+00 - val_rmse: 0.7203\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5214 - acc: 0.8077 - rmse: 0.4099 - val_loss: 1.2743 - val_acc: 0.0000e+00 - val_rmse: 0.7204\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5201 - acc: 0.8462 - rmse: 0.4092 - val_loss: 1.2745 - val_acc: 0.0000e+00 - val_rmse: 0.7204\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38158\n",
      " - 4s - loss: 0.7441 - acc: 0.6538 - rmse: 0.5158 - val_loss: 0.6274 - val_acc: 1.0000 - val_rmse: 0.4660\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7408 - acc: 0.6538 - rmse: 0.5145 - val_loss: 0.6275 - val_acc: 1.0000 - val_rmse: 0.4661\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7375 - acc: 0.6538 - rmse: 0.5131 - val_loss: 0.6276 - val_acc: 1.0000 - val_rmse: 0.4661\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7343 - acc: 0.6538 - rmse: 0.5118 - val_loss: 0.6277 - val_acc: 1.0000 - val_rmse: 0.4662\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7311 - acc: 0.6538 - rmse: 0.5105 - val_loss: 0.6278 - val_acc: 1.0000 - val_rmse: 0.4662\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7281 - acc: 0.6538 - rmse: 0.5093 - val_loss: 0.6279 - val_acc: 1.0000 - val_rmse: 0.4663\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7250 - acc: 0.6538 - rmse: 0.5080 - val_loss: 0.6279 - val_acc: 1.0000 - val_rmse: 0.4663\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7221 - acc: 0.6538 - rmse: 0.5068 - val_loss: 0.6280 - val_acc: 1.0000 - val_rmse: 0.4664\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7191 - acc: 0.6538 - rmse: 0.5056 - val_loss: 0.6281 - val_acc: 1.0000 - val_rmse: 0.4664\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7162 - acc: 0.6538 - rmse: 0.5044 - val_loss: 0.6282 - val_acc: 1.0000 - val_rmse: 0.4664\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7133 - acc: 0.6923 - rmse: 0.5032 - val_loss: 0.6283 - val_acc: 1.0000 - val_rmse: 0.4665\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7104 - acc: 0.6923 - rmse: 0.5020 - val_loss: 0.6284 - val_acc: 1.0000 - val_rmse: 0.4665\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7076 - acc: 0.6923 - rmse: 0.5008 - val_loss: 0.6284 - val_acc: 1.0000 - val_rmse: 0.4666\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7047 - acc: 0.6923 - rmse: 0.4996 - val_loss: 0.6285 - val_acc: 1.0000 - val_rmse: 0.4666\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.7019 - acc: 0.6923 - rmse: 0.4984 - val_loss: 0.6286 - val_acc: 1.0000 - val_rmse: 0.4667\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6991 - acc: 0.6923 - rmse: 0.4973 - val_loss: 0.6287 - val_acc: 1.0000 - val_rmse: 0.4667\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6963 - acc: 0.6923 - rmse: 0.4961 - val_loss: 0.6287 - val_acc: 1.0000 - val_rmse: 0.4667\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6935 - acc: 0.6923 - rmse: 0.4949 - val_loss: 0.6288 - val_acc: 1.0000 - val_rmse: 0.4668\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6907 - acc: 0.6923 - rmse: 0.4937 - val_loss: 0.6289 - val_acc: 1.0000 - val_rmse: 0.4668\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6879 - acc: 0.6923 - rmse: 0.4925 - val_loss: 0.6290 - val_acc: 1.0000 - val_rmse: 0.4669\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6851 - acc: 0.6923 - rmse: 0.4913 - val_loss: 0.6290 - val_acc: 1.0000 - val_rmse: 0.4669\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6823 - acc: 0.6923 - rmse: 0.4901 - val_loss: 0.6291 - val_acc: 1.0000 - val_rmse: 0.4669\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6796 - acc: 0.6923 - rmse: 0.4889 - val_loss: 0.6292 - val_acc: 1.0000 - val_rmse: 0.4670\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6769 - acc: 0.6923 - rmse: 0.4878 - val_loss: 0.6293 - val_acc: 1.0000 - val_rmse: 0.4670\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6742 - acc: 0.6923 - rmse: 0.4866 - val_loss: 0.6293 - val_acc: 1.0000 - val_rmse: 0.4671\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6714 - acc: 0.6923 - rmse: 0.4854 - val_loss: 0.6294 - val_acc: 1.0000 - val_rmse: 0.4671\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6687 - acc: 0.6923 - rmse: 0.4842 - val_loss: 0.6295 - val_acc: 1.0000 - val_rmse: 0.4671\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6660 - acc: 0.6923 - rmse: 0.4830 - val_loss: 0.6296 - val_acc: 1.0000 - val_rmse: 0.4672\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6634 - acc: 0.6923 - rmse: 0.4819 - val_loss: 0.6296 - val_acc: 1.0000 - val_rmse: 0.4672\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6607 - acc: 0.6923 - rmse: 0.4807 - val_loss: 0.6297 - val_acc: 1.0000 - val_rmse: 0.4673\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6580 - acc: 0.6923 - rmse: 0.4795 - val_loss: 0.6298 - val_acc: 1.0000 - val_rmse: 0.4673\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6554 - acc: 0.6923 - rmse: 0.4783 - val_loss: 0.6299 - val_acc: 1.0000 - val_rmse: 0.4673\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6527 - acc: 0.6923 - rmse: 0.4771 - val_loss: 0.6299 - val_acc: 1.0000 - val_rmse: 0.4674\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6501 - acc: 0.6923 - rmse: 0.4760 - val_loss: 0.6300 - val_acc: 1.0000 - val_rmse: 0.4674\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6475 - acc: 0.6923 - rmse: 0.4748 - val_loss: 0.6301 - val_acc: 1.0000 - val_rmse: 0.4675\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6449 - acc: 0.6923 - rmse: 0.4736 - val_loss: 0.6302 - val_acc: 1.0000 - val_rmse: 0.4675\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6423 - acc: 0.6923 - rmse: 0.4724 - val_loss: 0.6303 - val_acc: 1.0000 - val_rmse: 0.4675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6397 - acc: 0.6923 - rmse: 0.4712 - val_loss: 0.6303 - val_acc: 1.0000 - val_rmse: 0.4676\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6371 - acc: 0.6923 - rmse: 0.4701 - val_loss: 0.6304 - val_acc: 1.0000 - val_rmse: 0.4676\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6345 - acc: 0.6923 - rmse: 0.4689 - val_loss: 0.6305 - val_acc: 1.0000 - val_rmse: 0.4677\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6319 - acc: 0.6923 - rmse: 0.4677 - val_loss: 0.6306 - val_acc: 1.0000 - val_rmse: 0.4677\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6294 - acc: 0.6923 - rmse: 0.4665 - val_loss: 0.6306 - val_acc: 1.0000 - val_rmse: 0.4677\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6268 - acc: 0.6923 - rmse: 0.4654 - val_loss: 0.6307 - val_acc: 1.0000 - val_rmse: 0.4678\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6243 - acc: 0.7308 - rmse: 0.4642 - val_loss: 0.6308 - val_acc: 1.0000 - val_rmse: 0.4678\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6218 - acc: 0.7308 - rmse: 0.4630 - val_loss: 0.6309 - val_acc: 1.0000 - val_rmse: 0.4679\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6193 - acc: 0.7308 - rmse: 0.4618 - val_loss: 0.6309 - val_acc: 1.0000 - val_rmse: 0.4679\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6168 - acc: 0.7308 - rmse: 0.4607 - val_loss: 0.6310 - val_acc: 1.0000 - val_rmse: 0.4680\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6143 - acc: 0.7308 - rmse: 0.4595 - val_loss: 0.6311 - val_acc: 1.0000 - val_rmse: 0.4680\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6118 - acc: 0.7308 - rmse: 0.4583 - val_loss: 0.6312 - val_acc: 1.0000 - val_rmse: 0.4680\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.6094 - acc: 0.7308 - rmse: 0.4572 - val_loss: 0.6312 - val_acc: 1.0000 - val_rmse: 0.4681\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6070 - acc: 0.7308 - rmse: 0.4560 - val_loss: 0.6313 - val_acc: 1.0000 - val_rmse: 0.4681\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6046 - acc: 0.7308 - rmse: 0.4549 - val_loss: 0.6314 - val_acc: 1.0000 - val_rmse: 0.4681\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.6021 - acc: 0.7308 - rmse: 0.4537 - val_loss: 0.6315 - val_acc: 1.0000 - val_rmse: 0.4682\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5997 - acc: 0.7308 - rmse: 0.4526 - val_loss: 0.6315 - val_acc: 1.0000 - val_rmse: 0.4682\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5973 - acc: 0.7308 - rmse: 0.4514 - val_loss: 0.6316 - val_acc: 1.0000 - val_rmse: 0.4683\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5949 - acc: 0.7308 - rmse: 0.4503 - val_loss: 0.6317 - val_acc: 1.0000 - val_rmse: 0.4683\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5926 - acc: 0.7308 - rmse: 0.4491 - val_loss: 0.6318 - val_acc: 1.0000 - val_rmse: 0.4683\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5902 - acc: 0.7308 - rmse: 0.4480 - val_loss: 0.6318 - val_acc: 1.0000 - val_rmse: 0.4684\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5878 - acc: 0.7308 - rmse: 0.4468 - val_loss: 0.6319 - val_acc: 1.0000 - val_rmse: 0.4684\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5855 - acc: 0.7308 - rmse: 0.4456 - val_loss: 0.6320 - val_acc: 1.0000 - val_rmse: 0.4685\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5831 - acc: 0.7308 - rmse: 0.4445 - val_loss: 0.6320 - val_acc: 1.0000 - val_rmse: 0.4685\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5808 - acc: 0.7692 - rmse: 0.4434 - val_loss: 0.6321 - val_acc: 1.0000 - val_rmse: 0.4685\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5785 - acc: 0.7692 - rmse: 0.4422 - val_loss: 0.6322 - val_acc: 1.0000 - val_rmse: 0.4686\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5762 - acc: 0.7692 - rmse: 0.4411 - val_loss: 0.6322 - val_acc: 1.0000 - val_rmse: 0.4686\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5739 - acc: 0.7692 - rmse: 0.4399 - val_loss: 0.6323 - val_acc: 1.0000 - val_rmse: 0.4686\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5716 - acc: 0.7692 - rmse: 0.4388 - val_loss: 0.6324 - val_acc: 1.0000 - val_rmse: 0.4687\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5694 - acc: 0.7692 - rmse: 0.4376 - val_loss: 0.6324 - val_acc: 1.0000 - val_rmse: 0.4687\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5671 - acc: 0.7692 - rmse: 0.4365 - val_loss: 0.6325 - val_acc: 1.0000 - val_rmse: 0.4687\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5648 - acc: 0.7692 - rmse: 0.4353 - val_loss: 0.6326 - val_acc: 1.0000 - val_rmse: 0.4688\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5626 - acc: 0.7692 - rmse: 0.4342 - val_loss: 0.6326 - val_acc: 1.0000 - val_rmse: 0.4688\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5603 - acc: 0.7692 - rmse: 0.4331 - val_loss: 0.6327 - val_acc: 1.0000 - val_rmse: 0.4688\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5581 - acc: 0.7692 - rmse: 0.4319 - val_loss: 0.6328 - val_acc: 1.0000 - val_rmse: 0.4689\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5558 - acc: 0.7692 - rmse: 0.4308 - val_loss: 0.6328 - val_acc: 1.0000 - val_rmse: 0.4689\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5536 - acc: 0.7692 - rmse: 0.4296 - val_loss: 0.6329 - val_acc: 1.0000 - val_rmse: 0.4690\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5514 - acc: 0.7692 - rmse: 0.4285 - val_loss: 0.6330 - val_acc: 1.0000 - val_rmse: 0.4690\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5491 - acc: 0.7692 - rmse: 0.4273 - val_loss: 0.6330 - val_acc: 1.0000 - val_rmse: 0.4690\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5469 - acc: 0.7692 - rmse: 0.4262 - val_loss: 0.6331 - val_acc: 1.0000 - val_rmse: 0.4691\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5447 - acc: 0.7692 - rmse: 0.4250 - val_loss: 0.6332 - val_acc: 1.0000 - val_rmse: 0.4691\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5425 - acc: 0.7692 - rmse: 0.4239 - val_loss: 0.6332 - val_acc: 1.0000 - val_rmse: 0.4691\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5403 - acc: 0.7692 - rmse: 0.4227 - val_loss: 0.6333 - val_acc: 1.0000 - val_rmse: 0.4692\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5381 - acc: 0.7692 - rmse: 0.4216 - val_loss: 0.6334 - val_acc: 1.0000 - val_rmse: 0.4692\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5360 - acc: 0.7692 - rmse: 0.4204 - val_loss: 0.6334 - val_acc: 1.0000 - val_rmse: 0.4692\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5338 - acc: 0.7692 - rmse: 0.4193 - val_loss: 0.6335 - val_acc: 1.0000 - val_rmse: 0.4693\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5316 - acc: 0.7692 - rmse: 0.4181 - val_loss: 0.6336 - val_acc: 1.0000 - val_rmse: 0.4693\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5295 - acc: 0.7692 - rmse: 0.4170 - val_loss: 0.6336 - val_acc: 1.0000 - val_rmse: 0.4693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5273 - acc: 0.7692 - rmse: 0.4158 - val_loss: 0.6337 - val_acc: 1.0000 - val_rmse: 0.4694\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5252 - acc: 0.7692 - rmse: 0.4147 - val_loss: 0.6338 - val_acc: 1.0000 - val_rmse: 0.4694\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5230 - acc: 0.7692 - rmse: 0.4136 - val_loss: 0.6338 - val_acc: 1.0000 - val_rmse: 0.4694\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5209 - acc: 0.7692 - rmse: 0.4124 - val_loss: 0.6339 - val_acc: 1.0000 - val_rmse: 0.4695\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5188 - acc: 0.7692 - rmse: 0.4113 - val_loss: 0.6339 - val_acc: 1.0000 - val_rmse: 0.4695\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5167 - acc: 0.7692 - rmse: 0.4101 - val_loss: 0.6340 - val_acc: 1.0000 - val_rmse: 0.4695\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5146 - acc: 0.7692 - rmse: 0.4090 - val_loss: 0.6341 - val_acc: 1.0000 - val_rmse: 0.4696\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5125 - acc: 0.7692 - rmse: 0.4079 - val_loss: 0.6341 - val_acc: 1.0000 - val_rmse: 0.4696\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.5104 - acc: 0.7692 - rmse: 0.4067 - val_loss: 0.6342 - val_acc: 1.0000 - val_rmse: 0.4696\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5083 - acc: 0.7692 - rmse: 0.4056 - val_loss: 0.6343 - val_acc: 1.0000 - val_rmse: 0.4697\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5063 - acc: 0.7692 - rmse: 0.4044 - val_loss: 0.6343 - val_acc: 1.0000 - val_rmse: 0.4697\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5042 - acc: 0.7692 - rmse: 0.4033 - val_loss: 0.6344 - val_acc: 1.0000 - val_rmse: 0.4698\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5021 - acc: 0.7692 - rmse: 0.4021 - val_loss: 0.6345 - val_acc: 1.0000 - val_rmse: 0.4698\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.38158\n",
      " - 1s - loss: 0.5001 - acc: 0.8077 - rmse: 0.4010 - val_loss: 0.6345 - val_acc: 1.0000 - val_rmse: 0.4698\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.38158\n",
      " - 0s - loss: 0.4980 - acc: 0.8077 - rmse: 0.3999 - val_loss: 0.6346 - val_acc: 1.0000 - val_rmse: 0.4699\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_31 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38158 to 0.37937, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 14s - loss: 0.7811 - acc: 0.4615 - rmse: 0.5310 - val_loss: 0.3794 - val_acc: 1.0000 - val_rmse: 0.3157\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7785 - acc: 0.4615 - rmse: 0.5300 - val_loss: 0.3795 - val_acc: 1.0000 - val_rmse: 0.3158\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.7760 - acc: 0.4615 - rmse: 0.5291 - val_loss: 0.3796 - val_acc: 1.0000 - val_rmse: 0.3159\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.7735 - acc: 0.4615 - rmse: 0.5281 - val_loss: 0.3797 - val_acc: 1.0000 - val_rmse: 0.3159\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7710 - acc: 0.4615 - rmse: 0.5272 - val_loss: 0.3798 - val_acc: 1.0000 - val_rmse: 0.3160\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7685 - acc: 0.4615 - rmse: 0.5262 - val_loss: 0.3799 - val_acc: 1.0000 - val_rmse: 0.3161\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7660 - acc: 0.4615 - rmse: 0.5253 - val_loss: 0.3800 - val_acc: 1.0000 - val_rmse: 0.3162\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7636 - acc: 0.4615 - rmse: 0.5243 - val_loss: 0.3801 - val_acc: 1.0000 - val_rmse: 0.3162\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7611 - acc: 0.4615 - rmse: 0.5234 - val_loss: 0.3802 - val_acc: 1.0000 - val_rmse: 0.3163\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7586 - acc: 0.4615 - rmse: 0.5224 - val_loss: 0.3804 - val_acc: 1.0000 - val_rmse: 0.3164\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7561 - acc: 0.4615 - rmse: 0.5215 - val_loss: 0.3805 - val_acc: 1.0000 - val_rmse: 0.3165\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7537 - acc: 0.4615 - rmse: 0.5205 - val_loss: 0.3806 - val_acc: 1.0000 - val_rmse: 0.3165\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7513 - acc: 0.4615 - rmse: 0.5196 - val_loss: 0.3807 - val_acc: 1.0000 - val_rmse: 0.3166\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7489 - acc: 0.4615 - rmse: 0.5187 - val_loss: 0.3808 - val_acc: 1.0000 - val_rmse: 0.3167\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7466 - acc: 0.4615 - rmse: 0.5177 - val_loss: 0.3809 - val_acc: 1.0000 - val_rmse: 0.3168\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7442 - acc: 0.4615 - rmse: 0.5168 - val_loss: 0.3810 - val_acc: 1.0000 - val_rmse: 0.3168\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7419 - acc: 0.4615 - rmse: 0.5159 - val_loss: 0.3811 - val_acc: 1.0000 - val_rmse: 0.3169\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7395 - acc: 0.5000 - rmse: 0.5149 - val_loss: 0.3813 - val_acc: 1.0000 - val_rmse: 0.3170\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7372 - acc: 0.5000 - rmse: 0.5140 - val_loss: 0.3814 - val_acc: 1.0000 - val_rmse: 0.3171\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.7349 - acc: 0.5000 - rmse: 0.5131 - val_loss: 0.3815 - val_acc: 1.0000 - val_rmse: 0.3172\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.7326 - acc: 0.5000 - rmse: 0.5121 - val_loss: 0.3816 - val_acc: 1.0000 - val_rmse: 0.3172\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7303 - acc: 0.5000 - rmse: 0.5112 - val_loss: 0.3817 - val_acc: 1.0000 - val_rmse: 0.3173\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7279 - acc: 0.5000 - rmse: 0.5103 - val_loss: 0.3818 - val_acc: 1.0000 - val_rmse: 0.3174\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7256 - acc: 0.5000 - rmse: 0.5093 - val_loss: 0.3820 - val_acc: 1.0000 - val_rmse: 0.3175\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7233 - acc: 0.5000 - rmse: 0.5084 - val_loss: 0.3821 - val_acc: 1.0000 - val_rmse: 0.3176\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7211 - acc: 0.5000 - rmse: 0.5075 - val_loss: 0.3822 - val_acc: 1.0000 - val_rmse: 0.3176\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7188 - acc: 0.5000 - rmse: 0.5065 - val_loss: 0.3823 - val_acc: 1.0000 - val_rmse: 0.3177\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7166 - acc: 0.5000 - rmse: 0.5056 - val_loss: 0.3824 - val_acc: 1.0000 - val_rmse: 0.3178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7143 - acc: 0.5000 - rmse: 0.5047 - val_loss: 0.3826 - val_acc: 1.0000 - val_rmse: 0.3179\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.7121 - acc: 0.5000 - rmse: 0.5038 - val_loss: 0.3827 - val_acc: 1.0000 - val_rmse: 0.3180\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.7099 - acc: 0.5000 - rmse: 0.5029 - val_loss: 0.3828 - val_acc: 1.0000 - val_rmse: 0.3180\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.7077 - acc: 0.5000 - rmse: 0.5020 - val_loss: 0.3829 - val_acc: 1.0000 - val_rmse: 0.3181\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.7055 - acc: 0.5000 - rmse: 0.5011 - val_loss: 0.3830 - val_acc: 1.0000 - val_rmse: 0.3182\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.7033 - acc: 0.5000 - rmse: 0.5002 - val_loss: 0.3831 - val_acc: 1.0000 - val_rmse: 0.3183\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.7012 - acc: 0.5000 - rmse: 0.4993 - val_loss: 0.3833 - val_acc: 1.0000 - val_rmse: 0.3184\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6990 - acc: 0.5385 - rmse: 0.4983 - val_loss: 0.3834 - val_acc: 1.0000 - val_rmse: 0.3185\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6968 - acc: 0.5385 - rmse: 0.4974 - val_loss: 0.3835 - val_acc: 1.0000 - val_rmse: 0.3185\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6947 - acc: 0.5385 - rmse: 0.4965 - val_loss: 0.3836 - val_acc: 1.0000 - val_rmse: 0.3186\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6925 - acc: 0.5385 - rmse: 0.4956 - val_loss: 0.3838 - val_acc: 1.0000 - val_rmse: 0.3187\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6903 - acc: 0.5385 - rmse: 0.4947 - val_loss: 0.3839 - val_acc: 1.0000 - val_rmse: 0.3188\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6882 - acc: 0.5385 - rmse: 0.4938 - val_loss: 0.3840 - val_acc: 1.0000 - val_rmse: 0.3189\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6860 - acc: 0.5385 - rmse: 0.4928 - val_loss: 0.3841 - val_acc: 1.0000 - val_rmse: 0.3190\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6839 - acc: 0.5385 - rmse: 0.4919 - val_loss: 0.3842 - val_acc: 1.0000 - val_rmse: 0.3190\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6817 - acc: 0.5385 - rmse: 0.4910 - val_loss: 0.3844 - val_acc: 1.0000 - val_rmse: 0.3191\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6796 - acc: 0.5385 - rmse: 0.4901 - val_loss: 0.3845 - val_acc: 1.0000 - val_rmse: 0.3192\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6774 - acc: 0.5385 - rmse: 0.4892 - val_loss: 0.3846 - val_acc: 1.0000 - val_rmse: 0.3193\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6753 - acc: 0.5769 - rmse: 0.4882 - val_loss: 0.3847 - val_acc: 1.0000 - val_rmse: 0.3194\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6732 - acc: 0.5769 - rmse: 0.4873 - val_loss: 0.3849 - val_acc: 1.0000 - val_rmse: 0.3194\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6711 - acc: 0.6154 - rmse: 0.4864 - val_loss: 0.3850 - val_acc: 1.0000 - val_rmse: 0.3195\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6689 - acc: 0.6154 - rmse: 0.4855 - val_loss: 0.3851 - val_acc: 1.0000 - val_rmse: 0.3196\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6668 - acc: 0.6154 - rmse: 0.4845 - val_loss: 0.3852 - val_acc: 1.0000 - val_rmse: 0.3197\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6647 - acc: 0.6154 - rmse: 0.4836 - val_loss: 0.3853 - val_acc: 1.0000 - val_rmse: 0.3198\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6626 - acc: 0.6154 - rmse: 0.4827 - val_loss: 0.3855 - val_acc: 1.0000 - val_rmse: 0.3199\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6606 - acc: 0.6154 - rmse: 0.4818 - val_loss: 0.3856 - val_acc: 1.0000 - val_rmse: 0.3200\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6585 - acc: 0.6154 - rmse: 0.4809 - val_loss: 0.3857 - val_acc: 1.0000 - val_rmse: 0.3200\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6565 - acc: 0.6154 - rmse: 0.4800 - val_loss: 0.3858 - val_acc: 1.0000 - val_rmse: 0.3201\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6544 - acc: 0.6154 - rmse: 0.4791 - val_loss: 0.3860 - val_acc: 1.0000 - val_rmse: 0.3202\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6524 - acc: 0.6154 - rmse: 0.4782 - val_loss: 0.3861 - val_acc: 1.0000 - val_rmse: 0.3203\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6504 - acc: 0.6154 - rmse: 0.4772 - val_loss: 0.3862 - val_acc: 1.0000 - val_rmse: 0.3204\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6483 - acc: 0.6154 - rmse: 0.4763 - val_loss: 0.3863 - val_acc: 1.0000 - val_rmse: 0.3205\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6463 - acc: 0.6154 - rmse: 0.4754 - val_loss: 0.3865 - val_acc: 1.0000 - val_rmse: 0.3205\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6443 - acc: 0.6154 - rmse: 0.4745 - val_loss: 0.3866 - val_acc: 1.0000 - val_rmse: 0.3206\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6423 - acc: 0.6154 - rmse: 0.4736 - val_loss: 0.3867 - val_acc: 1.0000 - val_rmse: 0.3207\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6403 - acc: 0.6538 - rmse: 0.4727 - val_loss: 0.3869 - val_acc: 1.0000 - val_rmse: 0.3208\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6383 - acc: 0.6538 - rmse: 0.4718 - val_loss: 0.3870 - val_acc: 1.0000 - val_rmse: 0.3209\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6363 - acc: 0.6538 - rmse: 0.4709 - val_loss: 0.3871 - val_acc: 1.0000 - val_rmse: 0.3210\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6343 - acc: 0.6923 - rmse: 0.4700 - val_loss: 0.3872 - val_acc: 1.0000 - val_rmse: 0.3211\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6323 - acc: 0.6923 - rmse: 0.4691 - val_loss: 0.3874 - val_acc: 1.0000 - val_rmse: 0.3212\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6303 - acc: 0.6923 - rmse: 0.4681 - val_loss: 0.3875 - val_acc: 1.0000 - val_rmse: 0.3212\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6283 - acc: 0.6923 - rmse: 0.4672 - val_loss: 0.3876 - val_acc: 1.0000 - val_rmse: 0.3213\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6263 - acc: 0.7308 - rmse: 0.4663 - val_loss: 0.3878 - val_acc: 1.0000 - val_rmse: 0.3214\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6244 - acc: 0.7308 - rmse: 0.4654 - val_loss: 0.3879 - val_acc: 1.0000 - val_rmse: 0.3215\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6224 - acc: 0.7308 - rmse: 0.4645 - val_loss: 0.3880 - val_acc: 1.0000 - val_rmse: 0.3216\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6205 - acc: 0.7308 - rmse: 0.4636 - val_loss: 0.3882 - val_acc: 1.0000 - val_rmse: 0.3217\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6186 - acc: 0.7308 - rmse: 0.4627 - val_loss: 0.3883 - val_acc: 1.0000 - val_rmse: 0.3218\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6166 - acc: 0.7308 - rmse: 0.4618 - val_loss: 0.3884 - val_acc: 1.0000 - val_rmse: 0.3219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6147 - acc: 0.7308 - rmse: 0.4609 - val_loss: 0.3885 - val_acc: 1.0000 - val_rmse: 0.3220\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6128 - acc: 0.7308 - rmse: 0.4600 - val_loss: 0.3887 - val_acc: 1.0000 - val_rmse: 0.3220\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6109 - acc: 0.7308 - rmse: 0.4591 - val_loss: 0.3888 - val_acc: 1.0000 - val_rmse: 0.3221\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6089 - acc: 0.7308 - rmse: 0.4582 - val_loss: 0.3889 - val_acc: 1.0000 - val_rmse: 0.3222\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6070 - acc: 0.7308 - rmse: 0.4573 - val_loss: 0.3891 - val_acc: 1.0000 - val_rmse: 0.3223\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6051 - acc: 0.7308 - rmse: 0.4564 - val_loss: 0.3892 - val_acc: 1.0000 - val_rmse: 0.3224\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6032 - acc: 0.7308 - rmse: 0.4555 - val_loss: 0.3893 - val_acc: 1.0000 - val_rmse: 0.3225\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6013 - acc: 0.7308 - rmse: 0.4546 - val_loss: 0.3895 - val_acc: 1.0000 - val_rmse: 0.3226\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5994 - acc: 0.7308 - rmse: 0.4537 - val_loss: 0.3896 - val_acc: 1.0000 - val_rmse: 0.3227\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5975 - acc: 0.7308 - rmse: 0.4528 - val_loss: 0.3898 - val_acc: 1.0000 - val_rmse: 0.3228\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5957 - acc: 0.7308 - rmse: 0.4519 - val_loss: 0.3899 - val_acc: 1.0000 - val_rmse: 0.3229\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5938 - acc: 0.7308 - rmse: 0.4510 - val_loss: 0.3900 - val_acc: 1.0000 - val_rmse: 0.3230\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5919 - acc: 0.7308 - rmse: 0.4501 - val_loss: 0.3902 - val_acc: 1.0000 - val_rmse: 0.3230\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5900 - acc: 0.7308 - rmse: 0.4492 - val_loss: 0.3903 - val_acc: 1.0000 - val_rmse: 0.3231\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5882 - acc: 0.7308 - rmse: 0.4483 - val_loss: 0.3904 - val_acc: 1.0000 - val_rmse: 0.3232\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5863 - acc: 0.7308 - rmse: 0.4474 - val_loss: 0.3906 - val_acc: 1.0000 - val_rmse: 0.3233\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5845 - acc: 0.7308 - rmse: 0.4465 - val_loss: 0.3907 - val_acc: 1.0000 - val_rmse: 0.3234\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5826 - acc: 0.7308 - rmse: 0.4456 - val_loss: 0.3908 - val_acc: 1.0000 - val_rmse: 0.3235\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5808 - acc: 0.7308 - rmse: 0.4447 - val_loss: 0.3910 - val_acc: 1.0000 - val_rmse: 0.3236\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5789 - acc: 0.7308 - rmse: 0.4439 - val_loss: 0.3911 - val_acc: 1.0000 - val_rmse: 0.3237\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5771 - acc: 0.7308 - rmse: 0.4430 - val_loss: 0.3912 - val_acc: 1.0000 - val_rmse: 0.3238\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5753 - acc: 0.7692 - rmse: 0.4421 - val_loss: 0.3914 - val_acc: 1.0000 - val_rmse: 0.3239\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5735 - acc: 0.7692 - rmse: 0.4412 - val_loss: 0.3915 - val_acc: 1.0000 - val_rmse: 0.3240\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5717 - acc: 0.7692 - rmse: 0.4403 - val_loss: 0.3916 - val_acc: 1.0000 - val_rmse: 0.3241\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_32 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.37937\n",
      " - 4s - loss: 0.6783 - acc: 0.6538 - rmse: 0.4920 - val_loss: 0.8458 - val_acc: 0.0000e+00 - val_rmse: 0.5708\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6763 - acc: 0.6538 - rmse: 0.4911 - val_loss: 0.8457 - val_acc: 0.0000e+00 - val_rmse: 0.5708\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6744 - acc: 0.6538 - rmse: 0.4902 - val_loss: 0.8457 - val_acc: 0.0000e+00 - val_rmse: 0.5707\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6725 - acc: 0.6538 - rmse: 0.4892 - val_loss: 0.8457 - val_acc: 0.0000e+00 - val_rmse: 0.5707\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6706 - acc: 0.6538 - rmse: 0.4883 - val_loss: 0.8457 - val_acc: 0.0000e+00 - val_rmse: 0.5707\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6687 - acc: 0.6538 - rmse: 0.4874 - val_loss: 0.8456 - val_acc: 0.0000e+00 - val_rmse: 0.5707\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6668 - acc: 0.6538 - rmse: 0.4865 - val_loss: 0.8456 - val_acc: 0.0000e+00 - val_rmse: 0.5707\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6649 - acc: 0.6538 - rmse: 0.4856 - val_loss: 0.8456 - val_acc: 0.0000e+00 - val_rmse: 0.5707\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6630 - acc: 0.6538 - rmse: 0.4847 - val_loss: 0.8455 - val_acc: 0.0000e+00 - val_rmse: 0.5707\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6611 - acc: 0.6538 - rmse: 0.4838 - val_loss: 0.8455 - val_acc: 0.0000e+00 - val_rmse: 0.5707\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6592 - acc: 0.6538 - rmse: 0.4829 - val_loss: 0.8455 - val_acc: 0.0000e+00 - val_rmse: 0.5706\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6574 - acc: 0.6538 - rmse: 0.4820 - val_loss: 0.8455 - val_acc: 0.0000e+00 - val_rmse: 0.5706\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6556 - acc: 0.6538 - rmse: 0.4810 - val_loss: 0.8454 - val_acc: 0.0000e+00 - val_rmse: 0.5706\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6537 - acc: 0.6538 - rmse: 0.4801 - val_loss: 0.8454 - val_acc: 0.0000e+00 - val_rmse: 0.5706\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6519 - acc: 0.6538 - rmse: 0.4792 - val_loss: 0.8454 - val_acc: 0.0000e+00 - val_rmse: 0.5706\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6500 - acc: 0.6538 - rmse: 0.4783 - val_loss: 0.8453 - val_acc: 0.0000e+00 - val_rmse: 0.5706\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6482 - acc: 0.6538 - rmse: 0.4774 - val_loss: 0.8453 - val_acc: 0.0000e+00 - val_rmse: 0.5706\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6464 - acc: 0.6538 - rmse: 0.4765 - val_loss: 0.8453 - val_acc: 0.0000e+00 - val_rmse: 0.5706\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6446 - acc: 0.6538 - rmse: 0.4757 - val_loss: 0.8453 - val_acc: 0.0000e+00 - val_rmse: 0.5706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6428 - acc: 0.6923 - rmse: 0.4748 - val_loss: 0.8452 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6410 - acc: 0.6923 - rmse: 0.4739 - val_loss: 0.8452 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6392 - acc: 0.6923 - rmse: 0.4730 - val_loss: 0.8452 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6374 - acc: 0.6923 - rmse: 0.4721 - val_loss: 0.8452 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6357 - acc: 0.6923 - rmse: 0.4712 - val_loss: 0.8452 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6339 - acc: 0.6923 - rmse: 0.4703 - val_loss: 0.8451 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6321 - acc: 0.6923 - rmse: 0.4694 - val_loss: 0.8451 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6304 - acc: 0.6923 - rmse: 0.4686 - val_loss: 0.8451 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6287 - acc: 0.6923 - rmse: 0.4677 - val_loss: 0.8451 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6269 - acc: 0.6923 - rmse: 0.4668 - val_loss: 0.8451 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6252 - acc: 0.6923 - rmse: 0.4659 - val_loss: 0.8450 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6235 - acc: 0.6923 - rmse: 0.4651 - val_loss: 0.8450 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6217 - acc: 0.6923 - rmse: 0.4642 - val_loss: 0.8450 - val_acc: 0.0000e+00 - val_rmse: 0.5705\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6200 - acc: 0.6923 - rmse: 0.4633 - val_loss: 0.8450 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6183 - acc: 0.6923 - rmse: 0.4624 - val_loss: 0.8450 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6166 - acc: 0.6923 - rmse: 0.4615 - val_loss: 0.8450 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6149 - acc: 0.7308 - rmse: 0.4607 - val_loss: 0.8450 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6132 - acc: 0.7692 - rmse: 0.4598 - val_loss: 0.8450 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6115 - acc: 0.7692 - rmse: 0.4589 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6098 - acc: 0.7692 - rmse: 0.4580 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6081 - acc: 0.7692 - rmse: 0.4572 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6064 - acc: 0.7692 - rmse: 0.4563 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6048 - acc: 0.7692 - rmse: 0.4554 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.6031 - acc: 0.7692 - rmse: 0.4546 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.6014 - acc: 0.7692 - rmse: 0.4537 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5998 - acc: 0.7692 - rmse: 0.4528 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5981 - acc: 0.7692 - rmse: 0.4519 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5964 - acc: 0.7692 - rmse: 0.4511 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5948 - acc: 0.7692 - rmse: 0.4502 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5931 - acc: 0.8077 - rmse: 0.4493 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5915 - acc: 0.8077 - rmse: 0.4485 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5898 - acc: 0.8077 - rmse: 0.4476 - val_loss: 0.8449 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5882 - acc: 0.8077 - rmse: 0.4467 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5866 - acc: 0.8077 - rmse: 0.4459 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5849 - acc: 0.8077 - rmse: 0.4450 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5834 - acc: 0.8077 - rmse: 0.4442 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5818 - acc: 0.8077 - rmse: 0.4433 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5803 - acc: 0.8077 - rmse: 0.4425 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5787 - acc: 0.8077 - rmse: 0.4417 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5772 - acc: 0.8077 - rmse: 0.4408 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5757 - acc: 0.8077 - rmse: 0.4400 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5742 - acc: 0.8077 - rmse: 0.4392 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.37937\n",
      " - 0s - loss: 0.5727 - acc: 0.8077 - rmse: 0.4384 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5712 - acc: 0.8077 - rmse: 0.4376 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5696 - acc: 0.8077 - rmse: 0.4367 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5704\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5681 - acc: 0.8077 - rmse: 0.4359 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5703\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5666 - acc: 0.8077 - rmse: 0.4351 - val_loss: 0.8448 - val_acc: 0.0000e+00 - val_rmse: 0.5703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5652 - acc: 0.8077 - rmse: 0.4343 - val_loss: 0.8447 - val_acc: 0.0000e+00 - val_rmse: 0.5703\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5637 - acc: 0.8077 - rmse: 0.4335 - val_loss: 0.8447 - val_acc: 0.0000e+00 - val_rmse: 0.5703\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5622 - acc: 0.8077 - rmse: 0.4327 - val_loss: 0.8447 - val_acc: 0.0000e+00 - val_rmse: 0.5703\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5607 - acc: 0.8077 - rmse: 0.4318 - val_loss: 0.8446 - val_acc: 0.0000e+00 - val_rmse: 0.5703\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5592 - acc: 0.8077 - rmse: 0.4310 - val_loss: 0.8446 - val_acc: 0.0000e+00 - val_rmse: 0.5703\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5577 - acc: 0.8077 - rmse: 0.4302 - val_loss: 0.8446 - val_acc: 0.0000e+00 - val_rmse: 0.5703\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5562 - acc: 0.8462 - rmse: 0.4294 - val_loss: 0.8446 - val_acc: 0.0000e+00 - val_rmse: 0.5703\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5547 - acc: 0.8462 - rmse: 0.4286 - val_loss: 0.8445 - val_acc: 0.0000e+00 - val_rmse: 0.5702\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5533 - acc: 0.8462 - rmse: 0.4277 - val_loss: 0.8445 - val_acc: 0.0000e+00 - val_rmse: 0.5702\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5518 - acc: 0.8462 - rmse: 0.4269 - val_loss: 0.8445 - val_acc: 0.0000e+00 - val_rmse: 0.5702\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5503 - acc: 0.8462 - rmse: 0.4261 - val_loss: 0.8445 - val_acc: 0.0000e+00 - val_rmse: 0.5702\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5488 - acc: 0.8462 - rmse: 0.4253 - val_loss: 0.8444 - val_acc: 0.0000e+00 - val_rmse: 0.5702\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5474 - acc: 0.8462 - rmse: 0.4245 - val_loss: 0.8444 - val_acc: 0.0000e+00 - val_rmse: 0.5702\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5460 - acc: 0.8462 - rmse: 0.4237 - val_loss: 0.8444 - val_acc: 0.0000e+00 - val_rmse: 0.5702\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5445 - acc: 0.8462 - rmse: 0.4229 - val_loss: 0.8444 - val_acc: 0.0000e+00 - val_rmse: 0.5702\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5431 - acc: 0.8462 - rmse: 0.4221 - val_loss: 0.8443 - val_acc: 0.0000e+00 - val_rmse: 0.5702\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5417 - acc: 0.8462 - rmse: 0.4213 - val_loss: 0.8443 - val_acc: 0.0000e+00 - val_rmse: 0.5701\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5403 - acc: 0.8462 - rmse: 0.4205 - val_loss: 0.8443 - val_acc: 0.0000e+00 - val_rmse: 0.5701\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5389 - acc: 0.8462 - rmse: 0.4197 - val_loss: 0.8443 - val_acc: 0.0000e+00 - val_rmse: 0.5701\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5375 - acc: 0.8846 - rmse: 0.4189 - val_loss: 0.8442 - val_acc: 0.0000e+00 - val_rmse: 0.5701\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5361 - acc: 0.8846 - rmse: 0.4181 - val_loss: 0.8442 - val_acc: 0.0000e+00 - val_rmse: 0.5701\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5347 - acc: 0.8846 - rmse: 0.4173 - val_loss: 0.8442 - val_acc: 0.0000e+00 - val_rmse: 0.5701\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5333 - acc: 0.8846 - rmse: 0.4165 - val_loss: 0.8441 - val_acc: 0.0000e+00 - val_rmse: 0.5701\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5319 - acc: 0.8846 - rmse: 0.4157 - val_loss: 0.8441 - val_acc: 0.0000e+00 - val_rmse: 0.5701\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5305 - acc: 0.8846 - rmse: 0.4150 - val_loss: 0.8441 - val_acc: 0.0000e+00 - val_rmse: 0.5700\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5291 - acc: 0.8846 - rmse: 0.4142 - val_loss: 0.8441 - val_acc: 0.0000e+00 - val_rmse: 0.5700\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5278 - acc: 0.8846 - rmse: 0.4134 - val_loss: 0.8440 - val_acc: 0.0000e+00 - val_rmse: 0.5700\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5264 - acc: 0.8846 - rmse: 0.4126 - val_loss: 0.8440 - val_acc: 0.0000e+00 - val_rmse: 0.5700\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5250 - acc: 0.8846 - rmse: 0.4119 - val_loss: 0.8440 - val_acc: 0.0000e+00 - val_rmse: 0.5700\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5237 - acc: 0.8846 - rmse: 0.4111 - val_loss: 0.8439 - val_acc: 0.0000e+00 - val_rmse: 0.5700\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5223 - acc: 0.8846 - rmse: 0.4103 - val_loss: 0.8439 - val_acc: 0.0000e+00 - val_rmse: 0.5700\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5210 - acc: 0.8846 - rmse: 0.4095 - val_loss: 0.8439 - val_acc: 0.0000e+00 - val_rmse: 0.5699\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5196 - acc: 0.8846 - rmse: 0.4087 - val_loss: 0.8438 - val_acc: 0.0000e+00 - val_rmse: 0.5699\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.37937\n",
      " - 1s - loss: 0.5183 - acc: 0.8846 - rmse: 0.4080 - val_loss: 0.8438 - val_acc: 0.0000e+00 - val_rmse: 0.5699\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_33 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37937 to 0.34051, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 14s - loss: 0.7332 - acc: 0.5769 - rmse: 0.5131 - val_loss: 0.3405 - val_acc: 1.0000 - val_rmse: 0.2886\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7307 - acc: 0.5769 - rmse: 0.5120 - val_loss: 0.3406 - val_acc: 1.0000 - val_rmse: 0.2886\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7283 - acc: 0.5769 - rmse: 0.5109 - val_loss: 0.3406 - val_acc: 1.0000 - val_rmse: 0.2887\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7258 - acc: 0.5769 - rmse: 0.5099 - val_loss: 0.3407 - val_acc: 1.0000 - val_rmse: 0.2887\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7234 - acc: 0.5769 - rmse: 0.5088 - val_loss: 0.3407 - val_acc: 1.0000 - val_rmse: 0.2887\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7209 - acc: 0.5769 - rmse: 0.5077 - val_loss: 0.3408 - val_acc: 1.0000 - val_rmse: 0.2888\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7185 - acc: 0.5769 - rmse: 0.5067 - val_loss: 0.3408 - val_acc: 1.0000 - val_rmse: 0.2888\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7161 - acc: 0.5769 - rmse: 0.5056 - val_loss: 0.3409 - val_acc: 1.0000 - val_rmse: 0.2888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7137 - acc: 0.5769 - rmse: 0.5045 - val_loss: 0.3409 - val_acc: 1.0000 - val_rmse: 0.2889\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7113 - acc: 0.5769 - rmse: 0.5034 - val_loss: 0.3410 - val_acc: 1.0000 - val_rmse: 0.2889\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7089 - acc: 0.5769 - rmse: 0.5024 - val_loss: 0.3410 - val_acc: 1.0000 - val_rmse: 0.2889\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7065 - acc: 0.5769 - rmse: 0.5013 - val_loss: 0.3410 - val_acc: 1.0000 - val_rmse: 0.2890\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7041 - acc: 0.5769 - rmse: 0.5002 - val_loss: 0.3411 - val_acc: 1.0000 - val_rmse: 0.2890\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7018 - acc: 0.5769 - rmse: 0.4992 - val_loss: 0.3411 - val_acc: 1.0000 - val_rmse: 0.2890\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6994 - acc: 0.6154 - rmse: 0.4982 - val_loss: 0.3412 - val_acc: 1.0000 - val_rmse: 0.2891\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6971 - acc: 0.6154 - rmse: 0.4971 - val_loss: 0.3412 - val_acc: 1.0000 - val_rmse: 0.2891\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6948 - acc: 0.6538 - rmse: 0.4961 - val_loss: 0.3413 - val_acc: 1.0000 - val_rmse: 0.2891\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6925 - acc: 0.6538 - rmse: 0.4951 - val_loss: 0.3413 - val_acc: 1.0000 - val_rmse: 0.2892\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6903 - acc: 0.6923 - rmse: 0.4940 - val_loss: 0.3414 - val_acc: 1.0000 - val_rmse: 0.2892\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6880 - acc: 0.6923 - rmse: 0.4930 - val_loss: 0.3414 - val_acc: 1.0000 - val_rmse: 0.2892\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6857 - acc: 0.6923 - rmse: 0.4920 - val_loss: 0.3414 - val_acc: 1.0000 - val_rmse: 0.2893\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6835 - acc: 0.6923 - rmse: 0.4910 - val_loss: 0.3415 - val_acc: 1.0000 - val_rmse: 0.2893\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6812 - acc: 0.6923 - rmse: 0.4899 - val_loss: 0.3415 - val_acc: 1.0000 - val_rmse: 0.2893\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6790 - acc: 0.6923 - rmse: 0.4889 - val_loss: 0.3416 - val_acc: 1.0000 - val_rmse: 0.2894\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6767 - acc: 0.6923 - rmse: 0.4879 - val_loss: 0.3416 - val_acc: 1.0000 - val_rmse: 0.2894\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6745 - acc: 0.7308 - rmse: 0.4869 - val_loss: 0.3417 - val_acc: 1.0000 - val_rmse: 0.2894\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6723 - acc: 0.7308 - rmse: 0.4859 - val_loss: 0.3417 - val_acc: 1.0000 - val_rmse: 0.2895\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6701 - acc: 0.7308 - rmse: 0.4849 - val_loss: 0.3418 - val_acc: 1.0000 - val_rmse: 0.2895\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6680 - acc: 0.7308 - rmse: 0.4839 - val_loss: 0.3418 - val_acc: 1.0000 - val_rmse: 0.2895\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6658 - acc: 0.7308 - rmse: 0.4828 - val_loss: 0.3419 - val_acc: 1.0000 - val_rmse: 0.2895\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6636 - acc: 0.7308 - rmse: 0.4818 - val_loss: 0.3419 - val_acc: 1.0000 - val_rmse: 0.2896\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6614 - acc: 0.7308 - rmse: 0.4808 - val_loss: 0.3419 - val_acc: 1.0000 - val_rmse: 0.2896\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6593 - acc: 0.7308 - rmse: 0.4798 - val_loss: 0.3420 - val_acc: 1.0000 - val_rmse: 0.2896\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6571 - acc: 0.7308 - rmse: 0.4788 - val_loss: 0.3420 - val_acc: 1.0000 - val_rmse: 0.2897\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6550 - acc: 0.7308 - rmse: 0.4778 - val_loss: 0.3421 - val_acc: 1.0000 - val_rmse: 0.2897\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6528 - acc: 0.7308 - rmse: 0.4768 - val_loss: 0.3421 - val_acc: 1.0000 - val_rmse: 0.2897\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6507 - acc: 0.7308 - rmse: 0.4758 - val_loss: 0.3422 - val_acc: 1.0000 - val_rmse: 0.2898\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6486 - acc: 0.7308 - rmse: 0.4748 - val_loss: 0.3422 - val_acc: 1.0000 - val_rmse: 0.2898\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6465 - acc: 0.7308 - rmse: 0.4738 - val_loss: 0.3423 - val_acc: 1.0000 - val_rmse: 0.2898\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6444 - acc: 0.7308 - rmse: 0.4729 - val_loss: 0.3423 - val_acc: 1.0000 - val_rmse: 0.2899\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6423 - acc: 0.7308 - rmse: 0.4719 - val_loss: 0.3424 - val_acc: 1.0000 - val_rmse: 0.2899\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6402 - acc: 0.7308 - rmse: 0.4709 - val_loss: 0.3424 - val_acc: 1.0000 - val_rmse: 0.2900\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6381 - acc: 0.7308 - rmse: 0.4699 - val_loss: 0.3425 - val_acc: 1.0000 - val_rmse: 0.2900\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6360 - acc: 0.7308 - rmse: 0.4689 - val_loss: 0.3425 - val_acc: 1.0000 - val_rmse: 0.2900\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6339 - acc: 0.7308 - rmse: 0.4679 - val_loss: 0.3426 - val_acc: 1.0000 - val_rmse: 0.2901\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6319 - acc: 0.7308 - rmse: 0.4669 - val_loss: 0.3426 - val_acc: 1.0000 - val_rmse: 0.2901\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6298 - acc: 0.7308 - rmse: 0.4660 - val_loss: 0.3427 - val_acc: 1.0000 - val_rmse: 0.2901\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6277 - acc: 0.7308 - rmse: 0.4650 - val_loss: 0.3427 - val_acc: 1.0000 - val_rmse: 0.2902\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6257 - acc: 0.7308 - rmse: 0.4640 - val_loss: 0.3428 - val_acc: 1.0000 - val_rmse: 0.2902\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6236 - acc: 0.7308 - rmse: 0.4630 - val_loss: 0.3428 - val_acc: 1.0000 - val_rmse: 0.2902\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6216 - acc: 0.7692 - rmse: 0.4620 - val_loss: 0.3428 - val_acc: 1.0000 - val_rmse: 0.2903\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6196 - acc: 0.7692 - rmse: 0.4610 - val_loss: 0.3429 - val_acc: 1.0000 - val_rmse: 0.2903\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6175 - acc: 0.7692 - rmse: 0.4601 - val_loss: 0.3429 - val_acc: 1.0000 - val_rmse: 0.2903\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6155 - acc: 0.7692 - rmse: 0.4591 - val_loss: 0.3430 - val_acc: 1.0000 - val_rmse: 0.2904\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6135 - acc: 0.7692 - rmse: 0.4581 - val_loss: 0.3430 - val_acc: 1.0000 - val_rmse: 0.2904\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6115 - acc: 0.7692 - rmse: 0.4571 - val_loss: 0.3431 - val_acc: 1.0000 - val_rmse: 0.2904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6095 - acc: 0.7692 - rmse: 0.4562 - val_loss: 0.3431 - val_acc: 1.0000 - val_rmse: 0.2904\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6075 - acc: 0.7692 - rmse: 0.4552 - val_loss: 0.3432 - val_acc: 1.0000 - val_rmse: 0.2905\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6056 - acc: 0.7692 - rmse: 0.4542 - val_loss: 0.3432 - val_acc: 1.0000 - val_rmse: 0.2905\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6036 - acc: 0.7692 - rmse: 0.4533 - val_loss: 0.3433 - val_acc: 1.0000 - val_rmse: 0.2905\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6017 - acc: 0.7692 - rmse: 0.4523 - val_loss: 0.3433 - val_acc: 1.0000 - val_rmse: 0.2906\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5997 - acc: 0.7692 - rmse: 0.4514 - val_loss: 0.3433 - val_acc: 1.0000 - val_rmse: 0.2906\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5978 - acc: 0.7692 - rmse: 0.4505 - val_loss: 0.3434 - val_acc: 1.0000 - val_rmse: 0.2906\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5959 - acc: 0.7692 - rmse: 0.4495 - val_loss: 0.3434 - val_acc: 1.0000 - val_rmse: 0.2907\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5941 - acc: 0.7692 - rmse: 0.4486 - val_loss: 0.3435 - val_acc: 1.0000 - val_rmse: 0.2907\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5922 - acc: 0.7692 - rmse: 0.4477 - val_loss: 0.3435 - val_acc: 1.0000 - val_rmse: 0.2907\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5903 - acc: 0.7692 - rmse: 0.4467 - val_loss: 0.3436 - val_acc: 1.0000 - val_rmse: 0.2908\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5884 - acc: 0.7692 - rmse: 0.4458 - val_loss: 0.3436 - val_acc: 1.0000 - val_rmse: 0.2908\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5865 - acc: 0.7692 - rmse: 0.4449 - val_loss: 0.3437 - val_acc: 1.0000 - val_rmse: 0.2908\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5847 - acc: 0.7692 - rmse: 0.4440 - val_loss: 0.3437 - val_acc: 1.0000 - val_rmse: 0.2909\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5829 - acc: 0.7692 - rmse: 0.4431 - val_loss: 0.3438 - val_acc: 1.0000 - val_rmse: 0.2909\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5811 - acc: 0.7692 - rmse: 0.4422 - val_loss: 0.3438 - val_acc: 1.0000 - val_rmse: 0.2909\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5793 - acc: 0.7692 - rmse: 0.4413 - val_loss: 0.3439 - val_acc: 1.0000 - val_rmse: 0.2910\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5775 - acc: 0.7692 - rmse: 0.4404 - val_loss: 0.3439 - val_acc: 1.0000 - val_rmse: 0.2910\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5757 - acc: 0.7692 - rmse: 0.4395 - val_loss: 0.3440 - val_acc: 1.0000 - val_rmse: 0.2910\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5739 - acc: 0.7692 - rmse: 0.4386 - val_loss: 0.3440 - val_acc: 1.0000 - val_rmse: 0.2911\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5721 - acc: 0.7692 - rmse: 0.4377 - val_loss: 0.3440 - val_acc: 1.0000 - val_rmse: 0.2911\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5704 - acc: 0.7692 - rmse: 0.4368 - val_loss: 0.3441 - val_acc: 1.0000 - val_rmse: 0.2911\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5686 - acc: 0.7692 - rmse: 0.4359 - val_loss: 0.3441 - val_acc: 1.0000 - val_rmse: 0.2912\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.5668 - acc: 0.7692 - rmse: 0.4350 - val_loss: 0.3442 - val_acc: 1.0000 - val_rmse: 0.2912\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5651 - acc: 0.7692 - rmse: 0.4341 - val_loss: 0.3442 - val_acc: 1.0000 - val_rmse: 0.2912\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5633 - acc: 0.7692 - rmse: 0.4332 - val_loss: 0.3443 - val_acc: 1.0000 - val_rmse: 0.2913\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5616 - acc: 0.7692 - rmse: 0.4323 - val_loss: 0.3443 - val_acc: 1.0000 - val_rmse: 0.2913\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5598 - acc: 0.7692 - rmse: 0.4315 - val_loss: 0.3444 - val_acc: 1.0000 - val_rmse: 0.2913\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5581 - acc: 0.7692 - rmse: 0.4306 - val_loss: 0.3444 - val_acc: 1.0000 - val_rmse: 0.2914\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5564 - acc: 0.7692 - rmse: 0.4297 - val_loss: 0.3445 - val_acc: 1.0000 - val_rmse: 0.2914\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5547 - acc: 0.7692 - rmse: 0.4288 - val_loss: 0.3445 - val_acc: 1.0000 - val_rmse: 0.2914\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5530 - acc: 0.7692 - rmse: 0.4280 - val_loss: 0.3446 - val_acc: 1.0000 - val_rmse: 0.2915\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5513 - acc: 0.7692 - rmse: 0.4271 - val_loss: 0.3446 - val_acc: 1.0000 - val_rmse: 0.2915\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5496 - acc: 0.7692 - rmse: 0.4262 - val_loss: 0.3447 - val_acc: 1.0000 - val_rmse: 0.2916\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5479 - acc: 0.7692 - rmse: 0.4253 - val_loss: 0.3447 - val_acc: 1.0000 - val_rmse: 0.2916\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5462 - acc: 0.7692 - rmse: 0.4245 - val_loss: 0.3448 - val_acc: 1.0000 - val_rmse: 0.2916\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5445 - acc: 0.7692 - rmse: 0.4236 - val_loss: 0.3448 - val_acc: 1.0000 - val_rmse: 0.2917\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5429 - acc: 0.7692 - rmse: 0.4227 - val_loss: 0.3449 - val_acc: 1.0000 - val_rmse: 0.2917\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5412 - acc: 0.7692 - rmse: 0.4219 - val_loss: 0.3449 - val_acc: 1.0000 - val_rmse: 0.2917\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5396 - acc: 0.7692 - rmse: 0.4210 - val_loss: 0.3450 - val_acc: 1.0000 - val_rmse: 0.2918\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5379 - acc: 0.7692 - rmse: 0.4202 - val_loss: 0.3450 - val_acc: 1.0000 - val_rmse: 0.2918\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.5363 - acc: 0.7692 - rmse: 0.4193 - val_loss: 0.3451 - val_acc: 1.0000 - val_rmse: 0.2918\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.5346 - acc: 0.7692 - rmse: 0.4185 - val_loss: 0.3451 - val_acc: 1.0000 - val_rmse: 0.2919\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5330 - acc: 0.7692 - rmse: 0.4176 - val_loss: 0.3452 - val_acc: 1.0000 - val_rmse: 0.2919\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_34 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34051\n",
      " - 4s - loss: 0.7278 - acc: 0.5769 - rmse: 0.5138 - val_loss: 0.6257 - val_acc: 1.0000 - val_rmse: 0.4651\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7259 - acc: 0.5769 - rmse: 0.5129 - val_loss: 0.6256 - val_acc: 1.0000 - val_rmse: 0.4651\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7239 - acc: 0.5769 - rmse: 0.5121 - val_loss: 0.6256 - val_acc: 1.0000 - val_rmse: 0.4651\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.7220 - acc: 0.5769 - rmse: 0.5113 - val_loss: 0.6256 - val_acc: 1.0000 - val_rmse: 0.4650\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7201 - acc: 0.5769 - rmse: 0.5104 - val_loss: 0.6255 - val_acc: 1.0000 - val_rmse: 0.4650\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7181 - acc: 0.5769 - rmse: 0.5096 - val_loss: 0.6255 - val_acc: 1.0000 - val_rmse: 0.4650\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7162 - acc: 0.5769 - rmse: 0.5088 - val_loss: 0.6254 - val_acc: 1.0000 - val_rmse: 0.4650\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7143 - acc: 0.5769 - rmse: 0.5080 - val_loss: 0.6254 - val_acc: 1.0000 - val_rmse: 0.4649\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7124 - acc: 0.5769 - rmse: 0.5071 - val_loss: 0.6253 - val_acc: 1.0000 - val_rmse: 0.4649\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7105 - acc: 0.5769 - rmse: 0.5063 - val_loss: 0.6253 - val_acc: 1.0000 - val_rmse: 0.4649\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7086 - acc: 0.5769 - rmse: 0.5055 - val_loss: 0.6252 - val_acc: 1.0000 - val_rmse: 0.4649\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7067 - acc: 0.5769 - rmse: 0.5046 - val_loss: 0.6252 - val_acc: 1.0000 - val_rmse: 0.4648\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7048 - acc: 0.5769 - rmse: 0.5038 - val_loss: 0.6251 - val_acc: 1.0000 - val_rmse: 0.4648\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7030 - acc: 0.5769 - rmse: 0.5030 - val_loss: 0.6251 - val_acc: 1.0000 - val_rmse: 0.4648\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.7011 - acc: 0.5769 - rmse: 0.5021 - val_loss: 0.6250 - val_acc: 1.0000 - val_rmse: 0.4648\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6992 - acc: 0.5769 - rmse: 0.5013 - val_loss: 0.6250 - val_acc: 1.0000 - val_rmse: 0.4647\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6974 - acc: 0.5769 - rmse: 0.5005 - val_loss: 0.6249 - val_acc: 1.0000 - val_rmse: 0.4647\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6955 - acc: 0.5769 - rmse: 0.4997 - val_loss: 0.6249 - val_acc: 1.0000 - val_rmse: 0.4647\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6937 - acc: 0.5769 - rmse: 0.4988 - val_loss: 0.6249 - val_acc: 1.0000 - val_rmse: 0.4647\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6918 - acc: 0.5769 - rmse: 0.4980 - val_loss: 0.6248 - val_acc: 1.0000 - val_rmse: 0.4646\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6900 - acc: 0.5769 - rmse: 0.4972 - val_loss: 0.6248 - val_acc: 1.0000 - val_rmse: 0.4646\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6882 - acc: 0.5769 - rmse: 0.4964 - val_loss: 0.6247 - val_acc: 1.0000 - val_rmse: 0.4646\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6864 - acc: 0.5769 - rmse: 0.4956 - val_loss: 0.6247 - val_acc: 1.0000 - val_rmse: 0.4646\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6846 - acc: 0.5769 - rmse: 0.4948 - val_loss: 0.6246 - val_acc: 1.0000 - val_rmse: 0.4645\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6828 - acc: 0.5769 - rmse: 0.4940 - val_loss: 0.6246 - val_acc: 1.0000 - val_rmse: 0.4645\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6810 - acc: 0.5769 - rmse: 0.4931 - val_loss: 0.6245 - val_acc: 1.0000 - val_rmse: 0.4645\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6792 - acc: 0.5769 - rmse: 0.4923 - val_loss: 0.6245 - val_acc: 1.0000 - val_rmse: 0.4645\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6775 - acc: 0.5769 - rmse: 0.4915 - val_loss: 0.6244 - val_acc: 1.0000 - val_rmse: 0.4644\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6757 - acc: 0.5769 - rmse: 0.4907 - val_loss: 0.6244 - val_acc: 1.0000 - val_rmse: 0.4644\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6739 - acc: 0.5769 - rmse: 0.4899 - val_loss: 0.6243 - val_acc: 1.0000 - val_rmse: 0.4644\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6721 - acc: 0.5769 - rmse: 0.4891 - val_loss: 0.6243 - val_acc: 1.0000 - val_rmse: 0.4644\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6704 - acc: 0.5769 - rmse: 0.4882 - val_loss: 0.6242 - val_acc: 1.0000 - val_rmse: 0.4643\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6686 - acc: 0.5769 - rmse: 0.4874 - val_loss: 0.6242 - val_acc: 1.0000 - val_rmse: 0.4643\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6669 - acc: 0.5769 - rmse: 0.4866 - val_loss: 0.6241 - val_acc: 1.0000 - val_rmse: 0.4643\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6651 - acc: 0.5769 - rmse: 0.4858 - val_loss: 0.6241 - val_acc: 1.0000 - val_rmse: 0.4642\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6634 - acc: 0.5769 - rmse: 0.4850 - val_loss: 0.6240 - val_acc: 1.0000 - val_rmse: 0.4642\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6617 - acc: 0.5769 - rmse: 0.4842 - val_loss: 0.6240 - val_acc: 1.0000 - val_rmse: 0.4642\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6600 - acc: 0.5769 - rmse: 0.4834 - val_loss: 0.6239 - val_acc: 1.0000 - val_rmse: 0.4642\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6583 - acc: 0.5769 - rmse: 0.4826 - val_loss: 0.6239 - val_acc: 1.0000 - val_rmse: 0.4641\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6566 - acc: 0.5769 - rmse: 0.4818 - val_loss: 0.6239 - val_acc: 1.0000 - val_rmse: 0.4641\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6550 - acc: 0.5769 - rmse: 0.4810 - val_loss: 0.6238 - val_acc: 1.0000 - val_rmse: 0.4641\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6533 - acc: 0.5769 - rmse: 0.4802 - val_loss: 0.6238 - val_acc: 1.0000 - val_rmse: 0.4641\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6516 - acc: 0.6154 - rmse: 0.4794 - val_loss: 0.6237 - val_acc: 1.0000 - val_rmse: 0.4641\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6499 - acc: 0.6154 - rmse: 0.4786 - val_loss: 0.6237 - val_acc: 1.0000 - val_rmse: 0.4640\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6483 - acc: 0.6538 - rmse: 0.4778 - val_loss: 0.6237 - val_acc: 1.0000 - val_rmse: 0.4640\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6466 - acc: 0.6538 - rmse: 0.4770 - val_loss: 0.6236 - val_acc: 1.0000 - val_rmse: 0.4640\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6450 - acc: 0.6538 - rmse: 0.4763 - val_loss: 0.6236 - val_acc: 1.0000 - val_rmse: 0.4640\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6433 - acc: 0.6538 - rmse: 0.4755 - val_loss: 0.6236 - val_acc: 1.0000 - val_rmse: 0.4640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6417 - acc: 0.6538 - rmse: 0.4747 - val_loss: 0.6235 - val_acc: 1.0000 - val_rmse: 0.4639\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6400 - acc: 0.6538 - rmse: 0.4739 - val_loss: 0.6235 - val_acc: 1.0000 - val_rmse: 0.4639\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6384 - acc: 0.6923 - rmse: 0.4731 - val_loss: 0.6235 - val_acc: 1.0000 - val_rmse: 0.4639\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6368 - acc: 0.6923 - rmse: 0.4723 - val_loss: 0.6234 - val_acc: 1.0000 - val_rmse: 0.4639\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6352 - acc: 0.6923 - rmse: 0.4715 - val_loss: 0.6234 - val_acc: 1.0000 - val_rmse: 0.4639\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6335 - acc: 0.6923 - rmse: 0.4707 - val_loss: 0.6234 - val_acc: 1.0000 - val_rmse: 0.4639\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6319 - acc: 0.6923 - rmse: 0.4699 - val_loss: 0.6233 - val_acc: 1.0000 - val_rmse: 0.4638\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6303 - acc: 0.6923 - rmse: 0.4691 - val_loss: 0.6233 - val_acc: 1.0000 - val_rmse: 0.4638\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6288 - acc: 0.6923 - rmse: 0.4684 - val_loss: 0.6233 - val_acc: 1.0000 - val_rmse: 0.4638\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6272 - acc: 0.6923 - rmse: 0.4676 - val_loss: 0.6232 - val_acc: 1.0000 - val_rmse: 0.4638\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6256 - acc: 0.6923 - rmse: 0.4668 - val_loss: 0.6232 - val_acc: 1.0000 - val_rmse: 0.4638\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6240 - acc: 0.6923 - rmse: 0.4660 - val_loss: 0.6232 - val_acc: 1.0000 - val_rmse: 0.4638\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6224 - acc: 0.6923 - rmse: 0.4652 - val_loss: 0.6231 - val_acc: 1.0000 - val_rmse: 0.4637\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6209 - acc: 0.6923 - rmse: 0.4644 - val_loss: 0.6231 - val_acc: 1.0000 - val_rmse: 0.4637\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6193 - acc: 0.6923 - rmse: 0.4637 - val_loss: 0.6231 - val_acc: 1.0000 - val_rmse: 0.4637\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34051\n",
      " - 0s - loss: 0.6177 - acc: 0.6923 - rmse: 0.4629 - val_loss: 0.6230 - val_acc: 1.0000 - val_rmse: 0.4637\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6162 - acc: 0.6923 - rmse: 0.4621 - val_loss: 0.6230 - val_acc: 1.0000 - val_rmse: 0.4637\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6146 - acc: 0.6923 - rmse: 0.4613 - val_loss: 0.6230 - val_acc: 1.0000 - val_rmse: 0.4637\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6131 - acc: 0.6923 - rmse: 0.4606 - val_loss: 0.6230 - val_acc: 1.0000 - val_rmse: 0.4637\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6116 - acc: 0.6923 - rmse: 0.4598 - val_loss: 0.6229 - val_acc: 1.0000 - val_rmse: 0.4636\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6101 - acc: 0.6923 - rmse: 0.4590 - val_loss: 0.6229 - val_acc: 1.0000 - val_rmse: 0.4636\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6086 - acc: 0.6923 - rmse: 0.4583 - val_loss: 0.6229 - val_acc: 1.0000 - val_rmse: 0.4636\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6071 - acc: 0.6923 - rmse: 0.4575 - val_loss: 0.6229 - val_acc: 1.0000 - val_rmse: 0.4636\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6056 - acc: 0.6923 - rmse: 0.4568 - val_loss: 0.6228 - val_acc: 1.0000 - val_rmse: 0.4636\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6042 - acc: 0.6923 - rmse: 0.4560 - val_loss: 0.6228 - val_acc: 1.0000 - val_rmse: 0.4636\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6027 - acc: 0.7308 - rmse: 0.4553 - val_loss: 0.6228 - val_acc: 1.0000 - val_rmse: 0.4636\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.6012 - acc: 0.7308 - rmse: 0.4545 - val_loss: 0.6228 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5997 - acc: 0.7308 - rmse: 0.4538 - val_loss: 0.6228 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5983 - acc: 0.7308 - rmse: 0.4530 - val_loss: 0.6227 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5968 - acc: 0.7308 - rmse: 0.4523 - val_loss: 0.6227 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5954 - acc: 0.7308 - rmse: 0.4515 - val_loss: 0.6227 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5939 - acc: 0.7308 - rmse: 0.4508 - val_loss: 0.6227 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5925 - acc: 0.7308 - rmse: 0.4500 - val_loss: 0.6226 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5911 - acc: 0.7308 - rmse: 0.4493 - val_loss: 0.6226 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5897 - acc: 0.7308 - rmse: 0.4486 - val_loss: 0.6226 - val_acc: 1.0000 - val_rmse: 0.4635\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5883 - acc: 0.7308 - rmse: 0.4478 - val_loss: 0.6226 - val_acc: 1.0000 - val_rmse: 0.4634\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5869 - acc: 0.7308 - rmse: 0.4471 - val_loss: 0.6226 - val_acc: 1.0000 - val_rmse: 0.4634\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5855 - acc: 0.7308 - rmse: 0.4464 - val_loss: 0.6225 - val_acc: 1.0000 - val_rmse: 0.4634\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5841 - acc: 0.7308 - rmse: 0.4457 - val_loss: 0.6225 - val_acc: 1.0000 - val_rmse: 0.4634\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5827 - acc: 0.7308 - rmse: 0.4449 - val_loss: 0.6225 - val_acc: 1.0000 - val_rmse: 0.4634\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5814 - acc: 0.7308 - rmse: 0.4442 - val_loss: 0.6225 - val_acc: 1.0000 - val_rmse: 0.4634\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5800 - acc: 0.7308 - rmse: 0.4435 - val_loss: 0.6224 - val_acc: 1.0000 - val_rmse: 0.4634\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5786 - acc: 0.7308 - rmse: 0.4428 - val_loss: 0.6224 - val_acc: 1.0000 - val_rmse: 0.4634\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5773 - acc: 0.7308 - rmse: 0.4421 - val_loss: 0.6224 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5759 - acc: 0.7308 - rmse: 0.4414 - val_loss: 0.6224 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5746 - acc: 0.7308 - rmse: 0.4406 - val_loss: 0.6224 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5732 - acc: 0.7308 - rmse: 0.4399 - val_loss: 0.6223 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5719 - acc: 0.7308 - rmse: 0.4392 - val_loss: 0.6223 - val_acc: 1.0000 - val_rmse: 0.4633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5705 - acc: 0.7308 - rmse: 0.4385 - val_loss: 0.6223 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5692 - acc: 0.7308 - rmse: 0.4378 - val_loss: 0.6223 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5679 - acc: 0.7308 - rmse: 0.4371 - val_loss: 0.6223 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.34051\n",
      " - 1s - loss: 0.5665 - acc: 0.7308 - rmse: 0.4364 - val_loss: 0.6223 - val_acc: 1.0000 - val_rmse: 0.4633\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_35 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34051 to 0.33275, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 14s - loss: 0.7269 - acc: 0.5769 - rmse: 0.5110 - val_loss: 0.3328 - val_acc: 1.0000 - val_rmse: 0.2831\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33275 to 0.33272, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7244 - acc: 0.5769 - rmse: 0.5100 - val_loss: 0.3327 - val_acc: 1.0000 - val_rmse: 0.2830\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33272 to 0.33269, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7219 - acc: 0.5769 - rmse: 0.5089 - val_loss: 0.3327 - val_acc: 1.0000 - val_rmse: 0.2830\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.33269 to 0.33266, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7195 - acc: 0.5769 - rmse: 0.5079 - val_loss: 0.3327 - val_acc: 1.0000 - val_rmse: 0.2830\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33266 to 0.33263, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7170 - acc: 0.5769 - rmse: 0.5069 - val_loss: 0.3326 - val_acc: 1.0000 - val_rmse: 0.2830\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33263 to 0.33260, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7146 - acc: 0.5769 - rmse: 0.5058 - val_loss: 0.3326 - val_acc: 1.0000 - val_rmse: 0.2829\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.33260 to 0.33257, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7121 - acc: 0.5769 - rmse: 0.5048 - val_loss: 0.3326 - val_acc: 1.0000 - val_rmse: 0.2829\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33257 to 0.33255, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7097 - acc: 0.5769 - rmse: 0.5038 - val_loss: 0.3325 - val_acc: 1.0000 - val_rmse: 0.2829\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33255 to 0.33252, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7072 - acc: 0.5769 - rmse: 0.5028 - val_loss: 0.3325 - val_acc: 1.0000 - val_rmse: 0.2829\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33252 to 0.33249, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7048 - acc: 0.5769 - rmse: 0.5017 - val_loss: 0.3325 - val_acc: 1.0000 - val_rmse: 0.2829\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33249 to 0.33246, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7024 - acc: 0.5769 - rmse: 0.5007 - val_loss: 0.3325 - val_acc: 1.0000 - val_rmse: 0.2828\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33246 to 0.33243, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.7000 - acc: 0.5769 - rmse: 0.4997 - val_loss: 0.3324 - val_acc: 1.0000 - val_rmse: 0.2828\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33243 to 0.33240, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6976 - acc: 0.5769 - rmse: 0.4986 - val_loss: 0.3324 - val_acc: 1.0000 - val_rmse: 0.2828\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33240 to 0.33235, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6952 - acc: 0.5769 - rmse: 0.4976 - val_loss: 0.3324 - val_acc: 1.0000 - val_rmse: 0.2828\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33235 to 0.33229, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6928 - acc: 0.5769 - rmse: 0.4966 - val_loss: 0.3323 - val_acc: 1.0000 - val_rmse: 0.2827\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33229 to 0.33224, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6904 - acc: 0.5769 - rmse: 0.4956 - val_loss: 0.3322 - val_acc: 1.0000 - val_rmse: 0.2827\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33224 to 0.33218, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6881 - acc: 0.5769 - rmse: 0.4945 - val_loss: 0.3322 - val_acc: 1.0000 - val_rmse: 0.2826\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33218 to 0.33213, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6857 - acc: 0.5769 - rmse: 0.4935 - val_loss: 0.3321 - val_acc: 1.0000 - val_rmse: 0.2826\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.33213 to 0.33207, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6834 - acc: 0.5769 - rmse: 0.4925 - val_loss: 0.3321 - val_acc: 1.0000 - val_rmse: 0.2826\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33207 to 0.33202, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6811 - acc: 0.5769 - rmse: 0.4915 - val_loss: 0.3320 - val_acc: 1.0000 - val_rmse: 0.2825\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.33202 to 0.33197, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6788 - acc: 0.5769 - rmse: 0.4905 - val_loss: 0.3320 - val_acc: 1.0000 - val_rmse: 0.2825\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33197 to 0.33193, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6765 - acc: 0.5769 - rmse: 0.4895 - val_loss: 0.3319 - val_acc: 1.0000 - val_rmse: 0.2825\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.33193 to 0.33188, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6742 - acc: 0.5769 - rmse: 0.4884 - val_loss: 0.3319 - val_acc: 1.0000 - val_rmse: 0.2824\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33188 to 0.33184, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6719 - acc: 0.5769 - rmse: 0.4874 - val_loss: 0.3318 - val_acc: 1.0000 - val_rmse: 0.2824\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.33184 to 0.33179, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6696 - acc: 0.5769 - rmse: 0.4864 - val_loss: 0.3318 - val_acc: 1.0000 - val_rmse: 0.2824\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.33179 to 0.33175, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6673 - acc: 0.5769 - rmse: 0.4854 - val_loss: 0.3318 - val_acc: 1.0000 - val_rmse: 0.2823\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33175 to 0.33171, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6651 - acc: 0.5769 - rmse: 0.4844 - val_loss: 0.3317 - val_acc: 1.0000 - val_rmse: 0.2823\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.33171 to 0.33167, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6628 - acc: 0.5769 - rmse: 0.4834 - val_loss: 0.3317 - val_acc: 1.0000 - val_rmse: 0.2823\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33167 to 0.33163, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6606 - acc: 0.5769 - rmse: 0.4824 - val_loss: 0.3316 - val_acc: 1.0000 - val_rmse: 0.2822\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33163 to 0.33159, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6583 - acc: 0.5769 - rmse: 0.4814 - val_loss: 0.3316 - val_acc: 1.0000 - val_rmse: 0.2822\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33159 to 0.33156, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6561 - acc: 0.5769 - rmse: 0.4804 - val_loss: 0.3316 - val_acc: 1.0000 - val_rmse: 0.2822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.33156 to 0.33152, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6539 - acc: 0.5769 - rmse: 0.4794 - val_loss: 0.3315 - val_acc: 1.0000 - val_rmse: 0.2822\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33152 to 0.33148, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6517 - acc: 0.5769 - rmse: 0.4784 - val_loss: 0.3315 - val_acc: 1.0000 - val_rmse: 0.2821\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.33148 to 0.33145, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6495 - acc: 0.6154 - rmse: 0.4774 - val_loss: 0.3314 - val_acc: 1.0000 - val_rmse: 0.2821\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.33145 to 0.33142, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6474 - acc: 0.6154 - rmse: 0.4765 - val_loss: 0.3314 - val_acc: 1.0000 - val_rmse: 0.2821\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.33142 to 0.33139, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6452 - acc: 0.6154 - rmse: 0.4755 - val_loss: 0.3314 - val_acc: 1.0000 - val_rmse: 0.2821\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.33139 to 0.33136, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6430 - acc: 0.6154 - rmse: 0.4745 - val_loss: 0.3314 - val_acc: 1.0000 - val_rmse: 0.2821\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.33136 to 0.33133, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6409 - acc: 0.6154 - rmse: 0.4735 - val_loss: 0.3313 - val_acc: 1.0000 - val_rmse: 0.2820\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.33133 to 0.33131, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6387 - acc: 0.6154 - rmse: 0.4725 - val_loss: 0.3313 - val_acc: 1.0000 - val_rmse: 0.2820\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33131 to 0.33128, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6366 - acc: 0.6154 - rmse: 0.4716 - val_loss: 0.3313 - val_acc: 1.0000 - val_rmse: 0.2820\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.33128 to 0.33126, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6344 - acc: 0.6154 - rmse: 0.4706 - val_loss: 0.3313 - val_acc: 1.0000 - val_rmse: 0.2820\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.33126 to 0.33124, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6323 - acc: 0.6154 - rmse: 0.4696 - val_loss: 0.3312 - val_acc: 1.0000 - val_rmse: 0.2820\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33124 to 0.33122, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6302 - acc: 0.6154 - rmse: 0.4686 - val_loss: 0.3312 - val_acc: 1.0000 - val_rmse: 0.2820\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33122 to 0.33120, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6280 - acc: 0.6154 - rmse: 0.4676 - val_loss: 0.3312 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33120 to 0.33119, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6259 - acc: 0.6154 - rmse: 0.4666 - val_loss: 0.3312 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33119 to 0.33117, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6238 - acc: 0.6154 - rmse: 0.4657 - val_loss: 0.3312 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33117 to 0.33116, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6217 - acc: 0.6154 - rmse: 0.4647 - val_loss: 0.3312 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33116 to 0.33115, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6196 - acc: 0.6154 - rmse: 0.4637 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.33115 to 0.33113, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6176 - acc: 0.6538 - rmse: 0.4628 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33113 to 0.33112, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6155 - acc: 0.6538 - rmse: 0.4618 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.33112 to 0.33111, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6135 - acc: 0.6538 - rmse: 0.4608 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.33111 to 0.33110, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6114 - acc: 0.6538 - rmse: 0.4599 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.33110 to 0.33109, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6094 - acc: 0.6538 - rmse: 0.4589 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.33109 to 0.33108, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6073 - acc: 0.6538 - rmse: 0.4579 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2819\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.33108 to 0.33107, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6053 - acc: 0.6538 - rmse: 0.4570 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.33107 to 0.33107, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6033 - acc: 0.6538 - rmse: 0.4560 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.33107 to 0.33106, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.6013 - acc: 0.6538 - rmse: 0.4550 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.33106 to 0.33105, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5993 - acc: 0.6538 - rmse: 0.4541 - val_loss: 0.3311 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.33105 to 0.33104, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5973 - acc: 0.6538 - rmse: 0.4531 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.33104 to 0.33104, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5953 - acc: 0.6923 - rmse: 0.4522 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.33104 to 0.33103, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5933 - acc: 0.6923 - rmse: 0.4512 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.33103 to 0.33102, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5913 - acc: 0.6923 - rmse: 0.4502 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.33102 to 0.33102, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5893 - acc: 0.6923 - rmse: 0.4493 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.33102 to 0.33101, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5874 - acc: 0.6923 - rmse: 0.4483 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.33101 to 0.33100, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5854 - acc: 0.6923 - rmse: 0.4474 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.33100 to 0.33100, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5834 - acc: 0.6923 - rmse: 0.4464 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.33100 to 0.33099, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5815 - acc: 0.6923 - rmse: 0.4454 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.33099 to 0.33099, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5795 - acc: 0.6923 - rmse: 0.4445 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.33099 to 0.33098, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5775 - acc: 0.6923 - rmse: 0.4435 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.33098 to 0.33098, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5756 - acc: 0.6923 - rmse: 0.4426 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.33098 to 0.33097, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5737 - acc: 0.6923 - rmse: 0.4416 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.33097 to 0.33097, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5717 - acc: 0.6923 - rmse: 0.4406 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.33097 to 0.33096, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5698 - acc: 0.6923 - rmse: 0.4397 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.33096 to 0.33096, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5679 - acc: 0.6923 - rmse: 0.4387 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.33096 to 0.33095, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5660 - acc: 0.6923 - rmse: 0.4378 - val_loss: 0.3310 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.33095 to 0.33095, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5641 - acc: 0.6923 - rmse: 0.4368 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.33095 to 0.33094, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5622 - acc: 0.6923 - rmse: 0.4359 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2818\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.33094 to 0.33094, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5603 - acc: 0.6923 - rmse: 0.4350 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.33094 to 0.33093, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5585 - acc: 0.6923 - rmse: 0.4340 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.33093 to 0.33093, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5566 - acc: 0.6923 - rmse: 0.4331 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.33093 to 0.33092, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5547 - acc: 0.6923 - rmse: 0.4321 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.33092 to 0.33091, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5529 - acc: 0.6923 - rmse: 0.4312 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.33091 to 0.33091, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5510 - acc: 0.6923 - rmse: 0.4303 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.33091 to 0.33090, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5492 - acc: 0.6923 - rmse: 0.4293 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.33090 to 0.33090, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5473 - acc: 0.6923 - rmse: 0.4284 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.33090 to 0.33089, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5455 - acc: 0.6923 - rmse: 0.4274 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.33089 to 0.33088, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5437 - acc: 0.6923 - rmse: 0.4265 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.33088 to 0.33087, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5419 - acc: 0.6923 - rmse: 0.4256 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.33087 to 0.33087, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5401 - acc: 0.6923 - rmse: 0.4247 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.33087 to 0.33086, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5383 - acc: 0.6923 - rmse: 0.4237 - val_loss: 0.3309 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.33086 to 0.33085, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5366 - acc: 0.6923 - rmse: 0.4228 - val_loss: 0.3308 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.33085 to 0.33084, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5348 - acc: 0.6923 - rmse: 0.4219 - val_loss: 0.3308 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.33084 to 0.33083, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5330 - acc: 0.6923 - rmse: 0.4210 - val_loss: 0.3308 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.33083 to 0.33082, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5313 - acc: 0.6923 - rmse: 0.4201 - val_loss: 0.3308 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.33082 to 0.33081, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5295 - acc: 0.6923 - rmse: 0.4192 - val_loss: 0.3308 - val_acc: 1.0000 - val_rmse: 0.2817\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.33081 to 0.33079, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5278 - acc: 0.6923 - rmse: 0.4183 - val_loss: 0.3308 - val_acc: 1.0000 - val_rmse: 0.2816\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.33079 to 0.33078, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5261 - acc: 0.6923 - rmse: 0.4174 - val_loss: 0.3308 - val_acc: 1.0000 - val_rmse: 0.2816\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.33078 to 0.33077, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5243 - acc: 0.6923 - rmse: 0.4165 - val_loss: 0.3308 - val_acc: 1.0000 - val_rmse: 0.2816\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.33077 to 0.33076, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5226 - acc: 0.6923 - rmse: 0.4156 - val_loss: 0.3308 - val_acc: 1.0000 - val_rmse: 0.2816\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.33076 to 0.33075, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 1s - loss: 0.5209 - acc: 0.6923 - rmse: 0.4147 - val_loss: 0.3307 - val_acc: 1.0000 - val_rmse: 0.2816\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_36 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33075\n",
      " - 6s - loss: 0.7516 - acc: 0.5385 - rmse: 0.5245 - val_loss: 0.9114 - val_acc: 0.0000e+00 - val_rmse: 0.5980\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7488 - acc: 0.5385 - rmse: 0.5234 - val_loss: 0.9111 - val_acc: 0.0000e+00 - val_rmse: 0.5979\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.33075\n",
      " - 0s - loss: 0.7461 - acc: 0.5385 - rmse: 0.5222 - val_loss: 0.9107 - val_acc: 0.0000e+00 - val_rmse: 0.5978\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7434 - acc: 0.5385 - rmse: 0.5211 - val_loss: 0.9104 - val_acc: 0.0000e+00 - val_rmse: 0.5976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7408 - acc: 0.5385 - rmse: 0.5200 - val_loss: 0.9100 - val_acc: 0.0000e+00 - val_rmse: 0.5975\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7382 - acc: 0.5385 - rmse: 0.5188 - val_loss: 0.9097 - val_acc: 0.0000e+00 - val_rmse: 0.5973\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7356 - acc: 0.5385 - rmse: 0.5177 - val_loss: 0.9093 - val_acc: 0.0000e+00 - val_rmse: 0.5972\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7331 - acc: 0.5385 - rmse: 0.5166 - val_loss: 0.9090 - val_acc: 0.0000e+00 - val_rmse: 0.5971\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7305 - acc: 0.5385 - rmse: 0.5155 - val_loss: 0.9087 - val_acc: 0.0000e+00 - val_rmse: 0.5970\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7280 - acc: 0.5385 - rmse: 0.5144 - val_loss: 0.9084 - val_acc: 0.0000e+00 - val_rmse: 0.5968\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7255 - acc: 0.5385 - rmse: 0.5133 - val_loss: 0.9081 - val_acc: 0.0000e+00 - val_rmse: 0.5967\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7230 - acc: 0.5385 - rmse: 0.5122 - val_loss: 0.9078 - val_acc: 0.0000e+00 - val_rmse: 0.5966\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7205 - acc: 0.5385 - rmse: 0.5111 - val_loss: 0.9075 - val_acc: 0.0000e+00 - val_rmse: 0.5965\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7181 - acc: 0.5385 - rmse: 0.5100 - val_loss: 0.9072 - val_acc: 0.0000e+00 - val_rmse: 0.5964\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7157 - acc: 0.5385 - rmse: 0.5089 - val_loss: 0.9070 - val_acc: 0.0000e+00 - val_rmse: 0.5962\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7132 - acc: 0.5385 - rmse: 0.5078 - val_loss: 0.9067 - val_acc: 0.0000e+00 - val_rmse: 0.5961\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7108 - acc: 0.5385 - rmse: 0.5068 - val_loss: 0.9064 - val_acc: 0.0000e+00 - val_rmse: 0.5960\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7085 - acc: 0.5385 - rmse: 0.5057 - val_loss: 0.9061 - val_acc: 0.0000e+00 - val_rmse: 0.5959\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7061 - acc: 0.5385 - rmse: 0.5046 - val_loss: 0.9058 - val_acc: 0.0000e+00 - val_rmse: 0.5958\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7037 - acc: 0.5385 - rmse: 0.5035 - val_loss: 0.9055 - val_acc: 0.0000e+00 - val_rmse: 0.5957\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7014 - acc: 0.5385 - rmse: 0.5025 - val_loss: 0.9052 - val_acc: 0.0000e+00 - val_rmse: 0.5956\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6990 - acc: 0.5385 - rmse: 0.5014 - val_loss: 0.9050 - val_acc: 0.0000e+00 - val_rmse: 0.5954\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6967 - acc: 0.5385 - rmse: 0.5004 - val_loss: 0.9047 - val_acc: 0.0000e+00 - val_rmse: 0.5953\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6944 - acc: 0.5385 - rmse: 0.4993 - val_loss: 0.9044 - val_acc: 0.0000e+00 - val_rmse: 0.5952\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6922 - acc: 0.5385 - rmse: 0.4983 - val_loss: 0.9041 - val_acc: 0.0000e+00 - val_rmse: 0.5951\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6900 - acc: 0.5769 - rmse: 0.4973 - val_loss: 0.9039 - val_acc: 0.0000e+00 - val_rmse: 0.5950\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6878 - acc: 0.5769 - rmse: 0.4963 - val_loss: 0.9036 - val_acc: 0.0000e+00 - val_rmse: 0.5949\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6856 - acc: 0.5769 - rmse: 0.4952 - val_loss: 0.9033 - val_acc: 0.0000e+00 - val_rmse: 0.5948\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6834 - acc: 0.5769 - rmse: 0.4942 - val_loss: 0.9030 - val_acc: 0.0000e+00 - val_rmse: 0.5947\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6812 - acc: 0.5769 - rmse: 0.4932 - val_loss: 0.9028 - val_acc: 0.0000e+00 - val_rmse: 0.5946\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6791 - acc: 0.5769 - rmse: 0.4922 - val_loss: 0.9025 - val_acc: 0.0000e+00 - val_rmse: 0.5944\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6769 - acc: 0.5769 - rmse: 0.4912 - val_loss: 0.9022 - val_acc: 0.0000e+00 - val_rmse: 0.5943\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6748 - acc: 0.5769 - rmse: 0.4902 - val_loss: 0.9020 - val_acc: 0.0000e+00 - val_rmse: 0.5942\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6726 - acc: 0.5769 - rmse: 0.4892 - val_loss: 0.9017 - val_acc: 0.0000e+00 - val_rmse: 0.5941\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6705 - acc: 0.5769 - rmse: 0.4882 - val_loss: 0.9015 - val_acc: 0.0000e+00 - val_rmse: 0.5940\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6684 - acc: 0.6154 - rmse: 0.4872 - val_loss: 0.9012 - val_acc: 0.0000e+00 - val_rmse: 0.5939\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6663 - acc: 0.6154 - rmse: 0.4862 - val_loss: 0.9010 - val_acc: 0.0000e+00 - val_rmse: 0.5938\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6642 - acc: 0.6154 - rmse: 0.4852 - val_loss: 0.9007 - val_acc: 0.0000e+00 - val_rmse: 0.5937\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6620 - acc: 0.6154 - rmse: 0.4842 - val_loss: 0.9005 - val_acc: 0.0000e+00 - val_rmse: 0.5936\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6599 - acc: 0.6154 - rmse: 0.4832 - val_loss: 0.9002 - val_acc: 0.0000e+00 - val_rmse: 0.5935\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6578 - acc: 0.6154 - rmse: 0.4822 - val_loss: 0.9000 - val_acc: 0.0000e+00 - val_rmse: 0.5934\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6557 - acc: 0.6154 - rmse: 0.4812 - val_loss: 0.8997 - val_acc: 0.0000e+00 - val_rmse: 0.5933\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6536 - acc: 0.6154 - rmse: 0.4802 - val_loss: 0.8995 - val_acc: 0.0000e+00 - val_rmse: 0.5932\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6516 - acc: 0.6154 - rmse: 0.4792 - val_loss: 0.8992 - val_acc: 0.0000e+00 - val_rmse: 0.5931\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6495 - acc: 0.6154 - rmse: 0.4782 - val_loss: 0.8990 - val_acc: 0.0000e+00 - val_rmse: 0.5930\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6474 - acc: 0.6154 - rmse: 0.4772 - val_loss: 0.8987 - val_acc: 0.0000e+00 - val_rmse: 0.5929\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6453 - acc: 0.6154 - rmse: 0.4762 - val_loss: 0.8985 - val_acc: 0.0000e+00 - val_rmse: 0.5928\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6433 - acc: 0.6154 - rmse: 0.4751 - val_loss: 0.8983 - val_acc: 0.0000e+00 - val_rmse: 0.5927\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6412 - acc: 0.6154 - rmse: 0.4741 - val_loss: 0.8980 - val_acc: 0.0000e+00 - val_rmse: 0.5926\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6391 - acc: 0.6154 - rmse: 0.4731 - val_loss: 0.8978 - val_acc: 0.0000e+00 - val_rmse: 0.5925\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6371 - acc: 0.6154 - rmse: 0.4721 - val_loss: 0.8975 - val_acc: 0.0000e+00 - val_rmse: 0.5924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6350 - acc: 0.6154 - rmse: 0.4711 - val_loss: 0.8973 - val_acc: 0.0000e+00 - val_rmse: 0.5923\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6330 - acc: 0.6154 - rmse: 0.4701 - val_loss: 0.8971 - val_acc: 0.0000e+00 - val_rmse: 0.5922\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6309 - acc: 0.6154 - rmse: 0.4691 - val_loss: 0.8968 - val_acc: 0.0000e+00 - val_rmse: 0.5921\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6289 - acc: 0.6154 - rmse: 0.4681 - val_loss: 0.8966 - val_acc: 0.0000e+00 - val_rmse: 0.5920\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6269 - acc: 0.6154 - rmse: 0.4671 - val_loss: 0.8964 - val_acc: 0.0000e+00 - val_rmse: 0.5920\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6249 - acc: 0.6154 - rmse: 0.4661 - val_loss: 0.8961 - val_acc: 0.0000e+00 - val_rmse: 0.5919\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6229 - acc: 0.6154 - rmse: 0.4651 - val_loss: 0.8959 - val_acc: 0.0000e+00 - val_rmse: 0.5918\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6209 - acc: 0.6154 - rmse: 0.4641 - val_loss: 0.8957 - val_acc: 0.0000e+00 - val_rmse: 0.5917\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6189 - acc: 0.6154 - rmse: 0.4631 - val_loss: 0.8955 - val_acc: 0.0000e+00 - val_rmse: 0.5916\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6169 - acc: 0.6154 - rmse: 0.4621 - val_loss: 0.8952 - val_acc: 0.0000e+00 - val_rmse: 0.5915\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6149 - acc: 0.6154 - rmse: 0.4611 - val_loss: 0.8950 - val_acc: 0.0000e+00 - val_rmse: 0.5914\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6129 - acc: 0.6154 - rmse: 0.4601 - val_loss: 0.8948 - val_acc: 0.0000e+00 - val_rmse: 0.5913\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6109 - acc: 0.6154 - rmse: 0.4591 - val_loss: 0.8946 - val_acc: 0.0000e+00 - val_rmse: 0.5912\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6090 - acc: 0.6538 - rmse: 0.4581 - val_loss: 0.8943 - val_acc: 0.0000e+00 - val_rmse: 0.5911\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6070 - acc: 0.6538 - rmse: 0.4571 - val_loss: 0.8941 - val_acc: 0.0000e+00 - val_rmse: 0.5910\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6051 - acc: 0.6538 - rmse: 0.4561 - val_loss: 0.8939 - val_acc: 0.0000e+00 - val_rmse: 0.5909\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6032 - acc: 0.6538 - rmse: 0.4552 - val_loss: 0.8937 - val_acc: 0.0000e+00 - val_rmse: 0.5908\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6013 - acc: 0.6538 - rmse: 0.4542 - val_loss: 0.8934 - val_acc: 0.0000e+00 - val_rmse: 0.5908\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5994 - acc: 0.6923 - rmse: 0.4532 - val_loss: 0.8932 - val_acc: 0.0000e+00 - val_rmse: 0.5907\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5975 - acc: 0.6923 - rmse: 0.4522 - val_loss: 0.8930 - val_acc: 0.0000e+00 - val_rmse: 0.5906\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5956 - acc: 0.6923 - rmse: 0.4513 - val_loss: 0.8928 - val_acc: 0.0000e+00 - val_rmse: 0.5905\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5937 - acc: 0.6923 - rmse: 0.4503 - val_loss: 0.8926 - val_acc: 0.0000e+00 - val_rmse: 0.5904\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5919 - acc: 0.6923 - rmse: 0.4494 - val_loss: 0.8924 - val_acc: 0.0000e+00 - val_rmse: 0.5903\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5900 - acc: 0.6923 - rmse: 0.4484 - val_loss: 0.8921 - val_acc: 0.0000e+00 - val_rmse: 0.5902\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5882 - acc: 0.7308 - rmse: 0.4474 - val_loss: 0.8919 - val_acc: 0.0000e+00 - val_rmse: 0.5901\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5864 - acc: 0.7308 - rmse: 0.4465 - val_loss: 0.8917 - val_acc: 0.0000e+00 - val_rmse: 0.5900\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5845 - acc: 0.7308 - rmse: 0.4455 - val_loss: 0.8915 - val_acc: 0.0000e+00 - val_rmse: 0.5900\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5827 - acc: 0.7308 - rmse: 0.4446 - val_loss: 0.8913 - val_acc: 0.0000e+00 - val_rmse: 0.5899\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5809 - acc: 0.7308 - rmse: 0.4436 - val_loss: 0.8911 - val_acc: 0.0000e+00 - val_rmse: 0.5898\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5791 - acc: 0.7308 - rmse: 0.4427 - val_loss: 0.8908 - val_acc: 0.0000e+00 - val_rmse: 0.5897\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5773 - acc: 0.7308 - rmse: 0.4417 - val_loss: 0.8906 - val_acc: 0.0000e+00 - val_rmse: 0.5896\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5755 - acc: 0.7308 - rmse: 0.4408 - val_loss: 0.8904 - val_acc: 0.0000e+00 - val_rmse: 0.5895\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5737 - acc: 0.7308 - rmse: 0.4398 - val_loss: 0.8902 - val_acc: 0.0000e+00 - val_rmse: 0.5894\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5719 - acc: 0.7308 - rmse: 0.4389 - val_loss: 0.8900 - val_acc: 0.0000e+00 - val_rmse: 0.5893\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5701 - acc: 0.7308 - rmse: 0.4379 - val_loss: 0.8898 - val_acc: 0.0000e+00 - val_rmse: 0.5892\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5683 - acc: 0.7308 - rmse: 0.4370 - val_loss: 0.8895 - val_acc: 0.0000e+00 - val_rmse: 0.5892\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5666 - acc: 0.7308 - rmse: 0.4361 - val_loss: 0.8893 - val_acc: 0.0000e+00 - val_rmse: 0.5891\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5648 - acc: 0.7308 - rmse: 0.4351 - val_loss: 0.8891 - val_acc: 0.0000e+00 - val_rmse: 0.5890\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5631 - acc: 0.7308 - rmse: 0.4342 - val_loss: 0.8889 - val_acc: 0.0000e+00 - val_rmse: 0.5889\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5613 - acc: 0.7308 - rmse: 0.4332 - val_loss: 0.8887 - val_acc: 0.0000e+00 - val_rmse: 0.5888\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5596 - acc: 0.7308 - rmse: 0.4323 - val_loss: 0.8885 - val_acc: 0.0000e+00 - val_rmse: 0.5887\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5578 - acc: 0.7308 - rmse: 0.4314 - val_loss: 0.8883 - val_acc: 0.0000e+00 - val_rmse: 0.5886\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5561 - acc: 0.7308 - rmse: 0.4304 - val_loss: 0.8880 - val_acc: 0.0000e+00 - val_rmse: 0.5885\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5543 - acc: 0.7308 - rmse: 0.4295 - val_loss: 0.8878 - val_acc: 0.0000e+00 - val_rmse: 0.5885\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5526 - acc: 0.7308 - rmse: 0.4286 - val_loss: 0.8876 - val_acc: 0.0000e+00 - val_rmse: 0.5884\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5509 - acc: 0.7308 - rmse: 0.4276 - val_loss: 0.8874 - val_acc: 0.0000e+00 - val_rmse: 0.5883\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5492 - acc: 0.7692 - rmse: 0.4267 - val_loss: 0.8872 - val_acc: 0.0000e+00 - val_rmse: 0.5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5475 - acc: 0.7692 - rmse: 0.4258 - val_loss: 0.8870 - val_acc: 0.0000e+00 - val_rmse: 0.5881\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.5458 - acc: 0.7692 - rmse: 0.4248 - val_loss: 0.8867 - val_acc: 0.0000e+00 - val_rmse: 0.5880\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_37 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33075\n",
      " - 5s - loss: 0.8158 - acc: 0.3462 - rmse: 0.5507 - val_loss: 0.6440 - val_acc: 1.0000 - val_rmse: 0.4748\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.8131 - acc: 0.3462 - rmse: 0.5496 - val_loss: 0.6444 - val_acc: 1.0000 - val_rmse: 0.4750\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.8103 - acc: 0.3462 - rmse: 0.5485 - val_loss: 0.6448 - val_acc: 1.0000 - val_rmse: 0.4753\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.8076 - acc: 0.3462 - rmse: 0.5474 - val_loss: 0.6452 - val_acc: 1.0000 - val_rmse: 0.4755\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.8048 - acc: 0.3462 - rmse: 0.5463 - val_loss: 0.6456 - val_acc: 1.0000 - val_rmse: 0.4757\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.8021 - acc: 0.3462 - rmse: 0.5452 - val_loss: 0.6460 - val_acc: 1.0000 - val_rmse: 0.4759\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7995 - acc: 0.3462 - rmse: 0.5441 - val_loss: 0.6464 - val_acc: 1.0000 - val_rmse: 0.4761\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7968 - acc: 0.3462 - rmse: 0.5431 - val_loss: 0.6469 - val_acc: 1.0000 - val_rmse: 0.4763\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7942 - acc: 0.3462 - rmse: 0.5420 - val_loss: 0.6473 - val_acc: 1.0000 - val_rmse: 0.4766\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7915 - acc: 0.3462 - rmse: 0.5409 - val_loss: 0.6478 - val_acc: 1.0000 - val_rmse: 0.4768\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7889 - acc: 0.3462 - rmse: 0.5398 - val_loss: 0.6482 - val_acc: 1.0000 - val_rmse: 0.4770\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7863 - acc: 0.3462 - rmse: 0.5388 - val_loss: 0.6487 - val_acc: 1.0000 - val_rmse: 0.4773\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7837 - acc: 0.3462 - rmse: 0.5377 - val_loss: 0.6492 - val_acc: 1.0000 - val_rmse: 0.4775\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7811 - acc: 0.3462 - rmse: 0.5366 - val_loss: 0.6497 - val_acc: 1.0000 - val_rmse: 0.4778\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7785 - acc: 0.3462 - rmse: 0.5356 - val_loss: 0.6502 - val_acc: 1.0000 - val_rmse: 0.4780\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7759 - acc: 0.3462 - rmse: 0.5345 - val_loss: 0.6506 - val_acc: 1.0000 - val_rmse: 0.4783\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7734 - acc: 0.3462 - rmse: 0.5334 - val_loss: 0.6511 - val_acc: 1.0000 - val_rmse: 0.4785\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7708 - acc: 0.3462 - rmse: 0.5324 - val_loss: 0.6516 - val_acc: 1.0000 - val_rmse: 0.4788\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7683 - acc: 0.3846 - rmse: 0.5313 - val_loss: 0.6521 - val_acc: 1.0000 - val_rmse: 0.4790\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7658 - acc: 0.3846 - rmse: 0.5303 - val_loss: 0.6526 - val_acc: 1.0000 - val_rmse: 0.4793\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7633 - acc: 0.3846 - rmse: 0.5292 - val_loss: 0.6531 - val_acc: 1.0000 - val_rmse: 0.4796\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7609 - acc: 0.3846 - rmse: 0.5282 - val_loss: 0.6536 - val_acc: 1.0000 - val_rmse: 0.4798\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7584 - acc: 0.3846 - rmse: 0.5272 - val_loss: 0.6540 - val_acc: 1.0000 - val_rmse: 0.4801\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7560 - acc: 0.3846 - rmse: 0.5262 - val_loss: 0.6545 - val_acc: 1.0000 - val_rmse: 0.4803\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7535 - acc: 0.3846 - rmse: 0.5251 - val_loss: 0.6550 - val_acc: 1.0000 - val_rmse: 0.4806\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7511 - acc: 0.3846 - rmse: 0.5241 - val_loss: 0.6555 - val_acc: 1.0000 - val_rmse: 0.4808\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7487 - acc: 0.3846 - rmse: 0.5230 - val_loss: 0.6560 - val_acc: 1.0000 - val_rmse: 0.4811\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7462 - acc: 0.3846 - rmse: 0.5220 - val_loss: 0.6565 - val_acc: 1.0000 - val_rmse: 0.4814\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7438 - acc: 0.3846 - rmse: 0.5210 - val_loss: 0.6570 - val_acc: 1.0000 - val_rmse: 0.4816\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7415 - acc: 0.4231 - rmse: 0.5200 - val_loss: 0.6575 - val_acc: 1.0000 - val_rmse: 0.4819\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7391 - acc: 0.4231 - rmse: 0.5190 - val_loss: 0.6581 - val_acc: 1.0000 - val_rmse: 0.4821\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7368 - acc: 0.4231 - rmse: 0.5179 - val_loss: 0.6586 - val_acc: 1.0000 - val_rmse: 0.4824\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7345 - acc: 0.4231 - rmse: 0.5169 - val_loss: 0.6591 - val_acc: 1.0000 - val_rmse: 0.4827\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7322 - acc: 0.4231 - rmse: 0.5159 - val_loss: 0.6596 - val_acc: 1.0000 - val_rmse: 0.4829\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7299 - acc: 0.4231 - rmse: 0.5149 - val_loss: 0.6601 - val_acc: 1.0000 - val_rmse: 0.4832\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7276 - acc: 0.4231 - rmse: 0.5140 - val_loss: 0.6606 - val_acc: 1.0000 - val_rmse: 0.4835\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7254 - acc: 0.4231 - rmse: 0.5130 - val_loss: 0.6611 - val_acc: 1.0000 - val_rmse: 0.4837\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7232 - acc: 0.4231 - rmse: 0.5120 - val_loss: 0.6616 - val_acc: 1.0000 - val_rmse: 0.4840\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7209 - acc: 0.4231 - rmse: 0.5110 - val_loss: 0.6621 - val_acc: 1.0000 - val_rmse: 0.4842\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7187 - acc: 0.4231 - rmse: 0.5100 - val_loss: 0.6626 - val_acc: 1.0000 - val_rmse: 0.4845\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7165 - acc: 0.4231 - rmse: 0.5090 - val_loss: 0.6631 - val_acc: 1.0000 - val_rmse: 0.4848\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7143 - acc: 0.4615 - rmse: 0.5081 - val_loss: 0.6636 - val_acc: 1.0000 - val_rmse: 0.4850\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7121 - acc: 0.4615 - rmse: 0.5071 - val_loss: 0.6641 - val_acc: 1.0000 - val_rmse: 0.4853\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7099 - acc: 0.4615 - rmse: 0.5061 - val_loss: 0.6646 - val_acc: 1.0000 - val_rmse: 0.4855\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7077 - acc: 0.5000 - rmse: 0.5051 - val_loss: 0.6651 - val_acc: 1.0000 - val_rmse: 0.4858\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7056 - acc: 0.5000 - rmse: 0.5042 - val_loss: 0.6657 - val_acc: 1.0000 - val_rmse: 0.4861\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7034 - acc: 0.5000 - rmse: 0.5032 - val_loss: 0.6662 - val_acc: 1.0000 - val_rmse: 0.4863\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.7012 - acc: 0.5000 - rmse: 0.5022 - val_loss: 0.6667 - val_acc: 1.0000 - val_rmse: 0.4866\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6991 - acc: 0.5000 - rmse: 0.5013 - val_loss: 0.6672 - val_acc: 1.0000 - val_rmse: 0.4868\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6970 - acc: 0.5000 - rmse: 0.5003 - val_loss: 0.6677 - val_acc: 1.0000 - val_rmse: 0.4871\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6948 - acc: 0.5000 - rmse: 0.4993 - val_loss: 0.6682 - val_acc: 1.0000 - val_rmse: 0.4874\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6927 - acc: 0.5000 - rmse: 0.4984 - val_loss: 0.6687 - val_acc: 1.0000 - val_rmse: 0.4876\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6906 - acc: 0.5385 - rmse: 0.4974 - val_loss: 0.6692 - val_acc: 1.0000 - val_rmse: 0.4879\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6884 - acc: 0.5769 - rmse: 0.4964 - val_loss: 0.6697 - val_acc: 1.0000 - val_rmse: 0.4881\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6863 - acc: 0.5769 - rmse: 0.4955 - val_loss: 0.6702 - val_acc: 1.0000 - val_rmse: 0.4884\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6842 - acc: 0.5769 - rmse: 0.4945 - val_loss: 0.6707 - val_acc: 1.0000 - val_rmse: 0.4887\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6822 - acc: 0.6154 - rmse: 0.4935 - val_loss: 0.6712 - val_acc: 1.0000 - val_rmse: 0.4889\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6801 - acc: 0.6154 - rmse: 0.4926 - val_loss: 0.6717 - val_acc: 1.0000 - val_rmse: 0.4892\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6780 - acc: 0.6154 - rmse: 0.4916 - val_loss: 0.6723 - val_acc: 1.0000 - val_rmse: 0.4894\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6760 - acc: 0.6154 - rmse: 0.4907 - val_loss: 0.6728 - val_acc: 1.0000 - val_rmse: 0.4897\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6739 - acc: 0.6154 - rmse: 0.4897 - val_loss: 0.6733 - val_acc: 1.0000 - val_rmse: 0.4900\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6719 - acc: 0.6154 - rmse: 0.4888 - val_loss: 0.6738 - val_acc: 1.0000 - val_rmse: 0.4902\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6698 - acc: 0.6538 - rmse: 0.4878 - val_loss: 0.6743 - val_acc: 1.0000 - val_rmse: 0.4905\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6678 - acc: 0.6538 - rmse: 0.4869 - val_loss: 0.6748 - val_acc: 1.0000 - val_rmse: 0.4907\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6658 - acc: 0.6538 - rmse: 0.4860 - val_loss: 0.6753 - val_acc: 1.0000 - val_rmse: 0.4910\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6638 - acc: 0.6538 - rmse: 0.4850 - val_loss: 0.6758 - val_acc: 1.0000 - val_rmse: 0.4913\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6618 - acc: 0.6538 - rmse: 0.4841 - val_loss: 0.6763 - val_acc: 1.0000 - val_rmse: 0.4915\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6598 - acc: 0.6538 - rmse: 0.4831 - val_loss: 0.6768 - val_acc: 1.0000 - val_rmse: 0.4918\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6578 - acc: 0.6538 - rmse: 0.4822 - val_loss: 0.6773 - val_acc: 1.0000 - val_rmse: 0.4920\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6559 - acc: 0.6538 - rmse: 0.4813 - val_loss: 0.6778 - val_acc: 1.0000 - val_rmse: 0.4923\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6539 - acc: 0.6538 - rmse: 0.4804 - val_loss: 0.6783 - val_acc: 1.0000 - val_rmse: 0.4925\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6520 - acc: 0.6538 - rmse: 0.4795 - val_loss: 0.6788 - val_acc: 1.0000 - val_rmse: 0.4928\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6501 - acc: 0.6538 - rmse: 0.4786 - val_loss: 0.6793 - val_acc: 1.0000 - val_rmse: 0.4930\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6482 - acc: 0.6538 - rmse: 0.4776 - val_loss: 0.6798 - val_acc: 1.0000 - val_rmse: 0.4933\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6463 - acc: 0.6538 - rmse: 0.4767 - val_loss: 0.6803 - val_acc: 1.0000 - val_rmse: 0.4935\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6444 - acc: 0.6538 - rmse: 0.4758 - val_loss: 0.6808 - val_acc: 1.0000 - val_rmse: 0.4938\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6425 - acc: 0.6538 - rmse: 0.4749 - val_loss: 0.6812 - val_acc: 1.0000 - val_rmse: 0.4940\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6406 - acc: 0.6538 - rmse: 0.4740 - val_loss: 0.6817 - val_acc: 1.0000 - val_rmse: 0.4943\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6388 - acc: 0.6538 - rmse: 0.4731 - val_loss: 0.6822 - val_acc: 1.0000 - val_rmse: 0.4945\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6369 - acc: 0.6923 - rmse: 0.4722 - val_loss: 0.6827 - val_acc: 1.0000 - val_rmse: 0.4948\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6350 - acc: 0.6923 - rmse: 0.4713 - val_loss: 0.6832 - val_acc: 1.0000 - val_rmse: 0.4950\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6332 - acc: 0.6923 - rmse: 0.4704 - val_loss: 0.6837 - val_acc: 1.0000 - val_rmse: 0.4953\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6313 - acc: 0.6923 - rmse: 0.4695 - val_loss: 0.6842 - val_acc: 1.0000 - val_rmse: 0.4955\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6295 - acc: 0.6923 - rmse: 0.4686 - val_loss: 0.6847 - val_acc: 1.0000 - val_rmse: 0.4957\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6276 - acc: 0.6923 - rmse: 0.4677 - val_loss: 0.6852 - val_acc: 1.0000 - val_rmse: 0.4960\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6258 - acc: 0.6923 - rmse: 0.4668 - val_loss: 0.6856 - val_acc: 1.0000 - val_rmse: 0.4962\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6239 - acc: 0.6923 - rmse: 0.4659 - val_loss: 0.6861 - val_acc: 1.0000 - val_rmse: 0.4965\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6221 - acc: 0.6923 - rmse: 0.4650 - val_loss: 0.6866 - val_acc: 1.0000 - val_rmse: 0.4967\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6203 - acc: 0.6923 - rmse: 0.4641 - val_loss: 0.6871 - val_acc: 1.0000 - val_rmse: 0.4970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6185 - acc: 0.6923 - rmse: 0.4632 - val_loss: 0.6876 - val_acc: 1.0000 - val_rmse: 0.4972\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6166 - acc: 0.6923 - rmse: 0.4624 - val_loss: 0.6881 - val_acc: 1.0000 - val_rmse: 0.4975\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6148 - acc: 0.6923 - rmse: 0.4615 - val_loss: 0.6886 - val_acc: 1.0000 - val_rmse: 0.4977\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6130 - acc: 0.6923 - rmse: 0.4606 - val_loss: 0.6890 - val_acc: 1.0000 - val_rmse: 0.4979\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6112 - acc: 0.6923 - rmse: 0.4597 - val_loss: 0.6895 - val_acc: 1.0000 - val_rmse: 0.4982\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6094 - acc: 0.6923 - rmse: 0.4588 - val_loss: 0.6900 - val_acc: 1.0000 - val_rmse: 0.4984\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6077 - acc: 0.6923 - rmse: 0.4579 - val_loss: 0.6905 - val_acc: 1.0000 - val_rmse: 0.4987\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33075\n",
      " - 2s - loss: 0.6059 - acc: 0.6923 - rmse: 0.4570 - val_loss: 0.6909 - val_acc: 1.0000 - val_rmse: 0.4989\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6041 - acc: 0.6923 - rmse: 0.4562 - val_loss: 0.6914 - val_acc: 1.0000 - val_rmse: 0.4991\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6024 - acc: 0.6923 - rmse: 0.4553 - val_loss: 0.6919 - val_acc: 1.0000 - val_rmse: 0.4994\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33075\n",
      " - 1s - loss: 0.6006 - acc: 0.6923 - rmse: 0.4544 - val_loss: 0.6923 - val_acc: 1.0000 - val_rmse: 0.4996\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_38 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33075 to 0.10972, saving model to /tmp/LSTM_LOO_checkpoint.h5\n",
      " - 60s - loss: 0.7807 - acc: 0.4615 - rmse: 0.5349 - val_loss: 0.1097 - val_acc: 1.0000 - val_rmse: 0.1039\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7778 - acc: 0.4615 - rmse: 0.5338 - val_loss: 0.1097 - val_acc: 1.0000 - val_rmse: 0.1039\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7749 - acc: 0.4615 - rmse: 0.5327 - val_loss: 0.1097 - val_acc: 1.0000 - val_rmse: 0.1039\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7721 - acc: 0.4615 - rmse: 0.5316 - val_loss: 0.1098 - val_acc: 1.0000 - val_rmse: 0.1039\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7692 - acc: 0.4615 - rmse: 0.5305 - val_loss: 0.1098 - val_acc: 1.0000 - val_rmse: 0.1040\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7664 - acc: 0.4615 - rmse: 0.5294 - val_loss: 0.1098 - val_acc: 1.0000 - val_rmse: 0.1040\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7635 - acc: 0.4615 - rmse: 0.5283 - val_loss: 0.1098 - val_acc: 1.0000 - val_rmse: 0.1040\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7607 - acc: 0.4615 - rmse: 0.5272 - val_loss: 0.1098 - val_acc: 1.0000 - val_rmse: 0.1040\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7579 - acc: 0.4615 - rmse: 0.5262 - val_loss: 0.1098 - val_acc: 1.0000 - val_rmse: 0.1040\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7551 - acc: 0.4615 - rmse: 0.5251 - val_loss: 0.1098 - val_acc: 1.0000 - val_rmse: 0.1040\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7523 - acc: 0.4615 - rmse: 0.5240 - val_loss: 0.1098 - val_acc: 1.0000 - val_rmse: 0.1040\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7495 - acc: 0.4615 - rmse: 0.5229 - val_loss: 0.1099 - val_acc: 1.0000 - val_rmse: 0.1040\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7468 - acc: 0.4615 - rmse: 0.5218 - val_loss: 0.1099 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7440 - acc: 0.4615 - rmse: 0.5207 - val_loss: 0.1099 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7412 - acc: 0.4615 - rmse: 0.5196 - val_loss: 0.1099 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7384 - acc: 0.4615 - rmse: 0.5185 - val_loss: 0.1099 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7357 - acc: 0.4615 - rmse: 0.5174 - val_loss: 0.1099 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7329 - acc: 0.4615 - rmse: 0.5163 - val_loss: 0.1099 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7302 - acc: 0.4615 - rmse: 0.5152 - val_loss: 0.1099 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7275 - acc: 0.5000 - rmse: 0.5141 - val_loss: 0.1099 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7248 - acc: 0.5385 - rmse: 0.5130 - val_loss: 0.1100 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7221 - acc: 0.5385 - rmse: 0.5119 - val_loss: 0.1100 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7194 - acc: 0.5385 - rmse: 0.5108 - val_loss: 0.1100 - val_acc: 1.0000 - val_rmse: 0.1041\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7167 - acc: 0.5385 - rmse: 0.5097 - val_loss: 0.1100 - val_acc: 1.0000 - val_rmse: 0.1042\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7140 - acc: 0.5385 - rmse: 0.5086 - val_loss: 0.1100 - val_acc: 1.0000 - val_rmse: 0.1042\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7114 - acc: 0.5385 - rmse: 0.5075 - val_loss: 0.1100 - val_acc: 1.0000 - val_rmse: 0.1042\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7087 - acc: 0.5385 - rmse: 0.5064 - val_loss: 0.1100 - val_acc: 1.0000 - val_rmse: 0.1042\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7060 - acc: 0.5769 - rmse: 0.5053 - val_loss: 0.1100 - val_acc: 1.0000 - val_rmse: 0.1042\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7034 - acc: 0.5769 - rmse: 0.5042 - val_loss: 0.1100 - val_acc: 1.0000 - val_rmse: 0.1042\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7007 - acc: 0.5769 - rmse: 0.5031 - val_loss: 0.1101 - val_acc: 1.0000 - val_rmse: 0.1042\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6981 - acc: 0.5769 - rmse: 0.5020 - val_loss: 0.1101 - val_acc: 1.0000 - val_rmse: 0.1042\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6955 - acc: 0.5769 - rmse: 0.5009 - val_loss: 0.1101 - val_acc: 1.0000 - val_rmse: 0.1042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6929 - acc: 0.5769 - rmse: 0.4998 - val_loss: 0.1101 - val_acc: 1.0000 - val_rmse: 0.1042\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6903 - acc: 0.5769 - rmse: 0.4987 - val_loss: 0.1101 - val_acc: 1.0000 - val_rmse: 0.1043\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6877 - acc: 0.5769 - rmse: 0.4977 - val_loss: 0.1101 - val_acc: 1.0000 - val_rmse: 0.1043\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6852 - acc: 0.5769 - rmse: 0.4966 - val_loss: 0.1101 - val_acc: 1.0000 - val_rmse: 0.1043\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6826 - acc: 0.5769 - rmse: 0.4955 - val_loss: 0.1101 - val_acc: 1.0000 - val_rmse: 0.1043\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6801 - acc: 0.5769 - rmse: 0.4944 - val_loss: 0.1102 - val_acc: 1.0000 - val_rmse: 0.1043\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6776 - acc: 0.5769 - rmse: 0.4933 - val_loss: 0.1102 - val_acc: 1.0000 - val_rmse: 0.1043\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6751 - acc: 0.5769 - rmse: 0.4922 - val_loss: 0.1102 - val_acc: 1.0000 - val_rmse: 0.1043\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6725 - acc: 0.5769 - rmse: 0.4912 - val_loss: 0.1102 - val_acc: 1.0000 - val_rmse: 0.1043\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6700 - acc: 0.5769 - rmse: 0.4901 - val_loss: 0.1102 - val_acc: 1.0000 - val_rmse: 0.1043\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6675 - acc: 0.5769 - rmse: 0.4890 - val_loss: 0.1102 - val_acc: 1.0000 - val_rmse: 0.1044\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6651 - acc: 0.5769 - rmse: 0.4879 - val_loss: 0.1102 - val_acc: 1.0000 - val_rmse: 0.1044\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6626 - acc: 0.5769 - rmse: 0.4868 - val_loss: 0.1102 - val_acc: 1.0000 - val_rmse: 0.1044\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6601 - acc: 0.5769 - rmse: 0.4857 - val_loss: 0.1103 - val_acc: 1.0000 - val_rmse: 0.1044\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6577 - acc: 0.5769 - rmse: 0.4847 - val_loss: 0.1103 - val_acc: 1.0000 - val_rmse: 0.1044\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6553 - acc: 0.5769 - rmse: 0.4836 - val_loss: 0.1103 - val_acc: 1.0000 - val_rmse: 0.1044\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6528 - acc: 0.5769 - rmse: 0.4825 - val_loss: 0.1103 - val_acc: 1.0000 - val_rmse: 0.1044\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6504 - acc: 0.5769 - rmse: 0.4814 - val_loss: 0.1103 - val_acc: 1.0000 - val_rmse: 0.1044\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6480 - acc: 0.5769 - rmse: 0.4804 - val_loss: 0.1103 - val_acc: 1.0000 - val_rmse: 0.1044\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6456 - acc: 0.5769 - rmse: 0.4793 - val_loss: 0.1103 - val_acc: 1.0000 - val_rmse: 0.1045\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6432 - acc: 0.5769 - rmse: 0.4782 - val_loss: 0.1103 - val_acc: 1.0000 - val_rmse: 0.1045\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6408 - acc: 0.5769 - rmse: 0.4771 - val_loss: 0.1104 - val_acc: 1.0000 - val_rmse: 0.1045\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6384 - acc: 0.5769 - rmse: 0.4761 - val_loss: 0.1104 - val_acc: 1.0000 - val_rmse: 0.1045\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6361 - acc: 0.5769 - rmse: 0.4750 - val_loss: 0.1104 - val_acc: 1.0000 - val_rmse: 0.1045\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6337 - acc: 0.5769 - rmse: 0.4740 - val_loss: 0.1104 - val_acc: 1.0000 - val_rmse: 0.1045\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6314 - acc: 0.5769 - rmse: 0.4729 - val_loss: 0.1104 - val_acc: 1.0000 - val_rmse: 0.1045\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6291 - acc: 0.5769 - rmse: 0.4718 - val_loss: 0.1104 - val_acc: 1.0000 - val_rmse: 0.1045\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6267 - acc: 0.5769 - rmse: 0.4708 - val_loss: 0.1104 - val_acc: 1.0000 - val_rmse: 0.1046\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6244 - acc: 0.5769 - rmse: 0.4697 - val_loss: 0.1104 - val_acc: 1.0000 - val_rmse: 0.1046\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6221 - acc: 0.5769 - rmse: 0.4686 - val_loss: 0.1105 - val_acc: 1.0000 - val_rmse: 0.1046\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6198 - acc: 0.6154 - rmse: 0.4676 - val_loss: 0.1105 - val_acc: 1.0000 - val_rmse: 0.1046\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6175 - acc: 0.6154 - rmse: 0.4665 - val_loss: 0.1105 - val_acc: 1.0000 - val_rmse: 0.1046\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6152 - acc: 0.6154 - rmse: 0.4654 - val_loss: 0.1105 - val_acc: 1.0000 - val_rmse: 0.1046\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6129 - acc: 0.6154 - rmse: 0.4644 - val_loss: 0.1105 - val_acc: 1.0000 - val_rmse: 0.1046\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6107 - acc: 0.6154 - rmse: 0.4633 - val_loss: 0.1105 - val_acc: 1.0000 - val_rmse: 0.1046\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6084 - acc: 0.6154 - rmse: 0.4623 - val_loss: 0.1105 - val_acc: 1.0000 - val_rmse: 0.1046\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6061 - acc: 0.6154 - rmse: 0.4612 - val_loss: 0.1106 - val_acc: 1.0000 - val_rmse: 0.1047\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6039 - acc: 0.6154 - rmse: 0.4601 - val_loss: 0.1106 - val_acc: 1.0000 - val_rmse: 0.1047\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6017 - acc: 0.6538 - rmse: 0.4591 - val_loss: 0.1106 - val_acc: 1.0000 - val_rmse: 0.1047\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5994 - acc: 0.6538 - rmse: 0.4580 - val_loss: 0.1106 - val_acc: 1.0000 - val_rmse: 0.1047\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5972 - acc: 0.6538 - rmse: 0.4570 - val_loss: 0.1106 - val_acc: 1.0000 - val_rmse: 0.1047\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5950 - acc: 0.6538 - rmse: 0.4559 - val_loss: 0.1106 - val_acc: 1.0000 - val_rmse: 0.1047\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5927 - acc: 0.6538 - rmse: 0.4549 - val_loss: 0.1106 - val_acc: 1.0000 - val_rmse: 0.1047\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5905 - acc: 0.6538 - rmse: 0.4538 - val_loss: 0.1106 - val_acc: 1.0000 - val_rmse: 0.1047\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5884 - acc: 0.6538 - rmse: 0.4527 - val_loss: 0.1107 - val_acc: 1.0000 - val_rmse: 0.1048\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5862 - acc: 0.6538 - rmse: 0.4517 - val_loss: 0.1107 - val_acc: 1.0000 - val_rmse: 0.1048\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5840 - acc: 0.6538 - rmse: 0.4506 - val_loss: 0.1107 - val_acc: 1.0000 - val_rmse: 0.1048\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5818 - acc: 0.6538 - rmse: 0.4496 - val_loss: 0.1107 - val_acc: 1.0000 - val_rmse: 0.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5797 - acc: 0.6538 - rmse: 0.4486 - val_loss: 0.1107 - val_acc: 1.0000 - val_rmse: 0.1048\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5775 - acc: 0.6923 - rmse: 0.4475 - val_loss: 0.1107 - val_acc: 1.0000 - val_rmse: 0.1048\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5754 - acc: 0.6923 - rmse: 0.4465 - val_loss: 0.1107 - val_acc: 1.0000 - val_rmse: 0.1048\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5733 - acc: 0.7308 - rmse: 0.4454 - val_loss: 0.1107 - val_acc: 1.0000 - val_rmse: 0.1048\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5712 - acc: 0.7308 - rmse: 0.4444 - val_loss: 0.1108 - val_acc: 1.0000 - val_rmse: 0.1048\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5691 - acc: 0.7308 - rmse: 0.4434 - val_loss: 0.1108 - val_acc: 1.0000 - val_rmse: 0.1049\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5670 - acc: 0.7308 - rmse: 0.4423 - val_loss: 0.1108 - val_acc: 1.0000 - val_rmse: 0.1049\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5649 - acc: 0.7308 - rmse: 0.4413 - val_loss: 0.1108 - val_acc: 1.0000 - val_rmse: 0.1049\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5628 - acc: 0.7692 - rmse: 0.4403 - val_loss: 0.1108 - val_acc: 1.0000 - val_rmse: 0.1049\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5607 - acc: 0.7692 - rmse: 0.4392 - val_loss: 0.1108 - val_acc: 1.0000 - val_rmse: 0.1049\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5586 - acc: 0.7692 - rmse: 0.4382 - val_loss: 0.1108 - val_acc: 1.0000 - val_rmse: 0.1049\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5565 - acc: 0.7692 - rmse: 0.4372 - val_loss: 0.1108 - val_acc: 1.0000 - val_rmse: 0.1049\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5545 - acc: 0.7692 - rmse: 0.4361 - val_loss: 0.1109 - val_acc: 1.0000 - val_rmse: 0.1049\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5524 - acc: 0.7692 - rmse: 0.4351 - val_loss: 0.1109 - val_acc: 1.0000 - val_rmse: 0.1049\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5504 - acc: 0.7692 - rmse: 0.4341 - val_loss: 0.1109 - val_acc: 1.0000 - val_rmse: 0.1050\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5483 - acc: 0.8077 - rmse: 0.4330 - val_loss: 0.1109 - val_acc: 1.0000 - val_rmse: 0.1050\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5463 - acc: 0.8077 - rmse: 0.4320 - val_loss: 0.1109 - val_acc: 1.0000 - val_rmse: 0.1050\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5442 - acc: 0.8077 - rmse: 0.4310 - val_loss: 0.1109 - val_acc: 1.0000 - val_rmse: 0.1050\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5422 - acc: 0.8077 - rmse: 0.4299 - val_loss: 0.1109 - val_acc: 1.0000 - val_rmse: 0.1050\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5402 - acc: 0.8077 - rmse: 0.4289 - val_loss: 0.1109 - val_acc: 1.0000 - val_rmse: 0.1050\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_39 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.10972\n",
      " - 16s - loss: 0.7677 - acc: 0.4615 - rmse: 0.5325 - val_loss: 1.0394 - val_acc: 0.0000e+00 - val_rmse: 0.6463\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7650 - acc: 0.4615 - rmse: 0.5314 - val_loss: 1.0397 - val_acc: 0.0000e+00 - val_rmse: 0.6464\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7624 - acc: 0.4615 - rmse: 0.5303 - val_loss: 1.0399 - val_acc: 0.0000e+00 - val_rmse: 0.6465\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7598 - acc: 0.4615 - rmse: 0.5292 - val_loss: 1.0401 - val_acc: 0.0000e+00 - val_rmse: 0.6466\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7572 - acc: 0.4615 - rmse: 0.5281 - val_loss: 1.0404 - val_acc: 0.0000e+00 - val_rmse: 0.6467\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7547 - acc: 0.4615 - rmse: 0.5270 - val_loss: 1.0406 - val_acc: 0.0000e+00 - val_rmse: 0.6468\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7521 - acc: 0.4615 - rmse: 0.5259 - val_loss: 1.0408 - val_acc: 0.0000e+00 - val_rmse: 0.6468\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7495 - acc: 0.4615 - rmse: 0.5248 - val_loss: 1.0411 - val_acc: 0.0000e+00 - val_rmse: 0.6469\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7470 - acc: 0.4615 - rmse: 0.5237 - val_loss: 1.0413 - val_acc: 0.0000e+00 - val_rmse: 0.6470\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7445 - acc: 0.4615 - rmse: 0.5226 - val_loss: 1.0415 - val_acc: 0.0000e+00 - val_rmse: 0.6471\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7420 - acc: 0.4615 - rmse: 0.5215 - val_loss: 1.0418 - val_acc: 0.0000e+00 - val_rmse: 0.6472\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7396 - acc: 0.4615 - rmse: 0.5204 - val_loss: 1.0420 - val_acc: 0.0000e+00 - val_rmse: 0.6473\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7371 - acc: 0.4615 - rmse: 0.5194 - val_loss: 1.0423 - val_acc: 0.0000e+00 - val_rmse: 0.6474\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7347 - acc: 0.4615 - rmse: 0.5183 - val_loss: 1.0425 - val_acc: 0.0000e+00 - val_rmse: 0.6474\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7322 - acc: 0.4615 - rmse: 0.5172 - val_loss: 1.0428 - val_acc: 0.0000e+00 - val_rmse: 0.6475\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7298 - acc: 0.4615 - rmse: 0.5161 - val_loss: 1.0430 - val_acc: 0.0000e+00 - val_rmse: 0.6476\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7274 - acc: 0.4615 - rmse: 0.5151 - val_loss: 1.0433 - val_acc: 0.0000e+00 - val_rmse: 0.6477\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7250 - acc: 0.4615 - rmse: 0.5140 - val_loss: 1.0436 - val_acc: 0.0000e+00 - val_rmse: 0.6478\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7226 - acc: 0.4615 - rmse: 0.5129 - val_loss: 1.0438 - val_acc: 0.0000e+00 - val_rmse: 0.6479\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7202 - acc: 0.4615 - rmse: 0.5119 - val_loss: 1.0441 - val_acc: 0.0000e+00 - val_rmse: 0.6480\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7179 - acc: 0.4615 - rmse: 0.5108 - val_loss: 1.0443 - val_acc: 0.0000e+00 - val_rmse: 0.6481\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7156 - acc: 0.4615 - rmse: 0.5098 - val_loss: 1.0446 - val_acc: 0.0000e+00 - val_rmse: 0.6482\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7133 - acc: 0.4615 - rmse: 0.5087 - val_loss: 1.0448 - val_acc: 0.0000e+00 - val_rmse: 0.6482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7110 - acc: 0.4615 - rmse: 0.5077 - val_loss: 1.0451 - val_acc: 0.0000e+00 - val_rmse: 0.6483\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7087 - acc: 0.4615 - rmse: 0.5067 - val_loss: 1.0453 - val_acc: 0.0000e+00 - val_rmse: 0.6484\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7064 - acc: 0.4615 - rmse: 0.5056 - val_loss: 1.0456 - val_acc: 0.0000e+00 - val_rmse: 0.6485\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7042 - acc: 0.5000 - rmse: 0.5046 - val_loss: 1.0459 - val_acc: 0.0000e+00 - val_rmse: 0.6486\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7019 - acc: 0.5000 - rmse: 0.5035 - val_loss: 1.0461 - val_acc: 0.0000e+00 - val_rmse: 0.6487\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6997 - acc: 0.5000 - rmse: 0.5025 - val_loss: 1.0464 - val_acc: 0.0000e+00 - val_rmse: 0.6488\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6974 - acc: 0.5000 - rmse: 0.5015 - val_loss: 1.0466 - val_acc: 0.0000e+00 - val_rmse: 0.6489\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6952 - acc: 0.5000 - rmse: 0.5004 - val_loss: 1.0469 - val_acc: 0.0000e+00 - val_rmse: 0.6490\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6930 - acc: 0.5000 - rmse: 0.4994 - val_loss: 1.0472 - val_acc: 0.0000e+00 - val_rmse: 0.6491\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6907 - acc: 0.5000 - rmse: 0.4983 - val_loss: 1.0474 - val_acc: 0.0000e+00 - val_rmse: 0.6492\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6885 - acc: 0.5000 - rmse: 0.4973 - val_loss: 1.0477 - val_acc: 0.0000e+00 - val_rmse: 0.6493\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6863 - acc: 0.5000 - rmse: 0.4963 - val_loss: 1.0480 - val_acc: 0.0000e+00 - val_rmse: 0.6494\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6841 - acc: 0.5000 - rmse: 0.4952 - val_loss: 1.0482 - val_acc: 0.0000e+00 - val_rmse: 0.6494\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6819 - acc: 0.5385 - rmse: 0.4942 - val_loss: 1.0485 - val_acc: 0.0000e+00 - val_rmse: 0.6495\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6797 - acc: 0.5385 - rmse: 0.4931 - val_loss: 1.0488 - val_acc: 0.0000e+00 - val_rmse: 0.6496\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6775 - acc: 0.5769 - rmse: 0.4921 - val_loss: 1.0491 - val_acc: 0.0000e+00 - val_rmse: 0.6497\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6754 - acc: 0.5769 - rmse: 0.4911 - val_loss: 1.0493 - val_acc: 0.0000e+00 - val_rmse: 0.6498\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6732 - acc: 0.5769 - rmse: 0.4900 - val_loss: 1.0496 - val_acc: 0.0000e+00 - val_rmse: 0.6499\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6710 - acc: 0.5769 - rmse: 0.4890 - val_loss: 1.0499 - val_acc: 0.0000e+00 - val_rmse: 0.6500\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6689 - acc: 0.6154 - rmse: 0.4880 - val_loss: 1.0501 - val_acc: 0.0000e+00 - val_rmse: 0.6501\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6667 - acc: 0.6154 - rmse: 0.4869 - val_loss: 1.0504 - val_acc: 0.0000e+00 - val_rmse: 0.6502\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6646 - acc: 0.6154 - rmse: 0.4859 - val_loss: 1.0507 - val_acc: 0.0000e+00 - val_rmse: 0.6503\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6625 - acc: 0.6154 - rmse: 0.4849 - val_loss: 1.0509 - val_acc: 0.0000e+00 - val_rmse: 0.6504\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6604 - acc: 0.6154 - rmse: 0.4838 - val_loss: 1.0512 - val_acc: 0.0000e+00 - val_rmse: 0.6505\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6583 - acc: 0.6154 - rmse: 0.4828 - val_loss: 1.0515 - val_acc: 0.0000e+00 - val_rmse: 0.6506\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6562 - acc: 0.6154 - rmse: 0.4818 - val_loss: 1.0517 - val_acc: 0.0000e+00 - val_rmse: 0.6507\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6541 - acc: 0.6154 - rmse: 0.4808 - val_loss: 1.0520 - val_acc: 0.0000e+00 - val_rmse: 0.6508\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6520 - acc: 0.6154 - rmse: 0.4797 - val_loss: 1.0523 - val_acc: 0.0000e+00 - val_rmse: 0.6509\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6499 - acc: 0.6154 - rmse: 0.4787 - val_loss: 1.0525 - val_acc: 0.0000e+00 - val_rmse: 0.6509\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6478 - acc: 0.6154 - rmse: 0.4777 - val_loss: 1.0528 - val_acc: 0.0000e+00 - val_rmse: 0.6510\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6458 - acc: 0.6154 - rmse: 0.4767 - val_loss: 1.0531 - val_acc: 0.0000e+00 - val_rmse: 0.6511\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6437 - acc: 0.6154 - rmse: 0.4756 - val_loss: 1.0533 - val_acc: 0.0000e+00 - val_rmse: 0.6512\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6417 - acc: 0.6154 - rmse: 0.4746 - val_loss: 1.0536 - val_acc: 0.0000e+00 - val_rmse: 0.6513\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6396 - acc: 0.6154 - rmse: 0.4736 - val_loss: 1.0538 - val_acc: 0.0000e+00 - val_rmse: 0.6514\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6376 - acc: 0.6538 - rmse: 0.4726 - val_loss: 1.0541 - val_acc: 0.0000e+00 - val_rmse: 0.6515\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6355 - acc: 0.6538 - rmse: 0.4716 - val_loss: 1.0544 - val_acc: 0.0000e+00 - val_rmse: 0.6516\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6335 - acc: 0.6538 - rmse: 0.4705 - val_loss: 1.0546 - val_acc: 0.0000e+00 - val_rmse: 0.6517\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6315 - acc: 0.6538 - rmse: 0.4695 - val_loss: 1.0549 - val_acc: 0.0000e+00 - val_rmse: 0.6518\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6295 - acc: 0.6923 - rmse: 0.4685 - val_loss: 1.0552 - val_acc: 0.0000e+00 - val_rmse: 0.6519\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6275 - acc: 0.6923 - rmse: 0.4675 - val_loss: 1.0554 - val_acc: 0.0000e+00 - val_rmse: 0.6520\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6255 - acc: 0.6923 - rmse: 0.4665 - val_loss: 1.0557 - val_acc: 0.0000e+00 - val_rmse: 0.6520\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6235 - acc: 0.7308 - rmse: 0.4655 - val_loss: 1.0560 - val_acc: 0.0000e+00 - val_rmse: 0.6521\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6215 - acc: 0.7308 - rmse: 0.4645 - val_loss: 1.0562 - val_acc: 0.0000e+00 - val_rmse: 0.6522\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6195 - acc: 0.7308 - rmse: 0.4635 - val_loss: 1.0565 - val_acc: 0.0000e+00 - val_rmse: 0.6523\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6175 - acc: 0.7308 - rmse: 0.4624 - val_loss: 1.0568 - val_acc: 0.0000e+00 - val_rmse: 0.6524\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6155 - acc: 0.7308 - rmse: 0.4614 - val_loss: 1.0570 - val_acc: 0.0000e+00 - val_rmse: 0.6525\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6135 - acc: 0.7308 - rmse: 0.4604 - val_loss: 1.0573 - val_acc: 0.0000e+00 - val_rmse: 0.6526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6115 - acc: 0.7308 - rmse: 0.4594 - val_loss: 1.0576 - val_acc: 0.0000e+00 - val_rmse: 0.6527\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6095 - acc: 0.7308 - rmse: 0.4583 - val_loss: 1.0578 - val_acc: 0.0000e+00 - val_rmse: 0.6528\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6075 - acc: 0.7308 - rmse: 0.4573 - val_loss: 1.0581 - val_acc: 0.0000e+00 - val_rmse: 0.6529\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6055 - acc: 0.7308 - rmse: 0.4563 - val_loss: 1.0584 - val_acc: 0.0000e+00 - val_rmse: 0.6530\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6035 - acc: 0.7308 - rmse: 0.4552 - val_loss: 1.0587 - val_acc: 0.0000e+00 - val_rmse: 0.6531\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6014 - acc: 0.7308 - rmse: 0.4542 - val_loss: 1.0589 - val_acc: 0.0000e+00 - val_rmse: 0.6532\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5994 - acc: 0.7308 - rmse: 0.4531 - val_loss: 1.0592 - val_acc: 0.0000e+00 - val_rmse: 0.6533\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5974 - acc: 0.7308 - rmse: 0.4521 - val_loss: 1.0595 - val_acc: 0.0000e+00 - val_rmse: 0.6534\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5954 - acc: 0.7308 - rmse: 0.4510 - val_loss: 1.0598 - val_acc: 0.0000e+00 - val_rmse: 0.6535\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5933 - acc: 0.7308 - rmse: 0.4500 - val_loss: 1.0600 - val_acc: 0.0000e+00 - val_rmse: 0.6536\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5913 - acc: 0.7308 - rmse: 0.4489 - val_loss: 1.0603 - val_acc: 0.0000e+00 - val_rmse: 0.6537\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5892 - acc: 0.7308 - rmse: 0.4478 - val_loss: 1.0606 - val_acc: 0.0000e+00 - val_rmse: 0.6538\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5871 - acc: 0.7308 - rmse: 0.4467 - val_loss: 1.0609 - val_acc: 0.0000e+00 - val_rmse: 0.6538\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5850 - acc: 0.7308 - rmse: 0.4456 - val_loss: 1.0612 - val_acc: 0.0000e+00 - val_rmse: 0.6539\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5829 - acc: 0.7308 - rmse: 0.4445 - val_loss: 1.0614 - val_acc: 0.0000e+00 - val_rmse: 0.6540\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5809 - acc: 0.7308 - rmse: 0.4435 - val_loss: 1.0617 - val_acc: 0.0000e+00 - val_rmse: 0.6541\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5788 - acc: 0.7308 - rmse: 0.4424 - val_loss: 1.0620 - val_acc: 0.0000e+00 - val_rmse: 0.6542\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5768 - acc: 0.7308 - rmse: 0.4413 - val_loss: 1.0623 - val_acc: 0.0000e+00 - val_rmse: 0.6543\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5748 - acc: 0.7308 - rmse: 0.4402 - val_loss: 1.0625 - val_acc: 0.0000e+00 - val_rmse: 0.6544\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5728 - acc: 0.7308 - rmse: 0.4392 - val_loss: 1.0628 - val_acc: 0.0000e+00 - val_rmse: 0.6545\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5709 - acc: 0.7308 - rmse: 0.4382 - val_loss: 1.0631 - val_acc: 0.0000e+00 - val_rmse: 0.6546\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5690 - acc: 0.7308 - rmse: 0.4371 - val_loss: 1.0634 - val_acc: 0.0000e+00 - val_rmse: 0.6547\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5671 - acc: 0.7308 - rmse: 0.4361 - val_loss: 1.0636 - val_acc: 0.0000e+00 - val_rmse: 0.6548\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5653 - acc: 0.7308 - rmse: 0.4351 - val_loss: 1.0639 - val_acc: 0.0000e+00 - val_rmse: 0.6549\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5634 - acc: 0.7308 - rmse: 0.4341 - val_loss: 1.0642 - val_acc: 0.0000e+00 - val_rmse: 0.6550\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5616 - acc: 0.7308 - rmse: 0.4331 - val_loss: 1.0645 - val_acc: 0.0000e+00 - val_rmse: 0.6551\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5598 - acc: 0.7308 - rmse: 0.4321 - val_loss: 1.0647 - val_acc: 0.0000e+00 - val_rmse: 0.6552\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5580 - acc: 0.7308 - rmse: 0.4312 - val_loss: 1.0650 - val_acc: 0.0000e+00 - val_rmse: 0.6553\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5562 - acc: 0.7308 - rmse: 0.4302 - val_loss: 1.0653 - val_acc: 0.0000e+00 - val_rmse: 0.6554\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5545 - acc: 0.7308 - rmse: 0.4292 - val_loss: 1.0656 - val_acc: 0.0000e+00 - val_rmse: 0.6555\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_40 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.10972\n",
      " - 8s - loss: 0.7562 - acc: 0.5769 - rmse: 0.5273 - val_loss: 0.9149 - val_acc: 0.0000e+00 - val_rmse: 0.5995\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7542 - acc: 0.5769 - rmse: 0.5264 - val_loss: 0.9149 - val_acc: 0.0000e+00 - val_rmse: 0.5994\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7522 - acc: 0.5769 - rmse: 0.5255 - val_loss: 0.9148 - val_acc: 0.0000e+00 - val_rmse: 0.5994\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7502 - acc: 0.5769 - rmse: 0.5247 - val_loss: 0.9148 - val_acc: 0.0000e+00 - val_rmse: 0.5994\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7482 - acc: 0.5769 - rmse: 0.5238 - val_loss: 0.9147 - val_acc: 0.0000e+00 - val_rmse: 0.5994\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7463 - acc: 0.5769 - rmse: 0.5229 - val_loss: 0.9147 - val_acc: 0.0000e+00 - val_rmse: 0.5994\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7443 - acc: 0.5769 - rmse: 0.5221 - val_loss: 0.9146 - val_acc: 0.0000e+00 - val_rmse: 0.5993\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7423 - acc: 0.5769 - rmse: 0.5212 - val_loss: 0.9146 - val_acc: 0.0000e+00 - val_rmse: 0.5993\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7404 - acc: 0.5769 - rmse: 0.5203 - val_loss: 0.9146 - val_acc: 0.0000e+00 - val_rmse: 0.5993\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7385 - acc: 0.6154 - rmse: 0.5195 - val_loss: 0.9145 - val_acc: 0.0000e+00 - val_rmse: 0.5993\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7365 - acc: 0.6154 - rmse: 0.5186 - val_loss: 0.9145 - val_acc: 0.0000e+00 - val_rmse: 0.5993\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7346 - acc: 0.6154 - rmse: 0.5178 - val_loss: 0.9144 - val_acc: 0.0000e+00 - val_rmse: 0.5992\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7327 - acc: 0.6154 - rmse: 0.5169 - val_loss: 0.9144 - val_acc: 0.0000e+00 - val_rmse: 0.5992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7308 - acc: 0.6154 - rmse: 0.5161 - val_loss: 0.9143 - val_acc: 0.0000e+00 - val_rmse: 0.5992\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7289 - acc: 0.6154 - rmse: 0.5152 - val_loss: 0.9143 - val_acc: 0.0000e+00 - val_rmse: 0.5992\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7270 - acc: 0.6538 - rmse: 0.5144 - val_loss: 0.9142 - val_acc: 0.0000e+00 - val_rmse: 0.5992\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7251 - acc: 0.6538 - rmse: 0.5135 - val_loss: 0.9142 - val_acc: 0.0000e+00 - val_rmse: 0.5992\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7233 - acc: 0.6923 - rmse: 0.5127 - val_loss: 0.9142 - val_acc: 0.0000e+00 - val_rmse: 0.5991\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7214 - acc: 0.6923 - rmse: 0.5118 - val_loss: 0.9141 - val_acc: 0.0000e+00 - val_rmse: 0.5991\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7195 - acc: 0.6923 - rmse: 0.5110 - val_loss: 0.9141 - val_acc: 0.0000e+00 - val_rmse: 0.5991\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7177 - acc: 0.6923 - rmse: 0.5101 - val_loss: 0.9140 - val_acc: 0.0000e+00 - val_rmse: 0.5991\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7159 - acc: 0.6923 - rmse: 0.5093 - val_loss: 0.9140 - val_acc: 0.0000e+00 - val_rmse: 0.5991\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7140 - acc: 0.6923 - rmse: 0.5084 - val_loss: 0.9139 - val_acc: 0.0000e+00 - val_rmse: 0.5991\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7122 - acc: 0.6923 - rmse: 0.5076 - val_loss: 0.9139 - val_acc: 0.0000e+00 - val_rmse: 0.5990\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7104 - acc: 0.6923 - rmse: 0.5068 - val_loss: 0.9139 - val_acc: 0.0000e+00 - val_rmse: 0.5990\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7086 - acc: 0.6923 - rmse: 0.5060 - val_loss: 0.9138 - val_acc: 0.0000e+00 - val_rmse: 0.5990\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7069 - acc: 0.6923 - rmse: 0.5051 - val_loss: 0.9138 - val_acc: 0.0000e+00 - val_rmse: 0.5990\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7051 - acc: 0.6923 - rmse: 0.5043 - val_loss: 0.9137 - val_acc: 0.0000e+00 - val_rmse: 0.5990\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7033 - acc: 0.6923 - rmse: 0.5035 - val_loss: 0.9137 - val_acc: 0.0000e+00 - val_rmse: 0.5990\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7015 - acc: 0.6923 - rmse: 0.5026 - val_loss: 0.9137 - val_acc: 0.0000e+00 - val_rmse: 0.5989\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6997 - acc: 0.6923 - rmse: 0.5018 - val_loss: 0.9136 - val_acc: 0.0000e+00 - val_rmse: 0.5989\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6980 - acc: 0.6923 - rmse: 0.5010 - val_loss: 0.9136 - val_acc: 0.0000e+00 - val_rmse: 0.5989\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6962 - acc: 0.6923 - rmse: 0.5002 - val_loss: 0.9136 - val_acc: 0.0000e+00 - val_rmse: 0.5989\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6945 - acc: 0.6923 - rmse: 0.4993 - val_loss: 0.9135 - val_acc: 0.0000e+00 - val_rmse: 0.5989\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6927 - acc: 0.6923 - rmse: 0.4985 - val_loss: 0.9135 - val_acc: 0.0000e+00 - val_rmse: 0.5989\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6910 - acc: 0.6923 - rmse: 0.4977 - val_loss: 0.9135 - val_acc: 0.0000e+00 - val_rmse: 0.5989\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6892 - acc: 0.6923 - rmse: 0.4968 - val_loss: 0.9134 - val_acc: 0.0000e+00 - val_rmse: 0.5989\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6875 - acc: 0.6923 - rmse: 0.4960 - val_loss: 0.9134 - val_acc: 0.0000e+00 - val_rmse: 0.5988\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6857 - acc: 0.6923 - rmse: 0.4952 - val_loss: 0.9134 - val_acc: 0.0000e+00 - val_rmse: 0.5988\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6840 - acc: 0.6923 - rmse: 0.4944 - val_loss: 0.9133 - val_acc: 0.0000e+00 - val_rmse: 0.5988\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6823 - acc: 0.6923 - rmse: 0.4936 - val_loss: 0.9133 - val_acc: 0.0000e+00 - val_rmse: 0.5988\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6806 - acc: 0.6923 - rmse: 0.4927 - val_loss: 0.9133 - val_acc: 0.0000e+00 - val_rmse: 0.5988\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6789 - acc: 0.6923 - rmse: 0.4919 - val_loss: 0.9133 - val_acc: 0.0000e+00 - val_rmse: 0.5988\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6772 - acc: 0.6923 - rmse: 0.4911 - val_loss: 0.9132 - val_acc: 0.0000e+00 - val_rmse: 0.5988\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6755 - acc: 0.6923 - rmse: 0.4903 - val_loss: 0.9132 - val_acc: 0.0000e+00 - val_rmse: 0.5988\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6738 - acc: 0.6923 - rmse: 0.4894 - val_loss: 0.9132 - val_acc: 0.0000e+00 - val_rmse: 0.5987\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6721 - acc: 0.6923 - rmse: 0.4886 - val_loss: 0.9131 - val_acc: 0.0000e+00 - val_rmse: 0.5987\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6704 - acc: 0.6923 - rmse: 0.4878 - val_loss: 0.9131 - val_acc: 0.0000e+00 - val_rmse: 0.5987\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6687 - acc: 0.6923 - rmse: 0.4870 - val_loss: 0.9131 - val_acc: 0.0000e+00 - val_rmse: 0.5987\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6670 - acc: 0.6923 - rmse: 0.4862 - val_loss: 0.9131 - val_acc: 0.0000e+00 - val_rmse: 0.5987\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6653 - acc: 0.6923 - rmse: 0.4854 - val_loss: 0.9130 - val_acc: 0.0000e+00 - val_rmse: 0.5987\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6637 - acc: 0.6923 - rmse: 0.4846 - val_loss: 0.9130 - val_acc: 0.0000e+00 - val_rmse: 0.5987\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6621 - acc: 0.6923 - rmse: 0.4838 - val_loss: 0.9130 - val_acc: 0.0000e+00 - val_rmse: 0.5987\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6604 - acc: 0.6923 - rmse: 0.4830 - val_loss: 0.9129 - val_acc: 0.0000e+00 - val_rmse: 0.5987\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6588 - acc: 0.6923 - rmse: 0.4822 - val_loss: 0.9129 - val_acc: 0.0000e+00 - val_rmse: 0.5986\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6572 - acc: 0.6923 - rmse: 0.4814 - val_loss: 0.9129 - val_acc: 0.0000e+00 - val_rmse: 0.5986\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6556 - acc: 0.6923 - rmse: 0.4806 - val_loss: 0.9129 - val_acc: 0.0000e+00 - val_rmse: 0.5986\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6540 - acc: 0.6923 - rmse: 0.4798 - val_loss: 0.9128 - val_acc: 0.0000e+00 - val_rmse: 0.5986\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6524 - acc: 0.6923 - rmse: 0.4790 - val_loss: 0.9128 - val_acc: 0.0000e+00 - val_rmse: 0.5986\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6508 - acc: 0.6923 - rmse: 0.4782 - val_loss: 0.9128 - val_acc: 0.0000e+00 - val_rmse: 0.5986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6492 - acc: 0.6923 - rmse: 0.4774 - val_loss: 0.9127 - val_acc: 0.0000e+00 - val_rmse: 0.5986\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6476 - acc: 0.6923 - rmse: 0.4766 - val_loss: 0.9127 - val_acc: 0.0000e+00 - val_rmse: 0.5986\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6460 - acc: 0.6923 - rmse: 0.4758 - val_loss: 0.9127 - val_acc: 0.0000e+00 - val_rmse: 0.5985\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6444 - acc: 0.6923 - rmse: 0.4750 - val_loss: 0.9126 - val_acc: 0.0000e+00 - val_rmse: 0.5985\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6429 - acc: 0.6923 - rmse: 0.4742 - val_loss: 0.9126 - val_acc: 0.0000e+00 - val_rmse: 0.5985\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6413 - acc: 0.6923 - rmse: 0.4734 - val_loss: 0.9126 - val_acc: 0.0000e+00 - val_rmse: 0.5985\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6398 - acc: 0.6923 - rmse: 0.4727 - val_loss: 0.9125 - val_acc: 0.0000e+00 - val_rmse: 0.5985\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6382 - acc: 0.6923 - rmse: 0.4719 - val_loss: 0.9125 - val_acc: 0.0000e+00 - val_rmse: 0.5985\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6367 - acc: 0.6923 - rmse: 0.4711 - val_loss: 0.9125 - val_acc: 0.0000e+00 - val_rmse: 0.5985\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6352 - acc: 0.6923 - rmse: 0.4703 - val_loss: 0.9124 - val_acc: 0.0000e+00 - val_rmse: 0.5985\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6336 - acc: 0.6923 - rmse: 0.4695 - val_loss: 0.9124 - val_acc: 0.0000e+00 - val_rmse: 0.5984\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6321 - acc: 0.6923 - rmse: 0.4688 - val_loss: 0.9124 - val_acc: 0.0000e+00 - val_rmse: 0.5984\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6306 - acc: 0.6923 - rmse: 0.4680 - val_loss: 0.9123 - val_acc: 0.0000e+00 - val_rmse: 0.5984\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6291 - acc: 0.6923 - rmse: 0.4672 - val_loss: 0.9123 - val_acc: 0.0000e+00 - val_rmse: 0.5984\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6275 - acc: 0.6923 - rmse: 0.4664 - val_loss: 0.9123 - val_acc: 0.0000e+00 - val_rmse: 0.5984\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6261 - acc: 0.6923 - rmse: 0.4657 - val_loss: 0.9122 - val_acc: 0.0000e+00 - val_rmse: 0.5984\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6246 - acc: 0.6923 - rmse: 0.4649 - val_loss: 0.9122 - val_acc: 0.0000e+00 - val_rmse: 0.5984\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6231 - acc: 0.6923 - rmse: 0.4642 - val_loss: 0.9122 - val_acc: 0.0000e+00 - val_rmse: 0.5984\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6216 - acc: 0.6923 - rmse: 0.4634 - val_loss: 0.9121 - val_acc: 0.0000e+00 - val_rmse: 0.5983\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6202 - acc: 0.6923 - rmse: 0.4626 - val_loss: 0.9121 - val_acc: 0.0000e+00 - val_rmse: 0.5983\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6187 - acc: 0.6923 - rmse: 0.4619 - val_loss: 0.9121 - val_acc: 0.0000e+00 - val_rmse: 0.5983\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6173 - acc: 0.6923 - rmse: 0.4612 - val_loss: 0.9121 - val_acc: 0.0000e+00 - val_rmse: 0.5983\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6158 - acc: 0.6923 - rmse: 0.4604 - val_loss: 0.9120 - val_acc: 0.0000e+00 - val_rmse: 0.5983\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6144 - acc: 0.6923 - rmse: 0.4597 - val_loss: 0.9120 - val_acc: 0.0000e+00 - val_rmse: 0.5983\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6130 - acc: 0.6923 - rmse: 0.4589 - val_loss: 0.9120 - val_acc: 0.0000e+00 - val_rmse: 0.5983\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6115 - acc: 0.6923 - rmse: 0.4582 - val_loss: 0.9119 - val_acc: 0.0000e+00 - val_rmse: 0.5983\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6101 - acc: 0.6923 - rmse: 0.4574 - val_loss: 0.9119 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6087 - acc: 0.6923 - rmse: 0.4567 - val_loss: 0.9119 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6073 - acc: 0.6923 - rmse: 0.4559 - val_loss: 0.9119 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6058 - acc: 0.6923 - rmse: 0.4552 - val_loss: 0.9118 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6044 - acc: 0.6923 - rmse: 0.4544 - val_loss: 0.9118 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6030 - acc: 0.6923 - rmse: 0.4537 - val_loss: 0.9118 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6016 - acc: 0.7308 - rmse: 0.4530 - val_loss: 0.9118 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6002 - acc: 0.7308 - rmse: 0.4522 - val_loss: 0.9117 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5988 - acc: 0.7308 - rmse: 0.4515 - val_loss: 0.9117 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5974 - acc: 0.7308 - rmse: 0.4508 - val_loss: 0.9117 - val_acc: 0.0000e+00 - val_rmse: 0.5982\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5960 - acc: 0.7308 - rmse: 0.4500 - val_loss: 0.9117 - val_acc: 0.0000e+00 - val_rmse: 0.5981\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5946 - acc: 0.7308 - rmse: 0.4493 - val_loss: 0.9116 - val_acc: 0.0000e+00 - val_rmse: 0.5981\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5933 - acc: 0.7308 - rmse: 0.4485 - val_loss: 0.9116 - val_acc: 0.0000e+00 - val_rmse: 0.5981\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5919 - acc: 0.7308 - rmse: 0.4478 - val_loss: 0.9116 - val_acc: 0.0000e+00 - val_rmse: 0.5981\n",
      "(26, 500, 17)\n",
      "X_train shape: (26, 17, 500)\n",
      "26 train samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_41 (LSTM)               (None, 256)               775168    \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 783,458\n",
      "Trainable params: 783,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.10972\n",
      " - 16s - loss: 0.7237 - acc: 0.6154 - rmse: 0.5108 - val_loss: 0.7521 - val_acc: 0.0000e+00 - val_rmse: 0.5286\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7216 - acc: 0.6154 - rmse: 0.5100 - val_loss: 0.7522 - val_acc: 0.0000e+00 - val_rmse: 0.5287\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7194 - acc: 0.6154 - rmse: 0.5091 - val_loss: 0.7523 - val_acc: 0.0000e+00 - val_rmse: 0.5287\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7173 - acc: 0.6154 - rmse: 0.5082 - val_loss: 0.7525 - val_acc: 0.0000e+00 - val_rmse: 0.5288\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7151 - acc: 0.6154 - rmse: 0.5073 - val_loss: 0.7526 - val_acc: 0.0000e+00 - val_rmse: 0.5288\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7130 - acc: 0.6154 - rmse: 0.5064 - val_loss: 0.7527 - val_acc: 0.0000e+00 - val_rmse: 0.5289\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7108 - acc: 0.6154 - rmse: 0.5055 - val_loss: 0.7528 - val_acc: 0.0000e+00 - val_rmse: 0.5290\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7087 - acc: 0.6154 - rmse: 0.5046 - val_loss: 0.7529 - val_acc: 0.0000e+00 - val_rmse: 0.5290\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7065 - acc: 0.6154 - rmse: 0.5037 - val_loss: 0.7531 - val_acc: 0.0000e+00 - val_rmse: 0.5291\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7043 - acc: 0.6154 - rmse: 0.5027 - val_loss: 0.7532 - val_acc: 0.0000e+00 - val_rmse: 0.5291\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.7021 - acc: 0.6154 - rmse: 0.5018 - val_loss: 0.7533 - val_acc: 0.0000e+00 - val_rmse: 0.5292\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6999 - acc: 0.6154 - rmse: 0.5009 - val_loss: 0.7534 - val_acc: 0.0000e+00 - val_rmse: 0.5292\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6977 - acc: 0.6154 - rmse: 0.4999 - val_loss: 0.7535 - val_acc: 0.0000e+00 - val_rmse: 0.5293\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6955 - acc: 0.6154 - rmse: 0.4990 - val_loss: 0.7536 - val_acc: 0.0000e+00 - val_rmse: 0.5293\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6933 - acc: 0.6154 - rmse: 0.4981 - val_loss: 0.7537 - val_acc: 0.0000e+00 - val_rmse: 0.5294\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6911 - acc: 0.6154 - rmse: 0.4971 - val_loss: 0.7539 - val_acc: 0.0000e+00 - val_rmse: 0.5295\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6889 - acc: 0.6154 - rmse: 0.4961 - val_loss: 0.7540 - val_acc: 0.0000e+00 - val_rmse: 0.5295\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6867 - acc: 0.6154 - rmse: 0.4952 - val_loss: 0.7541 - val_acc: 0.0000e+00 - val_rmse: 0.5296\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6845 - acc: 0.6154 - rmse: 0.4943 - val_loss: 0.7542 - val_acc: 0.0000e+00 - val_rmse: 0.5296\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6824 - acc: 0.6154 - rmse: 0.4933 - val_loss: 0.7543 - val_acc: 0.0000e+00 - val_rmse: 0.5297\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6803 - acc: 0.6154 - rmse: 0.4924 - val_loss: 0.7544 - val_acc: 0.0000e+00 - val_rmse: 0.5297\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6782 - acc: 0.6154 - rmse: 0.4915 - val_loss: 0.7545 - val_acc: 0.0000e+00 - val_rmse: 0.5298\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6761 - acc: 0.6154 - rmse: 0.4906 - val_loss: 0.7546 - val_acc: 0.0000e+00 - val_rmse: 0.5298\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6740 - acc: 0.6154 - rmse: 0.4897 - val_loss: 0.7547 - val_acc: 0.0000e+00 - val_rmse: 0.5299\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6720 - acc: 0.6154 - rmse: 0.4888 - val_loss: 0.7548 - val_acc: 0.0000e+00 - val_rmse: 0.5299\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6700 - acc: 0.6154 - rmse: 0.4879 - val_loss: 0.7549 - val_acc: 0.0000e+00 - val_rmse: 0.5300\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6679 - acc: 0.6154 - rmse: 0.4870 - val_loss: 0.7550 - val_acc: 0.0000e+00 - val_rmse: 0.5300\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6659 - acc: 0.6154 - rmse: 0.4861 - val_loss: 0.7551 - val_acc: 0.0000e+00 - val_rmse: 0.5301\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6640 - acc: 0.6538 - rmse: 0.4852 - val_loss: 0.7552 - val_acc: 0.0000e+00 - val_rmse: 0.5301\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6620 - acc: 0.6538 - rmse: 0.4843 - val_loss: 0.7553 - val_acc: 0.0000e+00 - val_rmse: 0.5302\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6600 - acc: 0.6538 - rmse: 0.4835 - val_loss: 0.7555 - val_acc: 0.0000e+00 - val_rmse: 0.5302\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6581 - acc: 0.6538 - rmse: 0.4826 - val_loss: 0.7556 - val_acc: 0.0000e+00 - val_rmse: 0.5302\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6561 - acc: 0.6538 - rmse: 0.4817 - val_loss: 0.7557 - val_acc: 0.0000e+00 - val_rmse: 0.5303\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6542 - acc: 0.6538 - rmse: 0.4809 - val_loss: 0.7558 - val_acc: 0.0000e+00 - val_rmse: 0.5303\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6523 - acc: 0.6538 - rmse: 0.4800 - val_loss: 0.7559 - val_acc: 0.0000e+00 - val_rmse: 0.5304\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6504 - acc: 0.6538 - rmse: 0.4791 - val_loss: 0.7560 - val_acc: 0.0000e+00 - val_rmse: 0.5304\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6485 - acc: 0.6538 - rmse: 0.4783 - val_loss: 0.7561 - val_acc: 0.0000e+00 - val_rmse: 0.5305\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6465 - acc: 0.6538 - rmse: 0.4774 - val_loss: 0.7562 - val_acc: 0.0000e+00 - val_rmse: 0.5305\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6446 - acc: 0.6538 - rmse: 0.4765 - val_loss: 0.7563 - val_acc: 0.0000e+00 - val_rmse: 0.5306\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6427 - acc: 0.6538 - rmse: 0.4757 - val_loss: 0.7564 - val_acc: 0.0000e+00 - val_rmse: 0.5306\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6408 - acc: 0.6538 - rmse: 0.4748 - val_loss: 0.7565 - val_acc: 0.0000e+00 - val_rmse: 0.5307\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6389 - acc: 0.6538 - rmse: 0.4739 - val_loss: 0.7566 - val_acc: 0.0000e+00 - val_rmse: 0.5307\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6370 - acc: 0.6538 - rmse: 0.4731 - val_loss: 0.7567 - val_acc: 0.0000e+00 - val_rmse: 0.5308\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6352 - acc: 0.6538 - rmse: 0.4722 - val_loss: 0.7568 - val_acc: 0.0000e+00 - val_rmse: 0.5308\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6333 - acc: 0.6538 - rmse: 0.4713 - val_loss: 0.7569 - val_acc: 0.0000e+00 - val_rmse: 0.5309\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6314 - acc: 0.6538 - rmse: 0.4705 - val_loss: 0.7570 - val_acc: 0.0000e+00 - val_rmse: 0.5309\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6296 - acc: 0.6538 - rmse: 0.4696 - val_loss: 0.7571 - val_acc: 0.0000e+00 - val_rmse: 0.5310\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6277 - acc: 0.6538 - rmse: 0.4687 - val_loss: 0.7572 - val_acc: 0.0000e+00 - val_rmse: 0.5310\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6258 - acc: 0.6538 - rmse: 0.4679 - val_loss: 0.7573 - val_acc: 0.0000e+00 - val_rmse: 0.5311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6240 - acc: 0.6923 - rmse: 0.4670 - val_loss: 0.7574 - val_acc: 0.0000e+00 - val_rmse: 0.5311\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6222 - acc: 0.6923 - rmse: 0.4661 - val_loss: 0.7575 - val_acc: 0.0000e+00 - val_rmse: 0.5312\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6203 - acc: 0.6923 - rmse: 0.4653 - val_loss: 0.7576 - val_acc: 0.0000e+00 - val_rmse: 0.5312\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6185 - acc: 0.6923 - rmse: 0.4644 - val_loss: 0.7577 - val_acc: 0.0000e+00 - val_rmse: 0.5312\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6167 - acc: 0.6923 - rmse: 0.4636 - val_loss: 0.7578 - val_acc: 0.0000e+00 - val_rmse: 0.5313\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6149 - acc: 0.6923 - rmse: 0.4627 - val_loss: 0.7579 - val_acc: 0.0000e+00 - val_rmse: 0.5313\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6131 - acc: 0.6923 - rmse: 0.4618 - val_loss: 0.7580 - val_acc: 0.0000e+00 - val_rmse: 0.5314\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6113 - acc: 0.6923 - rmse: 0.4610 - val_loss: 0.7581 - val_acc: 0.0000e+00 - val_rmse: 0.5314\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6096 - acc: 0.6923 - rmse: 0.4601 - val_loss: 0.7581 - val_acc: 0.0000e+00 - val_rmse: 0.5315\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6078 - acc: 0.6923 - rmse: 0.4593 - val_loss: 0.7582 - val_acc: 0.0000e+00 - val_rmse: 0.5315\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6060 - acc: 0.6923 - rmse: 0.4584 - val_loss: 0.7583 - val_acc: 0.0000e+00 - val_rmse: 0.5315\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6043 - acc: 0.6923 - rmse: 0.4576 - val_loss: 0.7584 - val_acc: 0.0000e+00 - val_rmse: 0.5316\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6025 - acc: 0.6923 - rmse: 0.4567 - val_loss: 0.7585 - val_acc: 0.0000e+00 - val_rmse: 0.5316\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.6007 - acc: 0.6923 - rmse: 0.4559 - val_loss: 0.7586 - val_acc: 0.0000e+00 - val_rmse: 0.5317\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5990 - acc: 0.6923 - rmse: 0.4550 - val_loss: 0.7587 - val_acc: 0.0000e+00 - val_rmse: 0.5317\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5972 - acc: 0.6923 - rmse: 0.4542 - val_loss: 0.7588 - val_acc: 0.0000e+00 - val_rmse: 0.5318\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5955 - acc: 0.6923 - rmse: 0.4533 - val_loss: 0.7589 - val_acc: 0.0000e+00 - val_rmse: 0.5318\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5938 - acc: 0.6923 - rmse: 0.4525 - val_loss: 0.7589 - val_acc: 0.0000e+00 - val_rmse: 0.5318\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5920 - acc: 0.6923 - rmse: 0.4516 - val_loss: 0.7590 - val_acc: 0.0000e+00 - val_rmse: 0.5319\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5903 - acc: 0.6923 - rmse: 0.4508 - val_loss: 0.7591 - val_acc: 0.0000e+00 - val_rmse: 0.5319\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5886 - acc: 0.6923 - rmse: 0.4499 - val_loss: 0.7592 - val_acc: 0.0000e+00 - val_rmse: 0.5320\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5869 - acc: 0.6923 - rmse: 0.4491 - val_loss: 0.7593 - val_acc: 0.0000e+00 - val_rmse: 0.5320\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5852 - acc: 0.6923 - rmse: 0.4482 - val_loss: 0.7594 - val_acc: 0.0000e+00 - val_rmse: 0.5320\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5835 - acc: 0.6923 - rmse: 0.4474 - val_loss: 0.7595 - val_acc: 0.0000e+00 - val_rmse: 0.5321\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5818 - acc: 0.6923 - rmse: 0.4466 - val_loss: 0.7596 - val_acc: 0.0000e+00 - val_rmse: 0.5321\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5802 - acc: 0.6923 - rmse: 0.4457 - val_loss: 0.7597 - val_acc: 0.0000e+00 - val_rmse: 0.5322\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5785 - acc: 0.6923 - rmse: 0.4449 - val_loss: 0.7598 - val_acc: 0.0000e+00 - val_rmse: 0.5322\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5768 - acc: 0.6923 - rmse: 0.4441 - val_loss: 0.7599 - val_acc: 0.0000e+00 - val_rmse: 0.5323\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5752 - acc: 0.6923 - rmse: 0.4432 - val_loss: 0.7600 - val_acc: 0.0000e+00 - val_rmse: 0.5323\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5735 - acc: 0.7308 - rmse: 0.4424 - val_loss: 0.7601 - val_acc: 0.0000e+00 - val_rmse: 0.5324\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5719 - acc: 0.7308 - rmse: 0.4416 - val_loss: 0.7602 - val_acc: 0.0000e+00 - val_rmse: 0.5324\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5702 - acc: 0.7308 - rmse: 0.4407 - val_loss: 0.7603 - val_acc: 0.0000e+00 - val_rmse: 0.5325\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5686 - acc: 0.7308 - rmse: 0.4399 - val_loss: 0.7604 - val_acc: 0.0000e+00 - val_rmse: 0.5325\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5669 - acc: 0.7692 - rmse: 0.4390 - val_loss: 0.7605 - val_acc: 0.0000e+00 - val_rmse: 0.5326\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5653 - acc: 0.7692 - rmse: 0.4382 - val_loss: 0.7606 - val_acc: 0.0000e+00 - val_rmse: 0.5326\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5636 - acc: 0.7692 - rmse: 0.4374 - val_loss: 0.7607 - val_acc: 0.0000e+00 - val_rmse: 0.5327\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5620 - acc: 0.7692 - rmse: 0.4365 - val_loss: 0.7609 - val_acc: 0.0000e+00 - val_rmse: 0.5327\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5603 - acc: 0.7692 - rmse: 0.4357 - val_loss: 0.7610 - val_acc: 0.0000e+00 - val_rmse: 0.5328\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5588 - acc: 0.7692 - rmse: 0.4349 - val_loss: 0.7611 - val_acc: 0.0000e+00 - val_rmse: 0.5328\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5572 - acc: 0.7692 - rmse: 0.4341 - val_loss: 0.7612 - val_acc: 0.0000e+00 - val_rmse: 0.5329\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5556 - acc: 0.7692 - rmse: 0.4332 - val_loss: 0.7613 - val_acc: 0.0000e+00 - val_rmse: 0.5330\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5540 - acc: 0.7692 - rmse: 0.4324 - val_loss: 0.7615 - val_acc: 0.0000e+00 - val_rmse: 0.5330\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5525 - acc: 0.7692 - rmse: 0.4316 - val_loss: 0.7616 - val_acc: 0.0000e+00 - val_rmse: 0.5331\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5509 - acc: 0.7692 - rmse: 0.4308 - val_loss: 0.7617 - val_acc: 0.0000e+00 - val_rmse: 0.5331\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5494 - acc: 0.7692 - rmse: 0.4300 - val_loss: 0.7618 - val_acc: 0.0000e+00 - val_rmse: 0.5332\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5478 - acc: 0.7692 - rmse: 0.4292 - val_loss: 0.7620 - val_acc: 0.0000e+00 - val_rmse: 0.5333\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5463 - acc: 0.7692 - rmse: 0.4284 - val_loss: 0.7621 - val_acc: 0.0000e+00 - val_rmse: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5448 - acc: 0.7692 - rmse: 0.4276 - val_loss: 0.7622 - val_acc: 0.0000e+00 - val_rmse: 0.5334\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5433 - acc: 0.7692 - rmse: 0.4268 - val_loss: 0.7624 - val_acc: 0.0000e+00 - val_rmse: 0.5334\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5417 - acc: 0.7692 - rmse: 0.4260 - val_loss: 0.7625 - val_acc: 0.0000e+00 - val_rmse: 0.5335\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10972\n",
      " - 1s - loss: 0.5402 - acc: 0.7692 - rmse: 0.4251 - val_loss: 0.7626 - val_acc: 0.0000e+00 - val_rmse: 0.5336\n"
     ]
    }
   ],
   "source": [
    "\"\"\"#### Implement Leave One Out\n",
    "\n",
    "log_train_accuracy = []\n",
    "log_validation_accuracy = []\n",
    "log_train_rmse = []\n",
    "log_validation_rmse = []\n",
    "log_train_loss = []\n",
    "log_validation_loss = []\n",
    "\n",
    "full_train_accuracy = []\n",
    "full_validation_accuracy = []\n",
    "full_train_rmse = []\n",
    "full_validation_rmse = []\n",
    "full_train_loss = []\n",
    "full_validation_loss = []\n",
    "\n",
    "for i, entry in enumerate(X):\n",
    "    X_validate = X[i]\n",
    "    X_train = np.delete(X, i, axis=0)\n",
    "    Y_validate = np.asarray([y[i]])\n",
    "    Y_train = np.delete(y, i, axis=0)\n",
    "    \n",
    "    time_steps = 500 #sample_size #seconds of data to include in one slice\n",
    "\n",
    "    kernels, chans, samples = 1, len(target_channels), time_steps\n",
    "    full_size = len(X)\n",
    "\n",
    "    # convert labels to one-hot encodings.\n",
    "    Y_train      = np_utils.to_categorical(Y_train, num_classes=2)\n",
    "    Y_validate   = np_utils.to_categorical(Y_validate, num_classes=2)\n",
    "    #Y_test       = np_utils.to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "\n",
    "    print(X_train.shape)\n",
    "    X_train      = X_train.reshape(X_train.shape[0],   chans, time_steps,)\n",
    "    X_validate   = X_validate.reshape(1, chans, time_steps)\n",
    "    #X_test       = X_test.reshape(X_test.shape[0], chans, time_steps)\n",
    "\n",
    "\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "\n",
    "\n",
    "    model = LSTM(samples=samples, time_steps=time_steps, chans=chans, nb_features=1, nb_classes=2, )\n",
    "    model.summary()\n",
    "\n",
    "    #import tensorflow \n",
    "    import tensorflow.keras.optimizers\n",
    "    opt_adam = tensorflow.keras.optimizers.Adam(lr=0.000001, \n",
    "                                    beta_1=0.99,\n",
    "                                    beta_2=0.999,\n",
    "                                    epsilon=1e-07)\n",
    "    sgd = tensorflow.keras.optimizers.SGD(lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "    def rmse (y_true, y_pred):\n",
    "\n",
    "        return K.sqrt(K.mean(K.square(y_pred -y_true)))\n",
    "\n",
    "    def rmse_np (y_true, y_pred):\n",
    "        y_true = y_true.astype(int)\n",
    "        y_pred=y_pred.astype(int)\n",
    "        print(y_pred.dtype)\n",
    "        return K.sqrt(K.mean(K.square(y_pred -y_true)))\n",
    "\n",
    "    # compile the model and set the optimizers\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt_adam, \n",
    "                  metrics=[#'mse', 'mae', \n",
    "                      'accuracy', rmse\n",
    "                     ])\n",
    "\n",
    "\n",
    "    # count number of parameters in the model\n",
    "    numParams    = model.count_params()    \n",
    "\n",
    " \n",
    "    \n",
    "    fitted_model = model.fit(X_train, Y_train, batch_size = 32, epochs = 100, \n",
    "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
    "                        callbacks=[checkpointer])#, class_weight = class_weights)\n",
    "\n",
    "\n",
    "    log_train_accuracy.append(fitted_model.history['acc'][-1])\n",
    "    log_validation_accuracy.append(fitted_model.history['val_acc'][-1])\n",
    "    log_train_rmse.append(fitted_model.history['rmse'][-1])\n",
    "    log_validation_rmse.append(fitted_model.history['val_rmse'][-1])\n",
    "    log_train_loss.append(fitted_model.history['loss'][-1])\n",
    "    log_validation_loss.append(fitted_model.history['val_loss'][-1])\n",
    "    \n",
    "    full_train_accuracy.append(fitted_model.history['acc'])\n",
    "    full_validation_accuracy.append(fitted_model.history['val_acc'])\n",
    "    full_train_rmse.append(fitted_model.history['rmse'])\n",
    "    full_validation_rmse.append(fitted_model.history['val_rmse'])\n",
    "    full_train_loss.append(fitted_model.history['loss'])\n",
    "    full_validation_loss.append(fitted_model.history['val_loss'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3tvCkHx4AXb4",
    "outputId": "5acda684-1f96-4dcb-9c02-f1c9a246e2a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Metrics for All Iterations \n",
      "\n",
      "Train Accuracy: 75.78% \n",
      "Validation Accuracy: 44.44% \n",
      "Train RMSE: 0.43 \n",
      "Validation RMSE: 0.52 \n",
      "Train Loss: 0.55 \n",
      "Validation Loss: 0.79 \n"
     ]
    }
   ],
   "source": [
    "print('Mean of Metrics for All Iterations \\n')\n",
    "print('Train Accuracy: {0:.2f}% '.format(np.mean(log_train_accuracy) * 100))\n",
    "print('Validation Accuracy: {0:.2f}% '.format(np.mean(log_validation_accuracy) * 100))\n",
    "print('Train RMSE: {0:.2f} '.format(np.mean(log_train_rmse)))\n",
    "print('Validation RMSE: {0:.2f} '.format(np.mean(log_validation_rmse)))\n",
    "print('Train Loss: {0:.2f} '.format(np.mean(log_train_loss)))\n",
    "print('Validation Loss: {0:.2f} '.format(np.mean(log_validation_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "JJ6N4S6CAXcW",
    "outputId": "a4919db9-8b0e-4e9f-8ca7-d60bc526c577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagrammed History of Model Metrics\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "# print(fitted_model.history.keys())\n",
    "\n",
    "print('Diagrammed History of Model Metrics')\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(log_validation_accuracy)\n",
    "plt.plot(log_train_accuracy)\n",
    "plt.title('Final Train & Validation Accuracy for Each Batch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Batch')\n",
    "plt.legend(['Validation', 'Train'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "6BGAOKIaAXcr",
    "outputId": "df99d218-9cdc-4be6-c9f2-3ef670a29ba0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize rmse\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(log_validation_rmse)\n",
    "plt.plot(log_train_rmse)\n",
    "plt.title('Final Train & Validation RMSE for Each Batch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Batch')\n",
    "plt.legend(['Validation', 'Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "8bWhpV5toeGO",
    "outputId": "c9e89fe3-2867-422b-8521-5889b6fea03a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0QAAAGDCAYAAAALa9ALAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl4VOX5//H3nR1IwjJhkR0S9j0gS+KuVbEKSm0riitKtYttbb+t1t26tbVW2/6sFStuiFrX1qrYVq3Kvsq+JBAg7AmEhEDWeX5/zIABCQTI5MxkPq/ryiWZOXPOZ84kZu55nuc+5pxDREREREQkGsV4HUBERERERMQrKohERERERCRqqSASEREREZGopYJIRERERESilgoiERERERGJWiqIREREREQkaqkgEpFGx8w6m9leM4uth309b2YP1keuOhzrbjN7uiGOVR/M7GUzuy/477PMbHldtj2B48QGX8/OJ5Y0PJnZo2ZWaGb5XmepjZk9aGbPe53jcGYWZ2bOzLp6nUVEIp8KIhGJWGaWZ2b7g2+WD3y1d85tdM4lO+eqQ3jsX9U4ZpmZVdf4vtbC4Gicc792zt18EplGm9lqMysxsy/NbOBRtj09uF3TI9y31MyOK4dz7lPnXL8TyX2E439hZtfV2Hd18PXcWB/7P+xY+WZ2Vn3vtw7H7QbcCvRyznWsh/0dKBBKD/t9uO3k055whp1mNtXMUuv4+PPMLC/EMUVEvkYFkYhEukuCb5YPfG1piIM65x4+cEzgZmBWjQxfKwzMLK4BYr0IPAqkAlcBe2rb0Dn3ObAdGFfzdjMbDPQAXgtdTAG6ADuccwXH+8Bj/Cz1O+z34fETj3jC+gV/LzKANsA9HmQQEakzFUQi0uiYWdfgJ9Vxwe8/NbNfm9mM4KjIR2aWVmP7v5vZNjPbY2afmdlJj3TU+LT8+2aWA6wK3v7n4KhEsZnNM7OsGo85OD3JzDKCj78muP1OM7v9GIetBPJcwDLn3IZjbP8icM1ht10D/MM5t9vMYszsjeC5KQqexz61PN9DPt03s6Fmtjh4vqcBiTXu85nZ+8HntNvM/mlmHYL3/QYYBTwdHGV44vDpUWbWIjgFb2dwlPAOM7PgfTea2f/M7A/BzOvM7PxjnIcjMrObzSwnOK3tHTM7JXh7jJn90cx2BH9mlphZ3+B9F5vZyuDzzjeznx5hvxcCHwAHpnY+G7z9UjNbHsz9sZn1qvGYfDP7PzNbCuw7gecyysxmB/e9NZg/vsb9A8zsP2a2K/h6/6LGwxOD57vEzJaZWWZdjumc2wP8E+hb4zg31jg/uWZ2Y/D25sFtD5yTvWbWJvja3x3cttjM5ptZ+xqHuSD4Gu02sz8e73kREQEVRCISPa4ErifwiXUC8PMa931AYFSkDbAQmFqPxx0DnAoMCH4/BxgItALeAP5uZom1PBYgi8An7RcA95tZjyNtFCwI5gDPmVmnOmZ7ETi7RjESC4wP3n7AewTOTTtgGfDSsXYafD7vAs8ReJ7vApfW2CQGmAx0JjBSUgk8CeCc+yUwC7g5OMLxkyMc4imgKdAdOAeYyKGFXRawFPABfwD+dqzMR3gO5wMPAJcDHYAtfPVzMRoYSeC8tASuAHYF75sCTHTOpRB4nf93+L6dcx8ClwAHpnbeGCw0XwZ+BLQG/gP8s2bREjzOaKD58T4foAr4MZAGZAMXAt8LPtfmB44HnAL0BD6t8dhLCbzuLQj8rtSp8DCzVsBYYHaNm7cD3yQwinkT8CczGxgsnmqek2Tn3A7g/wi8BhcGj38jUFZjfxcBQ4EhwAQzO68u2UREalJBJCKR7p3gp95FZvbOUbab4pxb45zbD7wODD5wh3PuOedciXOuHLgPGBR8k1gfHnbO7Q4eF+fcS865Xc65KuC3BN4YZhzl8fc558qccwuB5cCgWra7E4gF7gU+PlAUmdktZnbE6W/OuTxgBoHpdQDnE/i78GHwfr9z7vnguSkjcG6GmlmzYzznbMABf3LOVTrnXgUW1TjuTufc2865/c65YuBh4Mxj7JPg84kHvgPcHsy1jkDRc3WNzXKDr2k18ALQ0WqMCNbRVcCzzrnFwed+O3CmmXUkUMClAr2Dz2eFc25b8HGVQF8zSwm+zgvreLwrCIzMfeycq+SrqY8jamzzpHMu/8DPUi2W1Ph9KDKzc4MZ5znn5jjnqoLn7Bm+OudjgE3OuSedc+XOuWLn3Nwa+/yfc2568Hy+RI3fnaNlAAoIFFiTD9zhnPunc25dcBTzY+C/wOlH2deNwK+cc2uDP4+LnXO7atz/iHNuT/Bn+dM6ZBMR+RoVRCIS6S51zrUIfl16lO221fj3PiAZDnYwe/TAlBwgL7jN8b6Brs2mmt+Y2S/MbJWZ7QF2A82Odqwab7QPyX0EPwYec869SGC05dNgUZRF4NP/2rzAV6MrVwNTg8XagXPz2+C0s2IgJ7jdsc5NeyDfOedq3HZw+p6ZNTOzZ81sY3C/H9dhnwe0IVD41ZwOuIHAKM4Bh58zqP281aZ9zWMEC7fdQAfn3EfA08BfgO1m9rSZpQQ3vYxAgbHRAlMMR1A3hx/PD+Rz6PPadPiDjmBgjd+HFs65/wKYWW8z+1dwOlwxgdGvA+e8E1+9tkdy+Pk8VkE80DnXAkgiMDr32YFR0OCUwjnBqXlFBIrwo732nYDc48h2vK+ziIgKIhGJelcSmNZzHoGpSF2Dt1s97f9gUWBmZwO3Ad8iMP2nJbC3no4VR2BaFM65PxModD4DhnPoFLjD/R3oZmZnEjgPNbe9hsCUpHMInJsDI1nHyrsVOLxzWs2W2b8AugHDnXOpwf3X5KjdDqCawFS7mvvefIxMx2tLzWMEC56WB47jnHvCOZcJ9CewRua24O1znHNjCBRu7wGvnuDxYgicw5rP62jn5Vj+SmDKY0bwnN/DV6/jJiD9JPZ9RM65CuBZAj83fcysCYFpoo8AbYNF00c1chzp+YUkm4hITSqIRCTapQDlQCGBdSkPh/hYVQSmEsUTmIJ2rE/b6+rvwO/NrJsFmknMJvDJezWBT+qPyDm3F3iLQAGV45xbfFjemufmoTpm+QKIMbMfBhfFfxuouRA/hcCn+bvNzMfXu5BtJ7A+6Eh5Kwm8qX7YzJIt0L76pwTW35yoBDNLqvEVB0wDJprZwODoxiPA5865fDMbHvyKA0qBCqDazJqY2ZVmlhrMWULg/NfF68AYC1zPKZ7A2pkSAuvC6kMKga6DpcH1St+rcd8/CDQz+KGZJZhZqpkNP9kDBtekXUfgtV5PoLFGArCTwPm6GDi3xkO2A2k1RtsgUFA9aGbpFjA4uDZJRKTeqCASkWj3IoGpSpuBFRy6ALy+vU9g+tpaAlPzigmMptSHnxDI/gWBN5a/AL4BrATeOGxx/uFeIDA6cfhI0hQCIxdbCKxfmlmXIMG1WJcRWDS/m0Br75rrux4nMOJUGNznB4ft4glgfHANzJHaRn+fQBGynkDTgheOkP14TAf21/i6K9j44AHgbQKvUWe+WmvVgsBUsCICr+NWAuuYAK4FNgSnpU3k0LVNtXLOLQ8+9i8ECoYLgTHBwup4LLdDr0P0++DtPwvuv4TAaNHBdWXBhgbfIDByuQNYQx3XdB0tA4HX/ipgbHCdTxGB4vVtAk0oLicwinYgxzLgTSAv+Nq3AX5H4GfnvwR+X57hKAW+iMiJsEOneIuIiIiIiEQPjRCJiIiIiEjUUkEkIiIiIiJRSwWRiIiIiIhELRVEIiIiIiIStVQQiYiIiIhI1IrzOsDxSktLc127dvU6hoiIiIiIhKkFCxYUOOda12XbiCuIunbtyvz5872OISIiIiIiYcrMNtR1W02ZExERERGRqKWCSEREREREopYKIhERERERiVoRt4boSCorK8nPz6esrMzrKI1KUlISHTt2JD4+3usoIiIiIiIh0SgKovz8fFJSUujatStm5nWcRsE5R2FhIfn5+XTr1s3rOCIiIiIiIdEopsyVlZXh8/lUDNUjM8Pn82nUTUREREQatUZREAEqhkJA51REREREGrtGUxB56ayzzmL69OmH3PbEE0/w/e9/v9bHJCcnA7BlyxYuv/zyWvd7rGsuPfHEE+zbt+/g9xdddBFFRUV1jS4iIiIiEtVUENWD8ePH8+qrrx5y26uvvsr48eOP+dj27dvzxhtvnPCxDy+I3n//fVq0aHHC+xMRERERiSYqiOrB5ZdfznvvvUd5eTkAeXl5bNmyhcGDB3PuueeSmZnJgAEDePfdd7/22Ly8PPr37w/A/v37ueKKKxg4cCDf/e532b9//8HtbrnlFoYNG0a/fv249957AfjjH//Ili1bOPvsszn77LMB6Nq1KwUFBQA8/vjj9O/fn/79+/PEE08cPF6fPn246aab6NevH+eff/4hxxERERERiSaNostcTff/czkrthTX6z77tk/l3kv61Xq/z+dj+PDhfPjhh4wdO5ZXX32V7373uzRp0oS3336b1NRUCgoKGDlyJGPGjKl1bc5f/vIXmjZtypIlS1iyZAmZmZkH73vooYdo1aoV1dXVnHvuuSxZsoRbb72Vxx9/nE8++YS0tLRD9rVgwQKmTJnCnDlzcM4xYsQIzjzzTFq2bMnatWuZNm0akydP5jvf+Q5vvvkmEyZMqJ+TJSIiIiISQTRCdIL8zrG3rJLyqmrg0GlzB6bLOef41a9+xcCBAznvvPPYvHkz27dvr3Wfn3322cHCZODAgQwcOPDgfa+//jqZmZkMGTKE5cuXs2LFiqPm++KLL7jsssto1qwZycnJjBs3js8//xyAbt26MXjwYACGDh1KXl7eCZ8HEREREZFI1uhGiI42klOf/H7HuoJS2qYm0TY1lksvvZTbbruNhQsXsn//fjIzM3n++efZuXMnCxYsID4+nq5dux6zjfWRRo/Wr1/PY489xrx582jZsiXXXXfdMffjnKv1vsTExIP/jo2N1ZQ5EREREYlaGiE6QXGxMTSJj2VveRUQ6Bp31llnccMNNxxsprBnzx7atGlDfHw8n3zyCRs2bDjqPs844wymTp0KwLJly1iyZAkAxcXFNGvWjObNm7N9+3Y++OCDg49JSUmhpKTkiPt655132LdvH6Wlpbz99tucfvrp9fLcRUREREQai0Y3QtSQkpPiKNhbQbXfERtjjB8/nnHjxh2cOnfVVVdxySWXMGzYMAYPHkzv3r2Pur9bbrmF66+/noEDBzJ48GCGDx8OwKBBgxgyZAj9+vWje/fuZGdnH3zMpEmTGD16NKeccgqffPLJwdszMzO57rrrDu7jxhtvZMiQIZoeJyIiIiJSgx1talU4GjZsmDv82jwrV66kT58+DZ6lpKyS9QWldEtrRkpSfIMfvyF4dW5FRERERE6UmS1wzg2ry7aaMncSmibEYWYHp82JiIiIiEhkUUF0EmJjjKbxsewtU0EkIiIiIhKJVBCdpOSkOPZXVlNV7fc6ioiIiIiIHKeQFURm9pyZ7TCzZUfZ5iwzW2xmy83sf6HKEkrJiYG+FKUVGiUSEREREYk0oRwheh64sLY7zawF8BQwxjnXD/h2CLOETJOEWGLM2FtW7XUUERERERE5TiEriJxznwG7jrLJlcBbzrmNwe13hCpLKMWY0SwxTo0VREREREQikJdriHoCLc3sUzNbYGbX1LahmU0ys/lmNn/nzp0NGLFuKvYWMfbcLAYNGky7du3o0KEDgwcPZvDgwVRUVNRpH9dffz2rV68OcVIREREREanJywuzxgFDgXOBJsAsM5vtnFtz+IbOuWeAZyBwHaIGTVkHndu35fXpn9OpZVOe/N3DJCcn8/Of//yQbZxzOOeIiTlyDTplypSGiCoiIiIiIjV4OUKUD3zonCt1zhUAnwGDPMxzwpLiY4mL+fr1iHJycujfvz8333wzmZmZbN26lUmTJjFs2DD69evHAw88cHDb0047jcWLF1NVVUWLFi24/fbbGTRoEKNGjWLHjoicTSgiIiIiEva8HCF6F/izmcUBCcAI4A8nvdcPbodtS096N4doNwBGP1rr3VZjHZFzhw5grVixgilTpvD0008D8Oijj9KqVSuqqqo4++yzufzyy+nbt+8hj9mzZw9nnnkmjz76KLfddhvPPfcct99+e/0+JxERERERCWnb7WnALKCXmeWb2UQzu9nMbgZwzq0EPgSWAHOBZ51ztbboDnfJiXFUVvup9h9aEKWnp3Pqqace/H7atGlkZmaSmZnJypUrWbFixdf21aRJE0aPHg3A0KFDycvLC2l2EREREZFoFbIRIufc+Dps8zvgd/V64KOM5ITSgesRVRx2gdZmzZod/PfatWt58sknmTt3Li1atGDChAmUlZV9bV8JCQkH/x0bG0tVlTrYiYiIiIiEgpdriBqVhLgY4mNjqKjy17pNcXExKSkppKamsnXrVqZPn96ACUVERERE5HBeriFqVMzs4LS5w9cRHZCZmUnfvn3p378/3bt3Jzs7u4FTioiIiIhITVbbm/dwNWzYMDd//vxDblu5ciV9+vTxKNFXdpdWsGn3Pnq0SaZJQuOoNcPl3IqIiIiI1JWZLXDODavLtpoyV4+SkwJF0OHtt0VEREREJDypIKpH8bExJMbFsre82usoIiIiIiJSByqI6llyUhyl5VX4I2wqooiIiIhINGo0BVG4rIVKTozF7xz7KyJ/lChczqmIiIiISKg0ioIoKSmJwsLCsHgD3yyhcawjcs5RWFhIUlKS11FEREREREKmUbRC69ixI/n5+ezcudPrKADsLi6jaIuxKyXR6ygnJSkpiY4dO3odQ0REREQkZBpFQRQfH0+3bt28jnHQOx+s5Lkv1vPlvefTtJG03xYRERERaYwaxZS5cJOdnkZltWPu+l1eRxERERERkaNQQRQCw7q2JD7WmJlb6HUUERERERE5ChVEIdA0IY4hnVsyM7fA6ygiIiIiInIUKohCJDs9jeVbiinaV+F1FBERERERqYUKohDJzvDhHMzStDkRERERkbClgihEBnVqQbOEWGZo2pyIiIiISNhSQRQi8bExDO/Wipk5GiESEREREQlXKohCKCs9jXUFpWzds9/rKCIiIiIicgQqiEIoK8MHoFEiEREREZEwpYIohPq0S6VVswStIxIRERERCVMqiEIoJsYY1d3HzJxCnHNexxERERERkcOoIAqxrAwf24rLWFdQ6nUUERERERE5jAqiEMtOTwNgZo6mzYmIiIiIhBsVRCHWxdeU9s2TmKkLtIqIiIiIhB0VRCFmZmRlpDFrXSF+v9YRiYiIiIiEExVEDSA7w0fRvkpWbC32OoqIiIiIiNSggqgBZAXXEc3QOiIRERERkbCigqgBtE1NIqNNMjO0jkhEREREJKyoIGogWek+5q3fRUWV3+soIiIiIiISpIKogWSlp7G/sprFm4q8jiIiIiIiIkEqiBrIqO4+YkzriEREREREwknICiIze87MdpjZsmNsd6qZVZvZ5aHKEg6aN42nf4fmzMxVQSQiIiIiEi5COUL0PHDh0TYws1jgN8D0EOYIG1npaSzaWERpeZXXUUREREREhBAWRM65z4Bdx9jsR8CbwI5Q5Qgn2Rk+qvyOuXnHOi0iIiIiItIQPFtDZGYdgMuAp73K0NCGdWlFQmwMs9R+W0REREQkLHjZVOEJ4JfOuepjbWhmk8xsvpnN37lzZwNEC40mCbEM6dxCjRVERERERMKElwXRMOBVM8sDLgeeMrNLj7Shc+4Z59ww59yw1q1bN2TGepedkcaKrcXsLq3wOoqIiIiISNTzrCByznVzznV1znUF3gC+75x7x6s8DSU7w4dzMGudps2JiIiIiHgtlG23pwGzgF5mlm9mE83sZjO7OVTHjAQDO7agWUKsps2JiIiIiISBuFDt2Dk3/ji2vS5UOcJNfGwMI7r7mKnGCiIiIiIinvNyDVHUykr3sb6glC1F+72OIiIiIiIS1VQQeSArPQ1Ao0QiIiIiIh5TQeSB3u1SaNUsgZlaRyQiIiIi4ikVRB6IiTFGpfuYkVuAc87rOCIiIiIiUUsFkUey09PYXlxO7s5Sr6OIiIiIiEQtFUQeyc7wATArV9PmRERERES8ooLII51bNaVDiybMyFFjBRERERERr6gg8oiZkZXuY9a6Qqr9WkckIiIiIuIFFUQeys5IY8/+SlZsKfY6ioiIiIhIVFJB5KGs9MA6ohlaRyQiIiIi4gkVRB5qk5pEjzbJzND1iEREREREPKGCyGNZ6T7m5e2iosrvdRQRERERkaijgshjWRlplFX6WbRxt9dRRERERESijgoij43s7iPGYEau2m+LiIiIiDQ0FUQea94kngEdmjNT64hERERERBqcCqIwkJWRxuJNRZSWV3kdRUREREQkqqggCgPZ6WlU+R1z83Z5HUVEREREJKqoIAoDQ7u0JCE2RtPmREREREQamAqiMNAkIZbMLi2YkaPGCiIiIiIiDUkFUZjITk9jxdZidpVWeB1FRERERCRqqCAKE1kZaQDMUvttEREREZEGo4IoTAzq2JzkxDhm5GodkYiIiESWNdtL2FehbrkSmVQQhYm42BhGdGulESIRERGJKCu3FjP6yc/5/tSFOOe8jiNy3FQQhZFR6T7WF5SypWi/11FEREREjsk5xz3vLsM5x6erd/Lekq1eRxI5biqIwkh2cB3RDLXfFhERkQjw9qLNzMvbzYOXDmBgx+bc/8/l7NlX6XUskeOigiiM9Gqbgq9ZAjM1bU5ERETC3J79lTz8/koGd2rBFad24uHLBrB7XyWPfLDS62gix0UFURiJiTFGpfuYkVOgObgiIiIS1v7w7zUUllbw4KX9iYkx+ndozsTTuvHqvE3MWacPdyVyqCAKM9kZaewoKSd3516vo4iIiIgc0Yotxbw4K48JI7rQv0Pzg7f/5LwedGzZhDveXkp5VbV3AUWOgwqiMJOV7gPQtDkREREJSwcaKbRomsDPz+91yH1NE+J48NL+rNtZylOf5HqUUOT4qCAKM51bNaVDiyZqrCAiIiJh6a2Fm5m/YTe3X9ib5k3jv3b/Wb3aMGZQe576NIecHSUeJBQ5PiqIwoyZkZ3hY1ZuIdV+rSMSERGR8LFnf6BpwpDOLbh8aMdat7v74r40TYjjjreW4tf7GQlzKojCUHZGGsVlVSzfssfrKCIiIiIH/eHfa9hVWsGvxwYaKdSmdUoid17Uh3l5u3lt/qYGTChy/EJWEJnZc2a2w8yW1XL/VWa2JPg108wGhSpLpBkVXEc0I0friERERCQ8HGykMPLQRgq1+fawjozs3oqH31/JjuKy0AcUOUGhHCF6HrjwKPevB850zg0Efg08E8IsEaVNShI92yYzM1friERERMR7fn+gkULLpgn87Bu9jv0AAssAHrpsAOWVfu5/b0WIE4qcuJAVRM65z4BdR7l/pnNud/Db2UDtE1GjUFZ6GvPydqllpYiIiHjurUWBRgq/HH3kRgq1SW+dzA/PyeBfS7by8artIUwocuLCZQ3RROADr0OEk6x0H2WVfhZtLPI6ioiIiESxPfsreeT9lWR2bsHlmcf/+fXNZ6bTo00yd7+znNLyqhAkFDk5nhdEZnY2gYLol0fZZpKZzTez+Tt37my4cB4a0d1HjMFMtd8WERERDz3+0Wp276vggWM0UqhNQlwMj4wbwOai/Tz+7zUhSChycjwtiMxsIPAsMNY5V2sHAefcM865Yc65Ya1bt264gB5q3iSeAR1bMEMXaBURERGPLN+yh5dmb+DqOjZSqM2wrq24akRnpsxYz5J8zX6R8OJZQWRmnYG3gKudc/q44Aiy0318uamIvRpeFhERkQYWaKSwnJZNE7jt/Lo1UjiaX1zYG19yIre/uZSqan89JBSpH6Fsuz0NmAX0MrN8M5toZjeb2c3BTe4BfMBTZrbYzOaHKkukys5Io8rvmLe+1t4UIiIiIiHx5sJ8FmzYze2je9O8Sd0bKdSmeZN47h/TjxVbi5kyI+/kA4rUk7hQ7dg5N/4Y998I3Biq4zcGQ7u0JCEuhhk5BZzdu43XcURERCRK7NlXyaMfrGJol5Z86wQaKdRmdP92nNenDY//ew0X9m9Hp1ZN623fIifK86YKUruk+FiGdm6pdUQiIiLSoH7/7wONFPqdUCOF2phZoDmDwV3vLMM5V2/7FjlRKojCXHaGj5VbiyncW+51FBEREYkCyzbv4eXZG7hmVFf6tT/xRgq1ad+iCT87vxf/W7OTf3y5pd73L3K8VBCFuayMNABmrdMokYiIiIRWoJHCMlo1S+Cn3+gZsuNcm9WVgR2b8+v3VlC0ryJkxxGpCxVEYW5gh+akJMYxI0cFkYiIiITWGwvzWbixiNtH96mXRgq1iY0xHhk3gN37Knnk/VUhO45IXaggCnNxsTGM6N6KWbm6QKuIiIiEzoFGCsO6tGTckA4hP16/9s258fRuvDZ/E7O0Xlo8pIIoAoxKTyOvcB+bi/Z7HUVEREQaqcc+Wk3RvopA04N6bKRwND85tyedWjXhzreXUlZZ3SDHFDmcCqIIkJ3hA2BGjkaJREREpP4t27yHqXMCjRT6tk9tsOM2SYjlwUsHsK6glKc+zW2w44rUpIIoAvRqm0JacgIzVRCJiIhIPfP7HXe/u4xWzRJD2kihNmf2bM2lg9vzl09zWLu9pMGPL6KCKAKYGaPS05iRW6h+/SIiIlKv3liQz6KNRdwxundIGykczV0X96VZYhx3vLUUv1/vdaRhqSCKENnpPnaWlJO7c6/XUURERKSRKNpXwaMfruLUri0Zlxn6Rgq1SUtO5M6L+jB/w26mzdvoWQ6JTiqIIkRWeuB6RGq/LSIiIvXlsY9Ws2d/JQ+M7Y9ZwzRSqM3lQzsyqruPRz9YxY7iMk+zSHRRQRQhOvua0rFlEzVWEBERkXqxNH8PU+ds5JpRXehzSsM1UqiNmfHQZf0pr/Jz/z9XeB1HoogKogiSnZ7G7HWFVGturYiIiJyEA40UfB41UqhN99bJ3HpOBv9aupX/rNjudRyJEiqIIkhWho/isiqWbd7jdRQRERGJYH9fsInFm4r41UW9SU3yppFCbSadkU7PtskuSQk0AAAgAElEQVTc8+4ySsurvI4jUUAFUQQ5uI4oV9PmRERE5MQU7avg0Q8CjRQuG+JdI4XaJMTF8Mi4AWzZU8bvP1rjdRyJAiqIIkjrlER6tU1hVq4aK4iIiMiJ+d301RSXVYVFI4XaDO3SigkjO/P8zPV8uanI6zjSyKkgijCj0n3My9tFeVW111FEREQkwizJL+KVuRu5dlTXsGikcDS/uLA3acmJ3P7WUiqr/V7HkUZMBVGEyc5Io6zSz8IN+rRERERE6i7QSGE5acmJ/OQbPbyOc0ypSfE8MLYfK7cW89wX672OI42YCqIIM6J7K2IMZmodkYiIiByH1+dv4stNRdx5UZ+wa6RQmwv6teO8Pm35w3/WsGnXPq/jSCOlgijCpCbFM7BjC12PSEREROpsd2kFv/lwFcO7tWLs4PZex6kzM+OBsf2INePOd5bhnC49IvVPBVEEys7w8WX+HvaqFaWIiIjUwe8+OtBIoV/YNlKoTfsWTfi/C3rx2Zqd/OPLLV7HkUZIBVEEyk5Po9rvmLte3eZERETk6JbkFzFt7kauy+pK73bh3UihNleP6sqgTi144J8rKNpX4XUcaWRUEEWgzC4tSYiLYUaOCiIRERGpnd/vuPudZYFGCueFfyOF2sTGGI+OG8Ce/ZU8/P5Kr+NII6OCKAIlxccyrEtLrSMSERGRo3pt/ia+zN/DXd/sQ0qENFKoTZ9TUrnx9O68Pj9fzaWkXqkgilDZGWms2lZCwd5yr6OIiIhIGDrQSGFEt1aMGRQ5jRSO5sfn9qBzq6bc+fYyyip1TUapHyqIIlRWug+AWbmaNiciIiJf99vpqykpq+KBsf0jrpFCbZokxPLQZf1ZX1DK//skx+s40kioIIpQAzo0JyUxjpkqiEREROQwX24q4tV5G7k+qyu92qV4Hadend6jNeOGdODp/+WyZnuJ13GkEVBBFKHiYmMY0b2V5tCKiIjIIar9jrvfXUbr5ER+HMGNFI7mzm/2ITkxjjveWorfr2sTyclRQRTBstLT2FC4j/zdunKziIiIBLw2bxNL8vdwZyNopFAbX3Iid36zLws27OaVuRu9jiMRTgVRBMvOSANgptpvi4iICLCrtILfTm9cjRRq863MDmSl+/jNB6vYXlzmdRyJYCqIIljPtsmkJScyQ9PmREREBPjd9FWUlFXx60sbTyOF2pgZD182gIpqP/f/c7nXcSSCqSCKYGZGVrqPmbmFOKf5syIiItFs8aYiXp23iRuyu9KzbeNqpFCbrmnNuPXcHry/dBv/XrHd6zgSoUJWEJnZc2a2w8yW1XK/mdkfzSzHzJaYWWaosjRm2Rk+dpaUk7Njr9dRRERExCPVfsc97y6jTUoiPz6vp9dxGtRNp3enV9sU7nl3GXvLq7yOIxEolCNEzwMXHuX+0UCP4Nck4C8hzNJoZaUH1hHNyNG0ORERkWj16ryNwUYKfUlOjPM6ToNKiIvh4XED2FZcxmPTV3sdRyJQyAoi59xnwK6jbDIWeNEFzAZamNkpocrTWHVq1ZROrZowQ9cjEhERiUq7Siv47YerGdXdxyUDo/Ot1NAuLbl6ZBdemJXH4k1FXseRCOPlGqIOwKYa3+cHb5PjlJ2exux1hVRV+72OIiIiIg3stx+uorS8ivvH9mv0jRSO5v8u6EXblCTueGsplXpPJMfBy4LoSL+xR+wMYGaTzGy+mc3fuXNniGNFnqyMNErKqli2pdjrKCIiItKAFm3cHWikcFq3qGmkUJuUpHjuG9OPlVuL+dsX672OIxHEy4IoH+hU4/uOwJYjbeice8Y5N8w5N6x169YNEi6SZKX7AJip9tsiIiJRI9BIYTltUxO59dweXscJCxf2b8f5fdvyxH/WsLFQF66XuvGyIPoHcE2w29xIYI9zbquHeSJWWnIivdul6AKtIiIiUWTa3I0s3byHu6KwkcLR3D+2H3ExMdz5zlJdlkTqJJRtt6cBs4BeZpZvZhPN7GYzuzm4yfvAOiAHmAx8P1RZosGodB/z8nZRVlntdRQRkajyyaodvD5/07E3FKlHhXvL+d301WSl+7g4Shsp1OaU5k34xYW9+HxtAe8uPuLkI5FDhOzjBOfc+GPc74AfhOr40SY7PY0pM/JYuHH3wVbcIiISWq/P38Qv31yCc7CjuIwfnqNpS9Iwfvvh6kAjhTHR3UihNleN6MJbCzfzwHsrOLNna1o2S/A6koQxL6fMST0a0b0VsTGmaXMiIg3kpVl5/OKNJZyWkcbYwe157KM1/OXTXK9jSRRYuHE3r83fxMTTutEjyhsp1CY2xnhk3ACK91fy0PsrvY4jYU4TThuJlKR4BnZszozcAn5OL6/jiIg0as9+vo4H/7WS8/q04c9XZhIXY/gd/ObDVcTFGDed0d3riNJIBRopLKNdahI/UiOFo+pzSiqTzujOU5/mMm5IB7IyNINGjqxOI0Rmlm5micF/n2Vmt5pZi9BGk+OVnZ7Gkvw9lJRVeh1FRKTR+vPHa3nwXyv55oBTeOqqoSTFxxIXG8MfvjOIbw44hYfeX8lzavkrIfLK3I0s21zMXRf3USOFOrj13B508TXlV28v1TprqVVdp8y9CVSbWQbwN6Ab8ErIUskJycrwUe13zF2/y+soIiKNjnOO301fxWMfrWHckA48ecVgEuK++jMaFxvDE1cM5oJ+bXngvRW8OCvPs6zSOBXuLed3H64iK93HNweokUJdJMXH8vBlA8gr3MefP87xOo6EqboWRH7nXBVwGfCEc+6ngH4Tw0xm55YkxsUwQ+uIRETqlXOOB/+1kv/3SS7jh3fisW8PIi72639C42Nj+NP4TM7r05Z73l3O1DkbPEgrjdVvPlzFvopqHhirRgrHIzsjjXGZHXj6f7ms3lbidRwJQ3UtiCrNbDxwLfBe8Lb40ESSE5UUH8uwri11gVYRkXrk9zvuemcZf/tiPddldeXhywYQE1P7m9GEuBj+31VDOKd3G+58exmvzdvYgGmlsVqwYTevz89n4undyGijRgrH665v9iUlKY473lqC369rE8mh6loQXQ+MAh5yzq03s27Ay6GLJScqKz2NVdtKKNhb7nUUEZGIV+13/OLNJUyds5Gbz0zn3kv61umT+cS4WJ66KpMze7bm9reW8nddp0hOQs1GCreqtfsJadUsgbsv7svCjUVMnasPKeRQdSqInHMrnHO3OuemmVlLIMU592iIs8kJyA52UJmVq2lzIiIno7Laz49fXcQbC/L56Xk9+eWFvY5rmlJSfCx/vXoop2Wk8Ys3l/D2ovwQppXG7JU5G1i+pZi7L+5LMzVSOGGXDelAdoaP336wim17yryOI2Gkrl3mPjWzVDNrBXwJTDGzx0MbTU5E//appCTFadqciMhJKK+q5gdTF/Lekq3cPro3Pz6vxwmt2UiKj+WZq4cxspuPn73+Je8u3hyCtNKYFewt53fTV5Od4eOiAe28jhPRzIyHLh1ARbWf+/6x3Os4EkbqOmWuuXOuGBgHTHHODQXOC10sOVFxsTGM6OZTYwURkRNUVlnNpBcX8NGK7dw/ph83n5l+UvtrkhDL364bxrCurfjpa4t5b8mWekoq0eA3H6xif2U194/pr0YK9aBrWjN+fF4PPly+jY+Wb/M6joSJuhZEcWZ2CvAdvmqqIGEqO8PHxl372LRrn9dRREQiSml5FddPmcdna3fy6LgBXJvVtV722zQhjinXnUpm55b8+NXFfLB0a73sVxq3BRt28fcF+Uw8rTsZbZK9jtNo3HR6d3q3S+Ged5fr2o0C1L0gegCYDuQ65+aZWXdgbehiyck4sI5I0+ZEROquuKySa5+by5z1hTz+nUFcMbxzve6/WWIcz98wnEEdm/OjaYv06bQcVbXfcfc7yzmleRI/OifD6ziNSnxsDI+MG8D2kjJ+/9Ear+NIGKhrU4W/O+cGOuduCX6/zjn3rdBGkxPVo00yrVMSNW1ORKSOivZVMOHZOSzeVMSfr8zksiEdQ3Kc5GBR1K9Dc37wykL+u3J7SI4jkW/qnA2s2KpGCqEypHNLrhnZhRdm5bFo426v44jH6tpUoaOZvW1mO8xsu5m9aWah+WshJ83MyEr3MTO3EOfUa19E5GgK9pZzxTOzWbW1hL9ePZSLBoT2uuOpSfG8eMNwerdL5ZaXF/Lp6h0hPZ5EngONFE7LSGN0fzVSCJWfX9CLtilJ3PHWUiqr/V7HEQ/VdcrcFOAfQHugA/DP4G0SprLT0yjYW87aHXu9jiIiEra2F5dxxTOzySss5W/XDePcPm0b5LjNm8Tz0sTh9GibzKSXFvD52p0NclyJDI9+sIqyymruG9NPjRRCKCUpngfG9mPVthKe/Xy913HEQ3UtiFo756Y456qCX88DrUOYS07SqHQfADNytI5IRORI8nfv4zt/ncXWov28cP1wTu/RsH/WWjRN4OWJI+ie1owbX5jPTP3/WoD5ebt4Y0E+N56uRgoN4fx+7biwXzue+M8aNhSWeh1HPFLXgqjAzCaYWWzwawKgBSphrFOrpnRu1VTriEREjmBDYSnf/etsdpVW8NKNIxjR3edJjpbNEph64wi6+ppxwwvzmL1O/8+OZlXVfu5+dznt1UihQd03ph/xsTHc+fYyLTWIUnUtiG4g0HJ7G7AVuBy4PlShpH5kZ/iYs66QKs2LFRE5KGfHXr7z11nsq6hi2k0jyezc0tM8vuREpt40gk4tm3LD8/OYu36Xp3nEO1PnbGRlsJFC0wQ1Umgo7Zon8csLe/FFTgHv6OLJUamuXeY2OufGOOdaO+faOOcuJXCRVgljWelplJRXsXTzHq+jiIiEhZVbi/nuX2dR7YdXJ42if4fmXkcCIC1YFLVrnsT1U+ayYIOKomizs6Scxz5azek90rhQjRQa3FUjupDZuQW/fm8lu0orvI4jDayuI0RHclu9pZCQyAquI5qZqykYIiJL8osYP3k28bExvPa9kfRql+J1pEO0SUli2k0jaZOaxLXPzVMr4ChzoJHC/Wqk4ImYGOORcQMp3l/JQ/9a6XUcaWAnUxDptzXM+ZIT6d0uRRdoFZGot2DDLq6aPIfkxDhe/94o0luH52L1tqlJvHLTCFo1S+Ca5+ayJL/I60jSAObl7eLNhfncdHp3uofpz2Y06NUuhe+d2Z03F+arKVWUOZmCSKvOIkBWehrz83ZTVlntdRQREU/Myi3k6r/NJS0lkde/N4rOvqZeRzqqU5o3YdqkkTRvEs+EZ+ewTNOeG7Wqaj93v7OM9s2T+KEaKXjuR+f0oKuvKXe+vVTvnaLIUQsiMysxs+IjfJUQuCaRhLnsDB/lVX4WbtDUCxGJPv9bs5PrpsylQ4smvDZpJO1bNPE6Up10aNGEaTeNJCUpngl/m8OKLcVeR5IQeXn2BlZtK+GeS9RIIRwkxcfy8GUDyCvcx58+Xut1HGkgRy2InHMpzrnUI3ylOOf0WxsBhndrRWyMMUPT5kQkyny0fBs3vTCf9NbJvDopsDYnknRq1ZRpN42kSXwsVz07m1XbVBQ1NjtLyvn9R2s4o2drLuinRgrhIisjjcuHduSv/1un37socTJT5iQCpCTFM6hjczVWEJGo8t6SLXx/6kL6tE9l2k0j8SUneh3phHT2BYqihLgYrpo8h7XbS7yOJPXokQ9WUlZVzX2X9FUjhTBz50V9SG0Szx1vLcXv1yqRxk4FURTIzkhjSf4eSsoqvY4iIhJyby7I59Zpi8js3JKXJw6nedN4ryOdlK5pzZh200hiYozxk+eQs2Ov15GkHsxdv4u3Fm5m0hlqpBCOWjZL4O6L+7BoYxFT52zwOo6EmAqiKDAq3Ue13zFnna5rISKN29Q5G/jZ378kKz2N5284lZSkyC6GDujeOplpN40E4MrJs1m3U0VRJKuq9nPPu8vo0KIJPzhbjRTC1aWDO3B6jzR+8+Fqtu0p8zqOhJAKoiiQ2bkliXExWkckIo3ac1+s5863l3FO7zY8e+2wRrdAPaNNMq/cNIJqv2P85NnkFZR6HUlO0IuzAo0U7r5YjRTCmZnx0KUDqPL7ufcfy7yOIyGkgigKJMXHcmrXVszM0ToiEWmcnvo0hwfeW8Ho/u14esJQkuJjvY4UEj3bpvDyjSOoqPJz5eTZbNq1z+tIcpx2lJTxh3+v4cyerbmgX1uv48gxdPY15Sfn9WT68u1MX77N6zgSIiqIokRWho/V20vYWVLudRQRkXrjnOPxj1bz2w9XM3Zwe/40fggJcY37T1ufU1J5+cYRlFZUc8Uzs8nfraIokjz6/irKq/zcN6afGilEiImndaN3uxTufXe51mM3Uo37r4YclJ2eBsCsdRolEpHGwTnHIx+s4o8f5/DdYZ14/DuDiYuNjj9r/do3Z+qNIygpq2T85NlsKdrvdSSpgznrCnlrUaCRQre0Zl7HkTqKj43h0W8NZHtJGY9NX+11HAmB6PjLIfTv0JyUpDhm5mgdkYhEPr/fce8/lvPMZ+u4ZlQXHhk3gNiY6Pq0vX+H5rw0cQRFpYGiSIu+w1tltZ973l2uRgoRanCnFlw7qisvzt7Awo262H1jE9KCyMwuNLPVZpZjZrcf4f7OZvaJmS0ysyVmdlEo80Sz2BhjZHefGiuISMSr9jvueGspL87awKQzunP/mH7ERFkxdMCgTi14YeJwCvdWMH7ybHYUqygKVy/O2sDq7SXcc0lfmiQ0zjVujd3PL+hFu9Qk7nhzKZXVfq/jSD0KWUFkZrHA/wNGA32B8WbW97DN7gJed84NAa4AngpVHoHsdB+bdu3XIlwRiVhV1X5ue30xr83fxK3n9uCO0b2jfh1GZueWvHDDqewoLgsURSUqisLNjuIynvj3Gs7q1Zrz+6qRQqRKTozjgbH9Wb29hMmfr/M6jtSjUI4QDQdynHPrnHMVwKvA2MO2cUBq8N/NgS0hzBP1sjMC64hmaNqciESgiio/P3xlEe8u3sIvLuzFbd/oGfXF0AFDu7RiyvXD2VJUxlWT51CwVw10wskjHwQbKVyiRgqR7ht92zK6fzue/M9atb5vREJZEHUANtX4Pj94W033ARPMLB94H/jRkXZkZpPMbL6Zzd+5c2coskaFjDbJtElJZGauGiuISGQpq6zm5pcX8OHybdxzcV++f5bWYBxueLdWPHfdqWzavY+rJs9hV2mF15GEQCOFtxdt5ntndqerGik0CveN6UdCbAx3vrMU55zXcaQehLIgOtJHIIf/1IwHnnfOdQQuAl4ys69lcs4945wb5pwb1rp16xBEjQ5mRla6j5m5hfoFFpGIsa+iihtfmM8nq3fw8GUDuOG0bl5HCluj0n387dpTySss5apn51C0T0WRl2o2UlAR33i0TU3il6N7MyOnkLcWbvY6jtSDUBZE+UCnGt935OtT4iYCrwM452YBSUBaCDNFvayMNAr2lrNm+16vo4iIHFNJWSXXPTePmbkFPHb5IK4c0dnrSGEvOyONydcMI3fnXib8bQ579um6KV55YWYeq7eXcK8aKTQ6Vw7vzNAuLXnwXys0GtsIxIVw3/OAHmbWDdhMoGnClYdtsxE4F3jezPoQKIg0Jy6EstJ9QGAdUa92KR6nERGp3Z59lVwzZS7LN+/hj+OHcPHA9l5Hihhn9GzNXycM5XsvLeDq5+bw0sQRNG8S73WsqLKjuIwn/rOWs3u15htqpNDoxMQYj4wbwDf/+DkP/msFj39nsNeR6lW131FaUUVJWRV7y6rYW15JSVnw+/LAbSUH/ltWGbitvIqR3X0R2VY+ZAWRc67KzH4ITAdigeecc8vN7AFgvnPuH8DPgMlm9lMC0+muc5rLFVIdWzali68pM3MLNO1ERMJW4d5yrv7bXHJ27OWpqzI5v187ryNFnLN7t+GpqzK5ZeoCrn1uLi9NHE5KkoqihvLw+yupqPJzrxopNFo926Zw85np/OnjHMYN6chpPbyf5FTtdweLkwOFTPHBouarQqakrPKr28qrgsVO5cFtSiuq63S85MS4wFdSHClJcfj9kfk23iKt/hg2bJibP3++1zEi2h1vLeW9L7ew6J5vRM1V3UUkcuwoLuOqZ+ewcdc+nrlmGGf21NrRkzF9+TZ+MHVh4JpFNwwnOTGUk0MEYPa6Qq54Zja3npPBbef38jqOhFBZZTWjn/wcv3NM/8kZJMWf2NTIOhUyZZUHR2UObBvY5sQLmZSkQDFz4N8pifGHfB/475Fui6NZQlxYXwPOzBY454bVZVv9XzEKZWf4mDZ3I0s372FI55ZexxEROWhL0X6uenYO24vLeP764YwKTvOVE3dBv3b8afwQfjhtEddPmcvz1w+nmYqikAk0UlhGx5ZNuEWNFBq9pPhYHr5sAOMnz+bRD1Zx8cBTDi1ajlDIlBycbnZihcyBoiQ5KY7UpDg6tmhy8PuDhU1SHMmHFTcHHhfuhYwX9H/EKDSqe+ANxszcQhVEIhI2Nu3ax/jJs9mzr5KXJg5naJdWXkdqNEYPOIUnnePWaYu44fl5TLn+VJom6C1AKLwwM4812/cy+ZphaqQQJUal+/j20I48PzOP52fmfe1+M0hO+KpgSU6Ko3mT+DoVMqk1RnBUyISO/m8YhXzJifRul8KMnIKIXPgmIo3Pup17uXLyHMqqqnnlppEM6Njc60iNzsUD21Ptd/z0tcXc+MJ8/nbtqXrDXs+2BxspnNO7Def1aeN1HGlAD102gNED2hEbExOceqZCJpKoIIpS2RlpvDR7A2WV1Sc831WkcG85q7eXMKq7T4uG5YSt3lbCVc/OARzTbhpJn1NSvY7UaI0d3IFqv+Nnf/+SSS/NZ/I1w/Q3oB49/P5KKqr93HtJX/0/McokxMVwTm91E4xUWlEfpbIzfFRU+VmwYbfXUSTCOOeYl7eLn7y6iFGPfMyVk+cwffk2r2NJhFq2eQ9XPDOL2Bh4ddIoFUMNYFxmR377rYF8kVPAzS8voLyqbmsX5Ohm5Rby7uIt3HxmOl18zbyOIyLHQQVRlBrezUdcjDEjp8DrKBIhSsoqeWlWHqOf/JxvPz2L/67cwfjhnejRJpmH31+lN1Vy3BZu3M34ybNpmhDH698bRUabZK8jRY1vD+vEI5cN4NPVO/n+ywupqPJ7HSmi1Wyk8P2z0r2OIyLHSVPmolRyYhyDOrVgZm6h11EkzK3YUszLczbw7qLNlFZU079DKo+OG8CYwe1pmhDHZ2t2cs1zc3lhZh6TztAbAambOesKueH5eaSlJPLKTSPp0KKJ15GizhXDO1Pld9z1zjJ+8MpCnroqk3hdiqHO/H7Hiq3FzMgp4L8rd7B2x16e1RREkYikgiiKZaf7+PMnORSXVZKqi/VJDWWV1by/dCsvz97Awo1FJMbFcMmg9kwY2YVBHZsfMjf+jJ6tOad3G/703xzGZXYkLTnRw+QSCT5fu5ObXpxPx5ZNmXrjCNqmJnkdKWpNGNmFar/j3n8s59Zpi/jj+CEqimrhnGN9QSkzcguZmVPArHWFFO2rBKBHm2T+74JenNdXa0hEIpEKoig2Kj2NP36cw5x1u/iG/icuQF5BKa/M3cjf529i975Kuqc1465v9uHyoR1p0TSh1sf96qI+XPjEZ/zh32t46LIBDZhYIs1/V27nlpcX0r11M16+cYQK6DBwbVZXqvyOX7+3gp+8tpgnvztYF+0O2ranjBk5BczMLWRmbgFb95QB0KFFE77Rpy3ZGWlkpftoo6JeJKKpIIpimV1akBQfw4ycAhVEUayq2s9/Vu5g6pwNfL62gNgY4/y+bZkwsgtZ6XXrHpfRJpkJI7vw4qw8rh7Vhd7ttDBevu79pVu5ddoi+rZP5cUbhh+1yJaGNfG0bvj9jofeX0msGX/47mBio7BN8J59lcxaV8CMnEJm5BawbmcpAC2bxpOVnkZWho/s9DS6+Jqqi5xII6KCKIolxsVyatdWzMxVY4VotL24jGlzN/Lq3E1sKy6jXWoSPz2vJ1cM73RCU5h+cl4P3l60mQffW8lLE4frzYIc4u1F+fzs9S/J7NyS564/VdN0w9BNZ3Snyu/4zYeriIsxfvftQY2+KNpfUc28vF3MyC1gZk4hy7bswTlomhDL8G6tGH9qZ7IyfPRpl6rryIg0YiqIolxWehq/+XAVO0vKaZ2iqSuNnd/vmJlbyMuzN/Dvldup9jvO6NmaB8b245zebU5qmkyLpgn85Lwe3P/PFXy8agfn9tGoowS8Oncjd7y9lFHdfUy+ZhjNEvWnJ1zdclY61X4/j320hpgY47ffGtioCoHKaj9L8osCI0A5BSzaWERFtZ/4WGNIp5b8+NweZGekMahjCxLiNG1QJFror1KUy87wATAzt4Cxgzt4nEZCpWhfBW8syGfqnI2sLyilZdN4bjytG1eO6Fyv18uYMLILL83ewEP/WskZPVtrcbbwwsw87v3Hcs7q1ZqnJwxVB64I8MNzelDldzzxn7XExRgPXzYgYosiv9+xenvJwXVAc9fvYm95FWbQ95RUrsvuSla6j+HdWtE0QW+JRKKVfvujXL/2zUlNimNmTqEKokbGOcfiTUW8PHsj7y3ZQnmVn6FdWnLruRmM7n9KSN6YxsfGcNc3+3DD8/N5adYGbjitW70fQyLHX/+XyyMfrOL8vm3505VDSIxTMRQpfnxuD6r9jj99nENsjPHgpf0jZhrsxsJ9zMgtYEZOAbNyCyksrQCgW1ozxg5uz2kZaYzs7qNlM61hE5EAFURRLjbGGNndxwytI2o0SsureHfxFqbO2cDyLcU0S4jl8qEdmTCyC31OCX2zg7N7teH0Hmk8+d+1XDakg950RCHnHE/+dy1P/Gctlwxqz+PfGaTRwghjZtz2jZ5U+R1/+TSXuBjjvjH9wrIo2llSzszgGqAZuQXk794PQJuURM7o2ZqsdB/ZGWm017WuRKQWKoiE7Iw0PlqxnY2F++jsa/QR+AAAACAASURBVOp1HDlBa7aX8PLsDby9cDMl5VX0bpfCg5f259IhHUhuwDUbZsZd3+zL6Cc/48n/ruW+Mf0a7NjiPeccv/lwNU//L5fLh3bkN98a2OgX5jdWZsYvLuhFtd/xzGfriIkx7rm4r+dFUUlZJXPWfdUIYfX2EgBSk+IYle5j0hndyUr3kd46+f+3d+fhUZV3G8e/TzYICSQkYYckQELYkUWWREAEKwrVatG6W2vr28XW1q3V1i7W1lat2r7aqvXV1r3WFUXcUFDZkX0ngQTCTgIh+zLzvH+cCZmEAAlkcpLM/bmuuTJz5mTmFziZnPs8m+u1ikjroEAkx8YRLcw6RGJ8osvVSGOUV3n4YP0+Xlqyk2XZ+USEhjBjeA+uHZ/IqMTOrp0MpHXvyFVjE3lhSQ7Xjk8kpWtHV+qQ5mWt5XfvbuRfi7K5dnwi9108tNWOPRGHMYa7LxxIpcfLcwuzCQsx3HPRoGb9bCmr9LBy5+FjLUBrcwvweC3twkIY2zeOb4zsRUZKPEN6xih8i8hpUSAS+neJpmvHdizKyuOqsQpErcGu/BJeXraT15bvIq+4gsS4Dtx94UAuH9OHuBbSRe228wcwe/Ue/jBnE8/dONbtciTAvF7LL99exyvLdnHTOX351YzmPWmWwDHGaRnyeC3//GIHoSEh/Hx6WsD+fz1ey/rdBcdagJZn51Ne5SU0xDCidww/PLc/6f0TGJUUq3FpItIkFIgEYwwZKQl8se0g1lqdxLRQHq/ls80HeHFpDgu2HsQAUwc5C6hOTElocVfi46Pb8eOpKfzx/c0s2HqQyQO6uF2SBEiVx8tdr6/lzVW7uWVKCrd/bYA+R9oYYwy/u3gIHq/lyQXOmKKm+n+21pJ1sOjYVNhLtudxtKwKgIHdO3LNuCQyUpyZ4Dpq/SoRCQAFIgEgvX88b63azZb9hQzsHviB99JwBwrLeG35Ll5ZtovdR0rp2rEdPz4vlSvP7tPiBwnfkJ7MS0t3cv97G8m4deIZrXMkLVOVx8utr65mzrq93PG1AdxyXqrbJUmAGGP4/SVD8Xgtj3+WSVio4afTBpzWa+05UnpsKuxFWYfYf7QcgD5xkVw0rAfpKQlM6Bev9fFEpFkoEAkA6SkJACzMzFMgagGstSzZns+LS3P4cP0+qryWjJR4fjVjENMGd2s1M3a1Cwvl7gsH8f0Xv+KV5bu4bnyS2yVJE3tyQRZz1u3llxcN4nuT+rldjgRYiG9dIv91ihoSgg8XV7B4e96xELTjUDEACdERTOifQIZvJrg+cZrYR0SanwKRANArNpLk+A4syjzETVo7xjUFpZW8udJZQDXzQBExkeHckJ7M1eMS6d8l2u3yTssFQ7oxvl8cj3y0hYtH9CQmUl1e2oot+wr567xtzBzeQ2EoiISEGP78zeF4vZaHP9pKaEgIPzi3f619SiqqWLYjn0VZTgjauPco1kJ0uzDG9Y3j2vFON7i0bh3VvVJEXKdAJMekpyQwe/UeqjxedW1qZutyC3hxSQ7vrNlNWaWXEX1ieWjWcL4+omdAFlBtTsYY7p05mJn/+yWPf7qNX84Y7HZJ0gSqPF7ufH0NndqH8ztNrR50QkMMD10+Ao+1/PmDzYQYGJXU2WkBysxj1a7DVHosEaEhjEqK5bZpA0hPSWB475hW08ItIsFDgUiOyeifwMtLd7J2dwGjEju7XU6bV1rh4d01zgKqa3ILiAwP5Rtn9eLa8UkM7RXjdnlNakjPGK4Y3Yd/Lcrm6nFJ9E2IcrskOUP//GIHa3MLeOLqUcRHa5xHMAoNMfzl8hFUeS0PzN0MgDEwrFcMN53Tj4yUeMYkxREZ0bov6ohI26dAJMdM6O+sR7Qo85ACUQBlHijipaU5vPFVLkfLqkjtGs3vLh7CpaN60akNz6B0+wUDeG/tHh54fxNPXz/G7XLkDGQeKOTRT7Zy4dDuzBjew+1yxEVhoSE89q2zmJiSQGyHCCb0iyemQ9v9HBORtkmBSI6Ji4pgUI9OLMzM00xRTazS4+WjDft5cUkOi7fnER5qmD60B9eOS2Rs37ig6EPftWN7fjglhYc+3MKirEOk909wuyQ5DR6v5c7X1xIVEcp9lwx1uxxpAcJDQ7hSa9iJSCumQCS1ZPSP5/klOZRVelr92JWWYM+RUl5ZtpNXl+/iYGE5vWIjufOCNK4Y0ycop5O96Zy+vLx0J79/bxPv/fgcrSrfCj375Q5W7TzCX688KyiPYRERaXsUiKSWjJQEnvlyByuyD3NOqq7gnw6v17Jg20FeWrKTTzfvxwJT0rpy7fhEJg/oGtQhoH14KHdfNJBbXl7Ff1fs0lXlVmb7wSIe/mgL5w/uxsUjerpdjoiISJNQIJJaxvaNIyzEsCjrkAJRI+UVlfPailxeXpbDrvxSEqIj+MG5/bny7EStreFnxrAe/Cspm4c/2sqM4T208nwr4fFa7np9Le3DQ/nDN4YGRTdPEREJDgpEUktUuzDO6hPLwqw8t0tpFay1rMg5zItLcpi7bh8VHi/j+sZx1wUDuWBIdyLCNL1sXdXTcF/yxEL+Pj+Ln08f6HZJ0gD/XpTNipzDPHLFCLp2au92OSIiIk1GgUiOk56SwOOfbqOgtFKLaJ7Esh353PfeBtbvPkrHdmFcPS6Ra8Ylktqto9ultXgj+sRy2che/N+XO7h6rFrQWrqcvGIe/HAz5w3syqUje7ldjoiISJPS5Ws5Tnr/eLwWlm5XK1F99haU8pNXVnHFU4vJL6rggcuGsfSXU/ntxUMUhhrhzulphBrDn3zrl0jL5PV1lQsPDeGPlw5TVzkREWlzAhqIjDHTjTFbjDGZxphfnGCfK4wxG40xG4wxLweyHmmYkYmxtA8PYZG6zdVSXuXhic8ymfqXBXywYR8/mZrKvNvP5aqxiXSIUGNrY/WIieT7k/szZ91elmfnu12OnMCLS3NYuiOfe2cOpnuMusqJiEjbE7CzOGNMKPAEcD6QCyw3xsy21m702ycVuBvIsNYeNsZ0DVQ90nDtwkI5OzmOhZmH3C6lxZi3aT/3vbeRnLwSvja4G/fOHKxuXk3g5kn9eHX5Tu57dyPv/CiDkCCega8l2pVfwp/mbmbSgC5cPrq32+WIiIgERCBbiMYCmdba7dbaCuBV4JI6+3wPeMJaexjAWnsggPVII2SkJLDtQBEHCsvcLsVV2w8WceNzy7jp3ysICzE8/52xPH39GIWhJhIZEcrPpw9k3e4C3lq12+1yxI+1lp+/sZYQY/jTZeoqJyIibVcgA1EvYJff41zfNn8DgAHGmIXGmCXGmOn1vZAx5mZjzApjzIqDBw8GqFzxl9HfmXJ7cZB2mysqr+KBuZu44LHPWZ59mF/NGMQHP53EpAFd3C6tzbl4RE9G9InlwQ83U1JR5XY54vPysp0sysrjnosG0TM20u1yREREAiaQgai+y4m2zuMwIBU4F7gKeMYYE3vcN1n7tLV2jLV2TJcuOiFtDoN7diImMjzous1Za3lrVS7nPTyfpxZs55KzevHpHZP57sR+hIdqDpJACAkx/HrmYPYfLefJBdvdLkeA3UdKeeD9zZyTksBVY/u4XY6IiEhABXIkeC7g/5e0N7Cnnn2WWGsrgR3GmC04AWl5AOuSBggNMYzvF8fCzDystUHRXWb97gJ+M3sDX+UcZkTvGJ66bjQjEzu7XVZQGJ3Uma+P6MlTC7L41tl96KUWCddYa/nFG2vxWssD6ionIiJBIJCXvJcDqcaYvsaYCOBKYHadfd4GpgAYYxJwutDpEnELkZGSwO4jpezML3G7lIDKL67gnrfW8fXHvyT7UDEPfnM4b/0wQ2Gomf18ehoAD36gabjd9NqKXXyx7RB3XzhQY+VERCQoBKyFyFpbZYy5BfgQCAWetdZuMMbcB6yw1s72Pfc1Y8xGwAPcaa0NzkErLVC6bxzRoqw8kuKjXK6m6VV5vLy8bCd/+WgrReVV3Jjel1unpWoxWpf07tyB703sx+OfZXJDejKjFEib3d6CUu5/bxPj+8Vxzbgkt8sRERFpFsbausN6WrYxY8bYFStWuF1GULDWMv6BeZydHMfjV49yu5wmtWR7Hr+dvYHN+wpJ7x/Pby8ewgAtquq64vIqzn14Pr07R/LmD9LVXasZWWv5zr+Ws2R7Ph/+dBKJ8WodEhGR1ssY85W1dkxD9tUocTkhYwwZ/RNYnJWH19u6gvOJ7DlSyi0vr+TKp5dQWFbFP64ZxUvfHacw1EJEtQvjzgvSWLXzCLPX1B1yKIH0xsrdfLblIHdNT1MYEhGRoKJAJCc1oX88ecUVbNlf6HYpZ6Ss0sPjn25j6l8W8PHG/dw6NZVPbpvMhcN6qBWihZk1qjdDenbiz3M3U1rhcbucoLD/aBn3vbuBsclx3DAh2e1yREREmpUCkZxURoozjqi1Tr9treXjjfv52qOf8/BHW5k8oAuf3DaZn50/gMiIULfLk3pUT8O9p6CMZ77QHCuBZq3ll2+tp7zKy59nDSckRBcIREQkuCgQyUn1jI2kb0IUi1rhAq1ZB4v49nPL+d7zK4gIC+HFm8bx5HWjNXNWKzCuXzwXDu3O3+dnsf9omdvltGmz1+zhk037ufOCNPomtL3JU0RERE5FgUhOKb1/PEu351Hp8bpdSoMUllXyx/c3ccGjn7My5zD3zhzM3Fsnck5qgtulSSPcfeEgPF7LQx9ucbuUNutAYRm/mb2BUYmx3JjR1+1yREREXKFAJKeUkZJAcYWHtbkFbpdyUl6v5c2VuZz3lwU8/fl2LhvVi0/vOJebzulLeKgO9dYmMb4DN56TzOtf5bKuhR97rZG1ll+/vYGSCg8PzhpBqLrKiYhIkNJZopzShH7xACxqweOI1uUWMOvJRdz22hp6xkby9o8yeHDWCLp0bOd2aXIGbpmSQnxUBL9/byOtbYmAlm7Our18sGEft50/gJSu0W6XIyIi4hoFIjmlzlERDO7RiYVZLS8Q5RWVc/eba7n4iS/ZmV/Cg7OG89YP0jmrT6zbpUkT6Ng+nNu/lsay7Hzmrt/ndjltRl5ROb9+ZwMjesfw3XPUVU5ERIJbmNsFSOuQkRLPvxflUFrhaRGzs1V5vLy4JIdHPt5KSYWH72T05dZpqXRqH+52adLEvnV2H55fnM0Dczdx3sCutA93//hr7X49ewNFZVU8dPkIwtSdVEREgpz+EkqDpKckUOHxsiIn3+1SWJR1iBl/+5LfvruR4b1jmXvrRO6dOVhhqI0KDTHcO3Mwu/JLeW5httvltHpz1+1lztq93DotVQsSi4iIoEAkDTQ2OY6wEOPq9Nu7j5Tyo5dWcvU/l1JcUcWT147mhZvGkqqTujYvIyWBaYO68sRnmRwsLHe7nFYrv7iCe99Zz9Benbh5Uj+3yxEREWkRFIikQaLahTEyMdaViRXKKj38bd42pv5lPp9s2s/Ppg3gk9smM31od4zRzFjB4p6LBlFW6eGRjzUN9+n63bsbKCit5KFZIzTzooiIiI/+IkqDpfdPYN3uAgpKK5vl/ay1fLhhH+c/uoBHPt7KeQO7Mu/2ydw6LVXjSIJQvy7RXD8hmf8s38XGPUfdLqfV+WjDPt5ZvYdbpqQyqEcnt8sRERFpMRSIpMHS+8fjtbBke+C7zWUeKOL6Z5fxPy98RfuwUF767jj+fs1oenfuEPD3lpbr1qmpdIoM5/45moa7MY6UVPDLt9czqEcnfjilv9vliIiItCgKRNJgIxM7ExkeGtBuc4VllfxhzkamP/Y5q3cd4dczB/P+rRPJSEkI2HtK6xHTIZyfTRvAoqw8Ptl0wO1yWo373tvI4eIKHpo1XF3lRERE6tC029JgEWEhnN03LiATK3i9ljdX7eZPczeTV1zOFaP7cOf0NBKitbCq1Hb1uEReWJLDH+ZsZPKALkSE6QT/ZD7dvJ83V+7mJ+elMLRXjNvliIiItDg6k5BGyegfz7YDRRw4WtZkr7k29wjffHIRd/x3Db07R/L2DzP486zhCkNSr/DQEH45YxDZeSU8vzjb7XJatILSSu55cz1p3Tpyy3mpbpcjIiLSIikQSaNUd11rilaiQ0Xl/Pz1tVzyxEJ25Zfy8OUjePMH6YzoE3vGry1t25S0rkwe0IW/zttGfnGF2+W0WH+Ys5GDReU8dPlwtaSJiIicgP5CSqMM7tGJmMhwFp7BOKJKj5dnv9zBlIfn88bKXL57Tl8+vWMys0b3JiRE02hLw/xqxiBKKjw89slWt0tpkRZsPchrK3L5n0n9GN5bFxlERERORGOIpFFCQgwT+sWzKCsPa22j1wFalHmI3767ga37i5iYmsBvvj6YlK5aWFUaL7VbR64Zl8hLS3dy3fgkLdDrp7CskrvfWEtK12h+MlVd5URERE5GLUTSaBkp8ew+UkpOXkmDvyf3cAk/fOkrrn5mKSUVHp66bjTPf2eswpCckZ9OG0BURCj3z9nkdiktyh/f38y+o2U8NGu41uwSERE5BbUQSaOl+40jSk6IOum+ZZUenlqwnX8syATgtvMHcPOkfjpJkyYRFxXBT6amcv+cTXy25QBT0rq6XZLrFmYe4pVlO/mfSf0YmdjZ7XJERERaPLUQSaP1S4iie6f2LMw68Tgiay0frN/HtEcW8OgnW5k6qBvzbj+Xn0xNVRiSJnX9hGT6JkTxhzmbqPR43S7HVUXlVdz1+lr6JUTxs/MHuF2OiIhIq6BAJI1mjCE9JZ7FWXl4vfa45zMPFHLd/y3j+y9+RVREGC9/bxxPXD2KXrGRLlQrbV1EWAj3XDSIzANFvLx0p9vluOrPczezp6CUhy5XVzkREZGGUiCS05LeP4H84go27ys8tu1oWSW/f28j0x/7grW5R/jt1wcz5yfnkN4/wcVKJRhMG9SVjJR4Hv1kKwUllW6X44rFWXm8sCSHG9P7Mjopzu1yREREWg0FIjktGSnxACzKOoTXa3ltxS7Oe3g+zy7cweVjevPZHefy7Yy+hIXqEJPAM8bwqxmDOVpayV/nbXO7nGZXUlHFz99YS1J8B+68IM3tckRERFoVTaogp6VHTCT9EqJ4Z/Ue3l27lzW7jjAqMZbnvj2WYb1j3C5PgtCgHp341tmJPL84m2vHJ9KvS7TbJTWbBz/Yws78Ev5z83giI9RVTkREpDF0+V5OW3pKPOt2F7DnSCmPXDGC17+frjAkrrrt/AG0Dw/lj+8HzzTcy7Pz+ffibG6YkMS4fvFulyMiItLqqIVITtsPzk2hX0I0l4/pTcf24W6XI0KXju245bwU/jR3M19uO8Q5qW17/FpphYe7Xl9L786R3DV9oNvliIiItEpqIZLT1is2ku+c01dhSFqUGzOS6RMXyf1zNuKpZxbEtuSRj7ew41Axf/7mcKLa6fqWiIjI6VAgEpE2pV1YKPdcOIjN+wr5z/JdbpcTMF/lHOaZL3dwzbhEzeQoIiJyBhSIRKTNmT60O2P7xvGXj7ZwtKztTcNdVunhrtfX0DMmkrsvGuR2OSIiIq1aQAORMWa6MWaLMSbTGPOLk+w3yxhjjTFjAlmPiAQHYwz3zhhMfkkFT3yW6XY5Te6xT7aRdbCYP31zGNHqKiciInJGAhaIjDGhwBPAhcBg4CpjzOB69usI/ARYGqhaRCT4DOsdwzdH9ea5L7PZmVfidjlNZvWuIzz9eRZXnt2Hiald3C5HRESk1QtkC9FYINNau91aWwG8ClxSz36/Bx4EygJYi4gEoTsvSCMs1PDA3LYxDXd5lYc7/7uGbp3ac88MdZUTERFpCoEMRL0A/xHNub5txxhjRgJ9rLXvneyFjDE3G2NWGGNWHDx4sOkrFZE2qVun9vxgcn/mrt/Hku15bpdzxv53XibbDhTxx8uG0UmzO4qIiDSJQAYiU8+2Y3PgGmNCgEeB20/1Qtbap621Y6y1Y7p0URcREWm4703qR8+Y9vz+vdY9Dfe63AL+sSCLWaN7MyWtq9vliIi/ihLIy4JKdXYRaY0CORo3F+jj97g3sMfvcUdgKDDfGAPQHZhtjLnYWrsigHWJSBBpHx7Kzy8cyK2vruaNlblcMabPqb+phamo8nLn62uIj4rg3hnHDcUUETcU58HWD2DzHMj6FKpKne0de0BsEnROgtjE2vc79YZQTYQi0tIE8rdyOZBqjOkL7AauBK6uftJaWwAcWzzDGDMfuENhSESa2sUjevKvRdk89OEWLhrWo9XNzPbEZ5ls3lfIM9ePIaaDusqJuCZ/O2x+H7a8DzsXg/VCp14w6jroPhyO7oEjOXBkJ+QshnX/dfapZkIhppcTko4FJV9Y6pwE0d0hRCuiiDS3gJ0VWGurjDG3AB8CocCz1toNxpj7gBXW2tmBem8REX/GGH49czCX/n0RT87P4o4L0twuqcE27Cngic8yuXRkL6YN7uZ2OSLBxVrYs8oJQJvnwIGNzvZuQ2HiHTBwBvQYAaa+UQKApxIKcp2AdCQHDufU3M/8BIr21d4/NAJi+hwflGKTnftRCSd+LxE5bcba1tWnfsyYMXbFCjUiiUjj/fTVVby/fh+f3j6Z3p07uF3OKVV6vFzy+EIOFJbzyW2TiO0Q4XZJxzu6F7Z/Bp2TnSvk7aLdrkjkzFRVQM6XTgDaMheO7gYTAonpTgAaeJFzvDeFyjIo2OULStlOWDqcU9PKVFJnMpjwKL+QlHh817zI2KapS6QNMMZ8Za1t0BqnravfiIjIGbhr+kA+2LCPP3+whf+9aqTb5ZzSk/Oz2Lj3KE9dN7plhSFPJWz9EFa9ANs+BuvxPWGgSxr0HAk9znK+dh8GES0/fEqQKzvqtNhsnuMc0+UFEBYJKVPhvF9B6gUQFd/07xveHhJSnVt9ygv9QlKdVqacRVB+tPb+7WP8glJynVamRIiIavqfIdh5qqCiEMqLfF0oe0Kouja3NgpEIhI0esZGcvOk/vxt3ja+nZ7E6KQ4t0s6oS37Cvnbp9v4+oieXDCku9vlOA5tg5XPw5pXofiAM94h41YY8g0o3O90LdqzyhlgvuYV53tMCHQZ5ISjnmdBz1HQbYhzIijipqN7a7rC7fgcvJXQIQEGfx0GzoR+50J4pLs1tuvo/L50G3L8c9ZC6eE6QckXlg5tg8x5NRM9VOuQUNMdr1YrUzLE9Iawds3yY7nKU+kEzYpiqChygkyF73F5kW9bPc+XF/ltK3S+VhRDVZ2ZBU2I82/Zua/z79o5GeL87kd2bv6fWU5JXeZEJKiUVFQx5eH5dI+J5K0fpBMS0vL641d5vFz690XsOVLKx7dNJi7KxdahimLY8BasfAF2LXEGhaddCCOvg5RpJ54x6+jemoC0dzXsXgklh5znQsKg62BfSPLdug6GsBbUCiZtj7VwcAtsfs8JQru/crZ37uvrCjcT+oyFkFB362wq1kLxQb+g5BeaDuc4Y5u8lX7fYJwZ8o7rjlc9Q14vd2bIOxZgivxCSWFNeKkorvN8Ue37dbd5yhv2viYEIqKdW7s6X0903xhfi1425O9wvlZ/7lVrH1sTjuqGJc1C2KQa02VOgUhEgs4bX+Vy+3/X8Oi3RnDpyN5ul3Ocv8/P5MEPtvDE1aOYMbxH8xdgLeSugFXPw/o3nROJ+BQnBI24CjqexuQO1jpjMapDUvWt9LDzfGiEcxXcPyR1GaiuJ3JmvB7IXe6EoM1znFniwGmpHDjDuXUZGJwTFXg9ULi3/u54R3Kc39fjZsjrffxED9WhKbqbM0NeVUU9oaQhLTJFftv8WmQaFWA6+sJJlF9Qqbutoy/IRNV5vnqb7/nwyKY5LsoLnWDkf6sOS0d21g6lIWG+STWSawelzslOcG/f6czrCSIKRM3BUwlv3AThHXy3SOcXKTzSGfQYHun0mz92v/o53/4Rvq9t5UpUa+f1QmUJVJbW+VpnW0Wx77Hfts5JkJTuzDqk/89Wweu1fOPvCzlwtJxP75hMh4iWc0Vu2/5CZvztS6YN7srfrxndvG9efMjpDrfqRTi4yfmMGnKpE4QSxzf9SaO1zolXrZC0xhm/ARDW3hmD5B+SEgbo90xOrrIUts+vmRSh5BCEhEPfSc6ECGkXOeM85OSqKuBo7vETPVTfL9pfe/9QXwuvp6Jhr18rwET7hZa6205yvzrQVJ9jtbZg6/U4wbNuUKq+lebX3j8yrp6w5Lvfqac+G+tQIGoO5UXwz/N8J8bFzirVdfvqNkRou5pwdFyw8g9P/iGrQ53nfCGsvtdpC1dXvZ46IcQ/qPi2VdTdVlwnyNQTbvxfp24f4IYICXf6W1cUOY/bdXJOGpPSISnDGVSuLkAt1vLsfC5/cjE/nZbKT6cNcLscADxeyzf/sYicvGI+vm0yCdHN0J/f63HG/Kx83jl59FZCrzHOuipDLmv+K5JeLxze4ReQVjtd7qp/z8I7ONMcV0/a0HOk03qltVuCW0m+M9HH5vec47myxPlMTj3faQVKmeZMOCBNp7IUjuzytSxlO7PlQcNbZMLat74A09xKj9T8+9YKSzucf/tjE9rgnJPEJtYfljonB+UMoApEbvF6nVBUqyWh2O+EvLjOcyV+J/N+wcr/RN1/34pioJH/XyFhJ2ixOlEIi6odsk4Ywny30PDTDyG1fvaSOq/ht+10w0r1z1br54us/bP4b4uou80/mEbWeb5DTdgsyHUW4Nu5yJn15+BmZ3tYJPQ52wlHiROg99mabauF+dFLK/l08wE+vWMyPWJcHjwNPP15Fn98fzN/vfIsLjmrV2Df7HC20xK0+mXnCmWHeBh+pROEug4K7Hs3ltcLeZm1W5L2rXU+I8A5weoxwjdpgy8kxfXTyVZbdzi7ZpHUnEXOyWHHnjWtQMkTdVFK2i5PldOCV7dV6fAOyM+uaWmvFtXl+C541fc79miTF5UUiNoqa6GqvE6QKqn/cUWdgFE3WJ0okHmrAv9z+IeV40JIPWElok4wUjpbRwAAEthJREFUCa8TTE4WVtxQfMhZwTxnEeQshH3rnH7YIeHOiVp1C1LiOF2xdNmu/BKmPrKAmcN68Mi3znK1lqyDRVz01y+YPKALT103GhOIk/nKMucK+srnYccCwDjTCo+8zjmBbE0nj54qOLS1TkhaVzPeoH2MXyuS72tskkJSa2Yt7F1TMzPc/vXO9q6DneN34EXQY2SbPLETabTSw8e3KlXfL8itPT4stJ3T/b9uUKq+tdKLuQpEcvqqKk7QQnWCli5v1cnDSkSH459vC934GqOsAHYtc8JRziJnti1vpdN/uttQJxwlpTu3qAS3qw06D36wmb/Pz+KdH2Uwoo87ixp6vJYrnlpM5oEiPr5tEl07NvGU1HvXOmsGrX0Nyo443SpGXgdnXe0Mkm4rPJVOC22tkLS+ZtByZOfa45F6jnRmzlJIark8lc5nZ/V4oIJdzmdnn/E1i6TG9XO7SpHWparCtyBw9vFhKT/bmdTCX3S348NSdde86G4t9jNUgUikJasogd0ralqQdi2vGX+WkFbTgpQ0oW2drLZQReVVnPvQfJLjO/Df708ITMvMKfzflzv4/XsbeeSKEVw2qon+z0uPwLr/OkFo7xrnCuCgrztd4pInBc9V9KpyOLCxdkg6sKmmNTyqS+2A1OMs6OTCzH5So7zQt0jq+7DtQ+eiUlh76H+eE4IGTNfFI5FAsdYZk3csKFWHpRynxenobmoN3wiL9LUu+QJScobzt6YFUCASaU2qKpxB49UtSDuX1Kw+HptUE46SMjQuIkD+s3wnP39jHY9fPZKZw5t39qnsQ8VM/+vnZPRP4JkbxpxZIPN6IedLZ82gTbOd8Xfdh8HI62HYLOjQcheibVaVpbB/Q82kDXtWObPqVXchie5+fEtSdBd3a27rCvf7LZK6wJmpLDLOWfMq7SLoP8XpPi0i7qoqdyZ0qNWq5Hd/6KVwyRPu1uijQCTSmnk9zsladQtSzqKahd2iu/m1IKVDl0HBc6U/gDxey9f/90sKSiuZd/tk2oc3z9SlXq/lyn8uYdPeo3z8s8l0jznNrnJH98Dql5xJEg5nQ7sYGH650y2up7tjo1qNimKne51/S9KhrRy7Etqpd+1JG3qOVMA8Uwe3wpY5TgjKXQFY5wpzmm99oD7jtEilSGtSPdY9vIm7fZ8mBSKRtsRaOLStJhzlLPQ1WeOseF09/igpHbqP0AnEaVqUdYir/7mUOy9I40dTUprlPf+9KJvfzN7Ag7OGc8WYPo375qoK2PqB0yUu8xOndSN5Ioy63umuEO7+rHmtXnmhM/7KPyTlZ9U8H5tUM2lDfGrtNVH810zR76TD63W6C29+z+kOl7fN2d7jLBg40xkP1HWwWsFFpEkoEIm0ZdY6i+P5tyBVn6SFRzmz1yWlQ2I69BrdYq7UtAY3P7+ChZmH+OzOc5t+YoM6duWXcMFjnzMmOY5/33h2w7vKHdzizBK35lWn5bBjT2dyhJHXaHB5cyg94kz57R+SDmef/HvC2p9gYck6i1BGRJ14zRb/NV1a08Q0lWVOF7jqSRGKDzjLQSRPdFqB0i7UWEkRCQgFIpFgU7jPF5B8twMbnO2hEc4im9UtSH3GOidUUq/sQ8Wc/+gCLhvZmz/PGh6w9/F6Ldc8s5R1uwv46GeT6Bl7itac8iLY8KYzNih3mXNCmXahMzYoZapWJ3dbSb5zkaKi2FlAtrzQ736RM2NTRbHvfpHf9iK/7YW1p8E9mdAIv1BVT4tUfQHruADmdz+siRcALj0MWz9yWoIy5zkzk0ZEO4ukps1wvka6M6OjiASPxgQiteOLtAUdu8PQy5wbOCdou5bWtCB9+Sh88TCYUGcBy2NrIY3XOAg/yQlRfDs9mWe+3MF1E5IY2isw60S9vGwni7fn8cBlw04chqx1pmtf9Tysf8s5qUxIg6/d7yygqkH+LUeHuDP/PbK2ZjmDikJfSGpEwCo76owlqyj27V/U8HXlQsJP0DpVJ2DVG7p8900o7PjcGROUvdBZJDW6Owy/wukO13di0wcvEZEmohYikWBQXuS0LFS3IOWuqFnAsuuQ2uOQOnZ3t1aXFZRWMuXh+aR2jebVm8c3+TTcuYdLuODRzxmZ2JkXbhp7/OsXHYQ1rzgTJBza4nSDHHqZMzao99kaXyENUz24+biAVV/YqtNS5R+2/EOXp+LU75uQ5lsfaAb0HKVJX0TENWohEpHa2kU7a3j0P895XFkGe1bWtCCtfhmW/9N5Lq5/7ZnsYhOD6iQ8JjKcn50/gHvfXs+HG/YzfWjTBURrLXe/uQ6ABy4bVhOGPFWQNc8ZG7T1A+fKfp9xcPHjMORS5/9PpDGMccYPhreHqPimec2qijpd/vwCVlWZE4ASmmdCEhGRpqRAJBKMwtvXtAiBc0K+b01NC9Kmd53ZywA69fJrQcqAhAFtPiBddXYfXliczQNzNzFlYBfahTXNGJ3/LN/FF9sO8ftvDKVPXAdn7YZVLzqBtHCPs0jo+B8402V3SWuS9xRpMmERENYE3QNFRFoYdZkTkeN5vc5ClccmalgIRfud5zok1CwUm5QO3Ya2yUH9n289yPXPLuOeiwZy86T+Z/x6ewtK+dojn3NWz3b8e/x+Qla9ANlfgAmBlPNh1HUwYHrrmkFMRESkhdIscyLStKyF/O21A9KRHOe5sEiISnBmjYrsXHNrX+dxrVsshHdo8S1N3/nXcpbvyGf+necSH336A8Kttfz2qZdJ2/M2V7ZfQkjFUejcF0Ze60yZ3alnE1YtIiIiCkQiEngFuZCzGPaudma1Kz18/M1beeLvD42oPywdC1L1BapYaBfTbAO1Mw8UMf2xz/nW2X34w6XDGv8CJfmw7r8cXvgsnY9upiqkHWFDLnFag5LO0YBzERGRANGkCiISeDG9Yfjlzq0+1kJlSf1BqfSws8Cl/+Mju2DvWud+ZfGJ39eEQPuYkwSpk7RKNbI7WkrXaK4dn8Tzi7O5fkIyad0bsIaT1wvZnztrBm16Fzzl7KUvb3T6Ed/5/p3QoXOjahAREZHAUiASkcAwxrf4Y1TjV6KvqoCyIw0LUiX5kJfl3C8rAE7S6h0RXX/r00nC1E8n9eStlbncP2cjz3+nnmmyqxXkOpMjrHrR6U7YPhY76nru2z2al3fG8sH1kwjpENW4fwcREREJOAUiEWl5wiIguqtzawyvF8oLThCg6glYBzafsntfLLDShJO3M4riRxOIju1SJ0jFOovgZs4DLPSdDFN/DQNn8s76PJ77YjW/mpFG3wSFIRERkZZIgUhE2o6QkJqw0hin6t5XcphlyzfRsaSQiXFhhNTt3tepF0y6E0ZeA52TAThQWMZvZm9gVGIsN2b0bfqfVURERJqEApGIyCm694UCHRL3c8O/VvCb1MG1A05VBYSE1ZogwVrLvW+vp7TSw4OzRhAa0rJn0xMREQlmmuJIRKQBpqR1ZWJqAo99so0jJRU1T4RFHDdb3Htr9/Lhhv3cfv4AUrpGN3OlIiIi0hgKRCIiDWCM4VczBlNYVsljn2w74X6Hisr59TvrGdEnlu9O7NeMFYqIiMjpUCASEWmgtO4duWpsIi8sySHzQFG9+/zmnQ0Ul3t4eNZwdZUTERFpBRSIREQa4bbzB9AhPJQ/vr/puOfeX7eXOev2cuu0VFK7NWDNIhEREXFdQAORMWa6MWaLMSbTGPOLep6/zRiz0Riz1hgzzxiTFMh6RETOVHx0O348NYVPNx/g860Hj23PL67g3rfXM6xXDP8zSV3lREREWouABSJjTCjwBHAhMBi4yhgzuM5uq4Ax1trhwOvAg4GqR0SkqdyQnkxSfAfun7ORKo8XgN/O3sDRskoeunw4YaFqfBcREWktAvlXeyyQaa3dbq2tAF4FLvHfwVr7mbW2xPdwCdDI5exFRJpfu7BQ7r5wEFv3F/HK8l18uGEfs9fs4ZYpqQzs3snt8kRERKQRArkOUS9gl9/jXGDcSfa/CZgbwHpERJrMBUO6Mb5fHI9+vJXQEMPgHp344ZT+bpclIiIijRTIFqL6pley9e5ozLXAGOChEzx/szFmhTFmxcGDB+vbRUSkWRljuHfmYA6XVHC4uIKHLh9OuLrKiYiItDqBbCHKBfr4Pe4N7Km7kzFmGvBLYLK1try+F7LWPg08DTBmzJh6Q5WISHMb0jOG3108hOh2YQzpGeN2OSIiInIaAhmIlgOpxpi+wG7gSuBq/x2MMSOBp4Dp1toDAaxFRCQgrp+Q7HYJIiIicgYC1r/DWlsF3AJ8CGwCXrPWbjDG3GeMudi320NANPBfY8xqY8zsQNUjIiIiIiJSVyBbiLDWvg+8X2fbr/3uTwvk+4uIiIiIiJyMRgCLiIiIiEjQUiASEREREZGgpUAkIiIiIiJBS4FIRERERESClgKRiIiIiIgELQUiEREREREJWgpEIiIiIiIStBSIREREREQkaCkQiYiIiIhI0FIgEhERERGRoKVAJCIiIiIiQctYa92uoVGMMQeBHLfr8JMAHHK7CHGVjgHRMSA6BkTHgOgYaFmSrLVdGrJjqwtELY0xZoW1dozbdYh7dAyIjgHRMSA6BkTHQOulLnMiIiIiIhK0FIhERERERCRoKRCduafdLkBcp2NAdAyIjgHRMSA6BlopjSESEREREZGgpRYiEREREREJWgpEp8kYM90Ys8UYk2mM+YXb9UjzMsb0McZ8ZozZZIzZYIy51e2axB3GmFBjzCpjzHtu1yLuMMbEGmNeN8Zs9n0mTHC7Jmlexpif+f4WrDfGvGKMae92TRJYxphnjTEHjDHr/bbFGWM+NsZs833t7GaN0nAKRKfBGBMKPAFcCAwGrjLGDHa3KmlmVcDt1tpBwHjgRzoGgtatwCa3ixBX/RX4wFo7EBiBjoegYozpBfwEGGOtHQqEAle6W5U0g38B0+ts+wUwz1qbCszzPZZWQIHo9IwFMq212621FcCrwCUu1yTNyFq711q70ne/EOcEqJe7VUlzM8b0BmYAz7hdi7jDGNMJmAT8H4C1tsJae8TdqsQFYUCkMSYM6ADscbkeCTBr7edAfp3NlwD/9t3/N/CNZi1KTpsC0enpBezye5yLToaDljEmGRgJLHW3EnHBY8BdgNftQsQ1/YCDwHO+rpPPGGOi3C5Kmo+1djfwMLAT2AsUWGs/crcqcUk3a+1ecC6cAl1drkcaSIHo9Jh6tmm6viBkjIkG3gB+aq096nY90nyMMTOBA9bar9yuRVwVBowC/mGtHQkUo24yQcU3TuQSoC/QE4gyxlzrblUi0hgKRKcnF+jj97g3ah4POsaYcJww9JK19k2365FmlwFcbIzJxuk2e54x5kV3SxIX5AK51trqFuLXcQKSBI9pwA5r7UFrbSXwJpDuck3ijv3GmB4Avq8HXK5HGkiB6PQsB1KNMX2NMRE4gydnu1yTNCNjjMEZM7DJWvuI2/VI87PW3m2t7W2tTcb5DPjUWqurwkHGWrsP2GWMSfNtmgpsdLEkaX47gfHGmA6+vw1T0cQawWo2cIPv/g3AOy7WIo0Q5nYBrZG1tsoYcwvwIc5sMs9aaze4XJY0rwzgOmCdMWa1b9s91tr3XaxJRNzxY+Al3wWy7cCNLtcjzchau9QY8zqwEmcG0lXA0+5WJYFmjHkFOBdIMMbkAr8B/gS8Zoy5CScoX+5ehdIYxloNfRERERERkeCkLnMiIiIiIhK0FIhERERERCRoKRCJiIiIiEjQUiASEREREZGgpUAkIiIiIiJBS4FIRERaDGOMxxiz2hizxhiz0hhz0gUujTGxxpgfNuB15xtjxjRdpSIi0lYoEImISEtSaq09y1o7ArgbeOAU+8cCpwxEIiIiJ6JAJCIiLVUn4DCAMSbaGDPP12q0zhhziW+fPwH9fa1KD/n2vcu3zxpjzJ/8Xu9yY8wyY8xWY8zE5v1RRESkpQpzuwARERE/kcaY1UB7oAdwnm97GXCptfaoMSYBWGKMmQ38AhhqrT0LwBhzIfANYJy1tsQYE+f32mHW2rHGmItwVpWf1kw/k4iItGAKRCIi0pKU+oWbCcDzxpihgAH+aIyZBHiBXkC3er5/GvCctbYEwFqb7/fcm76vXwHJgSlfRERaGwUiERFpkay1i32tQV2Ai3xfR1trK40x2TitSHUZwJ7gJct9Xz3o75+IiPhoDJGIiLRIxpiBQCiQB8QAB3xhaAqQ5NutEOjo920fAd8xxnTwvYZ/lzkREZHj6AqZiIi0JNVjiMBp7bnBWusxxrwEvGuMWQGsBjYDWGvzjDELjTHrgbnW2juNMWcBK4wxFcD7wD0u/BwiItJKGGtP1LNARERERESkbVOXORERERERCVoKRCIiIiIiErQUiEREREREJGgpEImIiIiISNBSIBIRERERkaClQCQiIiIiIkFLgUhERERERIKWApGIiIiIiASt/wfde3mX78nU/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize loss \n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(log_validation_loss)\n",
    "plt.plot(log_train_loss)\n",
    "plt.title('Final Train & Validation Loss for Each Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.legend(['Validation', 'Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oCjtEji1AXdK",
    "outputId": "8a88b8d7-2b16-4464-c161-3e38d2d21836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.7.1\n",
      "alabaster==0.7.12\n",
      "altgraph==0.16.1\n",
      "anaconda-client==1.7.2\n",
      "anaconda-navigator==1.9.6\n",
      "anaconda-project==0.8.2\n",
      "asn1crypto==0.24.0\n",
      "astor==0.8.0\n",
      "astroid==2.1.0\n",
      "astropy==3.1\n",
      "atomicwrites==1.2.1\n",
      "attrs==18.2.0\n",
      "Babel==2.6.0\n",
      "backcall==0.1.0\n",
      "backports.os==0.1.1\n",
      "backports.shutil-get-terminal-size==1.0.0\n",
      "beautifulsoup4==4.6.0\n",
      "bitarray==0.8.3\n",
      "bkcharts==0.2\n",
      "blaze==0.11.3\n",
      "bleach==3.0.2\n",
      "blis==0.2.4\n",
      "bokeh==1.0.2\n",
      "boto==2.49.0\n",
      "boto3==1.9.169\n",
      "botocore==1.12.169\n",
      "Bottleneck==1.2.1\n",
      "cachetools==3.1.1\n",
      "certifi==2018.11.29\n",
      "cffi==1.11.5\n",
      "chardet==3.0.4\n",
      "Click==7.0\n",
      "cloudpickle==0.6.1\n",
      "clyent==1.2.2\n",
      "colorama==0.4.1\n",
      "colorlover==0.3.0\n",
      "comtypes==1.1.7\n",
      "conda==4.5.12\n",
      "conda-build==3.17.6\n",
      "conda-verify==3.1.1\n",
      "contextlib2==0.5.5\n",
      "cryptography==2.4.2\n",
      "cufflinks==0.15\n",
      "cycler==0.10.0\n",
      "cymem==2.0.2\n",
      "Cython==0.29.2\n",
      "cytoolz==0.9.0.1\n",
      "dask==1.0.0\n",
      "datashape==0.5.4\n",
      "decorator==4.3.0\n",
      "defusedxml==0.5.0\n",
      "distributed==1.25.1\n",
      "docutils==0.14\n",
      "entrypoints==0.2.3\n",
      "et-xmlfile==1.0.1\n",
      "fastcache==1.0.2\n",
      "filelock==3.0.10\n",
      "Flask==1.0.2\n",
      "Flask-Cors==3.0.7\n",
      "future==0.17.1\n",
      "gast==0.2.2\n",
      "genderdecoder==0.3\n",
      "gensim==3.7.3\n",
      "gevent==1.3.7\n",
      "glob2==0.6\n",
      "google-auth==1.8.2\n",
      "google-auth-oauthlib==0.4.1\n",
      "google-pasta==0.1.8\n",
      "graphviz==0.13.2\n",
      "greenlet==0.4.15\n",
      "grpcio==1.21.1\n",
      "h5py==2.8.0\n",
      "heapdict==1.0.0\n",
      "html2text==2018.1.9\n",
      "html5lib==1.0.1\n",
      "idna==2.8\n",
      "imageio==2.4.1\n",
      "imagesize==1.1.0\n",
      "importlib-metadata==0.6\n",
      "inflection==0.3.1\n",
      "ipykernel==5.1.0\n",
      "ipython==7.2.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.4.2\n",
      "isort==4.3.4\n",
      "itsdangerous==1.1.0\n",
      "jdcal==1.4\n",
      "jedi==0.13.2\n",
      "Jinja2==2.10\n",
      "jmespath==0.9.4\n",
      "joblib==0.14.1\n",
      "jsonschema==2.6.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==5.2.4\n",
      "jupyter-console==6.0.0\n",
      "jupyter-core==4.4.0\n",
      "jupyterlab==0.35.3\n",
      "jupyterlab-server==0.2.0\n",
      "Keras==2.2.4\n",
      "Keras-Applications==1.0.8\n",
      "Keras-Preprocessing==1.0.9\n",
      "keyring==17.0.0\n",
      "kiwisolver==1.0.1\n",
      "lazy-object-proxy==1.3.1\n",
      "libarchive-c==2.8\n",
      "llvmlite==0.26.0\n",
      "locket==0.2.0\n",
      "lxml==4.2.5\n",
      "Markdown==3.0.1\n",
      "MarkupSafe==1.1.0\n",
      "matplotlib==3.0.2\n",
      "mccabe==0.6.1\n",
      "menuinst==1.4.14\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.0.6\n",
      "mkl-random==1.0.2\n",
      "mlxtend==0.17.0\n",
      "mne==0.19.2\n",
      "mock==3.0.5\n",
      "more-itertools==4.3.0\n",
      "mpmath==1.1.0\n",
      "msgpack==0.5.6\n",
      "multipledispatch==0.6.0\n",
      "murmurhash==1.0.2\n",
      "navigator-updater==0.2.1\n",
      "nbconvert==5.4.0\n",
      "nbformat==4.4.0\n",
      "ndg-httpsclient==0.5.1\n",
      "networkx==2.2\n",
      "nltk==3.4.1\n",
      "nose==1.3.7\n",
      "notebook==5.7.4\n",
      "numba==0.41.0\n",
      "numexpr==2.6.8\n",
      "numpy==1.16.5\n",
      "numpydoc==0.8.0\n",
      "oauthlib==3.1.0\n",
      "odo==0.5.1\n",
      "olefile==0.46\n",
      "openpyxl==2.5.12\n",
      "opt-einsum==3.1.0\n",
      "packaging==18.0\n",
      "pandas==0.25.3\n",
      "pandocfilters==1.4.2\n",
      "parso==0.3.1\n",
      "partd==0.3.9\n",
      "path.py==11.5.0\n",
      "pathlib2==2.3.3\n",
      "patsy==0.5.1\n",
      "pefile==2019.4.18\n",
      "pep8==1.7.1\n",
      "pickleshare==0.7.5\n",
      "Pillow==5.3.0\n",
      "pkginfo==1.4.2\n",
      "plac==0.9.6\n",
      "plotly==3.10.0\n",
      "pluggy==0.8.0\n",
      "ply==3.11\n",
      "preshed==2.0.1\n",
      "prometheus-client==0.5.0\n",
      "prompt-toolkit==2.0.7\n",
      "protobuf==3.7.1\n",
      "psutil==5.4.8\n",
      "pupygrib==0.5.0\n",
      "py==1.7.0\n",
      "pyargus==1.0.post3\n",
      "pyasn1==0.4.7\n",
      "pyasn1-modules==0.2.7\n",
      "pycodestyle==2.4.0\n",
      "pycosat==0.6.3\n",
      "pycparser==2.19\n",
      "pycrypto==2.6.1\n",
      "pycurl==7.43.0.2\n",
      "pydot==1.4.1\n",
      "pyEDFlib==0.1.15\n",
      "pyflakes==2.0.0\n",
      "Pygments==2.3.1\n",
      "PyInstaller==4.0.dev0+1eadfa55f2\n",
      "pylint==2.2.2\n",
      "pymssql==2.1.4\n",
      "PyMySQL==0.9.3\n",
      "pyodbc==4.0.25\n",
      "pyOpenSSL==18.0.0\n",
      "pyparsing==2.3.0\n",
      "Pyphen==0.9.5\n",
      "pyproj==2.4.2.post1\n",
      "pyriemann==0.2.5\n",
      "PySocks==1.6.8\n",
      "pytest==4.0.2\n",
      "pytest-arraydiff==0.3\n",
      "pytest-astropy==0.5.0\n",
      "pytest-doctestplus==0.2.0\n",
      "pytest-openfiles==0.3.1\n",
      "pytest-remotedata==0.3.1\n",
      "python-dateutil==2.7.5\n",
      "pytz==2018.7\n",
      "PyWavelets==1.0.1\n",
      "pywin32==223\n",
      "pywin32-ctypes==0.2.0\n",
      "pywinpty==0.5.5\n",
      "PyYAML==3.13\n",
      "pyzmq==17.1.2\n",
      "QtAwesome==0.5.3\n",
      "qtconsole==4.4.3\n",
      "QtPy==1.5.2\n",
      "Quandl==3.4.8\n",
      "repoze.lru==0.7\n",
      "requests==2.21.0\n",
      "requests-oauthlib==1.3.0\n",
      "retrying==1.3.3\n",
      "rope==0.11.0\n",
      "rsa==4.0\n",
      "ruamel-yaml==0.15.46\n",
      "s3transfer==0.2.1\n",
      "scikit-image==0.14.1\n",
      "scikit-learn==0.22.1\n",
      "scipy==1.4.1\n",
      "seaborn==0.9.0\n",
      "Send2Trash==1.5.0\n",
      "simplegeneric==0.8.1\n",
      "singledispatch==3.4.0.3\n",
      "six==1.12.0\n",
      "smart-open==1.8.4\n",
      "snowballstemmer==1.2.1\n",
      "sortedcollections==1.0.1\n",
      "sortedcontainers==2.1.0\n",
      "spacy==2.1.4\n",
      "Sphinx==1.8.2\n",
      "sphinxcontrib-websupport==1.1.0\n",
      "spyder==3.3.2\n",
      "spyder-kernels==0.3.0\n",
      "SQLAlchemy==1.2.15\n",
      "srsly==0.0.5\n",
      "statsmodels==0.9.0\n",
      "style==1.1.0\n",
      "sympy==1.3\n",
      "tables==3.4.4\n",
      "tblib==1.3.2\n",
      "tensorboard==1.13.1\n",
      "tensorflow==1.13.1\n",
      "tensorflow-estimator==1.13.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.8.1\n",
      "testpath==0.4.2\n",
      "textblob==0.15.3\n",
      "textstat==0.5.6\n",
      "thinc==7.0.4\n",
      "toolz==0.9.0\n",
      "tornado==5.1.1\n",
      "tqdm==4.28.1\n",
      "traitlets==4.3.2\n",
      "unicodecsv==0.14.1\n",
      "update==0.0.1\n",
      "urllib3==1.24.1\n",
      "wasabi==0.2.2\n",
      "wcwidth==0.1.7\n",
      "webencodings==0.5.1\n",
      "Werkzeug==0.14.1\n",
      "widgetsnbextension==3.4.2\n",
      "win-inet-pton==1.0.1\n",
      "win-unicode-console==0.5\n",
      "wincertstore==0.2\n",
      "wrapt==1.11.2\n",
      "xlrd==1.2.0\n",
      "XlsxWriter==1.1.2\n",
      "xlwings==0.15.1\n",
      "xlwt==1.3.0\n",
      "zict==0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KNEh8pXvAXdo",
    "outputId": "9a5bda9a-afda-4f26-b082-6495cbd31be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7RNlm6OAXeG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM with raw EEG data - 2020-01-25.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
