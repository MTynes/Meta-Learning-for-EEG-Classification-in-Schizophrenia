{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using homepath \\Users\\marit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "raw_data_dir = ''\n",
    "\n",
    "if  'COLAB_GPU' in os.environ:\n",
    "    print('Using Google Colab. Setting up environment')\n",
    "    raw_data_dir = '/content/drive/My Drive/Colab Notebooks/' \n",
    "    !pip install mne\n",
    "    !pip install pyedflib\n",
    "\n",
    "    print('\\n \\n To load files from Google Drive, account validation is required.')\n",
    "    #mount to drive -- files should be located in the Colab notebooks directory\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "else:\n",
    "    if 'HOMEPATH' in os.environ:\n",
    "        print('Using homepath ' + os.environ['HOMEPATH'])\n",
    "    #declare local data directory here:\n",
    "    raw_data_dir = '../Data/Raw/' \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marit\\Anaconda3\\lib\\site-packages\\numba\\decorators.py:146: RuntimeWarning: Caching is not available when the 'parallel' target is in use. Caching is now being disabled to allow execution to continue.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random \n",
    "import math\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pyedflib\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmf\n",
    "ignore_list = ['s12', 's14']  #list of patient files that should be skipped\n",
    "#seconds of data to include in one slice\n",
    "time_window = 250 * 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum duration:  740\n"
     ]
    }
   ],
   "source": [
    "# tmf\n",
    "\n",
    "#returns file duration in seconds\n",
    "def get_edf_file_duration(file_name):\n",
    "    f = pyedflib.EdfReader(file_name)\n",
    "    duration = f.file_duration\n",
    "    f.close()\n",
    "    return  duration\n",
    "\n",
    "# get the minimum length of the files\n",
    "def get_minimum_duration(group_directory_name, patient_group_file_prefix):\n",
    "    file_durations = []\n",
    "    for i in range (1, 15): # reading 14 files\n",
    "        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n",
    "        file_name = raw_data_dir +'{}/{}.edf'.format(group_directory_name, patient_id)\n",
    "        file_durations.append(get_edf_file_duration(file_name))\n",
    "\n",
    "    return(min(file_durations))\n",
    "\n",
    "\n",
    "minimum_duration = min(get_minimum_duration(\"Healthy Controls\", \"h\"), get_minimum_duration('SZ Patients', 's'))\n",
    "print('Minimum duration: ', minimum_duration)\n",
    "all_channels = ['Fp2', 'F8', 'T4', 'T6', 'O2', 'Fp1', 'F7', 'T3', 'T5', 'O1', 'F4',\n",
    "                'C4', 'P4', 'F3', 'C3', 'P3', 'Fz', 'Cz', 'Pz']\n",
    "excluded_channels = ['O1', 'O2', 'T3', 'Fp1', 'Fp2', 'T6', 'F3', 'F4', 'F7', 'F8', 'Fz']\n",
    "\n",
    "\n",
    "def get_raw_eeg_mne(file_name, tmin=None, tmax=None, exclude=[]):\n",
    "    raw = mne.io.read_raw_edf(file_name, preload=True, exclude=exclude).load_data()\n",
    "    raw.set_montage(\"standard_1020\") #set montage to 10-20\n",
    "    #print('tmin: ', tmin)\n",
    "    #print('tmax: ', tmax)\n",
    "    tmin = tmin if tmin else 1\n",
    "    tmax = tmax if tmax else (get_edf_file_duration(file_name)-1) #get_edf_file_duration rounds values up\n",
    "    raw.crop(tmin=tmin, tmax=tmax)\n",
    "    raw.resample(250, npad=\"auto\") #set sampling frequency to 250Hz\n",
    "    \n",
    "    return raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Input Data From Random Patient\n",
      "Sz patient #07\n",
      "\n",
      "Cleaned Data\n",
      "Excluding channels ; \n",
      "Removing first 120s of data; and last 120s of shortest sample. Limiting all other samples to range of shortest sample\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5da5c8a68337>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Example of Input Data From Random Patient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sz patient #{:02d}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrand_patient_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0mplot_examples_plotly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrand_patient_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Example of Input Data From Random Control\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-5da5c8a68337>\u001b[0m in \u001b[0;36mplot_examples_plotly\u001b[1;34m(file_name, excluded_channels)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mcleaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_raw_eeg_mne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_duration\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexcluded_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mcleaned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mplot_eeg_plotly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcluded_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;31m# plot a random patient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-5da5c8a68337>\u001b[0m in \u001b[0;36mplot_eeg_plotly\u001b[1;34m(raw, excluded_channels)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_xaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"outside\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtickwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtickcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticklen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'top'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0miplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'shared xaxis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\offline\\offline.py\u001b[0m in \u001b[0;36miplot\u001b[1;34m(figure_or_data, show_link, link_text, validate, image, filename, image_width, image_height, config, auto_play, animation_opts)\u001b[0m\n\u001b[0;32m    373\u001b[0m              \u001b[0mauto_play\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauto_play\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m              \u001b[0mpost_script\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpost_script\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m              animation_opts=animation_opts)\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\io\\_renderers.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[1;31m# Mimetype renderers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     bundle = renderers._build_mime_bundle(\n\u001b[1;32m--> 348\u001b[1;33m         fig_dict, renderers_string=renderer, **kwargs)\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbundle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mipython_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\io\\_renderers.py\u001b[0m in \u001b[0;36m_build_mime_bundle\u001b[1;34m(self, fig_dict, renderers_string, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m                         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 \u001b[0mbundle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_mimebundle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbundle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\io\\_base_renderers.py\u001b[0m in \u001b[0;36mto_mimebundle\u001b[1;34m(self, fig_dict)\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mdefault_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'100%'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0mdefault_height\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m525\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         )\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\io\\_html.py\u001b[0m in \u001b[0;36mto_html\u001b[1;34m(fig, config, auto_play, include_plotlyjs, include_mathjax, post_script, full_html, animation_opts, default_width, default_height, validate)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mfig_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPlotlyJSONEncoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         sort_keys=True)\n\u001b[0m\u001b[0;32m    139\u001b[0m     jlayout = json.dumps(\n\u001b[0;32m    140\u001b[0m         \u001b[0mfig_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'layout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         **kw).encode(obj)\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\_plotly_utils\\utils.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# this will raise errors in a normal-expected way\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mencoded_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPlotlyJSONEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# now:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\_plotly_utils\\utils.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;31m# TODO: The ordering if these methods is *very* important. Is this OK?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         encoding_methods = (\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_as_plotly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_as_sage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_as_numpy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# tmf\n",
    "mne.set_log_level(\"WARNING\")\n",
    "\n",
    "def plot_examples(file_name, excluded_channels):\n",
    "    patient_id = file_name.split(\"\\\\\")[-1][:-4]\n",
    "    print('Raw Data')\n",
    "    raw = get_raw_eeg_mne(file_name)\n",
    "    #events = mne.find_events(raw, stim_channel=raw.ch_names, initial_event=True, consecutive=True)\n",
    "    raw.plot()\n",
    "    df = raw.to_data_frame()\n",
    "    print('Shape: ', df.shape)\n",
    "\n",
    "    print('Cleaned Data ')\n",
    "    print('Excluding channels {}; '.format(\", \".join(excluded_channels)))\n",
    "    print('Removing first 120s of data; and last 120s of shortest sample. Limiting all other samples to range of shortest sample')\n",
    "    cleaned = get_raw_eeg_mne(file_name, tmin=120, tmax=minimum_duration-120, exclude=excluded_channels)\n",
    "    cleaned.crop()\n",
    "    cleaned.plot()\n",
    "    print('Shape: ', cleaned.to_data_frame().shape)\n",
    "\n",
    "from plotly.graph_objs import Layout, Scatter, Figure, Marker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly    \n",
    "import chart_studio.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "import cufflinks as cf\n",
    "#import plotly.graph_objs.layout.scene.Annotation\n",
    "cf.go_offline()\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "#cl_layout = go.Layout(width=950, height=800)\n",
    "\n",
    "\n",
    "def plot_eeg_plotly(raw, excluded_channels):\n",
    "    n_channels = len(all_channels) - len(excluded_channels)\n",
    "    picks = range(n_channels)\n",
    "    start, stop = raw.time_as_index([0, -1])\n",
    "\n",
    "    data, times = raw[picks[:n_channels], start:stop]\n",
    "    ch_names = [raw.info['ch_names'][p] for p in picks[:n_channels]]\n",
    "    \n",
    "    step = 1. / n_channels\n",
    "    kwargs = dict(domain=[1 - step, 1], showticklabels=False, zeroline=False, showgrid=False)\n",
    "    mc = 'rgb(27,61,120)'\n",
    "    # create objects for layout and traces\n",
    "    layout = Layout(yaxis=go.layout.YAxis(kwargs), showlegend=False)\n",
    "    layout.update({'yaxis%d' % (0 + 1): go.layout.YAxis(kwargs), 'showlegend': False})\n",
    "    traces = [Scatter(x=times, y=data.T[:, 0], marker_color=mc)]\n",
    "    \n",
    "\n",
    "    # loop over the channels\n",
    "    for ii in range(1, n_channels):\n",
    "            kwargs.update(domain=[1 - (ii + 1) * step, 1 - ii * step])\n",
    "            layout.update({'yaxis%d' % (ii + 1): go.layout.YAxis(kwargs), 'showlegend': False})\n",
    "            traces.append(Scatter(x=times, y=data.T[:, ii], marker_color = mc, yaxis='y%d' % (ii + 1)))\n",
    "\n",
    "    # add channel names using Annotations\n",
    "    annotations = [go.layout.Annotation(x=-0.06, y=0, xref='paper', yref='y%d' % (ii + 1),\n",
    "                                          text=ch_name, showarrow=False)\n",
    "                              for ii, ch_name in enumerate(ch_names)]\n",
    "    layout.update(annotations=annotations)\n",
    "    traces.reverse() #set the fist trace to the bottom of the plot sine it is the only one with xaxis\n",
    "\n",
    "    # set the size of the figure and plot it\n",
    "    layout.update(autosize=False, width=900, height=400)\n",
    "    fig = Figure(data=traces, layout=layout)\n",
    "    fig.update_xaxes(ticks=\"outside\", tickwidth=2, tickcolor='black', ticklen=10, side='top')\n",
    "\n",
    "    iplot(fig, filename='shared xaxis')\n",
    "    \n",
    "    \n",
    "#adapted from https://plot.ly/python/v3/ipython-notebooks/mne-tutorial/\n",
    "def plot_examples_plotly(file_name, excluded_channels):\n",
    "    patient_id = file_name.split(\"\\\\\")[-1][:-4]\n",
    "    ### print('\\nRaw Data')\n",
    "    ### raw = get_raw_eeg_mne(file_name)\n",
    "    ### plot_eeg_plotly(raw, [])\n",
    "    \n",
    "    print('\\nCleaned Data')\n",
    "    print('Excluding channels {}; '.format(\", \".join(excluded_channels)))\n",
    "    print('Removing first 120s of data; and last 120s of shortest sample. Limiting all other samples to range of shortest sample')\n",
    "\n",
    "    cleaned = get_raw_eeg_mne(file_name, tmin=120, tmax=minimum_duration-120, exclude=excluded_channels)\n",
    "    cleaned.crop()\n",
    "    plot_eeg_plotly(cleaned, excluded_channels)\n",
    "\n",
    "# plot a random patient\n",
    "sz_patient_list = list(range(1, 15, 1))\n",
    "sz_patient_list.remove(12) #drop value from list of exclusions\n",
    "sz_patient_list.remove(14) #drop value from list of exclusions\n",
    "rand_patient_id =  random.choice(sz_patient_list)\n",
    "rand_patient_file =  raw_data_dir + 'SZ Patients/{}.edf'.format(\"{}{:02d}\").format('s', rand_patient_id)\n",
    "\n",
    "rand_control_id = random.randrange(1, 15, 1)\n",
    "rand_control_file = raw_data_dir + 'Healthy Controls/{}{:02d}.edf'.format('h', rand_control_id)\n",
    "\n",
    "print('Example of Input Data From Random Patient')\n",
    "print('Sz patient #{:02d}'.format(rand_patient_id))\n",
    "plot_examples_plotly(rand_patient_file, [])\n",
    "\n",
    "print(\"Example of Input Data From Random Control\")\n",
    "print('Control subject #{:02d}'.format(rand_control_id))\n",
    "plot_examples_plotly(rand_control_file, [])\n",
    "\n",
    "print('Ignored files: ')\n",
    "print(\",\".join(ignore_list))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmf\n",
    "\n",
    "\n",
    "# modified based on https://stackoverflow.com/a/48704557/2466781\n",
    "def chunk(seq, size):\n",
    "    sl = len(seq) - (len(seq)%size) #exclude values that will be out of range\n",
    "    r = [np.asarray(seq[pos:pos + size]) for pos in range(0, sl, size)]\n",
    "    \"\"\"print('r begin')\n",
    "    print(r)\n",
    "    print('r end')\"\"\"\n",
    "    return r\n",
    "\n",
    "def chunk_list(nested_list, size):\n",
    "    v = []\n",
    "    for d in nested_list:\n",
    "        df = pd.DataFrame(np.asarray(d))\n",
    "        c = chunk(df, size)\n",
    "        for e in c:\n",
    "            v.append(e)\n",
    "    return v\n",
    "\n",
    "# modified version of process_patient_group in older notebooks\n",
    "# Uses the raw EDF files and converts to dataframe, dropping the first 150 and last 30 seconds of the shortest  file\n",
    "# All other files are trimmed similarly to produce the same size\n",
    "# Adapted from page 1 of https://buildmedia.readthedocs.org/media/pdf/pyedflib/latest/pyedflib.pdf\n",
    "def process_patient_group(group_directory_name, patient_group_file_prefix, \n",
    "                          minimum_original_duration,\n",
    "                          plot_channels = False,\n",
    "                          excluded_channels = []):\n",
    "    meta_df = pd.DataFrame()\n",
    "    meta = []\n",
    "    patient_id_list = []\n",
    "\n",
    "    for i in range (1, 15): # reading 14 files\n",
    "        patient_id = \"{}{:02d}\".format(patient_group_file_prefix, i)\n",
    "        patient_id_list.append(patient_id)\n",
    "        \n",
    "        file_name = raw_data_dir + '{}/{}.edf'.format(group_directory_name, patient_id)\n",
    "        data = get_raw_eeg_mne(file_name, exclude=excluded_channels, tmin=120, tmax=minimum_duration-120)\n",
    "        df = data.to_data_frame()\n",
    "        ## based on visual inspection, drop the first 120 seconds\n",
    "        if patient_id not in ignore_list:\n",
    "            meta.append(np.asarray(df))            \n",
    "            \n",
    "\n",
    "    return np.asarray(meta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 125001, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12, 125001, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tmf - setup function\n",
    "\n",
    "# create the /tmp directory if it doesn't already exist\n",
    "import os\n",
    "if not os.path.exists('tmp'):\n",
    "    os.makedirs('tmp')\n",
    "\n",
    "\n",
    "    \n",
    "hc_data_all = process_patient_group('Healthy Controls', 'h', minimum_duration, excluded_channels=[])\n",
    "display(np.asarray(hc_data_all).shape)\n",
    "\n",
    "sz_data_all = process_patient_group('SZ Patients', 's', minimum_duration, excluded_channels=[])\n",
    "display(np.asarray(sz_data_all).shape)\n",
    "#print(sz_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3c5884c317dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#plt.grid()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhc_data_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msz_data_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "# get ideal number of components\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#plt.grid()\n",
    "\n",
    "X =  np.concatenate((hc_data_all, sz_data_all), axis=0)\n",
    "data = X.reshape(X.shape[0] * X.shape[1], X.shape[2])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "#data_rescaled = scaler.fit_transform(data[1:, 0:8])\n",
    "data_rescaled = scaler.fit_transform(data)\n",
    "\n",
    "#Fitting the PCA algorithm with our Data\n",
    "pca = PCA().fit(data_rescaled)\n",
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('RepOD EEG in Sz Dataset Explained Variance')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance: \n",
      "[5.29569690e+04 1.09464990e+04 1.04057472e+04 6.72521991e+03\n",
      " 3.99676697e+03 2.22050034e+03 1.42506224e+03 1.28504007e+03\n",
      " 1.10029635e+03 8.26151145e+02 5.16024148e+02 4.24550647e+02\n",
      " 3.50432209e+02 2.78608594e+02 2.32296231e+02 2.22213583e+02\n",
      " 1.87225583e+02 1.41160324e+02 9.16303963e-26]\n",
      "[9.76332649e+02 4.43888480e+02 4.32785685e+02 3.47928094e+02\n",
      " 2.68219696e+02 1.99922500e+02 1.60159671e+02 1.52087874e+02\n",
      " 1.40731426e+02 1.21945564e+02 9.63765255e+01 8.74180281e+01\n",
      " 7.94215321e+01 7.08163447e+01 6.46632210e+01 6.32443238e+01\n",
      " 5.80522222e+01 5.04072001e+01 1.28426910e-12]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-a1579feac3d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m#send all channels and all patient data; s07 is still skipped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mrate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhc_data_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[0mhc_data_all_denoised_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_denoised_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhc_data_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0msz_data_all_denoised_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_denoised_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msz_data_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-96-a1579feac3d9>\u001b[0m in \u001b[0;36mrate_features\u001b[1;34m(patient_data)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m#https://stackoverflow.com/questions/22984335/recovering-features-names-of-explained-variance-ratio-in-pca-with-sklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#i = np.identity(df.shape[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mcoeffs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\twodim_base.py\u001b[0m in \u001b[0;36meye\u001b[1;34m(N, M, k, dtype, order)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "feature_ratings = {}\n",
    "\n",
    "\n",
    "from sklearn import decomposition\n",
    "def rate_features(patient_data):\n",
    "    all_features = []\n",
    "  \n",
    "    \n",
    "    for entry in patient_data[:1]:\n",
    "        sample_features = []\n",
    "        pca = decomposition.PCA(n_components=19)\n",
    "        df = entry.transpose()\n",
    "        # normalize data\n",
    "        #from sklearn import preprocessing\n",
    "        #df_scaled = pd.DataFrame(preprocessing.scale(df)) \n",
    "        df_norm = (df - df.mean()) / df.std()\n",
    "\n",
    "        pca_output = pca.fit_transform(df_norm)\n",
    "        print('explained variance: ')\n",
    "        print(pca.explained_variance_)\n",
    "        print(pca.singular_values_)\n",
    "        #print(pca_outuput.explained_variance)\n",
    "    \n",
    "        #print(pca.components_)\n",
    "        #print(pca_denoise.components_)\n",
    "        denoised_data = pca.components_\n",
    "        \n",
    "        #get coefficients used to calculate components\n",
    "        #https://stackoverflow.com/questions/22984335/recovering-features-names-of-explained-variance-ratio-in-pca-with-sklearn\n",
    "        #i = np.identity(df.shape[1])\n",
    "        i = np.eye(df.shape[1])\n",
    "        print(df.shape[1])\n",
    "        coeffs = pca.transform(i)\n",
    "        \n",
    "        print(np.allclose(df_norm.values.dot(coef), pca.fit_transform(df_norm.values)))\n",
    "        \n",
    "        \n",
    "        #print(pd.DataFrame(pca.components_))\n",
    "\n",
    "        \n",
    "        ######all_features.append(np.asarray(denoised_data)) \n",
    "        #print(denoised_data)\n",
    "        \n",
    "        #denoised_data = pca.transform(entry.transpose())\n",
    "        denoised_patient_data = [x for _,x in sorted(zip(pca_output.explained_variance_,denoised_data))]\n",
    "        \n",
    "        # use explained variance to sort features by salience\n",
    "        print(denoised_patient_data)\n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    return all_features\n",
    "    \n",
    "\n",
    "sample_size = minimum_duration #use entire window\n",
    "#send all channels and all patient data; s07 is still skipped\n",
    "\n",
    "rate_features(hc_data_all)\n",
    "hc_data_all_denoised_selected = select_denoised_data(hc_data_all)\n",
    "sz_data_all_denoised_selected = select_denoised_data(sz_data_all)\n",
    "\n",
    "print('Shape of denoised data (extracted components) :')\n",
    "print(np.asarray(hc_data_all_denoised_selected).shape)\n",
    "print(np.asarray(sz_data_all_denoised_selected).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3250026\n",
      "(3250026, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=19, n_jobs=None,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/feature-selection-machine-learning-python/\n",
    "X =  np.concatenate((hc_data_all, sz_data_all), axis=0)\n",
    "y = ([0] * len(hc_data_all.reshape(-1, hc_data_all.shape[-1]))) + ( [1] * len(sz_data_all.reshape(-1, sz_data_all.shape[-1])))\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# feature selection\n",
    "feature_selection_model = ExtraTreesClassifier(n_estimators=19)\n",
    "print(len(y))\n",
    "print(np.asarray(X.reshape(-1, X.shape[-1])).shape)\n",
    "flattened_X = X.reshape(-1, X.shape[-1])\n",
    "feature_selection_model.fit(flattened_X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking of Channels, according to Feature Importance Model (Tree Classifier)\n",
      "['Cz', 'P3', 'P4', 'Pz', 'T4', 'O2', 'T3', 'C4', 'C3', 'T6', 'T5', 'F3', 'F4', 'O1', 'Fz', 'F7', 'Fp2', 'F8', 'Fp1']\n",
      "\n",
      "\n",
      "Scores: \n",
      "[0.08060796353071435, 0.0658660290172496, 0.06373515775957168, 0.06188804002592751, 0.055908688057012816, 0.054996887616922265, 0.05264403404881429, 0.052529385820546885, 0.051163713488321244, 0.05045640505967478, 0.049220405286900984, 0.04915219964460713, 0.048336622980680144, 0.046249768898948204, 0.04412461680367867, 0.04407183106096143, 0.04323023450713641, 0.04291598476083345, 0.04290203163149817]\n"
     ]
    }
   ],
   "source": [
    "#print(feature_selection_model.feature_importances_)\n",
    "\n",
    "#sort the features in order of the importance score generated by the model\n",
    "ranking = [x for _,x in sorted(zip(feature_selection_model.feature_importances_, all_channels), reverse=True)]\n",
    " \n",
    "#print(sorted(feature_selection_model.feature_importances_, reverse=True))\n",
    "print('Ranking of Channels, according to Feature Importance Model (Tree Classifier)')\n",
    "print(ranking)\n",
    "\n",
    "print('\\n\\nScores: ')\n",
    "print(sorted(feature_selection_model.feature_importances_, reverse=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the feature vectors so that input can be used in scikit learn \n",
    "def flatten_features(data):\n",
    "    flattened_data = []\n",
    "    for entry in data: \n",
    "        # shift axes so that data shape is time * channels * features. Then flatten data\n",
    "        flattened_data.append(np.moveaxis(entry, 0, -1).flatten())\n",
    "    return np.asarray(flattened_data, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  (17, 12, 740)\n",
      "Flattened input size:  (17, 8880)\n"
     ]
    }
   ],
   "source": [
    "# load extracted features\n",
    "\n",
    "X =  np.concatenate((hc_data_all_denoised_selected, sz_data_all_denoised_selected), axis=0)\n",
    "X_original = X.copy()\n",
    "print('Input size: ', X.shape)\n",
    "y = ([0] * len(hc_data_all_denoised_selected)) +( [1] * len(sz_data_all_denoised_selected))\n",
    "sample_size = 2\n",
    "\n",
    "X = flatten_features(X)\n",
    "print('Flattened input size: ', X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of randomly selected sets of numbers based on a range\n",
    "# the proportion of values selected for each set is determined by the ratio_array\n",
    "def get_mixed_indexes_for_ml_train_test(length, ratios_array):\n",
    "    input_indexes = range(0, length)\n",
    "    output_indexes = []\n",
    "    for ratio in ratios_array:\n",
    "        selection = random.choices(input_indexes, k=math.floor(ratio * length))\n",
    "        input_indexes = [i for i in input_indexes if i not in selection]\n",
    "        output_indexes.append(selection)\n",
    "    return output_indexes\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 11 samples; testing on 5 samples\n"
     ]
    }
   ],
   "source": [
    "train_idxs, test_idxs = get_mixed_indexes_for_ml_train_test(len(X), [.70, 0.30])\n",
    "\n",
    "X_train      = X[train_idxs][0:,]\n",
    "Y_train      = np.asarray(y)[train_idxs]\n",
    "X_test       = X[test_idxs][0:,]\n",
    "Y_test       = np.asarray(y)[test_idxs]\n",
    "\n",
    "print('Training on {} samples; testing on {} samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy for Y_test:  60.000%\n"
     ]
    }
   ],
   "source": [
    "# from https://machinelearningmastery.com/indoor-movement-time-series-classification-with-machine-learning-algorithms/\n",
    "\n",
    "scaler = StandardScaler()\n",
    "##kernel = ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’,  | gamma = 'scale', 'auto'\n",
    "svm = SVC(gamma='scale', kernel='rbf', degree=3, decision_function_shape = 'ovr')#default values \n",
    "\n",
    "model = Pipeline(steps=[('s',scaler), ('m', svm)]) \n",
    "model.fit(X_train, Y_train)\n",
    "# predict\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate\n",
    "score = accuracy_score(Y_test, yhat) * 100\n",
    "# summarize\n",
    "print('%s %.3f%%' % ('SVM accuracy for Y_test: ', score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing environment settings\n",
      "\n",
      "Python version:  3.7.1\n",
      "\n",
      "Installed modules:\n",
      "\n",
      "absl-py==0.7.1\n",
      "alabaster==0.7.12\n",
      "altgraph==0.16.1\n",
      "anaconda-client==1.7.2\n",
      "anaconda-navigator==1.9.6\n",
      "anaconda-project==0.8.2\n",
      "asn1crypto==0.24.0\n",
      "astor==0.8.0\n",
      "astroid==2.1.0\n",
      "astropy==3.1\n",
      "atomicwrites==1.2.1\n",
      "attrs==18.2.0\n",
      "Babel==2.6.0\n",
      "backcall==0.1.0\n",
      "backports.os==0.1.1\n",
      "backports.shutil-get-terminal-size==1.0.0\n",
      "beautifulsoup4==4.6.0\n",
      "bitarray==0.8.3\n",
      "bkcharts==0.2\n",
      "blaze==0.11.3\n",
      "bleach==3.0.2\n",
      "blis==0.2.4\n",
      "bokeh==1.0.2\n",
      "boto==2.49.0\n",
      "boto3==1.9.169\n",
      "botocore==1.12.169\n",
      "Bottleneck==1.2.1\n",
      "cachetools==3.1.1\n",
      "certifi==2018.11.29\n",
      "cffi==1.11.5\n",
      "chardet==3.0.4\n",
      "Click==7.0\n",
      "cloudpickle==0.6.1\n",
      "clyent==1.2.2\n",
      "colorama==0.4.1\n",
      "colorlover==0.3.0\n",
      "comtypes==1.1.7\n",
      "conda==4.5.12\n",
      "conda-build==3.17.6\n",
      "conda-verify==3.1.1\n",
      "contextlib2==0.5.5\n",
      "cryptography==2.4.2\n",
      "cufflinks==0.15\n",
      "cycler==0.10.0\n",
      "cymem==2.0.2\n",
      "Cython==0.29.2\n",
      "cytoolz==0.9.0.1\n",
      "dask==1.0.0\n",
      "datashape==0.5.4\n",
      "decorator==4.3.0\n",
      "defusedxml==0.5.0\n",
      "distributed==1.25.1\n",
      "docutils==0.14\n",
      "entrypoints==0.2.3\n",
      "et-xmlfile==1.0.1\n",
      "fastcache==1.0.2\n",
      "filelock==3.0.10\n",
      "Flask==1.0.2\n",
      "Flask-Cors==3.0.7\n",
      "future==0.17.1\n",
      "gast==0.2.2\n",
      "genderdecoder==0.3\n",
      "gensim==3.7.3\n",
      "gevent==1.3.7\n",
      "glob2==0.6\n",
      "google-auth==1.8.2\n",
      "google-auth-oauthlib==0.4.1\n",
      "google-pasta==0.1.8\n",
      "graphviz==0.13.2\n",
      "greenlet==0.4.15\n",
      "grpcio==1.21.1\n",
      "h5py==2.8.0\n",
      "heapdict==1.0.0\n",
      "html2text==2018.1.9\n",
      "html5lib==1.0.1\n",
      "idna==2.8\n",
      "imageio==2.4.1\n",
      "imagesize==1.1.0\n",
      "importlib-metadata==0.6\n",
      "inflection==0.3.1\n",
      "ipykernel==5.1.0\n",
      "ipython==7.2.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.4.2\n",
      "isort==4.3.4\n",
      "itsdangerous==1.1.0\n",
      "jdcal==1.4\n",
      "jedi==0.13.2\n",
      "Jinja2==2.10\n",
      "jmespath==0.9.4\n",
      "joblib==0.14.1\n",
      "jsonschema==2.6.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==5.2.4\n",
      "jupyter-console==6.0.0\n",
      "jupyter-core==4.4.0\n",
      "jupyterlab==0.35.3\n",
      "jupyterlab-server==0.2.0\n",
      "Keras==2.2.4\n",
      "Keras-Applications==1.0.8\n",
      "Keras-Preprocessing==1.0.9\n",
      "keyring==17.0.0\n",
      "kiwisolver==1.0.1\n",
      "lazy-object-proxy==1.3.1\n",
      "libarchive-c==2.8\n",
      "llvmlite==0.26.0\n",
      "locket==0.2.0\n",
      "lxml==4.2.5\n",
      "Markdown==3.0.1\n",
      "MarkupSafe==1.1.0\n",
      "matplotlib==3.0.2\n",
      "mccabe==0.6.1\n",
      "menuinst==1.4.14\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.0.6\n",
      "mkl-random==1.0.2\n",
      "mlxtend==0.17.0\n",
      "mne==0.19.2\n",
      "mock==3.0.5\n",
      "more-itertools==4.3.0\n",
      "mpmath==1.1.0\n",
      "msgpack==0.5.6\n",
      "multipledispatch==0.6.0\n",
      "murmurhash==1.0.2\n",
      "navigator-updater==0.2.1\n",
      "nbconvert==5.4.0\n",
      "nbformat==4.4.0\n",
      "ndg-httpsclient==0.5.1\n",
      "networkx==2.2\n",
      "nltk==3.4.1\n",
      "nose==1.3.7\n",
      "notebook==5.7.4\n",
      "numba==0.41.0\n",
      "numexpr==2.6.8\n",
      "numpy==1.16.5\n",
      "numpydoc==0.8.0\n",
      "oauthlib==3.1.0\n",
      "odo==0.5.1\n",
      "olefile==0.46\n",
      "openpyxl==2.5.12\n",
      "opt-einsum==3.1.0\n",
      "packaging==18.0\n",
      "pandas==0.25.3\n",
      "pandocfilters==1.4.2\n",
      "parso==0.3.1\n",
      "partd==0.3.9\n",
      "path.py==11.5.0\n",
      "pathlib2==2.3.3\n",
      "patsy==0.5.1\n",
      "pefile==2019.4.18\n",
      "pep8==1.7.1\n",
      "pickleshare==0.7.5\n",
      "Pillow==5.3.0\n",
      "pkginfo==1.4.2\n",
      "plac==0.9.6\n",
      "plotly==3.10.0\n",
      "pluggy==0.8.0\n",
      "ply==3.11\n",
      "preshed==2.0.1\n",
      "prometheus-client==0.5.0\n",
      "prompt-toolkit==2.0.7\n",
      "protobuf==3.7.1\n",
      "psutil==5.4.8\n",
      "pupygrib==0.5.0\n",
      "py==1.7.0\n",
      "pyargus==1.0.post3\n",
      "pyasn1==0.4.7\n",
      "pyasn1-modules==0.2.7\n",
      "pycodestyle==2.4.0\n",
      "pycosat==0.6.3\n",
      "pycparser==2.19\n",
      "pycrypto==2.6.1\n",
      "pycurl==7.43.0.2\n",
      "pydot==1.4.1\n",
      "pyEDFlib==0.1.15\n",
      "pyflakes==2.0.0\n",
      "Pygments==2.3.1\n",
      "PyInstaller==4.0.dev0+1eadfa55f2\n",
      "pylint==2.2.2\n",
      "pymssql==2.1.4\n",
      "PyMySQL==0.9.3\n",
      "pyodbc==4.0.25\n",
      "pyOpenSSL==18.0.0\n",
      "pyparsing==2.3.0\n",
      "Pyphen==0.9.5\n",
      "pyproj==2.4.2.post1\n",
      "pyriemann==0.2.5\n",
      "PySocks==1.6.8\n",
      "pytest==4.0.2\n",
      "pytest-arraydiff==0.3\n",
      "pytest-astropy==0.5.0\n",
      "pytest-doctestplus==0.2.0\n",
      "pytest-openfiles==0.3.1\n",
      "pytest-remotedata==0.3.1\n",
      "python-dateutil==2.7.5\n",
      "pytz==2018.7\n",
      "PyWavelets==1.0.1\n",
      "pywin32==223\n",
      "pywin32-ctypes==0.2.0\n",
      "pywinpty==0.5.5\n",
      "PyYAML==3.13\n",
      "pyzmq==17.1.2\n",
      "QtAwesome==0.5.3\n",
      "qtconsole==4.4.3\n",
      "QtPy==1.5.2\n",
      "Quandl==3.4.8\n",
      "repoze.lru==0.7\n",
      "requests==2.21.0\n",
      "requests-oauthlib==1.3.0\n",
      "retrying==1.3.3\n",
      "rope==0.11.0\n",
      "rsa==4.0\n",
      "ruamel-yaml==0.15.46\n",
      "s3transfer==0.2.1\n",
      "scikit-image==0.14.1\n",
      "scikit-learn==0.22.1\n",
      "scipy==1.4.1\n",
      "seaborn==0.9.0\n",
      "Send2Trash==1.5.0\n",
      "simplegeneric==0.8.1\n",
      "singledispatch==3.4.0.3\n",
      "six==1.12.0\n",
      "smart-open==1.8.4\n",
      "snowballstemmer==1.2.1\n",
      "sortedcollections==1.0.1\n",
      "sortedcontainers==2.1.0\n",
      "spacy==2.1.4\n",
      "Sphinx==1.8.2\n",
      "sphinxcontrib-websupport==1.1.0\n",
      "spyder==3.3.2\n",
      "spyder-kernels==0.3.0\n",
      "SQLAlchemy==1.2.15\n",
      "srsly==0.0.5\n",
      "statsmodels==0.9.0\n",
      "style==1.1.0\n",
      "sympy==1.3\n",
      "tables==3.4.4\n",
      "tblib==1.3.2\n",
      "tensorboard==1.13.1\n",
      "tensorflow==1.13.1\n",
      "tensorflow-estimator==1.13.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.8.1\n",
      "testpath==0.4.2\n",
      "textblob==0.15.3\n",
      "textstat==0.5.6\n",
      "thinc==7.0.4\n",
      "toolz==0.9.0\n",
      "tornado==5.1.1\n",
      "tqdm==4.28.1\n",
      "traitlets==4.3.2\n",
      "unicodecsv==0.14.1\n",
      "update==0.0.1\n",
      "urllib3==1.24.1\n",
      "wasabi==0.2.2\n",
      "wcwidth==0.1.7\n",
      "webencodings==0.5.1\n",
      "Werkzeug==0.14.1\n",
      "widgetsnbextension==3.4.2\n",
      "win-inet-pton==1.0.1\n",
      "win-unicode-console==0.5\n",
      "wincertstore==0.2\n",
      "wrapt==1.11.2\n",
      "xlrd==1.2.0\n",
      "XlsxWriter==1.1.2\n",
      "xlwings==0.15.1\n",
      "xlwt==1.3.0\n",
      "zict==0.1.3\n"
     ]
    }
   ],
   "source": [
    "## End of implementation code  \n",
    "\n",
    "print('Printing environment settings')\n",
    "\n",
    "from platform import python_version\n",
    "print('\\nPython version: ', python_version())\n",
    "print('\\nInstalled modules:\\n')\n",
    "\n",
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
